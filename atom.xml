<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Longda&#39;s Interesting World</title>
  
  <subtitle>Longda&#39;s Interesting World</subtitle>
  <link href="http://ilongda.com/atom.xml" rel="self"/>
  
  <link href="http://ilongda.com/"/>
  <updated>2024-02-02T12:56:06.957Z</updated>
  <id>http://ilongda.com/</id>
  
  <author>
    <name>Longda Feng</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>HashCorp Reading Notes</title>
    <link href="http://ilongda.com/2022/hashcorp-read-notes/"/>
    <id>http://ilongda.com/2022/hashcorp-read-notes/</id>
    <published>2022-02-28T11:07:43.000Z</published>
    <updated>2024-02-02T12:56:06.957Z</updated>
    
    <content type="html"><![CDATA[<h1 id="随谈"><a href="#随谈" class="headerlink" title="随谈"></a>随谈</h1><p>万字 大文章 <span class="exturl" data-url="aHR0cHM6Ly9tcC53ZWl4aW4ucXEuY29tL3MvWTJBNy1VaTJuelVnb2RrRWJnUjZsUQ==">https://mp.weixin.qq.com/s/Y2A7-Ui2nzUgodkEbgR6lQ<i class="fa fa-external-link-alt"></i></span></p><p>有很多理念,还是比较认同的:</p><span id="more"></span><ol><li>技术挑战 放到 开源里面做,  这一点不是很认同, 我认为, 开源解决的是规模小的需求, 或者某个特定的的非常common的问题, 而当规模上来后, 是需要商业化来解决, 或者当需求变得复杂, 需要一系列的措施来解决, 是需要商业化的技术方案来解决. </li><li>个人或者小的团队, 就应该免费使用, 这个逻辑基本成立. 跨团队协作的需求, 商业化机会比较大</li><li>要把价格门槛低的核心产品做的简单易用，同时又要兼顾未来组织内部对产品的复杂需求。 – 这个很认同</li><li>即使某些功能在开源中有，但是这些功能无法从一个完整的use case level来解决企业面对的问题。  真实操作中, 会将这个放大. </li><li>讨论放到一个具体的use case,而不是某一个功能，这样对于sales也会更好沟通</li><li>开源公司要拿到一些客户订单并不难。但是这里说到市场和销售，核心是repeatable&#x2F;scalable。</li><li>利用开源形成事实标准，是企业最牢固的隐形护城河。</li><li>开源模式下，sales最大的挑战就是公司自己的开源产品。</li><li>开源模式的S&amp;M (Sales &amp; Marketing)花费应该比传统软件公司要少呀。但是Hashicorp S&amp;M&#x2F;Rev 比例超过60%，在整个public SaaS公司中，算是比较高的了. 时代在变, 有很多开源运作的成本, 处于技术和品牌交叉的, 这块如果放在marketing, 自然markteing的成本会大幅上升, 而且这个会成为趋势. </li><li>开源天生就是global的生意。– Hashicorp和Confluent的国际业务发展都很快。两家商业化都是5年左右的时间，都已经有35%的收入来自美国以外。</li><li>渠道玩得溜溜的 – Hashicorp在开始商业化以后第二年就开始大力发展partners, 三四年的时间，已经建立起来一个170+ ISVs，超过450个integration partner的网络</li><li>面对大客户，只是交给对方工具远远不够。 – 最先进的enterprise software公司，输出的不仅是工具，更是工具背后的方法论(当然，输出方法论的成本也是不低的)。  – 于这样一个大工程，你不能光是提供一系列工具，还要向他们展示the way to get there.  – 工具类产品比拼的往往不是单纯的性能，而是工具背后的代表新的生产方式的方法论。把best practice抽象成方法论，难度可不比工程上的性能提升要小。一旦让这个方法论成为事实标准，才是真正的护城河。</li><li>护城河绝不是单纯把产品做成大而全的平台，把一堆60-70分的产品盲目堆砌起来。</li><li>Hashicorp的S-1中，把这个模式进一步细化为adopt, land, expand, and extend。其实本质也是PLG里的套路：</li></ol><ul><li>用社区&#x2F;marketing促进Adopt</li><li>用简单易上手的产品+初始低价降低初始Landing的门槛</li><li>基于Usage实现自然增长Expand</li><li>最后用product portfolio在每个cohort中Extend</li></ul><ol start="15"><li>在SaaS land&amp;expand这个模式中，不可缺少的一环就是usage-based pricing。– 看看现在HCP上几个产品的pricing,你也许会发现一个问题，就是这个pricing unit的设计其实很有讲究。– 你设定的pricing unit除了要计算方便之外，必须避免Usage is discouraged when customers feel the marginal cost of consumption</li><li>etl 公司, Airbyte（<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2FpcmJ5dGVocS9haXJieXRlJUVGJUJDJTg5">https://github.com/airbytehq/airbyte）<i class="fa fa-external-link-alt"></i></span>,  – 刚刚close了B轮融资$150M, 估值已经飙升到$1.5Bn！不到20个月，已经刷刷刷地三轮融了$181M</li><li>在SaaS模式已经被广泛接受的年代，后来者迅速开发Cloud版本抢占“基层”市场，几乎是个定式，只会到来得越来越快。</li><li>Win developer’s mind and heart! hashcorp – 他们旗下的repo加起来超过220k stars </li><li>几乎没有哪个成功的开源社区，早期的时候没有在线下做大量后来看起来完全不scalable的事情。  纯粹误解: Github一上线，HN、Reddit各种线上宣传一下，回答问题和PR，然后做好技术和performance，社区啊用户啊就应该自己围过来了么？</li><li>首先，Meetup不可少，抓住各种community抱大腿。– 一开始靠身边的亲朋好友宣传，速度当然很慢。后来，两位创始人很积极到各种Seattle当地的社区meetup、Ruby社区、QCon,DevOpsDay等等，在各种活动上寻找刷脸的机会</li><li>Hashicorp就开始全方位建立自己的社区，其中最重要的就是HUG - Hashicorp User Groups. 这个分散在世界各地的自发性组织，如今已经有37k+的会员，遍及53个国家。各种自发的Meetup和活动，不断深化与开发者的关系</li><li>Hashicorp对于Conference的投入格外重视。</li><li>特别重要的是，主动出击，在一线跟早期用户深度交流。</li><li>你要能叫出你的项目前100个用户的名字！</li><li>社区不是最终目的。M小姐认为，终极目标，还是成为行业的事实标准. – 要实现这一点，产品设计、社区搭建，以及商业伙伴的合作，是不可割裂的整体。</li><li>从产品设计上来说：不要憋大招，第一个产品只要能prove idea就可以。</li><li>简单对比了几个比较顶尖的开源项目Star数和Contributor的比例，很有意思的发现是，这个比例惊人的相似，几乎都在0.03！</li><li>有些开源公司将社群运营看成了一个纯粹marketing的“用户社区”，忽视了开源这个复杂生态中，每个stakeholder的重要性。– 要能在商业有起色之前，有如此热血的坚持，真爱是必要条件。</li><li>产品设计的一套方法论, 首先，永远被摆在第一位的，Built for workflow, not technologies. – 他们将workflow拆解成三个部分：People, process, tools. – 设计一个workflow产品&#x2F;工具的时候，很多人只是看着工具本身的功能，而没有想到，这里面对人的技能的要求是怎样的，对IT流程的假设是self-service还是工单系统，这些随着环境和具体技术的变化，有什么可以抽象出来保持一致的？</li><li>尊重技术，但是更要重视human element. 就像前面说的Cloud Operation Model.他们发现你不能直接把最终的牛逼哄哄的最佳实践给客户，向客户展现your way to get there，就要接受在这个过程中一些不那么完美的方案。</li><li>跟很多开源公司很像，Hashicorp也遵循transparent operation的理念，将公司的很多管理细则、决策原则等等，都公开在网上. 这个挺难的, 刚开始还比较容易, 当商业化逐渐深入, 很多事情反而扑朔迷离. </li><li>两家公司都非常非常强调writing以及Over communication! 这个不错.</li></ol><img data-src="/assets/640.png" ><img data-src="/assets/640-2.png" ><img data-src="/assets/640-3.png" ><img data-src="/assets/640-4.png" ><img data-src="/assets/640-5.png" ><img data-src="/assets/640-6.png" ><img data-src="/assets/640-7.png" ><img data-src="/assets/640-8.png" ><img data-src="/assets/640-9.png" ><img data-src="/assets/640-10.png" ><img data-src="/assets/640-11.png" ><img data-src="/assets/640-12.png" >]]></content>
    
    
    <summary type="html">HashCorp 读后感</summary>
    
    
    
    <category term="读书笔记" scheme="http://ilongda.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
    <category term="读书笔记" scheme="http://ilongda.com/tags/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
  </entry>
  
  <entry>
    <title>Tesla 行驶中突然失去动力</title>
    <link href="http://ilongda.com/2022/tesla-is-bullshit/"/>
    <id>http://ilongda.com/2022/tesla-is-bullshit/</id>
    <published>2022-02-26T11:07:43.000Z</published>
    <updated>2024-02-02T13:13:25.867Z</updated>
    
    <content type="html"><![CDATA[<h1 id="随谈"><a href="#随谈" class="headerlink" title="随谈"></a>随谈</h1><p>从这次开车开车过程中, 车子突然失去动力后, 坦白讲, 我从一位Tesla 粉开始转黑. 过去4年一直推荐朋友买Tesla, 我现在只会建议, 大家还是买老牌的油车, 不要选择一个以互联网方式做事的车企. </p><p>Tesla 太激进了, 一直将用户当作小白鼠来实验, 从Tesla 系统的升级策略上来讲, 基本上一个月一次, 这么高的频率, 试问怎么可能会做大量充分的测试呢. 而且, 过去很多事实(1. 在中国偷工减料; 2. 私传数据; 3. 刹车门事件)已经证明, Tesla 只是对中国消费者身上如何获得利润, 而不是如何更好的服务. </p><img data-src="/assets/tesla-stop.jpg" ><span id="more"></span><h1 id="经过"><a href="#经过" class="headerlink" title="经过"></a>经过</h1><p>即使Tesla 对我赔偿, 我根本也不care, 只是国内太多的Tesla粉, 觉得这个事情太傻了. 我先陈述一下事实,  事情经过是:</p><ol><li>2022年2月26日早上9点半，在路上正常行驶，拿手机过程中可能碰了一下换挡拨片，不知道切到了哪个档位，一下子屏幕出现报警，平时白色字显示的档位，全部变成红色，屏幕不停提示“前电机禁用” 过一会儿出现“路边安全停车”，此时车子完全失去动力.  (以前也出现过, 行驶中无意中触碰换挡拨片, 但都是只告警一后, 处理一下就恢复正常)</li><li>此时, 无论怎么切换档位，踩油门或者刹车都不行，就依靠车子惯性路边停车。 还好这个时候, 不是在高速上, 在一个流量不大的行驶道上, 否则不堪设想. </li><li>停车后，操作启动，换挡，加油，开门，关门 都无法启动车子，车子始终显示“前电机禁用” ，平时白色字显示的档位全部红色加粗显示。</li><li>强制重启特斯拉，花了很久（比平时关机时间长）才关机成功，重启也花了很久（也比平时重启的时间长，期间屏幕一直黑，估计后台自检程序检测不过），屏幕亮后，和重启前一样，屏幕显示“前电机禁用”，平时白色字显示的档位全部红色加粗显示，操作启动，换挡，加油，刹车，开门关门，各种操作无法启动车子。</li><li>最神奇的事情来了, 打电话给400特斯拉客服，告知安排拖车过来，人下车注意安全，下车后，过了15分钟左右，再上车发现一切恢复正常了，可以正常启动和操作，此时拖车公司电话过来，就取消了拖车. 事后, 和Tesla 维修人员沟通才了解, Tesla 自带一块手机卡, 非用户实名注册的手机卡, 可以直接将数据直接传输到Tesla 服务中心. </li><li>400特斯拉客服电话过来，我要求解释为什么行驶中突然失去动力？客服一堆官方各种推脱, 后来客户看实在是回答不下去了, 答应半小时给一个回复. </li><li>过了3小时，一直没有收到Tesla答复, 直到再次电话400特斯拉客服，客服才安排第二天送到4s店对电机进行检修。</li><li>再一次神奇的事情发生了,  Tesla 检修完, 给出一个官方的答复是 “数据量太大, 数据网关处理不过来, 发生故障”. 也就是这个时候, Tesla工作人员解释了这件事情, Tesla 会在后台收集数据, 然后上传到Tesla 数据中心, 数据量太大, 程序响应不过来, 现在, 已经讲固件重新格式化, 重新安装最新版本. <img data-src="/assets/tesla_fix.jpg" ></li></ol><h1 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h1><p>以前, 以为Tesla 在美国已经跑了很多年, 应该是非常成熟的技术, 而且用户量也非常大, 现在想想, Tesla 还是太激进了, 而且百度一下 “tesla 失去动力”, 搜出一大堆问题, 这种事情, 个人推测tesla 为了更快的迭代速度, 根本没有做足够多的测试, 就把产品放到用户身上进行测试.<br>另外一点也一直想不通, tesla的自动驾驶, 居然还要花钱去买, 这种完全把用户当小白鼠来进行测试的一个不成熟的产品, 还要用户花 2万 ~ 8万, 将性命交给一个自动驾驶level 仅仅为2级的系统, 就算免费给我使用, 我都不会使用, 而且还有各种宣传各种开车睡觉的视频, 这种草菅人命的营销, 纯属误导消费者的行为, 希望国家或有关单位能勒令禁止. </p>]]></content>
    
    
    <summary type="html">Tesla 行驶中突然失去动力</summary>
    
    
    
    <category term="生活" scheme="http://ilongda.com/categories/%E7%94%9F%E6%B4%BB/"/>
    
    
    <category term="Tesla" scheme="http://ilongda.com/tags/Tesla/"/>
    
  </entry>
  
  <entry>
    <title>OceanBase监控对接Prometheus/Grafana</title>
    <link href="http://ilongda.com/2021/obagent/"/>
    <id>http://ilongda.com/2021/obagent/</id>
    <published>2021-11-21T11:42:57.000Z</published>
    <updated>2024-02-02T13:11:06.278Z</updated>
    
    <content type="html"><![CDATA[<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文讲介绍如何让OceanBase监控对接Prometheus和Grafana. </p><p>​<img data-src="/img/ob/obagent1.jpg" ><br>​<span id="more"></span></p><h1 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h1><p>大致过程, 分为3大步骤:</p><ol><li>安装oceanbase和obagent</li><li>安装prometheus和grafana</li><li>配置prometheus和grafana</li></ol><h2 id="安装OceanBase和Obagent"><a href="#安装OceanBase和Obagent" class="headerlink" title="安装OceanBase和Obagent"></a>安装OceanBase和Obagent</h2><p>如何安装OceanBase 可以参考上一篇文章<a href="http://ilongda.com/2021/ob_offline_install/">《OceanBase离线安装》</a>, 本节重点介绍如何安装obagent, 可以参考文档<span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vZG9jcy9jb21tdW5pdHkvb2NlYW5iYXNlLWRhdGFiYXNlL1YzLjEuMS91c2Utb2JkLXRvLWRlcGxveS1vYmFnZW50">使用 OBD 部署 OBAgent<i class="fa fa-external-link-alt"></i></span></p><p>OBAgent 是一个监控采集框架。OBAgent 支持推、拉两种数据采集模式，可以满足不同的应用场景。OBAgent 默认支持的插件包括主机数据采集、OceanBase 数据库指标的采集、监控数据标签处理和 Prometheus 协议的 HTTP 服务。要使 OBAgent 支持其他数据源的采集，或者自定义数据的处理流程，您只需要开发对应的插件即可。</p><p>obagent 的配置, 在原来的配置基础上, 增加了obagent的配置, 详情可以参考<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vYmRlcGxveS9ibG9iL21hc3Rlci9leGFtcGxlL2F1dG9kZXBsb3kvZGlzdHJpYnV0ZWQtd2l0aC1vYnByb3h5LWFuZC1vYmFnZW50LWV4YW1wbGUueWFtbA==">distributed-with-obproxy-and-obagent-example<i class="fa fa-external-link-alt"></i></span>:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">obagent:</span><br><span class="line">  depends:</span><br><span class="line">    - oceanbase-ce</span><br><span class="line">  # The list of servers to be monitored. This list is consistent with the servers in oceanbase-ce. </span><br><span class="line">  servers:</span><br><span class="line">    - name: server1</span><br><span class="line">      # Please don&#x27;t use hostname, only IP is supported.</span><br><span class="line">      ip: 172.19.33.2</span><br><span class="line">    - name: server2</span><br><span class="line">      ip: 172.19.33.3</span><br><span class="line">    - name: server3</span><br><span class="line">      ip: 172.19.33.4</span><br><span class="line">  # Set dependent components for the component.</span><br><span class="line">  # When the associated configurations are not done, OBD will automatically get the these configurations from the dependent components.</span><br><span class="line">  depends:</span><br><span class="line">    - oceanbase-ce</span><br><span class="line">  global:</span><br><span class="line">    # The working directory for obagent. obagent is started under this directory. This is a required field.</span><br><span class="line">    home_path: /root/observer</span><br><span class="line">    skip_proxy_sys_private_check: true</span><br></pre></td></tr></table></figure><p>特别说明:</p><ol><li>depends里面的 “oceanbase-ce” 的名字必须和配置文件集群的名字一致. </li><li>servers里面的配置必须与在配置文件中”oceanbase-ce”一节中servers 配置一摸一样</li><li>记住home_path, 后续需要用到这个路径.</li></ol><p>安装完成后, 可以执行“obd cluster display ” 看到obagent 已经启动了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">obd cluster display obtest</span><br><span class="line">Get local repositories and plugins ok</span><br><span class="line">Open ssh connection ok</span><br><span class="line">Cluster status check ok</span><br><span class="line">Connect to observer ok</span><br><span class="line">Wait for observer init ok</span><br><span class="line">+-------------------------------------------------+</span><br><span class="line">|                     observer                    |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line">| ip            | version | port | zone  | status |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line">| 172.30.62.210 | 3.1.1   | 2881 | zone1 | active |</span><br><span class="line">| 172.30.62.211 | 3.1.1   | 2881 | zone2 | active |</span><br><span class="line">| 172.30.62.212 | 3.1.1   | 2881 | zone3 | active |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line"></span><br><span class="line">Connect to obproxy ok</span><br><span class="line">+-------------------------------------------------+</span><br><span class="line">|                     obproxy                     |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br><span class="line">| ip            | port | prometheus_port | status |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br><span class="line">| 172.30.62.213 | 2883 | 2884            | active |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br><span class="line">+---------------------------------------------------+</span><br><span class="line">|                      obagent                      |</span><br><span class="line">+---------------+-------------+------------+--------+</span><br><span class="line">| ip            | server_port | pprof_port | status |</span><br><span class="line">+---------------+-------------+------------+--------+</span><br><span class="line">| 172.30.62.210 | 8088        | 8089       | active |</span><br><span class="line">| 172.30.62.211 | 8088        | 8089       | active |</span><br><span class="line">| 172.30.62.212 | 8088        | 8089       | active |</span><br><span class="line">+---------------+-------------+------------+--------+</span><br></pre></td></tr></table></figure><h2 id="安装prometheus和grafana"><a href="#安装prometheus和grafana" class="headerlink" title="安装prometheus和grafana"></a>安装prometheus和grafana</h2><p>选择一台机器上安装prometheus 和grafana, 这台机器尽量不是observer 中的一台, 本例中, prometheus 和grafana 部署在obproxy机器上. </p><ol><li>从<span class="exturl" data-url="aHR0cHM6Ly9wcm9tZXRoZXVzLmlvL2Rvd25sb2FkLw==">https://prometheus.io/download/<i class="fa fa-external-link-alt"></i></span> 上把prometheus 和alertmanager 下载下来, 本章将不介绍 alertmanager 怎么使用. </li><li>从<span class="exturl" data-url="aHR0cHM6Ly9ncmFmYW5hLmNvbS9ncmFmYW5hL2Rvd25sb2FkP3BnPWdldCZwbGNtdD1zZWxmbWFuYWdlZC1ib3gxLWN0YTE=">https://grafana.com/grafana/download?pg=get&amp;plcmt=selfmanaged-box1-cta1<i class="fa fa-external-link-alt"></i></span> 上下载grapha</li><li>讲prometheus 和grafana 压缩包拷贝到obproxy 的机器上, </li><li>解压prometheus 和grafana<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># tar -xzf prometheus-2.31.0.linux-amd64.tar.gz</span><br><span class="line"># tar -xzf grafana-enterprise-8.2.3.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure></li></ol><h2 id="配置prometheus和grafana"><a href="#配置prometheus和grafana" class="headerlink" title="配置prometheus和grafana"></a>配置prometheus和grafana</h2><h3 id="配置prometheus"><a href="#配置prometheus" class="headerlink" title="配置prometheus"></a>配置prometheus</h3><ol><li>讲obagent上的prometheus 的配置文件给拷贝到prometheus 的安装目录中<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># cd prometheus-2.31.0.linux-amd64</span><br><span class="line"># mv prometheus.yml prometheus.yml.old</span><br><span class="line"># scp -r observer001:/root/observer/conf/prometheus_config/* . </span><br></pre></td></tr></table></figure>备注说明: </li><li>observer001 为安装obagent的一台机器</li><li>&#x2F;root&#x2F;observer 为之前在配置文件中, 配置obagent中配置的home_path路径</li><li>从observer001 上会copy 过来几个文件, prometheus.yaml 和rules, rules 是存储拉取规则, prometheus 是配置prometheus的文件.</li></ol><p>启动prometheus</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nohup ./prometheus --config.file=./prometheus.yaml &gt;&gt; run.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure><p>检查run.log 可以查看运行日志. 正常情况下, </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># curl http://localhost:9090/metrics</span><br></pre></td></tr></table></figure><p>可以获得大量的数据. </p><h3 id="配置grafana"><a href="#配置grafana" class="headerlink" title="配置grafana"></a>配置grafana</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># cd grafana-8.2.3/</span><br><span class="line"># nohup bin/grafana-server &gt; run.log 2&gt;&amp;1 &amp;</span><br><span class="line"># ps -ef|grep grafana</span><br></pre></td></tr></table></figure><p>可以坚持run.log 或ps -ef|grep grafana 均可以查看到grafana 正常工作. </p><p>打开grafana 的页面,  第一次登录, 输入admin&#x2F;admin, 然后设置管理员密码, 然后增加data source<br>​<img data-src="/img/ob/obagent2.jpg" ><br>进入增加data source后, 选择prometheus, 然后进入配置prometheus 后, 关键设置url<br>​<img data-src="/img/ob/obagent3.jpg" ></p><p>import 配置项<br>​<img data-src="/img/ob/obagent4.jpg" ></p><p>ob 已经提前准备好了 15215和15216 , 一个是监控oceanbase, 一个是监控host的.<br>当加载好模版后, 在dashboard 就可以看到2个预设好的dashboard, </p><p>​<img data-src="/img/ob/obagent1.jpg" ></p><p>恭喜你, 已经完成配置oceanbase对接prometheus 和grafana</p>]]></content>
    
    
    <summary type="html">OceanBase 入门 -- OceanBase监控对接Prometheus/Grafana</summary>
    
    
    
    <category term="OceanBase" scheme="http://ilongda.com/categories/OceanBase/"/>
    
    <category term="DBA" scheme="http://ilongda.com/categories/OceanBase/DBA/"/>
    
    
    <category term="OceanBase" scheme="http://ilongda.com/tags/OceanBase/"/>
    
  </entry>
  
  <entry>
    <title>OceanBase离线安装</title>
    <link href="http://ilongda.com/2021/ob_offline_install/"/>
    <id>http://ilongda.com/2021/ob_offline_install/</id>
    <published>2021-11-20T03:42:57.000Z</published>
    <updated>2024-02-02T13:10:55.979Z</updated>
    
    <content type="html"><![CDATA[<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>将8月份写的离线安装文档, share 出来. 后续可能会发一系列的使用文档. </p><p>本文将以线上业务运行OceanBase为目标, 部署分布式版本, 如果想简单测试和试用OceanBase, 请参考<span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vcXVpY2tTdGFydA==">https://open.oceanbase.com/quickStart<i class="fa fa-external-link-alt"></i></span><br>​</p><h1 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h1><p>​<img data-src="/img/ob/install1.jpg" ></p><span id="more"></span><h1 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h1><p>安装前, 均使用root 进行操作, 安装过程中, 可以使用对应的普通用户</p><h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ul><li>OBD: OceanBase Deployer,   OceanBase 部署工具</li><li>主控机: 运行OBD 安装包机器</li><li>OBServer : 每台安装 OceanBase 的物理机上面运行的 OceanBase 数据库进程&#x2F;服务，称为 OBServer  </li><li>OBProxy : OceanBase Proxy, 是 OceanBase 高性能反向代理服务器，具有防连接闪断、 屏蔽后端异常(宕机、升级、网络抖动)、MySQL 协议兼容、强校 验、支持热升级和多集群等功能<br>​</li></ul><h2 id="部署模式"><a href="#部署模式" class="headerlink" title="部署模式"></a>部署模式</h2><p>在本例采用经典的三幅本部署模式, 使用4台机器:</p><ul><li>1台机器 部署 OBProxy  – 推荐客户端应用和OBProxy 部署一起, 减少第一次网络时延.</li><li>1-1-1 部署3副本OceanBase 集群, 每个zone 表示一个副本, 在本例中, 一个zone 只包含一台机器. 3个zone 可以生产环境中常常部署两地三中心模式, 三个机房三个副本, 每个机房一个副本, 其中两个机房距离较近.</li></ul><p>​</p><h2 id="软硬件要求"><a href="#软硬件要求" class="headerlink" title="软硬件要求"></a>软硬件要求</h2><table><thead><tr><th>项目</th><th>描述</th></tr></thead><tbody><tr><td>系统</td><td>Red Hat Enterprise Linux Server 7.x 版本（内核 Linux 3.10.0 版本及以上） </br>CentOS Linux 7.x 版本（内核 Linux 3.10.0 版本及以上）</br> Anolis OS 8.x 版本（内核 Linux 3.10.0 版本及以上）</td></tr><tr><td>CPU</td><td>企业级用户最低要求16核, 推荐32核及以上 </br>个人测试最低要求2核, 推荐8核及以上</td></tr><tr><td>内存</td><td>企业级应用最低要求64G,  推荐256G 及以上 </br>个人测试最低要求8G, 推荐64G 及以上</td></tr><tr><td>磁盘类型</td><td>推荐SSD</td></tr><tr><td>磁盘空间</td><td>内存大小的4倍及以上</td></tr><tr><td>文件系统</td><td>ext4或xfs, 当数据量超过16TB时, 使用xfs</td></tr><tr><td>网卡</td><td>千兆互联及以上</td></tr></tbody></table><h2 id="设置无密码SSH-登录"><a href="#设置无密码SSH-登录" class="headerlink" title="设置无密码SSH 登录"></a>设置无密码SSH 登录</h2><p>在安装前, 需要对每台机器的环境进行设置, 这些设置都需在超级管理员下操作, 建议打通 主控机器 到OBServer 和OBProxy 机器的信任登陆(即无密码登录), 如何设置无密码SSH 登录, 详情参考 <span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vZG9jcy9jb21tdW5pdHkvb2NlYW5iYXNlLWRhdGFiYXNlL1YzLjEuMC9vcHRpb25hbC1zZXQtcGFzc3dvcmQtZnJlZS1zc2gtbG9nb24=">https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/optional-set-password-free-ssh-logon<i class="fa fa-external-link-alt"></i></span><br>​</p><p>推荐2个脚本, 方便在集群中批量执行命令和拷贝文件<br>批量拷贝文件,  可以将host list 换成自己实际机器列表</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">#/usr/bin/bash</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hosts=(</span><br><span class="line">    &quot;ob001&quot;</span><br><span class="line">    &quot;ob002&quot;</span><br><span class="line">    &quot;ob003&quot;</span><br><span class="line">    &quot;obdriver&quot;</span><br><span class="line">    )</span><br><span class="line">    for host in &quot;$&#123;hosts[@]&#125;&quot;</span><br><span class="line">    do</span><br><span class="line"></span><br><span class="line">        echo &quot;begin to scp &quot; $@ &quot; on &quot; $host</span><br><span class="line">        scp -r $1 $host:$2</span><br><span class="line">    done</span><br></pre></td></tr></table></figure><p>批量执行命令, 可以将host list  换成自己实际的机器列表</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">/usr/bin/bash</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hosts=(</span><br><span class="line">    &quot;ob001&quot;</span><br><span class="line">    &quot;ob002&quot;</span><br><span class="line">    &quot;ob003&quot;</span><br><span class="line">    &quot;obdriver&quot;</span><br><span class="line">    )</span><br><span class="line">    for host in &quot;$&#123;hosts[@]&#125;&quot;</span><br><span class="line">    do</span><br><span class="line">        echo &quot;begin to run &quot; $@ &quot; on &quot; $host</span><br><span class="line">        ssh $host $@</span><br><span class="line">    done</span><br></pre></td></tr></table></figure><h2 id="创建使用用户"><a href="#创建使用用户" class="headerlink" title="创建使用用户"></a>创建使用用户</h2><p>对于个人测试用户, 可以直接使用root 账号, 对于企业用户, 推荐创新普通用户, 避免对系统照成安全冲击.  在本例中, 使用admin 作为示范, 企业用户可以根据自己需要, 使用自己常用的账户<br>​</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">useradd -U admin -d /home/admin -s /bin/bash</span><br><span class="line">mkdir -p /home/admin</span><br><span class="line">sudo chown -R admin:admin /home/admin</span><br></pre></td></tr></table></figure><p>设置密码</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">passwd admin</span><br></pre></td></tr></table></figure><p>​</p><p>设置sudo 权限<br>vi &#x2F;etc&#x2F;sudoers      #添加oceanbase一行内容</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">## Same thing without a password</span><br><span class="line"># %wheel        ALL=(ALL)       NOPASSWD: ALL</span><br><span class="line">admin       ALL=(ALL)       NOPASSWD: ALL</span><br></pre></td></tr></table></figure><h2 id="磁盘规划"><a href="#磁盘规划" class="headerlink" title="磁盘规划"></a>磁盘规划</h2><p>OceanBase 数据库服务器依赖3个目录,   当个人测试使用时, 可以将所有数据放到1块盘下, 但在企业级用户中, 必须分别挂载3块磁盘: 数据盘, 事务日志盘, OBServer 安装盘. 当机器上没有3块盘时或者使用RAID 磁盘阵列时,  需要对磁盘或者磁盘阵列的逻辑卷进行分区, 分3块分区, 分区大小参考下面说明:</p><ul><li><p>数据盘</p><ul><li>配置参数为data_dir.  要根据业务需要，做好数据盘的规划. 数据盘承载了基线数据，物理上只有一个基线数据文件 block_file，在安装目录 store&#x2F;sstable 下。通过 OBServer 进程启动时一 次性创建，大小根据启动参数 datafile_disk_percentage 采用磁盘预分 配策略，默认值为 95%，创建后无法调整大小。OceanBase 的扩容缩 容采用加减机器的策略，目前不支持单机的磁盘级扩容和缩容。</li></ul></li><li><p>事务日志盘</p><ul><li>配置参数为redo_dir.  推荐大小为OBServer 内存3到4倍或以上. 事务日志盘包含多个固定大小的小文件，位于安装目录 store&#x2F;{clog,ilog,slog}，按需自动创建和清除，磁盘写到 80%会触发自 清除逻辑，但前提是这部分日志数据对应的内存数据已经通过合并融 合到了基线数据中，才能被删除。同等数据量， 事务日志的大小约为内存数据大小的三倍。所以事务日志盘所需空间 上限与两次合并操作间的业务数据总量成正比，经验公式是:事务日 志文件大小 &#x3D; 增量数据内存上限的 3 到 4 倍。</li></ul></li><li><p>OBServer 安装盘</p><ul><li><p>配置参数home_path. 推荐200G 或以上(保存7天或以上的日志量). OceanBase 的 rpm 包安装目录在&#x2F;home&#x2F;admin&#x2F;oceanbase 下，其中 基线数据文件和事务日志文件会通过软连接指向上述的两个独立磁 盘，还有另外一个不断增长的文件是 OB 运行日志，在安装目录 log 下。OB 进程本身无法自删除运行日志，需要定时任务或运维脚本完 成删除逻辑。 </p><p>磁盘划分后, 可以通过df -h 命令检查, 结果如下:</p></li></ul></li></ul><p>​<img data-src="/img/ob/install2.png" ><br>在本示例中: &#x2F;data 为数据磁盘, 大小1TB, &#x2F;redo 存放 redo 日志,  &#x2F;home&#x2F;admin&#x2F;oceanbase 存放oceanbase binary 和运行日志<br>​</p><p>检查目录权限</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">ls –al #执行该命令</span><br><span class="line">drwxr-xr-x 2 admin admin 4096 2 月 9 18:43 </span><br><span class="line">drwxr-xr-x 2 admin admin 4096 2 月 9 18:43 log1</span><br><span class="line"></span><br><span class="line">若 admin 用户无权限，则以 root 用户执行如下命令 </span><br><span class="line">chown -R admin:admin /data</span><br><span class="line">chown -R admin:admin /redo</span><br><span class="line">chown -R admin:admin /home/admin</span><br></pre></td></tr></table></figure><p>​</p><h2 id="预检查"><a href="#预检查" class="headerlink" title="预检查"></a>预检查</h2><p>企业级用户建议运行OBServer 所有机器硬件配置和软件配置(操作系统, 操作系统内核, glibc, python 等软件包) 一致, OBProxy 机器和OBServer 机器软件配置一致(操作系统, 操作系统内核, glibc, python等软件包). </p><h3 id="检查操作系统"><a href="#检查操作系统" class="headerlink" title="检查操作系统"></a>检查操作系统</h3><p>当前支持的操作系统为:<br>​</p><p>Red Hat Enterprise Linux Server 7.x 版本（内核 Linux 3.10.0 版本及以上）<br>CentOS Linux 7.x 版本（内核 Linux 3.10.0 版本及以上）<br>​</p><ol><li>以root 用户登录服务器</li><li>查看os 版本</li></ol><p> </p><p>RedHat7 系统显示如下 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@redhat-04 /root]#cat /etc/redhat-release</span><br><span class="line">Red Hat Enterprise Linux Server release 7.2 (Maipo)</span><br></pre></td></tr></table></figure><p>CentOS7 系统显示如下: </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@centos-01 /root]#cat /etc/redhat-release </span><br><span class="line">CentOS Linux release 7.2.1511 (Core)</span><br></pre></td></tr></table></figure><p>在anolis 系统上:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@anolis ~]# cat /etc/os-release</span><br><span class="line">NAME=&quot;Anolis OS&quot;</span><br><span class="line">VERSION=&quot;8.2&quot;</span><br><span class="line">ID=&quot;anolis&quot;</span><br><span class="line">ID_LIKE=&quot;rhel fedora centos&quot;</span><br><span class="line">VERSION_ID=&quot;8.2&quot;</span><br><span class="line">PLATFORM_ID=&quot;platform:an8&quot;</span><br><span class="line">PRETTY_NAME=&quot;Anolis OS 8.2&quot;</span><br><span class="line">ANSI_COLOR=&quot;0;31&quot;</span><br><span class="line">HOME_URL=&quot;https://openanolis.org/&quot;</span><br></pre></td></tr></table></figure><p>​</p><p>其他系统, 如Debian9 系统显示如下:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">root@ob001:~# cat /etc/os-release</span><br><span class="line">PRETTY_NAME=&quot;Debian GNU/Linux 9 (stretch)&quot;</span><br><span class="line">NAME=&quot;Debian GNU/Linux&quot;</span><br><span class="line">VERSION_ID=&quot;9&quot;</span><br><span class="line">VERSION=&quot;9 (stretch)&quot;</span><br><span class="line">VERSION_CODENAME=stretch</span><br><span class="line">ID=debian</span><br><span class="line">HOME_URL=&quot;https://www.debian.org/&quot;</span><br><span class="line">SUPPORT_URL=&quot;https://www.debian.org/support&quot;</span><br><span class="line">BUG_REPORT_URL=&quot;https://bugs.debian.org/&quot;</span><br></pre></td></tr></table></figure><p>在unbutu 系统上:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">NAME=&quot;Ubuntu&quot;</span><br><span class="line">VERSION=&quot;20.04.2 LTS (Focal Fossa)&quot;</span><br><span class="line">ID=ubuntu</span><br><span class="line">ID_LIKE=debian</span><br><span class="line">PRETTY_NAME=&quot;Ubuntu 20.04.2 LTS&quot;</span><br><span class="line">VERSION_ID=&quot;20.04&quot;</span><br><span class="line">HOME_URL=&quot;https://www.ubuntu.com/&quot;</span><br><span class="line">SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;</span><br><span class="line">BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;</span><br><span class="line">PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;</span><br><span class="line">VERSION_CODENAME=focal</span><br><span class="line">UBUNTU_CODENAME=focal</span><br></pre></td></tr></table></figure><p>对于一些系统, 如Ubuntu&#x2F;Debian, 需要安装yum:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install build-essential </span><br><span class="line">sudo apt-get install yum -y</span><br><span class="line">sudo apt install yum-utils -y</span><br><span class="line">sudo ln -s /bin/bash /bin/sh</span><br><span class="line">apt-get install alien -y</span><br><span class="line">apt-get install rpm</span><br></pre></td></tr></table></figure><pre><code> 3. 查看内核版本, 要求操作系统3.10.0 及以上</code></pre><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@centos-01 /root]#uname -r </span><br><span class="line">3.10.0-327.el7.x86_64</span><br></pre></td></tr></table></figure><h3 id="检查内存"><a href="#检查内存" class="headerlink" title="检查内存"></a>检查内存</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">free -g</span><br></pre></td></tr></table></figure><p>企业级应用最低要求64G,  推荐256G 及以上<br>如果free -g<br>​<img data-src="/img/ob/install3.png" ><br>显示的free列的内存小于配置文件中的memory_limit配置, 需要清理缓存或者修改配置memory_limit, 将memory_limit修改小于free 列的值. 清理缓存操作如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># echo 3 &gt; /proc/sys/vm/drop_caches</span><br></pre></td></tr></table></figure><p>​</p><h2 id="检查磁盘"><a href="#检查磁盘" class="headerlink" title="检查磁盘"></a>检查磁盘</h2><p>​</p><p>确保配置文件中, <code>data_dir, redo_dir, home_path</code>,  对应的磁盘已经完成挂载,   data_dir和redo_dir 对应目录为空, data_dir 对应目录的磁盘已经使用率必须低于4%.<br>​<img data-src="/img/ob/install4.png" ></p><h2 id="检查网卡名称"><a href="#检查网卡名称" class="headerlink" title="检查网卡名称"></a>检查网卡名称</h2><p>​<img data-src="/img/ob/install5.png" ><br>配置文件中, 有一个配置项”devname” 需要指定网卡. 在启动 OBServer 服务时，需要通过“-i”参数指定网卡，服务器有 可能有多个网卡以及多个 IP，OBServer 之间通信依赖指定的网卡和 IP。可以通过 ifconfig 命令查看网卡名称 (需要先安装 net-tools 依赖 包)，确保存在有效的网卡即可。<br>在本例中:<br>​<img data-src="/img/ob/install6.png" ></p><h2 id="配置limits-conf"><a href="#配置limits-conf" class="headerlink" title="配置limits.conf"></a>配置limits.conf</h2><p>ulimit 用于限制 shell 启动进程所占用的资源。个人测试使用,可以不用设置, 但企业用户必须设置.<br>有两种方法可以修 改资源限制，一种是通过启动时 session 级别指定，另外一种是修改 &#x2F;etc&#x2F;security&#x2F;limits.conf 配置文件，全局生效。<br>OBServer 进程涉及的几个限制包括线程最大栈空间大小(stack)， 最大文件句柄数(open files)，core 文件大小(core file size)。<br>如下在启动 OBServer 进程时，session 级别设置最大栈空间大小 为 unlimited，最大文件句柄数为 655350，core 文件大小为 unlimited </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">$vi /etc/security/limits.conf 添加</span><br><span class="line">root soft nofile 655350</span><br><span class="line">root hard nofile 655350</span><br><span class="line">* soft nofile 655350</span><br><span class="line">* hard nofile 655350</span><br><span class="line">* soft stack 20480</span><br><span class="line">* hard stack 20480</span><br><span class="line">* soft nproc 655360</span><br><span class="line">* hard nproc 655360</span><br><span class="line">* soft core unlimited</span><br><span class="line">* hard core unlimited</span><br></pre></td></tr></table></figure><pre><code> 退出当前session, 重新登录</code></pre><p>​</p><p>检查配置是否生效</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">ulimit -a</span><br><span class="line"># 执行该命令，资源限制详情如下 (blocks, -c) 0</span><br><span class="line">core file size</span><br><span class="line">data seg size scheduling priority file size</span><br><span class="line">pending signals max locked memory</span><br><span class="line">(kbytes, -d) unlimited (-e) 0</span><br><span class="line">(blocks, -f) unlimited (-i) 772861</span><br><span class="line">(kbytes, -l) 64</span><br><span class="line">max memory size</span><br><span class="line">open files</span><br><span class="line">pipe size</span><br><span class="line">POSIX message queues real-time priority</span><br><span class="line">stack size</span><br><span class="line">cpu time</span><br><span class="line">max user processes virtual memory file locks</span><br><span class="line">(kbytes, -m) unlimited (-n) 1024</span><br><span class="line">(512 bytes, -p) 8</span><br><span class="line">(bytes, -q) 819200</span><br><span class="line">(-r) 0 (kbytes, -s) 8192</span><br><span class="line">(seconds, -t) unlimited (-u) 655360</span><br><span class="line">(kbytes, -v) unlimited (-x) unlimited</span><br></pre></td></tr></table></figure><p>​</p><h2 id="配置“sysctl-conf”文件"><a href="#配置“sysctl-conf”文件" class="headerlink" title="配置“sysctl.conf”文件"></a>配置“sysctl.conf”文件</h2><p>为保证 OceanBase 正常运行，请在安装 OceanBase 前修改所有物理机的“&#x2F;etc&#x2F;sysctl.conf”配置(用以提高 Linux 的系统性能)。</p><p>有一些参数, 操作系统已经提前设置了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"># for oceanbase</span><br><span class="line">## 修改内核异步 I/O 限制</span><br><span class="line">fs.aio-max-nr=1048576</span><br><span class="line"></span><br><span class="line">## 网络优化</span><br><span class="line">net.core.somaxconn = 2048</span><br><span class="line">net.core.netdev_max_backlog = 10000 </span><br><span class="line">net.core.rmem_default = 16777216 </span><br><span class="line">net.core.wmem_default = 16777216 </span><br><span class="line">net.core.rmem_max = 16777216 </span><br><span class="line">net.core.wmem_max = 16777216</span><br><span class="line"></span><br><span class="line">net.ipv4.ip_local_port_range = 3500 65535 </span><br><span class="line">net.ipv4.ip_forward = 0 </span><br><span class="line">net.ipv4.conf.default.rp_filter = 1 </span><br><span class="line">net.ipv4.conf.default.accept_source_route = 0 </span><br><span class="line">net.ipv4.tcp_syncookies = 0 </span><br><span class="line">net.ipv4.tcp_rmem = 4096 87380 16777216 </span><br><span class="line">net.ipv4.tcp_wmem = 4096 65536 16777216 </span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384 </span><br><span class="line">net.ipv4.tcp_fin_timeout = 15 </span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384 </span><br><span class="line">net.ipv4.tcp_tw_reuse = 1 </span><br><span class="line">net.ipv4.tcp_tw_recycle = 1 </span><br><span class="line">net.ipv4.tcp_slow_start_after_idle=0</span><br><span class="line"></span><br><span class="line">vm.swappiness = 0</span><br><span class="line">vm.min_free_kbytes = 2097152</span><br><span class="line"></span><br><span class="line"># 此处为oceanbase 的data 目录</span><br><span class="line">kernel.core_pattern = /data/core-%e-%p-%t </span><br></pre></td></tr></table></figure><p>其中, “kernel.core_pattern &#x3D; &#x2F;data&#x2F;core-%e-%p-%t ”,  &#x2F;data 为 oceanbase的data 目录,  另外如果是个人测试, 也可以只设置 “fs.aio-max-nr&#x3D;1048576”<br>​</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 配置生效</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure><p>​</p><h2 id="关闭防火墙和-SELinux"><a href="#关闭防火墙和-SELinux" class="headerlink" title="关闭防火墙和 SELinux"></a>关闭防火墙和 SELinux</h2><p>个人测试可以不用设置, 但企业用户建议进行设置</p><h3 id="firewalld关闭"><a href="#firewalld关闭" class="headerlink" title="firewalld关闭"></a>firewalld关闭</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">#依次执行这 3 条命令 </span><br><span class="line">systemctl disable firewalld </span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl status firewalld</span><br></pre></td></tr></table></figure><h3 id="selinux关闭"><a href="#selinux关闭" class="headerlink" title="selinux关闭"></a>selinux关闭</h3><p>vi &#x2F;etc&#x2F;selinux&#x2F;linux</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure><p>执行该命令</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">#查看配置已生效</span><br><span class="line">cat /etc/selinux/config</span><br></pre></td></tr></table></figure><h2 id="设置时钟同步"><a href="#设置时钟同步" class="headerlink" title="设置时钟同步"></a>设置时钟同步</h2><p>当下面任一状况时, 可以跳过设置时钟同步:</p><ol><li>若 NTP 时钟已经处于同步状态</li><li>部署为单机版</li><li>个人测试</li></ol><p>​</p><p>OceanBase 集群中各服务器的时间需保持一致，否则会导致 OceanBase 集群无法启动，运行时也会出现故障。对于企业用户来说, 时钟同步是<strong>非常非常重要</strong>, 物理机与时钟服务器的误差在 50ms 以下可认为时钟是同步状态 , 最大容忍误差不能超过200ms. 当超过200ms, 会出现无主状况, 恢复时钟同步后, 重启observer, 可以恢复状态. </p><h3 id="检查时钟同步"><a href="#检查时钟同步" class="headerlink" title="检查时钟同步"></a>检查时钟同步</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo clockdiff  $IP</span><br></pre></td></tr></table></figure><h3 id="配置时钟同步"><a href="#配置时钟同步" class="headerlink" title="配置时钟同步"></a>配置时钟同步</h3><p><span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vZG9jcy9jb21tdW5pdHkvb2NlYW5iYXNlLWRhdGFiYXNlL1YzLjEuMC9vcHRpb25hbC1jb25maWd1cmluZy1jbG9jay1zb3VyY2Vz">https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/optional-configuring-clock-sources<i class="fa fa-external-link-alt"></i></span><br>​</p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="安装包组件"><a href="#安装包组件" class="headerlink" title="安装包组件"></a>安装包组件</h2><p>从<span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vc29mdHdhcmVDZW50ZXIvY29tbXVuaXR5">https://open.oceanbase.com/softwareCenter/community<i class="fa fa-external-link-alt"></i></span> 上下载所有的安装包, 本文展示的安装包的版本,可能已经过期, 麻烦从开源OceanBase官网下载最新版本的安装包.<br>​<img data-src="/img/ob/install7.png" ><br>如您的机器可以访问公网，并能够添加三方 YUM 软件源，您可以运行以下命令，使用 OceanBase 的官方软件源安装 OBD：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y yum-utils</span><br><span class="line">sudo yum-config-manager --add-repo https://mirrors.aliyun.com/oceanbase/OceanBase.repo</span><br><span class="line">sudo yum install -y ob-deploy</span><br></pre></td></tr></table></figure><p>​</p><p>将所有的软件包, scp至 主控机器上</p><p>​</p><h2 id="安装OBD"><a href="#安装OBD" class="headerlink" title="安装OBD"></a>安装OBD</h2><p>当前使用root 用户, 当前操作只在主控机器上进行操作</p><h3 id="在线安装"><a href="#在线安装" class="headerlink" title="在线安装"></a>在线安装</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y ob-deploy</span><br></pre></td></tr></table></figure><h3 id="本地安装"><a href="#本地安装" class="headerlink" title="本地安装"></a>本地安装</h3><p>centos或redhat</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install ob-deploy-1.1.0-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><p>Ubuntu&#x2F;Debian</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alien -i ob-deploy-1.1.0-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><h2 id="安装OBLibs"><a href="#安装OBLibs" class="headerlink" title="安装OBLibs"></a>安装OBLibs</h2><p>当前使用root 用户, 需要在每台机器上执行,  </p><h3 id="在线安装-1"><a href="#在线安装-1" class="headerlink" title="在线安装"></a>在线安装</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y oceanbase-ce-libs</span><br></pre></td></tr></table></figure><h3 id="本地安装-1"><a href="#本地安装-1" class="headerlink" title="本地安装"></a>本地安装</h3><p>先将oceanbase-ce-libs-3.1.0-3.el7.x86_64.rpm 拷贝到每台机器下<br>​</p><p>centos或redhat或anolis</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install oceanbase-ce-libs-3.1.0-3.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><p>Ubuntu&#x2F;Debian</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alien -i oceanbase-ce-libs-3.1.0-3.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><h2 id="安装OBServer-OBProxy"><a href="#安装OBServer-OBProxy" class="headerlink" title="安装OBServer &amp; OBProxy"></a>安装OBServer &amp; OBProxy</h2><p>切换到admin 用户下<br>​</p><h3 id="将OceanBase数据库的离线软件包加入本地镜像"><a href="#将OceanBase数据库的离线软件包加入本地镜像" class="headerlink" title="将OceanBase数据库的离线软件包加入本地镜像"></a>将OceanBase数据库的离线软件包加入本地镜像</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">admin@obdriver:/data/rpm$ obd mirror clone *.rpm</span><br><span class="line">name: libobclient</span><br><span class="line">version: 2.0.0</span><br><span class="line">release:2.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: f73cae67e2ff5be0682ac2803aba33a7ed26430e</span><br><span class="line">add libobclient-2.0.0-2.el7.x86_64.rpm to local mirror</span><br><span class="line">name: obclient</span><br><span class="line">version: 2.0.0</span><br><span class="line">release:2.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: 1d2c3ee31f40b9d2fbf97f653f549d896b7e7060</span><br><span class="line">add obclient-2.0.0-2.el7.x86_64.rpm to local mirror</span><br><span class="line">name: ob-deploy</span><br><span class="line">version: 1.1.0</span><br><span class="line">release:1.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: c01dbbebc7f44b700833ce6846df09f20033675c</span><br><span class="line">add ob-deploy-1.1.0-1.el7.x86_64.rpm to local mirror</span><br><span class="line">name: obproxy</span><br><span class="line">version: 3.1.0</span><br><span class="line">release:1.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: 0b17cf0459a3b53c5a2febb6572894d183154c64</span><br><span class="line">add obproxy-3.1.0-1.el7.x86_64.rpm to local mirror</span><br><span class="line">name: oceanbase-ce</span><br><span class="line">version: 3.1.0</span><br><span class="line">release:3.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: b73bcd531bdf3f087391991b290ff2cbcdaa0dc9</span><br><span class="line">add oceanbase-ce-3.1.0-3.el7.x86_64.rpm to local mirror</span><br><span class="line">name: oceanbase-ce-libs</span><br><span class="line">version: 3.1.0</span><br><span class="line">release:3.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: 528144ec7ff0194a8b326491a396b8f5c87b1eaa</span><br><span class="line">add oceanbase-ce-libs-3.1.0-3.el7.x86_64.rpm to local mirror</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">admin@obdriver:~$ obd mirror list local</span><br><span class="line">+-------------------------------------------------------------------------------------------+</span><br><span class="line">|                                     local Package List                                    |</span><br><span class="line">+-------------------+---------+---------+--------+------------------------------------------+</span><br><span class="line">| name              | version | release | arch   | md5                                      |</span><br><span class="line">+-------------------+---------+---------+--------+------------------------------------------+</span><br><span class="line">| libobclient       | 2.0.0   | 2.el7   | x86_64 | f73cae67e2ff5be0682ac2803aba33a7ed26430e |</span><br><span class="line">| obclient          | 2.0.0   | 2.el7   | x86_64 | 1d2c3ee31f40b9d2fbf97f653f549d896b7e7060 |</span><br><span class="line">| ob-deploy         | 1.1.0   | 1.el7   | x86_64 | c01dbbebc7f44b700833ce6846df09f20033675c |</span><br><span class="line">| obproxy           | 3.1.0   | 1.el7   | x86_64 | 0b17cf0459a3b53c5a2febb6572894d183154c64 |</span><br><span class="line">| oceanbase-ce      | 3.1.0   | 3.el7   | x86_64 | b73bcd531bdf3f087391991b290ff2cbcdaa0dc9 |</span><br><span class="line">| oceanbase-ce-libs | 3.1.0   | 3.el7   | x86_64 | 528144ec7ff0194a8b326491a396b8f5c87b1eaa |</span><br><span class="line">+-------------------+---------+---------+--------+------------------------------------------+</span><br></pre></td></tr></table></figure><h3 id="下载配置文件"><a href="#下载配置文件" class="headerlink" title="下载配置文件"></a>下载配置文件</h3><p>到<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vYmRlcGxveS90cmVlL21hc3Rlci9leGFtcGxlL2F1dG9kZXBsb3k=">https://github.com/oceanbase/obdeploy/tree/master/example/autodeploy<i class="fa fa-external-link-alt"></i></span> 上将所有配置文件下载下来<br>当前有几个配置文件:<br>​</p><ul><li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vYmRlcGxveS9ibG9iL21hc3Rlci9leGFtcGxlL2F1dG9kZXBsb3kvZGlzdHJpYnV0ZWQtZXhhbXBsZS55YW1s">distributed-example.yaml<i class="fa fa-external-link-alt"></i></span>    :  分布式example</li><li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vYmRlcGxveS9ibG9iL21hc3Rlci9leGFtcGxlL2F1dG9kZXBsb3kvZGlzdHJpYnV0ZWQtd2l0aC1vYnByb3h5LWV4YW1wbGUueWFtbA==">distributed-with-obproxy-example.yaml<i class="fa fa-external-link-alt"></i></span>  : 分布式带obproxy的example</li><li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vYmRlcGxveS9ibG9iL21hc3Rlci9leGFtcGxlL2F1dG9kZXBsb3kvc2luZ2xlLWV4YW1wbGUueWFtbA==">single-example.yaml<i class="fa fa-external-link-alt"></i></span>  : 单机example</li><li><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vYmRlcGxveS9ibG9iL21hc3Rlci9leGFtcGxlL2F1dG9kZXBsb3kvc2luZ2xlLXdpdGgtb2Jwcm94eS1leGFtcGxlLnlhbWw=">single-with-obproxy-example.yaml<i class="fa fa-external-link-alt"></i></span>  : 单机example</li></ul><p>​</p><p>在本例中, 我们使用分布式example, 我们将分布式配置文件 scp到 主控机器上. </p><h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>本例中, 以distributed-with-obproxy-example.yaml为例</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">## Only need to configure when remote login is required</span><br><span class="line"># user:</span><br><span class="line">#   username: your username</span><br><span class="line">#   password: your password if need</span><br><span class="line">#   key_file: your ssh-key file path if need</span><br><span class="line">#   port: your ssh port, default 22</span><br><span class="line">#   timeout: ssh connection timeout (second), default 30</span><br><span class="line">oceanbase-ce:</span><br><span class="line">  servers:</span><br><span class="line">    - name: z1</span><br><span class="line">      # Please don&#x27;t use hostname, only IP can be supported</span><br><span class="line">      ip: 192.168.1.2</span><br><span class="line">    - name: z2</span><br><span class="line">      ip: 192.168.1.3</span><br><span class="line">    - name: z3</span><br><span class="line">      ip: 192.168.1.4</span><br><span class="line">  global:</span><br><span class="line">    # The working directory for OceanBase Database. OceanBase Database is started under this directory. This is a required field.</span><br><span class="line">    home_path: /root/observer</span><br><span class="line">    # The directory for data storage. The default value is $home_path/store.</span><br><span class="line">    # data_dir: /data</span><br><span class="line">    # The directory for clog, ilog, and slog. The default value is the same as the data_dir value.</span><br><span class="line">    # redo_dir: /redo</span><br><span class="line">    # External port for OceanBase Database. The default value is 2881.</span><br><span class="line">    # mysql_port: 2881</span><br><span class="line">    # Internal port for OceanBase Database. The default value is 2882.</span><br><span class="line">    # rpc_port: 2882</span><br><span class="line">    # Defines the zone for an observer. The default value is zone1.</span><br><span class="line">    # zone: zone1</span><br><span class="line">    # The maximum running memory for an observer. When ignored, autodeploy calculates this value based on the current server available resource.</span><br><span class="line">    # memory_limit: 58G</span><br><span class="line">    # The percentage of the maximum available memory to the total memory. This value takes effect only when memory_limit is 0. The default value is 80.</span><br><span class="line">    # memory_limit_percentage: 80 </span><br><span class="line">    # The reserved system memory. system_memory is reserved for general tenants. The default value is 30G. Autodeploy calculates this value based on the current server available resource.</span><br><span class="line">    # system_memory: 22G</span><br><span class="line">    # The size of a data file. When ignored, autodeploy calculates this value based on the current server available resource.</span><br><span class="line">    # datafile_size: 200G</span><br><span class="line">    # The percentage of the data_dir space to the total disk space. This value takes effect only when datafile_size is 0. The default value is 90.</span><br><span class="line">    # datafile_disk_percentage: 90</span><br><span class="line">    # System log level. The default value is INFO.</span><br><span class="line">    # syslog_level: INFO</span><br><span class="line">    # Print system logs whose levels are higher than WARNING to a separate log file. The default value is true. The default value for autodeploy mode is false.</span><br><span class="line">    # enable_syslog_wf: false</span><br><span class="line">    # Enable auto system log recycling or not. The default value is false. The default value for autodeploy mode is on.</span><br><span class="line">    # enable_syslog_recycle: true</span><br><span class="line">    # The maximum number of reserved log files before enabling auto recycling. When set to 0, no logs are deleted. The default value for autodeploy mode is 4.</span><br><span class="line">    # max_syslog_file_count: 4</span><br><span class="line">    # Cluster name for OceanBase Database. The default value is obcluster. When you deploy OceanBase Database and obproxy, this value must be the same as the cluster_name for obproxy.</span><br><span class="line">    # appname: obcluster</span><br><span class="line">    # Password for root. The default value is empty.</span><br><span class="line">    # root_password:</span><br><span class="line">    # Password for proxyro. proxyro_password must be the same as observer_sys_password. The default value is empty.</span><br><span class="line">    # proxyro_password:</span><br><span class="line">  z1:</span><br><span class="line">    zone: zone1</span><br><span class="line">  z2:</span><br><span class="line">    zone: zone2</span><br><span class="line">  z3:</span><br><span class="line">    zone: zone3</span><br><span class="line">obproxy:</span><br><span class="line">  servers:</span><br><span class="line">    - 192.168.1.5</span><br><span class="line">  global:</span><br><span class="line">    # The working directory for obproxy. Obproxy is started under this directory. This is a required field.</span><br><span class="line">    home_path: /root/obproxy</span><br><span class="line">    # External port. The default value is 2883.</span><br><span class="line">    # listen_port: 2883</span><br><span class="line">    # The Prometheus port. The default value is 2884.</span><br><span class="line">    # prometheus_listen_port: 2884</span><br><span class="line">    # rs_list is the root server list for observers. The default root server is the first server in the zone.</span><br><span class="line">    # The format for rs_list is observer_ip:observer_mysql_port;observer_ip:observer_mysql_port.</span><br><span class="line">    # Ignore this value in autodeploy mode.</span><br><span class="line">    # rs_list: 127.0.0.1:2881</span><br><span class="line">    # Cluster name for the proxy OceanBase Database. The default value is obcluster. This value must be set to the same with the appname for OceanBase Database.</span><br><span class="line">    # cluster_name: obcluster</span><br><span class="line">    # Password for obproxy system tenant. The default value is empty.</span><br><span class="line">    # obproxy_sys_password:</span><br><span class="line">    # Password for proxyro. proxyro_password must be the same with proxyro_password. The default value is empty.</span><br><span class="line">    # observer_sys_password:</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">## Only need to configure when remote login is required</span><br><span class="line"># user:</span><br><span class="line">#   username: your username</span><br><span class="line">#   password: your password if need</span><br><span class="line">#   key_file: your ssh-key file path if need</span><br><span class="line">#   port: your ssh port, default 22</span><br><span class="line">#   timeout: ssh connection timeout (second), default 30</span><br></pre></td></tr></table></figure><p>修改用户名和密码<br>​</p><p>通常这几个变量需要人肉设置一下, 每台机器的ip,  home_path, data_dir, redo_dir,  在本例中, 分别修改为&#x2F;home&#x2F;admin&#x2F;oceanbase&#x2F;ob, &#x2F;data&#x2F;ob, &#x2F;redo&#x2F;ob,  分别为之前挂载的磁盘. </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">oceanbase-ce:</span><br><span class="line">  servers:</span><br><span class="line">    - name: z1</span><br><span class="line">      # Please don&#x27;t use hostname, only IP can be supported</span><br><span class="line">      ip: 172.30.62.200</span><br><span class="line">    - name: z2</span><br><span class="line">      ip: 172.30.62.201</span><br><span class="line">    - name: z3</span><br><span class="line">      ip: 172.30.62.202</span><br><span class="line">  global:</span><br><span class="line">    # The working directory for OceanBase Database. OceanBase Database is started under this directory. This is a required field.</span><br><span class="line">    home_path: /home/admin/oceanbase/ob</span><br><span class="line">    # The directory for data storage. The default value is $home_path/store.</span><br><span class="line">    data_dir: /data/ob</span><br><span class="line">    # The directory for clog, ilog, and slog. The default value is the same as the data_dir value.</span><br><span class="line">    redo_dir: /redo/ob</span><br></pre></td></tr></table></figure><p>配置proxy,  修改ip 和home_path</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">obproxy:</span><br><span class="line">  servers:</span><br><span class="line">    - 172.30.62.203</span><br><span class="line">  global:</span><br><span class="line">    # The working directory for obproxy. Obproxy is started under this directory. This is a required field.</span><br><span class="line">    home_path: /home/admin/oceanbase</span><br></pre></td></tr></table></figure><p>另外推荐一个网站<span class="exturl" data-url="aHR0cHM6Ly93d3cuYmVqc29uLmNvbS92YWxpZGF0b3JzL3lhbWxfZWRpdG9yLw==">https://www.bejson.com/validators/yaml_editor&#x2F;<i class="fa fa-external-link-alt"></i></span>, 可以对配置文件进行yaml 检测, 很多时候, 配置文件 多一个空格, 少一个空格, 极难发现,<br>​</p><p>​</p><h3 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h3><p>对于离线安装, 需要执行一步操作, 当连不上服务器, 需要把远程的repo 配置给删掉, 避免浪费时间消耗在连接远程的repo 之上. </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -fr ~/.obd/mirror/remote/*.repo</span><br></pre></td></tr></table></figure><p>开始安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">admin@obdriver:~$ obd cluster autodeploy obtest -c distributed-with-obproxy-example.yaml </span><br></pre></td></tr></table></figure><p>检查安装是否成功</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">admin@obdriver:~$ obd cluster list</span><br><span class="line">+------------------------------------------------------------+</span><br><span class="line">|                        Cluster List                        |</span><br><span class="line">+--------+---------------------------------+-----------------+</span><br><span class="line">| Name   | Configuration Path              | Status (Cached) |</span><br><span class="line">+--------+---------------------------------+-----------------+</span><br><span class="line">| obtest | /home/admin/.obd/cluster/obtest | running         |</span><br><span class="line">+--------+---------------------------------+-----------------+</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">admin@obdriver:~$ obd cluster display obtest</span><br><span class="line">Get local repositories and plugins ok</span><br><span class="line">Open ssh connection ok</span><br><span class="line">Cluster status check ok</span><br><span class="line">Connect to observer ok</span><br><span class="line">Wait for observer init ok</span><br><span class="line">+-------------------------------------------------+</span><br><span class="line">|                     observer                    |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line">| ip            | version | port | zone  | status |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line">| 172.30.62.200 | 3.1.0   | 2881 | zone1 | active |</span><br><span class="line">| 172.30.62.201 | 3.1.0   | 2881 | zone2 | active |</span><br><span class="line">| 172.30.62.202 | 3.1.0   | 2881 | zone3 | active |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line"></span><br><span class="line">Connect to obproxy ok</span><br><span class="line">+-------------------------------------------------+</span><br><span class="line">|                     obproxy                     |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br><span class="line">| ip            | port | prometheus_port | status |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br><span class="line">| 172.30.62.203 | 2883 | 2884            | active |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br></pre></td></tr></table></figure><h2 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h2><p>OceanBase 数据库有数百个配置项，有些配置是耦合的，在您熟悉 OceanBase 数据库之前，不建议您修改示例配件文件中的配置。此处示例用来说明如何修改配置，并使之生效。<br>​</p><p>所有的参数介绍请参考</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://github.com/oceanbase/obdeploy/blob/master/plugins/oceanbase/3.1.0/parameter.yaml</span><br></pre></td></tr></table></figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># 使用 edit-config 命令进入编辑模式，修改集群配置</span><br><span class="line">obd cluster edit-config lo</span><br><span class="line"># 修改 sys_bkgd_migration_retry_num 为 5</span><br><span class="line"># 注意 sys_bkgd_migration_retry_num 值最小为 3</span><br><span class="line"># 保存并退出后，OBD 会告知您如何使得此次改动生效</span><br><span class="line"># 此配置项仅需要 reload 即可生效</span><br><span class="line">obd cluster reload lo</span><br></pre></td></tr></table></figure><h1 id="验证​"><a href="#验证​" class="headerlink" title="验证​"></a>验证​</h1><h2 id="安装obclient"><a href="#安装obclient" class="headerlink" title="安装obclient"></a>安装obclient</h2><p>通常在主控机器上安装obclient,  需要切换到root 账号</p><h3 id="在线安装-2"><a href="#在线安装-2" class="headerlink" title="在线安装"></a>在线安装</h3><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install -y libobclient</span><br><span class="line">yum install -y obclient</span><br></pre></td></tr></table></figure><h3 id="本地安装-2"><a href="#本地安装-2" class="headerlink" title="本地安装"></a>本地安装</h3><p>​</p><p>centos或redhat或anolis</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">yum install libobclient-2.0.0-2.el7.x86_64.rpm</span><br><span class="line">yum install obclient-2.0.0-2.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><p>Ubuntu&#x2F;Debian</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">alien -i libobclient-2.0.0-2.el7.x86_64.rpm</span><br><span class="line">alien -i obclient-2.0.0-2.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><p>在debian 下需要把路径设置到系统环境变量中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/app/mariadb/bin:$PATH</span><br></pre></td></tr></table></figure><p>​</p><p>在ubuntu下需要把路径设置到系统环境变量中</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export PATH=/u01/obclient/bin:$PATH</span><br></pre></td></tr></table></figure><p>​</p><p>​</p><h2 id="安装mysql-开发包"><a href="#安装mysql-开发包" class="headerlink" title="安装mysql 开发包"></a>安装mysql 开发包</h2><p>如果需要运行sysbench, 或者tpch 等程序, 需要安装mysql 开发包</p><p>​</p><p>centos或redhat或anolis</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install mariadb</span><br><span class="line">yum install mariadb-libs</span><br><span class="line">yum install mariadb-devel</span><br></pre></td></tr></table></figure><p>Ubuntu</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install mariadb-server</span><br></pre></td></tr></table></figure><p>Debian</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install mysql-server mysql-client libmariadbd18 libmariadbd-dev</span><br></pre></td></tr></table></figure><h2 id="检查租户"><a href="#检查租户" class="headerlink" title="检查租户"></a>检查租户</h2><p>使用oceanbase, 需要创建租户, 用户真正应用必须运行在租户下<br>创建租户有2种方式:<br>可以使用obd 来创建租户, 使用obd 创建租户时, 会把所有的资源</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">obd cluster tenant create $&#123;cluster_name&#125; -n $&#123;tenant_name&#125;</span><br></pre></td></tr></table></figure><p>​</p><p>创建租户, 请参考<br><span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vZG9jcy9jb21tdW5pdHkvb2NlYW5iYXNlLWRhdGFiYXNlL1YzLjEuMC9jcmVhdGUtYS11c2VyLXRlbmFudA==">https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/create-a-user-tenant<i class="fa fa-external-link-alt"></i></span><br>​</p><p>在本例中:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">admin@obdriver:~$ mysql -h$&#123;obproxy_ip&#125; -P$&#123;obproxy_port&#125; -uroot</span><br><span class="line">Welcome to the MariaDB monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 2</span><br><span class="line">Server version: 5.6.25 OceanBase 3.1.0 (r3-b20901e8c84d3ea774beeaca963c67d7802e4b4e) (Built Aug 10 2021 07:51:04)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">MySQL [(none)]&gt; use oceanbase;</span><br><span class="line">Reading table information for completion of table and column names</span><br><span class="line">You can turn off this feature to get a quicker startup with -A</span><br><span class="line"></span><br><span class="line">Database changed</span><br><span class="line">MySQL [oceanbase]&gt; select * from gv$tenant;</span><br><span class="line">+-----------+-------------+-------------------+-------------------+----------------+---------------+-----------+---------------------------------------------+</span><br><span class="line">| tenant_id | tenant_name | zone_list         | primary_zone      | collation_type | info          | read_only | locality                                    |</span><br><span class="line">+-----------+-------------+-------------------+-------------------+----------------+---------------+-----------+---------------------------------------------+</span><br><span class="line">|         1 | sys         | zone1;zone2;zone3 | zone1;zone2,zone3 |              0 | system tenant |         0 | FULL&#123;1&#125;@zone1, FULL&#123;1&#125;@zone2, FULL&#123;1&#125;@zone3 |</span><br><span class="line">|      1001 | mytest      | zone1;zone2;zone3 | RANDOM            |              0 |               |         0 | FULL&#123;1&#125;@zone1, FULL&#123;1&#125;@zone2, FULL&#123;1&#125;@zone3 |</span><br><span class="line">+-----------+-------------+-------------------+-------------------+----------------+---------------+-----------+---------------------------------------------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">MySQL [(none)]&gt;</span><br></pre></td></tr></table></figure><p>​</p><h1 id="企业用户最佳实践"><a href="#企业用户最佳实践" class="headerlink" title="企业用户最佳实践"></a>企业用户最佳实践</h1><h2 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h2><p>ob  运行日志, 事务日志, 数据文件 必须独立开, 如果没有3块盘支持, 则可以一块盘分3块分区<br>​</p><h2 id="时钟依赖"><a href="#时钟依赖" class="headerlink" title="时钟依赖"></a>时钟依赖</h2><p>OceanBase 集群中各服务器的时间需保持一致，否则会导致 OceanBase 集群无法启动，运行时也会出现故障。对于企业用户来说, 时钟同步是<strong>非常非常重要</strong>, 物理机与时钟服务器的误差在 50ms 以下可认为时钟是同步状态 , 最大容忍误差不能超过200ms. 当超过200ms, 会出现无主状况, 恢复时钟同步后, 重启observer, 可以恢复状态.<br>​</p><h2 id="网络时延"><a href="#网络时延" class="headerlink" title="网络时延"></a>网络时延</h2><p>server间的网络时延不能超过200ms，否则同步会严重滞后, 并且可能影响选举<br>网卡设置<br>建议配置2块万兆网卡，bond模式取名bond0，mode1或mode4均可以，推荐使用mode4，如果是mode4，交换机需要配置802.3ad。网卡名建议使用eth0，eth1。建议使用network服务，不要使用NetworkManager。</p><h2 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h2><ul><li><p>当系统写入tps 过高时, 超过系统支撑能力时, 为防止系统停止响应</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">alter system set writing_throttling_trigger_percentage=75 tenant=all(或者具体tenantname);</span><br></pre></td></tr></table></figure></li><li><p>除非业务应用有配置重连尝试，否则建议关闭轮转合并, 切主也不能保证不杀事务</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER SYSTEM SET enable_merge_by_turn = &#x27;False&#x27;;</span><br></pre></td></tr></table></figure></li><li><p>内存设置</p><ul><li>租户的cpu和内存规格比建议不低于1:4,否则容易oom； </li><li>普通租户最小内存规格暂定5G以上；</li><li>租户内存太小时建议调大ob_sql_work_area_percentage，默认值5%，租户内存小于10G建议配20%左右；</li><li>partition 个数限制, 单机建议不要超过10万个分区, 另外partition 数量会受内存限制,  每个副本预留内存为168KB，因此10000个副本至少需要预留1.68G内存，或者说1G的租户最多能建6k左右个partition，需要根据partition数的规划设置租户内存；另外单机. </li><li>物理内存使用限制，默认为80，memstore内存可用百分比，建议服务器内存256G以上配置调整为90，256G以下保持默认50<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER SYSTEM SET memstore_limit_percentage = &#x27;90&#x27;;</span><br></pre></td></tr></table></figure></li></ul></li></ul><p>​</p><ul><li><p>slow query阈值调整 trace_log_slow_query_watermark 默认100ms，可以根据业务特点调整。如果阈值设置的太小，打印大量trace日志会影响性能.MySQL  默认值是1s. 大查询时间为10s</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">ALTER SYSTEM SET trace_log_slow_query_watermark = &#x27;1s&#x27;;</span><br><span class="line">ALTER SYSTEM SET large_query_threshold = &#x27;10s&#x27;;</span><br></pre></td></tr></table></figure><p>​</p></li><li><p>cpu 并发度调整</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- CPU并发度参数，建议配置为4，arm系统为2</span><br><span class="line">ALTER SYSTEM SET cpu_quota_concurrency = &#x27;4&#x27;;</span><br><span class="line"></span><br><span class="line">-- 资源软负载开关，控制资源均衡水位，默认为50%，即CPU内存使用超过50%就进行unit均衡，线上建议调整为100，达到手工控制unit分布的效果</span><br><span class="line">ALTER SYSTEM SET resource_soft_limit = &#x27;100&#x27;;</span><br></pre></td></tr></table></figure></li><li><p>转储合并相关</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">-- 配置转储50次</span><br><span class="line">ALTER SYSTEM SET minor_freeze_times = 50;</span><br><span class="line"></span><br><span class="line">-- 转储触发水位百分比，建议256G以上配置调整为70，256G以下调整为60</span><br><span class="line">ALTER SYSTEM SET freeze_trigger_percentage = &#x27;60&#x27;;</span><br><span class="line"></span><br><span class="line">-- 数据拷贝并发为100</span><br><span class="line">ALTER SYSTEM SET data_copy_concurrency = 100;</span><br><span class="line">-- 服务器上数据传出并发为10</span><br><span class="line">ALTER SYSTEM SET server_data_copy_out_concurrency = 10;</span><br><span class="line">-- 服务器上数据传入并发为10</span><br><span class="line">ALTER SYSTEM SET server_data_copy_in_concurrency = 10;</span><br><span class="line"></span><br><span class="line">-- 转储预热时间，默认30s，设置了会延后转储释放的时间，改成0s</span><br><span class="line">ALTER SYSTEM SET minor_warm_up_duration_time = &#x27;0s&#x27;;</span><br><span class="line">-- 配置chunk内存大小(建议保持默认值0，ob自行分配)</span><br><span class="line">ALTER SYSTEM SET memory_chunk_cache_size = 0;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-- 最大包括版本数量，影响磁盘可用空间，默认为2，将多保留一个版本的数据在数据盘中，需调整为1</span><br><span class="line">ALTER SYSTEM SET max_kept_major_version_number = &#x27;1&#x27;;</span><br><span class="line">ALTER SYSTEM SET max_stale_time_for_weak_consistency = &#x27;2h&#x27;;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>​</p></li><li><p>事务相关</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ALTER SYSTEM SET clog_sync_time_warn_threshold = &#x27;1s&#x27;;</span><br><span class="line">ALTER SYSTEM SET trx_try_wait_lock_timeout = &#x27;0ms&#x27;;（默认就是 0ms，无需修改）</span><br><span class="line"></span><br><span class="line">-- 建议关闭一阶段提交，该参数值默认是false</span><br><span class="line">ALTER SYSTEM SET enable_one_phase_commit=&#x27;False&#x27;;</span><br></pre></td></tr></table></figure></li><li><p>分区迁移速度控制, 若是集群负载很低，可以通过加大并发任务数加快 partition迁移速度, 调大迁移并发数</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">alter system set data_copy_concurrency=40;</span><br><span class="line">alter system set server_data_copy_out_concurrency=20;</span><br><span class="line">alter system set server_data_copy_in_concurrency=20;</span><br></pre></td></tr></table></figure></li><li><p>压缩相关</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- （默认就是 zstd_1.0，无需修改）, 不过系统支持多种压缩算法</span><br><span class="line">ALTER SYSTEM SET default_compress_func = &#x27;zstd_1.0&#x27;;</span><br></pre></td></tr></table></figure><p>​</p></li><li><p>cache 刷新相关</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER SYSTEM SET autoinc_cache_refresh_interval = &#x27;43200s&#x27;;</span><br></pre></td></tr></table></figure></li><li><p>prepare statement, server端ps受_ob_enable_prepared_statement开关控制，除了objdbc和oci的用户可以按照文档提供的说明使用server端ps，其他情况不建议用了；</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">-- Prepared Statement参数，不用java建联的配置建议设为0</span><br><span class="line">ALTER SYSTEM SET _ob_enable_prepared_statement = 0;</span><br></pre></td></tr></table></figure></li><li><p>系统相关</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">ALTER SYSTEM SET server_permanent_offline_time = &#x27;7200s&#x27;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-- （公有云建议5M，外部环境建议5M，否则建议默认值30M）</span><br><span class="line">ALTER SYSTEM SET syslog_io_bandwidth_limit = &#x27;5M&#x27;;</span><br></pre></td></tr></table></figure></li><li><p>集群升级策略, 在进行版本升级，机器临时上下线，可以先进行一次转储，可以减少启动observer时候恢复时间</p></li><li><p>批量导入大量数据最佳策略, 如果集群是多租户的，如果某个租户要大批量导入数据，为避免影响其他租户, 导完数据后可以恢复以上两个参数: </p><ul><li>1.调整 cpu_quota_concurrency &#x3D;1 ，防止租户间cpu抢占</li><li>开启多轮转储减少合并触发，这样可以提高导入速度</li></ul></li></ul><p>​</p><ul><li>租户primary_zone配置, <ul><li><p>primar_zone配置到具体某个zone中, 适用场景：业务使用单表、zone_name1与应用在同机房、zone_name2和zone_name3作为从副本平时无业务流量，具体zone顺序需按机房优先级、按应用和ob的机房配置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TENANT SET PRIMARY_ZONE = &#x27;zone_name1;zone_name2,zone_name3&#x27;;</span><br></pre></td></tr></table></figure></li><li><p>打散primary_zone到所有全功能zone中, 使用场景：业务使用分区表、集群中所有副本都在同一机房或不同zone机房间网络延迟在1ms内，需要所有副</p></li></ul></li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ALTER TENANT SET PRIMARY_ZONE = &#x27;zone_name1,zone_name2,zone_name3&#x27;;</span><br></pre></td></tr></table></figure><h3 id="租户设置"><a href="#租户设置" class="headerlink" title="租户设置"></a>租户设置</h3><ul><li><p>并发度设置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">-- 最大并发度，默认32，有大查询业务的建议调整为128</span><br><span class="line">SET GLOBAL ob_max_parallel_degree = 128;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line">parallel_max_servers 推荐设置为测试租户分配的 resource unit cpu 数的 10 倍</span><br><span class="line">如测试租户使用的 unit 配置为：create resource unit $unit_name max_cpu 26</span><br><span class="line">那么该值设置为 260</span><br><span class="line">parallel_server_target 推荐设置为 parallel_max_servers * 机器数*0.8</span><br><span class="line">那么该值为 260*3*0.8=624</span><br><span class="line">*/</span><br><span class="line">set global parallel_max_servers=260;</span><br><span class="line">set global parallel_servers_target=624;</span><br></pre></td></tr></table></figure></li><li><p>回收站设置</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-- 回收站参数，ddl执行频率过大的场景一定要关闭，避免ddl执行过多引起租户性能异常</span><br><span class="line">SET GLOBAL recyclebin = 0;</span><br><span class="line"></span><br><span class="line">-- truncate回滚参数，truncate执行频率过大的场景一定要关闭</span><br><span class="line">SET GLOBAL ob_enable_truncate_flashback = 0;</span><br></pre></td></tr></table></figure></li><li><p>客户端命令长度,  OB客户端可发的命令长度受限于租户系统变量_max_allowed_packet_的限制（缺省4M),可以酌情调大；</p></li></ul><h3 id="obproxy配置"><a href="#obproxy配置" class="headerlink" title="obproxy配置"></a>obproxy配置</h3><ul><li>obproxy探活<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">alter proxyconfig set sock_option_flag_out = 2;  --  2代表keepalive</span><br><span class="line">alter proxyconfig set server_tcp_keepidle = 5;  --  启动keepalive探活前的idle时间，5秒。</span><br><span class="line">alter proxyconfig set server_tcp_keepintvl = 5;  -- 两个keepalive探活包之间的时间间隔，5秒</span><br><span class="line">alter proxyconfig set server_tcp_keepcnt = 2;  --  最多发送多少个keepalive包，2个。最长5+5*2=15秒发现dead_socket。</span><br><span class="line">alter proxyconfig set server_tcp_user_timeout = 5;  --  等待TCP层ACK确认消息的超时时长，5秒。</span><br></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <summary type="html">OceanBase 入门 -- 离线安装</summary>
    
    
    
    <category term="OceanBase" scheme="http://ilongda.com/categories/OceanBase/"/>
    
    <category term="DBA" scheme="http://ilongda.com/categories/OceanBase/DBA/"/>
    
    
    <category term="OceanBase" scheme="http://ilongda.com/tags/OceanBase/"/>
    
  </entry>
  
  <entry>
    <title>《OceanBase开发者手册》之五 如何debug OceanBase</title>
    <link href="http://ilongda.com/2021/debug_ob/"/>
    <id>http://ilongda.com/2021/debug_ob/</id>
    <published>2021-11-11T11:42:57.000Z</published>
    <updated>2024-02-02T12:53:50.816Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>《OceanBase开发者手册》 主要指导开发者如何参与到OceanBase 的研发, 铺平参与OceanBase 开发的准备工作遇到的问题, 当前章节大概这几篇文章, 未来可能会增加部分文章, 目前OceanBase 源码参考OceanBase 开源官网的<span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vYXJ0aWNsZXMvODYwMDEyOQ==">《开源数据库OceanBase源码解读》 系列<i class="fa fa-external-link-alt"></i></span> :</p><ol><li>如何编译OceanBase源码</li><li>如何设置IDE开发环境</li><li>如何成为OceanBase Contributor</li><li>如何修改OceanBase文档</li><li>如何debug OceanBase</li><li>如何运行测试</li><li>如何修bug<br>​</li></ol><p>本文将介绍如何debug OceanBase, 如何debug OceanBase, 推荐几种方式:</p><ol><li>使用vscode 远程debug OceanBase</li><li>使用gdb 本地debug OceanBase</li><li>在linux 环境下, 使用CLion 本地debug OceanBase</li></ol><span id="more"></span><p>​</p><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>debug OceanBase 有一个重要的步骤, 就是弄到oceanbase 的启动参数, 每台机器有每台机器的硬件配置, 也会导致启动参数是不一样的. 但做法基本类似. </p><ol><li>用OBD (<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vYmRlcGxveQ==">https://github.com/oceanbase/obdeploy<i class="fa fa-external-link-alt"></i></span>) 安装部署一套环境 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1. 单机部署并且是联网环境, 请参考文档https://open.oceanbase.com/quickStart</span><br><span class="line">2. 分布式环境或者离线部署, 请参考文档 https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.1/deploy-the-distributed-oceanbase-cluster</span><br></pre></td></tr></table></figure></li><li>成功部署环境后, 编译debug 版本OceanBase 参考之前文档 《如何编译OceanBase源码》</li><li>捕获oceanbase 的启动参数 (通过‘ps -ef|grep observer’).</li><li>(可选)在分布式环境下, 用编译好的binary observer 去替换 用obd 安装部署的observer</li></ol><p>我在我的单机测试环境下, 我用OBD安装部署OceanBase后, 我的OceanBase的启动参数是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">observer -r xxx.xxx.xxx.xxx:2882:2881 -o __min_full_resource_pool_memory=268435456,enable_syslog_recycle=True,enable_syslog_wf=True,max_syslog_file_count=4,memory_limit=69G,system_memory=27G,cpu_count=19,datafile_size=1029G,clog_disk_utilization_threshold=95,clog_disk_usage_limit_percentage=98 -z zone1 -p 2881 -P 2882 -n obcluster -c 1 -d /home/xxxxxxx/observer/store -i em1 -l INFO</span><br></pre></td></tr></table></figure><h2 id="vscode-调试"><a href="#vscode-调试" class="headerlink" title="vscode 调试"></a>vscode 调试</h2><ol><li><p>搭建remote 链接环境</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1.1 建立开发机到测试机的信任登录, 参考 文档 https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.1/optional-set-password-free-ssh-logon</span><br><span class="line">1.2 搭建vscode 的remote debug 环境  “Remote-SSH: Connect to Host...”, 参考文章 https://blog.csdn.net/zbbzb/article/details/102957076/ 进行配置</span><br></pre></td></tr></table></figure></li><li><p>remote ssh 连接远程机器 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Ctril + p</span><br><span class="line">选择Remote-SSH:Connect to Host</span><br></pre></td></tr></table></figure></li><li><p>打开对应的源码目录</p></li><li><p>参考之前文章 介绍 《如何编译OceanBase源码》</p></li><li><p>设置debug 启动参数, 在菜单栏  “Run” –&gt; “Add Configuration”, 如果之前已经设置过, 修改启动参数就是 菜单栏 “Run” –&gt; “Open Configurations”</p></li></ol><p>我的 配置是</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    // Use IntelliSense to learn about possible attributes.</span><br><span class="line">    // Hover to view descriptions of existing attributes.</span><br><span class="line">    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387</span><br><span class="line">    &quot;version&quot;: &quot;0.2.0&quot;,</span><br><span class="line">    &quot;configurations&quot;: [</span><br><span class="line">    </span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;observer&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;cppdbg&quot;,</span><br><span class="line">            &quot;request&quot;: &quot;launch&quot;,</span><br><span class="line">            &quot;program&quot;: &quot;$&#123;OB_SRC_DIR&#125;/build_debug/src/observer/observer&quot;,</span><br><span class="line">            &quot;args&quot;: [&quot;-r&quot;, &quot;$&#123;IP&#125;:2882:2881&quot;, &quot;-o&quot;, &quot;__min_full_resource_pool_memory=268435456,enable_syslog_recycle=True,enable_syslog_wf=True,max_syslog_file_count=4,memory_limit=69G,system_memory=27G,cpu_count=19,datafile_size=1029G,clog_disk_utilization_threshold=95,clog_disk_usage_limit_percentage=98&quot;, &quot;-z&quot;, &quot;zone1&quot;, &quot;-p&quot;, &quot;2881&quot;, &quot;-P&quot;, &quot;2882&quot;, &quot;-n&quot;, &quot;obcluster&quot;, &quot;-c&quot;, 1, &quot;-d&quot;, &quot;/home/XXX/observer/store&quot;, &quot;-i&quot;, &quot;em1&quot;, &quot;-l&quot;, &quot;INFO&quot;],</span><br><span class="line">            &quot;stopAtEntry&quot;: true,</span><br><span class="line">            &quot;cwd&quot;: &quot;$&#123;OB_SRC_DIR&#125;&quot;,</span><br><span class="line">            &quot;environment&quot;: [],</span><br><span class="line">            &quot;externalConsole&quot;: false,</span><br><span class="line">            &quot;MIMode&quot;: &quot;gdb&quot;,</span><br><span class="line">            &quot;setupCommands&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;,</span><br><span class="line">                    &quot;text&quot;: &quot;-enable-pretty-printing&quot;,</span><br><span class="line">                    &quot;ignoreFailures&quot;: true</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>备注: 这个里面有arg的参数来自于第一步的准备工作中获取的启动参数, 每台机器有每台机器的配置, 笔者的参数如下, 其中:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. $&#123;OB_SRC_DIR&#125; 为源码目录, $&#123;IP&#125; 为observer 的绑定ip</span><br><span class="line">2. 需要设置“cwd”, 为$&#123;OB_SRC_DIR&#125;</span><br><span class="line">3. 建议设置“stopAtEntry” 为true</span><br><span class="line">4. 在args 参数中, 其中 -d 设置的目录 &quot;/home/xxxxx/observer/store&quot;, 需要设置为真实的参数</span><br><span class="line">5. 在args 参数中, 其中-i 设置的设备名称 &quot;em1&quot;, 为ip 对应的设备名称</span><br></pre></td></tr></table></figure><ol start="6"><li>开始debug, 点击菜单 “Run” –&gt; “Start Debugging”.</li></ol><h2 id="直接用gdb-本地调试"><a href="#直接用gdb-本地调试" class="headerlink" title="直接用gdb 本地调试"></a>直接用gdb 本地调试</h2><ol><li><p>登录remote 机器, 并进入${OB_SRC_DIR} 源码目录</p></li><li><p>参考之前文章 介绍 《如何编译OceanBase源码》</p></li><li><p>修改 用户目录下的.gdbinit, 添加下面一行, 其中${OB_SRC_DIR}需要换成OB 源码根目录</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add-auto-load-safe-path $&#123;OB_SRC_DIR&#125;/.gdbinit</span><br></pre></td></tr></table></figure></li><li><p>vi ${OB_SRC_DIR}&#x2F;.gdbinit</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">file build_debug/src/observer/observer</span><br><span class="line">set args &quot;-r&quot;, &quot;XXX.XXX.XXX.XXX:2882:2881&quot;, &quot;-o&quot;, &quot;__min_full_resource_pool_memory=268435456,enable_syslog_recycle=True,enable_syslog_wf=True,max_syslog_file_count=4,memory_limit=69G,system_memory=27G,cpu_count=19,datafile_size=1029G,clog_disk_utilization_threshold=95,clog_disk_usage_limit_percentage=98&quot;, &quot;-z&quot;, &quot;zone1&quot;, &quot;-p&quot;, &quot;2881&quot;, &quot;-P&quot;, &quot;2882&quot;, &quot;-n&quot;, &quot;obcluster&quot;, &quot;-c&quot;, 1, &quot;-d&quot;, &quot;/home/longda/observer/store&quot;, &quot;-i&quot;, &quot;em1&quot;, &quot;-l&quot;, &quot;INFO&quot;</span><br><span class="line">b main</span><br><span class="line">r</span><br></pre></td></tr></table></figure></li></ol><p>备注: 这个里面有args的参数来自于第一步的准备工作中获取的启动参数, 每台机器有每台机器的配置, 笔者的参数如下, 其中:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1. $&#123;OB_SRC_DIR&#125; 为源码目录, $&#123;IP&#125; 为observer 的绑定ip</span><br><span class="line">2. 需要设置“cwd”, 为$&#123;OB_SRC_DIR&#125;</span><br><span class="line">3. 当前的工作目录必须是$&#123;OB_SRC_DIR&#125;</span><br><span class="line">4. 在args 参数中, 其中 -d 设置的目录 &quot;/home/xxxxx/observer/store&quot;, 需要设置为真实的参数</span><br><span class="line">5. 在args 参数中, 其中-i 设置的设备名称 &quot;em1&quot;, 为ip 对应的设备名称</span><br></pre></td></tr></table></figure><ol start="5"><li>推荐使用tui<br>tui是gdb自带的图形界面，比较直观，这里简单说一下切换方法和常用命令<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">1、gdb -tui + (可执行程序)  直接进入tui图形界面</span><br><span class="line"></span><br><span class="line">2、gdb进入后，使用命令focus进入tui图形界面，或者使用快捷键：Ctl+x+a (注意按键顺序，记忆：x：focus，a：another)</span><br><span class="line"></span><br><span class="line">3、在tui中使用相同的快捷键Ctl+x+a返回到gdb原生界面</span><br><span class="line"></span><br><span class="line">4、在gdb中↑和↓切换上一个命令和下一个命令，但是在tui中只是控制代码视图。想达到切换命令的目的，使用Ctl+n （记忆：next）和Ctl+p（记忆：previous），这其实就是gdb的原生快捷键</span><br></pre></td></tr></table></figure></li><li>在源码目录下, 敲入gdb 即可启动gdb debug</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gdb </span><br></pre></td></tr></table></figure><h2 id="clion-本地调试"><a href="#clion-本地调试" class="headerlink" title="clion 本地调试"></a>clion 本地调试</h2><p>clion 看源码非常方便， symbol 跳转非常友好， 而且天然code format 支持clang-format。 不过， 我没有试过clion 远程debug， 只试过本地clion debug， 不过如果想用clion 本地debug oceanbase， 则开发机器得运行linux。<br>clion 是debug 中最舒服的方式， 但也是最复杂的方式， 要求也非常高</p><ol><li>参考之前文章 介绍 《如何编译OceanBase源码》</li><li>配置 clion的cmake<img data-src="/img/ob/clion_debug1.png" ></li></ol><p>详情步骤参考图片所示， 需要说明的是， </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&quot;Build Directory&quot; 需要设置为“build_debug”</span><br><span class="line">&quot;CMake options&quot; 需要设置为“$&#123;OB_SRC_DIR&#125; -DCMAKE_BUILD_TYPE=Debug”, 其中$&#123;OB_SRC_DIR&#125; 需要修改为真实的目录全路径</span><br></pre></td></tr></table></figure><ol start="3"><li>等待几分钟生成cmake 生成结束后， 点击菜单“Run” –》 “Edit configurations”, 也可以类似下面图片， 进行选择编译目标observer</li></ol><img data-src="/img/ob/clion_debug2.JPG" ><ol start="4"><li><p>点击菜单“Build” –》 “Build observer”， 编译observer</p></li><li><p>修改启动参数， 点击菜单“Run” –》 “Edit configurations”， 出现界面后</p></li></ol><img data-src="/img/ob/clion_debug3.JPG" ><p>在我的机器上”Program Arguements” 为</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-r $&#123;ip&#125;:2882:2881 -o __min_full_resource_pool_memory=268435456,enable_syslog_recycle=True,enable_syslog_wf=True,    max_syslog_file_count=4,memory_limit=8G,system_memory=4G,cpu_count=16,datafile_size=44G,clog_disk_utilization_threshold=95,clog_disk_usage_limit_percentage=98 -z zone1 -p 2881 -P 2882 -n obcluster -c 1 -d $&#123;data_dir&#125; -i $&#123;devname&#125; -l INFO</span><br></pre></td></tr></table></figure><p>${ip} : 为本机ip</p><p>${data_dir}: 为数据目录</p><p>${devname}： 为ip 所对应的网卡名称， 通常为eth0 或lo</p><p>在“Woring Directory”必须为${OB_SRC_DIR}</p><ol start="6"><li><p>打开文件src&#x2F;observer&#x2F;main.cpp, 在main 函数下断点</p></li><li><p>启动debug， 点击菜单”Run” –&gt; “Debug Observer”</p></li></ol>]]></content>
    
    
    <summary type="html">《OceanBase开发者手册》之五 如何debug OceanBase</summary>
    
    
    
    <category term="OceanBase" scheme="http://ilongda.com/categories/OceanBase/"/>
    
    <category term="开发者手册" scheme="http://ilongda.com/categories/OceanBase/%E5%BC%80%E5%8F%91%E8%80%85%E6%89%8B%E5%86%8C/"/>
    
    
    <category term="OceanBase" scheme="http://ilongda.com/tags/OceanBase/"/>
    
  </entry>
  
  <entry>
    <title>《OceanBase开发者手册》之四 如何修改OceanBase文档</title>
    <link href="http://ilongda.com/2021/modify_ob_docs/"/>
    <id>http://ilongda.com/2021/modify_ob_docs/</id>
    <published>2021-11-10T11:42:57.000Z</published>
    <updated>2024-02-02T13:00:56.149Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>《OceanBase开发者手册》 主要指导开发者如何参与到OceanBase 的研发, 铺平参与OceanBase 开发的准备工作遇到的问题, 当前章节大概这几篇文章, 未来可能会增加部分文章, 目前OceanBase 源码参考OceanBase 开源官网的<span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vYXJ0aWNsZXMvODYwMDEyOQ==">《开源数据库OceanBase源码解读》 系列<i class="fa fa-external-link-alt"></i></span> :</p><ol><li>如何编译OceanBase源码</li><li>如何设置IDE开发环境</li><li>如何成为OceanBase Contributor</li><li>如何修改OceanBase文档</li><li>如何debug OceanBase</li><li>如何运行测试</li><li>如何修bug<br>​</li></ol><p>在OceanBase 修改文档的过程, 和修改代码的过程完全一样, 可以参考《如何成为OceanBase Contributor》直接修改文档, 如果不做文档修改的预览, 比如直接修改少量的错别字, 可以直接修改, 但如果增加大段文字或新增文章, 建议做预览一下. 那在这种情况下, 需要看看, 修改的效果如何. 可以安装mkdocs, 对修改的效果进行预览. </p><span id="more"></span><p>​</p><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h1 id="Build-documentation-with-MkDocs"><a href="#Build-documentation-with-MkDocs" class="headerlink" title="Build documentation with MkDocs"></a>Build documentation with MkDocs</h1><p>OceanBase documentation is built with <span class="exturl" data-url="aHR0cHM6Ly93d3cubWtkb2NzLm9yZy8=">MkDocs<i class="fa fa-external-link-alt"></i></span>. You can check <a href="mkdocs.yml"><code>mkdocs.yml</code></a> for more information.<br>Please install MkDocs according to <span class="exturl" data-url="aHR0cHM6Ly93d3cubWtkb2NzLm9yZy91c2VyLWd1aWRlL2luc3RhbGxhdGlvbi8=">the installation documents of MkDocs<i class="fa fa-external-link-alt"></i></span></p><h2 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h2><p>Before installing dependencies, please make sure you have installed a recent version of Python 3 and pip.</p><p>Then you can run the following command in your terminal at current directory:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ pip install -r requirements.txt</span><br><span class="line">$ pip install mkdocs-material</span><br></pre></td></tr></table></figure><h2 id="Build-the-documentation"><a href="#Build-the-documentation" class="headerlink" title="Build the documentation"></a>Build the documentation</h2><p>You can build the documentation by running the following command:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkdocs build</span><br></pre></td></tr></table></figure><p>This will create a new directory to store the output files, which is <code>site/</code> by default.</p><h2 id="Start-a-server-locally"><a href="#Start-a-server-locally" class="headerlink" title="Start a server locally"></a>Start a server locally</h2><p>You can start a server locally by running the following command:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ mkdocs serve</span><br></pre></td></tr></table></figure><p>Open up <span class="exturl" data-url="aHR0cDovLzEyNy4wLjAuMTo4MDAwLw==">http://127.0.0.1:8000/<i class="fa fa-external-link-alt"></i></span> in your browser, and you’ll see the default home page.</p><h2 id="Modify-pages"><a href="#Modify-pages" class="headerlink" title="Modify pages"></a>Modify pages</h2><h3 id="Edit-a-page"><a href="#Edit-a-page" class="headerlink" title="Edit a page"></a>Edit a page</h3><p>If you want to modify the content of a page, you can edit the markdown file in <code>docs/</code> directory directly.</p><h3 id="Modify-the-layout-of-pages"><a href="#Modify-the-layout-of-pages" class="headerlink" title="Modify the layout of pages"></a>Modify the layout of pages</h3><p>To modify the layout of pages, you need to edit <code>mkdocs.yml</code>.</p><p>For configuration details, see <span class="exturl" data-url="aHR0cHM6Ly93d3cubWtkb2NzLm9yZy91c2VyLWd1aWRlL2NvbmZpZ3VyYXRpb24v">MkDocs User Guide<i class="fa fa-external-link-alt"></i></span>.</p><p>Note the following rules when editing documents:</p><ul><li>All paths in <code>nav</code> must be relative to the <code>docs_dir</code>, which is <code>docs</code> by default. So here <code>./</code> is equivalent to <a href="docs">docs</a>.</li><li>All internal links must be relative paths, as MkDocs only supports regular Markdown linking syntax.</li></ul>]]></content>
    
    
    <summary type="html">《OceanBase开发者手册》之四 如何修改OceanBase文档</summary>
    
    
    
    <category term="OceanBase" scheme="http://ilongda.com/categories/OceanBase/"/>
    
    <category term="开发者手册" scheme="http://ilongda.com/categories/OceanBase/%E5%BC%80%E5%8F%91%E8%80%85%E6%89%8B%E5%86%8C/"/>
    
    
    <category term="OceanBase" scheme="http://ilongda.com/tags/OceanBase/"/>
    
    <category term="开发者手册" scheme="http://ilongda.com/tags/%E5%BC%80%E5%8F%91%E8%80%85%E6%89%8B%E5%86%8C/"/>
    
  </entry>
  
  <entry>
    <title>《OceanBase开发者手册》之三 如何成为OceanBase Contributor</title>
    <link href="http://ilongda.com/2021/contribute_to_ob/"/>
    <id>http://ilongda.com/2021/contribute_to_ob/</id>
    <published>2021-10-30T11:42:57.000Z</published>
    <updated>2024-02-02T12:53:08.724Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文将指导用户如何成为OceanBase Contributor, 即使是一个小白, 也可以成为contributor. </p><p>《OceanBase开发者手册》 主要指导开发者如何参与到OceanBase 的研发, 铺平参与OceanBase 开发的准备工作遇到的问题, 当前章节大概这几篇文章, 未来可能会增加部分文章, 目前OceanBase 源码参考OceanBase 开源官网的<span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vYXJ0aWNsZXMvODYwMDEyOQ==">《开源数据库OceanBase源码解读》 系列<i class="fa fa-external-link-alt"></i></span> :</p><ol><li>如何编译OceanBase源码</li><li>如何设置IDE开发环境</li><li>如何成为OceanBase Contributor</li><li>如何修改OceanBase文档</li><li>如何debug OceanBase</li><li>如何运行测试</li><li>如何修bug<br>​<span id="more"></span>​</li></ol><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ol><li>在<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tLw==">https://github.com<i class="fa fa-external-link-alt"></i></span> 上注册一个用户, 如果已经有了一个账户, 则跳过此步骤<ol><li>因为现在github 不允许通过用户名和密码提交代码, 需要用户自己 创建token 来提交代码, <span class="exturl" data-url="aHR0cHM6Ly9kb2NzLmdpdGh1Yi5jb20vY24vYXV0aGVudGljYXRpb24va2VlcGluZy15b3VyLWFjY291bnQtYW5kLWRhdGEtc2VjdXJlL2NyZWF0aW5nLWEtcGVyc29uYWwtYWNjZXNzLXRva2Vu">https://docs.github.com/cn/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token<i class="fa fa-external-link-alt"></i></span> ,  用新的token 来代替过去的密码来提交.</li></ol></li><li>fork <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vY2VhbmJhc2U=">https://github.com/oceanbase/oceanbase<i class="fa fa-external-link-alt"></i></span> 到自己github账户下</li></ol><img data-src="/img/ob/contributor1.png" ><p>如果已经fork 了代码, 在github 点击<br><img data-src="/img/ob/contributor2.png" ></p><ol start="3"><li>准备编译环境, 参考文档  <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vY2VhbmJhc2Uvd2lraS9ob3dfdG9fYnVpbGQ=">how-to-build<i class="fa fa-external-link-alt"></i></span></li></ol><h2 id="代码编写"><a href="#代码编写" class="headerlink" title="代码编写"></a>代码编写</h2><ol><li><p>下载代码到本地, </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># git clone https://github.com/$&#123;用户&#125;/oceanbase</span><br></pre></td></tr></table></figure><p>备注:  ${用户} 为用户的名字</p></li><li><p>在<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vY2VhbmJhc2UvaXNzdWVz">https://github.com/oceanbase/oceanbase/issues<i class="fa fa-external-link-alt"></i></span> 上找一个简单的issue,</p></li></ol><p>推荐找一个拼写错误的issue, 修改这些issue 比较简单, 容易上手.<br> <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vY2VhbmJhc2UvaXNzdWVzP3E9aXM6aXNzdWUraXM6b3BlbitsYWJlbDp0eXBvcw==">https://github.com/oceanbase/oceanbase/issues?q=is%3Aissue+is%3Aopen+label%3Atypos<i class="fa fa-external-link-alt"></i></span><br>​</p><p>创建对应的分支</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"># git checkout -b issue$&#123;issue_number&#125;</span><br></pre></td></tr></table></figure><p>备注: ${issue_number} 为issue 的编号<br>​</p><ol start="3"><li><p>在IDE 中修改代码, 推荐使用vscode, 并且vscode 使用远程链接功能. </p></li><li><p>修改完代码后, 进行编译</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">#bash build.sh debug --init --make</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>大概等待10分钟</p></li><li><p>开始单元测试, 如果只是修改注释, 修改文档, 则不需要进行单元测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># cd build_debug/unittest/</span><br><span class="line">#make -j 4</span><br><span class="line">#./run_tests.sh</span><br></pre></td></tr></table></figure><p>整个过程, 需要1个小时</p></li></ol><h2 id="代码提交"><a href="#代码提交" class="headerlink" title="代码提交"></a>代码提交</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># git status</span><br><span class="line"></span><br><span class="line"># 位于分支 master</span><br><span class="line"># 尚未暂存以备提交的变更：</span><br><span class="line">#   （使用 &quot;git add &lt;file&gt;...&quot; 更新要提交的内容）</span><br><span class="line">#   （使用 &quot;git checkout -- &lt;file&gt;...&quot; 丢弃工作区的改动）</span><br><span class="line">#</span><br><span class="line">#修改：      ../../src/$&#123;修改文件&#125;</span><br><span class="line">#</span><br><span class="line">修改尚未加入提交（使用 &quot;git add&quot; 和/或 &quot;git commit -a&quot;）</span><br></pre></td></tr></table></figure><p>备注: ${修改文件}为修改文件<br>然后 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git add $&#123;修改文件&#125;</span><br><span class="line">git commit -m &quot;fixed $&#123;issue_number&#125;, xxxxxxx&quot;</span><br><span class="line">git push origin issue$&#123;issue_number&#125;</span><br></pre></td></tr></table></figure><p>备注: ${issue_number}为issue的编号<br>commit的comments 需要带上”fixed ${issue_number}”, 这样可以将issue number 和pull request 关联起来<br>然后<br>​</p><p>创建pull request<br><img data-src="/img/ob/contributor3.png" ></p><p>即可,<br>​</p><p>创建pull request 后, 需要 签署CLA, 如果已经签署了, 类似这样<br><img data-src="/img/ob/contributor4.png" ><br>​</p><p>后续等待 OceanBase 的官方进行approve</p><h2 id="其他注意事项"><a href="#其他注意事项" class="headerlink" title="其他注意事项"></a>其他注意事项</h2><h3 id="注意切换分支"><a href="#注意切换分支" class="headerlink" title="注意切换分支"></a>注意切换分支</h3><p>当同时修改几个bug时， 每提交一个pull request 后， 就switch 到master上, 避免每个pull request 相互之间影响。 </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout master</span><br></pre></td></tr></table></figure><h3 id="发生冲突"><a href="#发生冲突" class="headerlink" title="发生冲突"></a>发生冲突</h3><p>自己的fork 的master 分支有可能会与远程master分支出现冲突， 这个时候， 在自己的fork 分支上， 把冲突commit 给删掉， 然后merge remote 的分支</p><ol><li>删除提交记录</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git reset --soft HEAD~i</span><br></pre></td></tr></table></figure><p>i代表要恢复到多少次提交前的状态，如指定i &#x3D; 2，则恢复到最近两次提交前的版本。–soft代表只删除服务器记录，不删除本地。</p><ol start="2"><li>执行<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git push origin master --force</span><br></pre></td></tr></table></figure>master代表当前分支</li></ol>]]></content>
    
    
    <summary type="html">《OceanBase开发者手册》之三 如何成为OceanBase Contributor</summary>
    
    
    
    <category term="OceanBase" scheme="http://ilongda.com/categories/OceanBase/"/>
    
    <category term="开发者手册" scheme="http://ilongda.com/categories/OceanBase/%E5%BC%80%E5%8F%91%E8%80%85%E6%89%8B%E5%86%8C/"/>
    
    
    <category term="OceanBase" scheme="http://ilongda.com/tags/OceanBase/"/>
    
  </entry>
  
  <entry>
    <title>《OceanBase开发者手册》之二 如何设置IDE开发环境</title>
    <link href="http://ilongda.com/2021/set_ide/"/>
    <id>http://ilongda.com/2021/set_ide/</id>
    <published>2021-10-23T11:42:57.000Z</published>
    <updated>2024-02-02T13:12:13.300Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>《OceanBase开发者手册》 主要指导开发者如何参与到OceanBase 的研发, 铺平参与OceanBase 开发的准备工作遇到的问题, 当前章节大概这几篇文章, 未来可能会增加部分文章, 目前OceanBase 源码参考OceanBase 开源官网的<span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vYXJ0aWNsZXMvODYwMDEyOQ==">《开源数据库OceanBase源码解读》 系列<i class="fa fa-external-link-alt"></i></span> :</p><ol><li>如何编译OceanBase源码</li><li>如何设置IDE开发环境</li><li>如何成为OceanBase Contributor</li><li>如何修改OceanBase文档</li><li>如何debug OceanBase</li><li>如何运行测试</li><li>如何修bug<br>​</li></ol><p>本文将介绍如何在开发环境中， 设置编译器， 重点设置编译器的 code format 工具 – clang-fromat。 本文内容来自内部同事分享, 该设置可以分享给所有的c&#x2F;c++ 项目中.  </b></p><p>clang-format是clang（一个面向C系语言的轻量级编译器）中一个工具，主要负责代码的格式化和排版工作，可独立于clang工作，所以经常被单独用来用作代码规范格式化，很多第三方插件也都集成了clang-fromat。clang-format与各个IDE集成. clang-format 差不多已经快成为c&#x2F;c++ 上实时的代码格式化标准. </p><span id="more"></span><p>​</p><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h1 id="vscode"><a href="#vscode" class="headerlink" title="vscode"></a>vscode</h1><p>既然看到这步了，我就姑且认为你已经装好了vscode，如果没有的话，可以先移步vscode官网下载</p><h2 id="STEP-1"><a href="#STEP-1" class="headerlink" title="STEP 1"></a>STEP 1</h2><p>首先确保你的开发环境下的vscode安装了C&#x2F;C++扩展;<br><img data-src="images/developer/vscode1.png"><br>这里要注意vscode远程和本地vscode插件不共用</p><h2 id="STEP-2"><a href="#STEP-2" class="headerlink" title="STEP 2"></a>STEP 2</h2><p>在setting中对Clang_format_style进行设置, 确认C&#x2F;C++扩展的配置Clang_format_style 设置成file （此处默认是file，如果不放心可以检查一下）;<br><img data-src="images/developer/vscode2.png"></p><h2 id="STEP-3"><a href="#STEP-3" class="headerlink" title="STEP 3"></a>STEP 3</h2><p>将准备好的<span class="exturl" data-url="aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL29jZWFuYmFzZS9vY2VhbmJhc2UvbWFzdGVyLy5jbGFuZy1mb3JtYXQ=">.clang-format<i class="fa fa-external-link-alt"></i></span>文件拷贝到工程目录下（部分项目工程目录下已存在）</p><h2 id="STEP-FINAL"><a href="#STEP-FINAL" class="headerlink" title="STEP FINAL"></a>STEP FINAL</h2><p>恭喜你已经完成vscode 中clang format 设置， 如果前面都完成了的话，那么在vscode中格式化代码时就会自动根据.clang-format配置格式化文件</p><h1 id="eclipse"><a href="#eclipse" class="headerlink" title="eclipse"></a>eclipse</h1><h2 id="STEP-1-1"><a href="#STEP-1-1" class="headerlink" title="STEP 1:"></a>STEP 1:</h2><p>首先需要在你的开发环境下载clang-format   （此处后面推广的时候提供wget包下载或者其他更通用的方式）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$brew install clang-format</span><br></pre></td></tr></table></figure><p>或者可以下载整个LLVM然后在目录下找到clang-format, 记录下clang-format的路径. </b><br>Linux&#x2F;Mac环境下最好拷贝至&#x2F;usr&#x2F;bin目录下，方便直接命令执行.</p><p>当执行$OBDEV_ROOT&#x2F;build.sh –init 后， 会自动下载clang-format, 你可以在这里看到它</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find ./ -name clang-format</span><br><span class="line">./deps/3rd/usr/local/oceanbase/devtools/bin/clang-format</span><br></pre></td></tr></table></figure><h2 id="STEP-2-1"><a href="#STEP-2-1" class="headerlink" title="STEP 2:"></a>STEP 2:</h2><p>eclipse中安装插件CppStyle</p><img data-src="images/developer/eclipse1.png"><h2 id="STEP-3-1"><a href="#STEP-3-1" class="headerlink" title="STEP 3:"></a>STEP 3:</h2><p>配置 CppStyle中clang-format的路径：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">（如果你CppStyle插件安装成功并重启的话，就会有这项配置）</span><br><span class="line">Preferences -&gt; C/C++ -&gt; CppStyle </span><br></pre></td></tr></table></figure><p>将之前下载的clang-format路径配置到Clang-format path中去</p><h2 id="STEP-4"><a href="#STEP-4" class="headerlink" title="STEP 4:"></a>STEP 4:</h2><p>配置 Code Formatter 为CppStyle：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Preferences -&gt; C/C++ -&gt; Code Style -&gt; Formatter</span><br></pre></td></tr></table></figure><p>将里面Code Formatter的配置选中下拉框选项 CppStyle(clang-format) （如果前面流程正确走完，此处应有此选项）</p><h2 id="STEP-5"><a href="#STEP-5" class="headerlink" title="STEP 5:"></a>STEP 5:</h2><p>将准备好的<span class="exturl" data-url="aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL29jZWFuYmFzZS9vY2VhbmJhc2UvbWFzdGVyLy5jbGFuZy1mb3JtYXQ=">.clang-format<i class="fa fa-external-link-alt"></i></span>文件拷贝到工程目录下（部分项目工程目录下已存在）</p><h2 id="STEP-FINAL-1"><a href="#STEP-FINAL-1" class="headerlink" title="STEP FINAL:"></a>STEP FINAL:</h2><p>此时就完成了所有准备工作，在eclipse编写代码的时候，格式化代码的时候，就会自动引用.clang-format的配置重新编排代码</p><h1 id="CLion"><a href="#CLion" class="headerlink" title="CLion"></a>CLion</h1><p>啊，写攻略终于写到一个轻松的了，JetBrains YYDS！<br>CLion天然集成了clang-format，所以只需要确认几项配置即可</p><h2 id="STEP-1-2"><a href="#STEP-1-2" class="headerlink" title="STEP 1:"></a>STEP 1:</h2><p>随便打开某个.h&#x2F;.c&#x2F;.cpp文件，在右下角点击’4 spaces’ 然后选择Enable ClangFormat</p><img data-src="images/developer/clion.png"><p>如果此处没有’4 spaces’，而是直接就是ClangFormat，那么就是CLion自动识别到存在.clang-format文件，帮忙配置好了</p><h2 id="STEP-2-2"><a href="#STEP-2-2" class="headerlink" title="STEP 2:"></a>STEP 2:</h2><p>确认’Enable ClangFormat’配置是否打开（这个CLion也是默认开启的）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Preferences -&gt; Editor -&gt; Code Style</span><br></pre></td></tr></table></figure><img data-src="images/developer/clion1.png"><h2 id="STEP-3-2"><a href="#STEP-3-2" class="headerlink" title="STEP 3:"></a>STEP 3:</h2><p>将准备好的<span class="exturl" data-url="aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL29jZWFuYmFzZS9vY2VhbmJhc2UvbWFzdGVyLy5jbGFuZy1mb3JtYXQ=">.clang-format<i class="fa fa-external-link-alt"></i></span>文件拷贝到工程目录下（部分项目工程目录下已存在）</p><h2 id="STEP-FINAL-2"><a href="#STEP-FINAL-2" class="headerlink" title="STEP FINAL:"></a>STEP FINAL:</h2><p>CLion就可以直接使用clang-format进行格式化了，当执行Reformat Code时就会自动编排代码</p><h1 id="VIM"><a href="#VIM" class="headerlink" title="VIM"></a>VIM</h1><h2 id="STEP-1-3"><a href="#STEP-1-3" class="headerlink" title="STEP 1:"></a>STEP 1:</h2><p>首先需要<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xsdm0vbGx2bS1wcm9qZWN0L2Jsb2IvbGx2bW9yZy0xMi4wLjEvY2xhbmcvdG9vbHMvY2xhbmctZm9ybWF0L2NsYW5nLWZvcm1hdC5weQ==">clang-format.py<i class="fa fa-external-link-alt"></i></span>文件我们可以直接去github上面把对应文件拷贝下来;</p><h2 id="STEP-2-3"><a href="#STEP-2-3" class="headerlink" title="STEP 2:"></a>STEP 2:</h2><p>然后配置当前用户的.vimrc文件（如果没有的话，在当前用户的根目录下创建.vimrc文件即可）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">map &lt;C-K&gt; :pyf &lt;path-to-this-file&gt;/clang-format.py&lt;cr&gt;</span><br><span class="line">imap &lt;C-K&gt; &lt;c-o&gt;:pyf &lt;path-to-this-file&gt;/clang-format.py&lt;cr&gt;</span><br><span class="line"></span><br><span class="line">function! Formatonsave()</span><br><span class="line">  let l:formatdiff = 1</span><br><span class="line">  pyf &lt;path-to-this-file&gt;/clang-format.py</span><br><span class="line">endfunction</span><br><span class="line">autocmd BufWritePre *.h,*.cc,*.cpp call Formatonsave()</span><br></pre></td></tr></table></figure><p>代码块中的 ‘<path-to-this-file>‘ 替换成之前拷贝下来的clang-format.py的路径，然后保存并重启终端</p><p>PS：前面两行是增加主动触发clang-format功能</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">normal模式下，ctrl+k将格式化一行代码</span><br><span class="line">visual模式下，ctrl+k将格式化选中代码</span><br><span class="line">insert模式下，ctrl+k将格式化一行代码</span><br></pre></td></tr></table></figure><p>最后一段的function则是当使用vim保存当前.h&#x2F;.cc&#x2F;.cpp文件时，会自动将文件所有内容格式化</p><h2 id="STEP-3-3"><a href="#STEP-3-3" class="headerlink" title="STEP 3:"></a>STEP 3:</h2><p>将准备好的<span class="exturl" data-url="aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL29jZWFuYmFzZS9vY2VhbmJhc2UvbWFzdGVyLy5jbGFuZy1mb3JtYXQ=">.clang-format<i class="fa fa-external-link-alt"></i></span>文件拷贝到工程目录下（部分项目工程目录下已存在）</p><h2 id="STEP-FINAL："><a href="#STEP-FINAL：" class="headerlink" title="STEP FINAL："></a>STEP FINAL：</h2><p>完成前面的工作，vim就成功集成了clang-format，只不过需要注意的是，使用的时候先需要cd到工程路径下，并确保工程路径下已有.clang-format文件，然后在该路径下，使用vim去修改文件即可（在使用vim时就不要切换当前目录啦）</p><h1 id="EMACS"><a href="#EMACS" class="headerlink" title="EMACS"></a>EMACS</h1><p>EMACS貌似很强大的一个编辑器（都不确定是否应该称之为编辑器），但是对新人来说学习成本略高，折腾了一个晚上才勉强搞定😅<br>如果看这一块的话，我就默认大家已经了解了emacs的一些基本操作，展开讲可以单开一个系列的语雀了，所以我这里只放出和clang-format集成相关的操作了，其他的不做过多讲解<br>STEP 1:<br>首先需要在你的开发环境下载clang-format   （此处后面推广的时候提供wget包下载或者其他更通用的方式）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install clang-format</span><br></pre></td></tr></table></figure><p>或者可以下载整个LLVM然后在目录下找到clang-format<br>Linux环境下需要拷贝至&#x2F;usr&#x2F;bin目录下<br>MAC环境也需要配置到对应PATH路径中</p><p>当执行$OBDEV_ROOT&#x2F;build.sh –init 后， 会自动下载clang-format, 你可以在这里看到它</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">find ./ -name clang-format</span><br><span class="line">./deps/3rd/usr/local/oceanbase/devtools/bin/clang-format</span><br></pre></td></tr></table></figure><h2 id="STEP-2-4"><a href="#STEP-2-4" class="headerlink" title="STEP 2:"></a>STEP 2:</h2><p>然后需要使用package-install安装clang-format包，如果没有的话，可以修改package sources，这里展示一下我使用的sources配置：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">(&quot;melpa&quot; . &quot;http://mirrors.tuna.tsinghua.edu.cn/elpa/melpa/&quot;)</span><br><span class="line">(&quot;org-cn&quot; . &quot;http://mirrors.tuna.tsinghua.edu.cn/elpa/org/&quot;)</span><br><span class="line">(&quot;gnu&quot; . &quot;http://mirrors.tuna.tsinghua.edu.cn/elpa/gnu/&quot;)</span><br></pre></td></tr></table></figure><h2 id="STEP-3-4"><a href="#STEP-3-4" class="headerlink" title="STEP 3:"></a>STEP 3:</h2><p>安装完成后，找到安装的插件位置，我的是mac系统，安装位置在用户根目录下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.emacs.d/elpa/clang-format-20191106.950</span><br></pre></td></tr></table></figure><p>找到该路径下的clang-format.el文件，讲该文件的路径配置到.emacs配置文件中去（配置路径自行根据实际情况调整）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(load &quot;/Users/xxx/.emacs.d/elpa/clang-format-20191106.950/clang-format.el&quot;)</span><br></pre></td></tr></table></figure><p>PS：如果是mac系统的话比较麻烦，mac系统使用GUI打开emacs时，shell里面配置的环境变量是不会自动带过来的，这个时候需要在.emacs中额外配置一些内容：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(defun set-exec-path-from-shell-PATH ()</span><br><span class="line">  &quot;Set up Emacs&#x27; `exec-path&#x27; and PATH environment variable to match</span><br><span class="line">that used by the user&#x27;s shell.</span><br><span class="line"></span><br><span class="line">This is particularly useful under Mac OS X and macOS, where GUI</span><br><span class="line">apps are not started from a shell.&quot;</span><br><span class="line">  (interactive)</span><br><span class="line">  (let ((path-from-shell (replace-regexp-in-string</span><br><span class="line">        &quot;[ \t\n]*$&quot; &quot;&quot; (shell-command-to-string</span><br><span class="line">            &quot;$SHELL --login -c &#x27;echo $PATH&#x27;&quot;</span><br><span class="line">                ))))</span><br><span class="line">    (setenv &quot;PATH&quot; path-from-shell)</span><br><span class="line">    (setq exec-path (split-string path-from-shell path-separator))))</span><br><span class="line"></span><br><span class="line">(set-exec-path-from-shell-PATH)</span><br></pre></td></tr></table></figure><h2 id="STEP-4-1"><a href="#STEP-4-1" class="headerlink" title="STEP 4:"></a>STEP 4:</h2><p>将准备好的<span class="exturl" data-url="aHR0cHM6Ly9yYXcuZ2l0aHVidXNlcmNvbnRlbnQuY29tL29jZWFuYmFzZS9vY2VhbmJhc2UvbWFzdGVyLy5jbGFuZy1mb3JtYXQ=">.clang-format<i class="fa fa-external-link-alt"></i></span>文件拷贝到工程目录下（部分项目工程目录下已存在）</p><h2 id="STEP-FINAL-3"><a href="#STEP-FINAL-3" class="headerlink" title="STEP FINAL:"></a>STEP FINAL:</h2><p>现在就已经完成了clang-format的集成工作，在开发中，只需要在文件编辑界面执行M-x clang-format-buffer 即可。此时clang-format会自动向本级及父级目录找到.clang-format文件，并根据文件配置格式化代码</p>]]></content>
    
    
    <summary type="html">《OceanBase开发者手册》之二 如何设置IDE开发环境</summary>
    
    
    
    <category term="OceanBase" scheme="http://ilongda.com/categories/OceanBase/"/>
    
    <category term="开发者手册" scheme="http://ilongda.com/categories/OceanBase/%E5%BC%80%E5%8F%91%E8%80%85%E6%89%8B%E5%86%8C/"/>
    
    
    <category term="OceanBase" scheme="http://ilongda.com/tags/OceanBase/"/>
    
    <category term="开发者手册" scheme="http://ilongda.com/tags/%E5%BC%80%E5%8F%91%E8%80%85%E6%89%8B%E5%86%8C/"/>
    
  </entry>
  
  <entry>
    <title>《OceanBase开发者手册》之一 如何编译OceanBase源码</title>
    <link href="http://ilongda.com/2021/build_ob/"/>
    <id>http://ilongda.com/2021/build_ob/</id>
    <published>2021-10-16T11:42:57.000Z</published>
    <updated>2024-02-02T12:52:46.988Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文将指导用户如何编译OceanBase, 本文大部分内容来自 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL29jZWFuYmFzZS9vY2VhbmJhc2U=">https://github.com/oceanbase/oceanbase<i class="fa fa-external-link-alt"></i></span> .  </p><p>《OceanBase开发者手册》 主要指导开发者如何参与到OceanBase 的研发, 铺平参与OceanBase 开发的准备工作遇到的问题, 当前章节大概这几篇文章, 未来可能会增加部分文章, 目前OceanBase 源码参考OceanBase 开源官网的<span class="exturl" data-url="aHR0cHM6Ly9vcGVuLm9jZWFuYmFzZS5jb20vYXJ0aWNsZXMvODYwMDEyOQ==">《开源数据库OceanBase源码解读》 系列<i class="fa fa-external-link-alt"></i></span> :</p><ol><li>如何编译OceanBase源码</li><li>如何设置IDE开发环境</li><li>如何成为OceanBase Contributor</li><li>如何修改OceanBase文档</li><li>如何debug OceanBase</li><li>如何运行测试</li><li>如何修bug<br>​<span id="more"></span>​</li></ol><h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h2 id="OS-compatibility-list"><a href="#OS-compatibility-list" class="headerlink" title="OS compatibility list"></a>OS compatibility list</h2><table><thead><tr><th>OS</th><th>Ver.</th><th>Arch</th><th>Compilable</th><th>Package Deployable</th><th>Compiled Binary Deployable</th><th>Mysqltest Passed</th></tr></thead><tbody><tr><td>Alibaba Cloud Linux</td><td>2.1903</td><td>x86_64</td><td>✅</td><td>✅</td><td>✅</td><td>✅</td></tr><tr><td>CentOS</td><td>7.2, 8.3</td><td>x86_64</td><td>✅</td><td>✅</td><td>✅</td><td>✅</td></tr><tr><td>Debian</td><td>9.8, 10.9</td><td>x86_64</td><td>✅</td><td>✅</td><td>✅</td><td>✅</td></tr><tr><td>Fedora</td><td>33</td><td>x86_64</td><td>✅</td><td>✅</td><td>✅</td><td>✅</td></tr><tr><td>MacOS</td><td>any</td><td>x86_64</td><td>❌</td><td>❌</td><td>❌</td><td>❌</td></tr><tr><td>openSUSE</td><td>15.2</td><td>x86_64</td><td>✅</td><td>✅</td><td>✅</td><td>✅</td></tr><tr><td>OpenAnolis</td><td>8.2</td><td>x86_64</td><td>✅</td><td>✅</td><td>✅</td><td>✅</td></tr><tr><td>SUSE</td><td>15.2</td><td>x86_64</td><td>✅</td><td>✅</td><td>✅</td><td>✅</td></tr><tr><td>Ubuntu</td><td>16.04, 18.04, 20.04</td><td>x86_64</td><td>✅</td><td>✅</td><td>✅</td><td>✅</td></tr><tr><td>UOS</td><td>20</td><td>x86_64</td><td>✅</td><td>✅</td><td>✅</td><td>✅</td></tr></tbody></table><h2 id="How-to-build"><a href="#How-to-build" class="headerlink" title="How to build"></a>How to build</h2><p>This document will show how to build oceanbase. </p><h3 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h3><p>Before building, you need to confirm that your device has installed the necessary software.</p><h4 id="Redhat-based-including-CentOS-Fedora-OpenAnolis-RedHat-UOS-etc"><a href="#Redhat-based-including-CentOS-Fedora-OpenAnolis-RedHat-UOS-etc" class="headerlink" title="Redhat based (, including CentOS, Fedora, OpenAnolis, RedHat, UOS, etc.)"></a>Redhat based (, including CentOS, Fedora, OpenAnolis, RedHat, UOS, etc.)</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install git wget rpm* cpio make glibc-devel glibc-headers binutils</span><br></pre></td></tr></table></figure><h4 id="Debian-based-including-Debian-Ubuntu-etc"><a href="#Debian-based-including-Debian-Ubuntu-etc" class="headerlink" title="Debian based (, including Debian, Ubuntu, etc.)"></a>Debian based (, including Debian, Ubuntu, etc.)</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install git wget rpm rpm2cpio cpio make build-essential binutils</span><br></pre></td></tr></table></figure><h4 id="SUSE-based-including-SUSE-openSUSE-etc"><a href="#SUSE-based-including-SUSE-openSUSE-etc" class="headerlink" title="SUSE based (, including SUSE, openSUSE, etc.)"></a>SUSE based (, including SUSE, openSUSE, etc.)</h4><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">zypper install git wget rpm cpio make glibc-devel binutils</span><br></pre></td></tr></table></figure><h3 id="debug-mode"><a href="#debug-mode" class="headerlink" title="debug mode"></a>debug mode</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash build.sh debug --init --make</span><br></pre></td></tr></table></figure><h3 id="release-mode"><a href="#release-mode" class="headerlink" title="release mode"></a>release mode</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash build.sh release --init --make</span><br></pre></td></tr></table></figure><h3 id="RPM-packages"><a href="#RPM-packages" class="headerlink" title="RPM packages"></a>RPM packages</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash build.sh rpm --init &amp;&amp; <span class="built_in">cd</span> build_rpm &amp;&amp; make -j16 rpm</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">《OceanBase开发者手册》之一 如何编译OceanBase源码</summary>
    
    
    
    <category term="OceanBase" scheme="http://ilongda.com/categories/OceanBase/"/>
    
    <category term="开发者手册" scheme="http://ilongda.com/categories/OceanBase/%E5%BC%80%E5%8F%91%E8%80%85%E6%89%8B%E5%86%8C/"/>
    
    
    <category term="OceanBase" scheme="http://ilongda.com/tags/OceanBase/"/>
    
  </entry>
  
  <entry>
    <title>漫步九寨沟</title>
    <link href="http://ilongda.com/2021/jiuzhaigou/"/>
    <id>http://ilongda.com/2021/jiuzhaigou/</id>
    <published>2021-10-10T03:42:57.000Z</published>
    <updated>2024-02-02T12:59:37.716Z</updated>
    
    <content type="html"><![CDATA[<h1 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h1><p>在大学的时候, 就常常听到朋友各种介绍九寨沟, 记得大学毕业那年, 同寝室的室友玩了一次毕业旅行, 去了趟九寨沟, 表达了对九寨沟略有失望, 这也让我对九寨沟一直没有强烈的诉求, 也没有说专程去四川玩一下九寨沟, 不过,因为老婆这次非常想去四川玩, 就提了一嘴是不是可以顺便去看看九寨沟, 现在回想起来, 幸好提了一嘴, 否则去了四川没有去九寨沟, 真的就少了点什么. </p><p>引用一段九寨沟的介绍</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">九寨沟位于四川省西北部岷山山脉南段的阿坝藏族羌族自治州九寨沟县漳扎镇境内，地处岷山南段弓杆岭的东北侧。距离成都市400多千米，系长江水系嘉陵江上游白水江源头的一条大支沟。 九寨沟自然保护区地势南高北低，山谷深切，高差悬殊。北缘九寨沟口海拔仅2000米，中部峰岭均在4000米以上，南缘达4500米以上，主沟长30多公里。</span><br><span class="line">九寨沟是世界自然遗产、国家重点风景名胜区、国家AAAAA级旅游景区、国家级自然保护区、国家地质公园、世界生物圈保护区网络，也是中国第一个以保护自然风景为主要目的的自然保护区。</span><br><span class="line"></span><br></pre></td></tr></table></figure><h2 id="攻略"><a href="#攻略" class="headerlink" title="攻略"></a>攻略</h2><p>去九寨沟, 其实不需要什么攻略, 建议就2点: </p><ol><li>记得提前在网上预定门门票; </li><li>建议直接飞到离九寨沟最近的机场, 然后乘车, 建议是包车, 自己租车会比较累.</li></ol><p>我们是先飞到成都, 然后开车到九寨沟, 正好是10.1 长假期间, 我们从成都开到九寨沟, 从早上8点出发, 中间吃饭休息几次, 一直堵一直堵, 直到晚上10点才到了酒店, 400公里, 在车上的时间超过了12个小时, 以后打死都不会在这种高速免费节假日的第一天或最后一天上高速. </p><img data-src="/img/jiuzhaigou/jiuzhai1.jpg" ><img data-src="/img/jiuzhaigou/19.jpg" ><span id="more"></span><h1 id="行程"><a href="#行程" class="headerlink" title="行程"></a>行程</h1><p>推荐行程路线是在入口做公交, 一直坐到剑崖, 然后慢慢往下走, 如果下一个站点远就做车, 一路玩到诺日朗瀑布, 然后换公交去五彩池, 看完五彩池, 然后再坐车回到诺日朗, 在沿途玩耍犀牛海, 树正瀑布, 卧龙湾, 双龙海等等. </p><img data-src="/img/jiuzhaigou/map.jpg" ><p>最前面的天鹅海, 芳草海, 箭竹海, 一路风景美不胜收, 边走边拍<br><img data-src="/img/jiuzhaigou/1.jpg" ><br><img data-src="/img/jiuzhaigou/2.jpg" ><br><img data-src="/img/jiuzhaigou/3.jpg" ><br><img data-src="/img/jiuzhaigou/4.jpg" ><br><img data-src="/img/jiuzhaigou/5.jpg" ><br><img data-src="/img/jiuzhaigou/6.jpg" ><br><img data-src="/img/jiuzhaigou/7.jpg" ><br><img data-src="/img/jiuzhaigou/8.jpg" ><br><img data-src="/img/jiuzhaigou/9.jpg" ></p><img data-src="/img/jiuzhaigou/12.jpg" ><p>金铃海<br><img data-src="/img/jiuzhaigou/10.jpg" ><br><img data-src="/img/jiuzhaigou/11.jpg" ><br><img data-src="/img/jiuzhaigou/16.jpg" ></p><p>熊猫海瀑布<br><img data-src="/img/jiuzhaigou/14.jpg" ></p><p>镜海<br><img data-src="/img/jiuzhaigou/18.jpg" ><br><img data-src="/img/jiuzhaigou/15.jpg" ></p><p>诺日朗瀑布<br><img data-src="/img/jiuzhaigou/17.jpg" ></p><p>长海, 到长海的时候, 正天降冰雹, 花生大小的冰雹砸下来, 噼里啪啦的作响<br><img data-src="/img/jiuzhaigou/21.jpg" ></p><p>著名的五色池, 5色池还是颜色非常丰富<br><img data-src="/img/jiuzhaigou/20.jpg" ><br><img data-src="/img/jiuzhaigou/19.jpg" ></p><p>后续沿途步行了3小时, 因为是从山上往下走, 也没有那么累, 所以还好, 沿途欣赏了犀牛海, 老虎海, 树正群海, 树正瀑布, 卧龙海, 双龙海, 最后</p><img data-src="/img/jiuzhaigou/22.jpg" ><img data-src="/img/jiuzhaigou/23.jpg" ><img data-src="/img/jiuzhaigou/24.jpg" ><img data-src="/img/jiuzhaigou/25.jpg" >最后一个景点, 芦苇海<img data-src="/img/jiuzhaigou/26.jpg" >]]></content>
    
    
    <summary type="html">旅游之漫步九寨沟</summary>
    
    
    
    <category term="旅游" scheme="http://ilongda.com/categories/%E6%97%85%E6%B8%B8/"/>
    
    
    <category term="旅游" scheme="http://ilongda.com/tags/%E6%97%85%E6%B8%B8/"/>
    
  </entry>
  
  <entry>
    <title>监控工具总结</title>
    <link href="http://ilongda.com/2021/docs/tools/monitor_tools/general/"/>
    <id>http://ilongda.com/2021/docs/tools/monitor_tools/general/</id>
    <published>2021-01-14T11:42:57.000Z</published>
    <updated>2024-02-02T13:32:40.323Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>将过去使用的几个监控工具分享一下， 也方便自己以后查找。 </p><ul><li><a href="/knowledge/tools/monitor_tools/sar.html">sar， Linux 上最为全面的系统性能分析工具之一</a></br></li><li><a href="/knowledge/tools/monitor_tools/pidstat.html">pidstat， 系统资源监控工具之一</a></br></li><li><a href="/knowledge/tools/monitor_tools/iostat.html">iostat， IO性能分析工具之一</a></br></li><li><a href="/knowledge/tools/monitor_tools/network.html">network 监控与分析工具</a></br></li><li><a href="/knowledge/tools/monitor_tools/perf.html">perf， 性能分析工具之一</a></br></li><li><a href="/knowledge/tools/monitor_tools/trace.html">trace系统</a></br></li><li><a href="/knowledge/tools/monitor_tools/vmstat.html">vmstat， 内存监控工具之一</a></br></li><li><a href="/knowledge/tools/monitor_tools/memory.html">内存监控与分析工具</a></br></li><li><a href="/knowledge/tools/monitor_tools/java_gc.html">对java gc 性能调优</a></br></li><li><a href="/knowledge/tools/monitor_tools/java_mem.html">java memory 监控与分析</a></br></li></ul>]]></content>
    
    
    <summary type="html">监控工具总结</summary>
    
    
    
    <category term="工具" scheme="http://ilongda.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="监控工具" scheme="http://ilongda.com/categories/%E5%B7%A5%E5%85%B7/%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="工具" scheme="http://ilongda.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="监控工具" scheme="http://ilongda.com/tags/%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>监控工具总结</title>
    <link href="http://ilongda.com/2021/docs/tools/monitor_tools/index/"/>
    <id>http://ilongda.com/2021/docs/tools/monitor_tools/index/</id>
    <published>2021-01-14T11:42:57.000Z</published>
    <updated>2024-02-02T13:32:40.323Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>将过去使用的几个监控工具分享一下， 也方便自己以后查找。 </p><ul><li><a href="/knowledge/tools/monitor_tools/sar.html">sar， Linux 上最为全面的系统性能分析工具之一</a></br></li><li><a href="/knowledge/tools/monitor_tools/pidstat.html">pidstat， 系统资源监控工具之一</a></br></li><li><a href="/knowledge/tools/monitor_tools/iostat.html">iostat， IO性能分析工具之一</a></br></li><li><a href="/knowledge/tools/monitor_tools/network.html">network 监控与分析工具</a></br></li><li><a href="/knowledge/tools/monitor_tools/perf.html">perf， 性能分析工具之一</a></br></li><li><a href="/knowledge/tools/monitor_tools/trace.html">trace系统</a></br></li><li><a href="/knowledge/tools/monitor_tools/vmstat.html">vmstat， 内存监控工具之一</a></br></li><li><a href="/knowledge/tools/monitor_tools/memory.html">内存监控与分析工具</a></br></li><li><a href="/knowledge/tools/monitor_tools/java_gc.html">对java gc 性能调优</a></br></li><li><a href="/knowledge/tools/monitor_tools/java_mem.html">java memory 监控与分析</a></br></li></ul>]]></content>
    
    
    <summary type="html">监控工具总结</summary>
    
    
    
    <category term="工具" scheme="http://ilongda.com/categories/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="监控工具" scheme="http://ilongda.com/categories/%E5%B7%A5%E5%85%B7/%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/"/>
    
    
    <category term="工具" scheme="http://ilongda.com/tags/%E5%B7%A5%E5%85%B7/"/>
    
    <category term="监控工具" scheme="http://ilongda.com/tags/%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7/"/>
    
  </entry>
  
  <entry>
    <title>paper推荐</title>
    <link href="http://ilongda.com/2020/docs/paper/general/"/>
    <id>http://ilongda.com/2020/docs/paper/general/</id>
    <published>2020-11-14T11:42:57.000Z</published>
    <updated>2024-02-02T13:29:55.473Z</updated>
    
    <content type="html"><![CDATA[<p>因为楼主有个不好的习惯， 论文看完后， 过了一段时间就忘了讲什么，另外英语并不是很好，英文论文常常理解抓不住重点，因为习惯做一个笔记， 方便以后进行会议， 也方便理解论文。<br>后期会不定时进行更新。有一些论文是之前留下的笔记，做了一些梳理。 </p><p>有一些论文，还没有读完， 读完的，会有link</p><h1 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h1><h2 id="System"><a href="#System" class="headerlink" title="System"></a>System</h2><ul><li><a href="/knowledge/paper/libr.html">《FusionInsight LibrA Huawei’s Enterprise Cloud Data Analytics Platform》</a></li><li><a href="/knowledge/paper/redshift.html">《Amazon Redshift and the Case for Simpler Data Warehouses》</a></li><li><a href="/knowledge/paper/snowflake.html">《The Snowflake Elastic Data Warehouse》</a></li><li><a href="/knowledge/paper/f1.html">《F1 Query: Declarative Querying at Scale》</a></li></ul><h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><ul><li>《Access Path Selection in a Relational Database Management System》 </li><li><a href="/knowledge/paper/The_Volcano_Optimizer_Generator.html">《The Volcano Optimizer Generator: Extensibility and Efficient Search》</a></li><li><a href="/knowledge/paper/Volcano.html">《Volcano-An Extensible and Parallel Query Evaluation System》</a></li><li><a href="/knowledge/paper/cascade.html">《The Cascades Framework for Query Optimization》</a></li><li><a href="/knowledge/paper/ms-sql-server-pdw.html">《Query Optimization in Microsoft SQL Server PDW》</a></li><li>《Inside The SQL Server Query Optimizer》</li><li>《Incorporating Partitioning and Parallel Plans into the SCOPE Optimizer》</li><li>《Orca: A Modular Query Optimizer Architecture for Big Data》</li><li>《How Good Are Query Optimizers, Really?》</li><li>《An overview of query optimization in relational systems.》</li><li>《Query optimization through the looking glass, and what we found running the Join Order Benchmark.》</li><li>《Adaptive statistics in Oracle 12c.》</li><li>《Exploiting Statistics on Query Expressions for Optimization》</li></ul><h1 id="BigData"><a href="#BigData" class="headerlink" title="BigData"></a>BigData</h1><ul><li><a href="/knowledge/paper/dataflow.html">《The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing》</a></li><li><a href="/knowledge/paper/heron.html">《Hero stream process stream》 </a></li><li><a href="/knowledge/paper/millwheel.html">《MillWheel: Fault-Tolerant Stream Processing at Internet Scale》</a></li><li><a href="/knowledge/paper/screamscope.html">《StreamScope: Continuous Reliable Distributed Processing of Big Data Streams》</a></li></ul>]]></content>
    
    
    <summary type="html">数据库大数据 论文推荐</summary>
    
    
    
    <category term="论文" scheme="http://ilongda.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
    <category term="论文" scheme="http://ilongda.com/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>paper推荐</title>
    <link href="http://ilongda.com/2020/docs/paper/index/"/>
    <id>http://ilongda.com/2020/docs/paper/index/</id>
    <published>2020-11-14T11:42:57.000Z</published>
    <updated>2024-02-02T13:29:55.473Z</updated>
    
    <content type="html"><![CDATA[<p>因为楼主有个不好的习惯， 论文看完后， 过了一段时间就忘了讲什么，另外英语并不是很好，英文论文常常理解抓不住重点，因为习惯做一个笔记， 方便以后进行会议， 也方便理解论文。<br>后期会不定时进行更新。有一些论文是之前留下的笔记，做了一些梳理。 </p><p>有一些论文，还没有读完， 读完的，会有link</p><h1 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h1><h2 id="System"><a href="#System" class="headerlink" title="System"></a>System</h2><ul><li><a href="/knowledge/paper/libr.html">《FusionInsight LibrA Huawei’s Enterprise Cloud Data Analytics Platform》</a></li><li><a href="/knowledge/paper/redshift.html">《Amazon Redshift and the Case for Simpler Data Warehouses》</a></li><li><a href="/knowledge/paper/snowflake.html">《The Snowflake Elastic Data Warehouse》</a></li><li><a href="/knowledge/paper/f1.html">《F1 Query: Declarative Querying at Scale》</a></li></ul><h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><ul><li>《Access Path Selection in a Relational Database Management System》 </li><li><a href="/knowledge/paper/The_Volcano_Optimizer_Generator.html">《The Volcano Optimizer Generator: Extensibility and Efficient Search》</a></li><li><a href="/knowledge/paper/Volcano.html">《Volcano-An Extensible and Parallel Query Evaluation System》</a></li><li><a href="/knowledge/paper/cascade.html">《The Cascades Framework for Query Optimization》</a></li><li><a href="/knowledge/paper/ms-sql-server-pdw.html">《Query Optimization in Microsoft SQL Server PDW》</a></li><li>《Inside The SQL Server Query Optimizer》</li><li>《Incorporating Partitioning and Parallel Plans into the SCOPE Optimizer》</li><li>《Orca: A Modular Query Optimizer Architecture for Big Data》</li><li>《How Good Are Query Optimizers, Really?》</li><li>《An overview of query optimization in relational systems.》</li><li>《Query optimization through the looking glass, and what we found running the Join Order Benchmark.》</li><li>《Adaptive statistics in Oracle 12c.》</li><li>《Exploiting Statistics on Query Expressions for Optimization》</li></ul><h1 id="BigData"><a href="#BigData" class="headerlink" title="BigData"></a>BigData</h1><ul><li><a href="/knowledge/paper/dataflow.html">《The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing》</a></li><li><a href="/knowledge/paper/heron.html">《Hero stream process stream》 </a></li><li><a href="/knowledge/paper/millwheel.html">《MillWheel: Fault-Tolerant Stream Processing at Internet Scale》</a></li><li><a href="/knowledge/paper/screamscope.html">《StreamScope: Continuous Reliable Distributed Processing of Big Data Streams》</a></li></ul>]]></content>
    
    
    <summary type="html">数据库大数据 论文推荐</summary>
    
    
    
    <category term="论文" scheme="http://ilongda.com/categories/%E8%AE%BA%E6%96%87/"/>
    
    
    <category term="论文" scheme="http://ilongda.com/tags/%E8%AE%BA%E6%96%87/"/>
    
  </entry>
  
  <entry>
    <title>磁盘性能测试</title>
    <link href="http://ilongda.com/2020/fileio/"/>
    <id>http://ilongda.com/2020/fileio/</id>
    <published>2020-07-12T11:42:57.000Z</published>
    <updated>2024-02-02T12:55:28.844Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>心血来潮，想测试一下阿里云的essd 和阿里云的本地ssd 性能， 不巧的是阿里云ecs 的存储， 有几种类型， essd， ssd 云盘， 高效云盘 和本地盘nvme 盘<br>最终测试下来确实nvme 盘的性能最好。</p><p>测试工具： 本文用sysbench 进行测试， 以前读书的时候使用过iometer 进行测试， sysbench 测试参数更多， 对iops 的测试效果更丰富， iometer 偏重吞吐量的测试。 </p><span id="more"></span><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>参考之前的博文， 学会如何安装sysbench</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>测试脚本</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">SYSBENCH_FILE_TOTAL_SIZE=16G</span><br><span class="line">SYSBENCH_FILE_NUM=16</span><br><span class="line">SYSBENCH_NUM_THREADS=16</span><br><span class="line">FSYNC=off</span><br><span class="line">SYSBENCH_BLOCK_SIZE=4096</span><br><span class="line">SYSBENCH_TIME=60</span><br><span class="line"></span><br><span class="line">#  --file-num=N                  number of files to create [128]</span><br><span class="line">#  --file-block-size=N           block size to use in all IO operations [16384]</span><br><span class="line">#  --file-total-size=SIZE        total size of files to create [2G]</span><br><span class="line">#  --file-test-mode=STRING       test mode &#123;seqwr, seqrewr, seqrd, rndrd, rndwr, rndrw&#125;</span><br><span class="line">#  --file-io-mode=STRING         file operations mode &#123;sync,async,mmap&#125; [sync]</span><br><span class="line">#  --file-extra-flags=[LIST,...] list of additional flags to use to open files &#123;sync,dsync,direct&#125; []</span><br><span class="line">#  --file-fsync-freq=N           do fsync() after this number of requests (0 - don&#x27;t use fsync()) [100]</span><br><span class="line">#  --file-fsync-all[=on|off]     do fsync() after each write operation [off]</span><br><span class="line">#  --file-fsync-end[=on|off]     do fsync() at the end of test [on]</span><br><span class="line">#  --file-fsync-mode=STRING      which method to use for synchronization &#123;fsync, fdatasync&#125; [fsync]</span><br><span class="line">#  --file-merged-requests=N      merge at most this number of IO requests if possible (0 - don&#x27;t merge) [0]</span><br><span class="line">#  --file-rw-ratio=N             reads/writes ratio for combined test [1.5]</span><br><span class="line"></span><br><span class="line">testmodes=(</span><br><span class="line">    &quot;seqwr&quot; </span><br><span class="line">    &quot;seqrewr&quot; </span><br><span class="line">    &quot;seqrd&quot;</span><br><span class="line">    &quot;rndrd&quot;</span><br><span class="line">    &quot;rndwr&quot; </span><br><span class="line">    &quot;rndrw&quot;</span><br><span class="line">    )</span><br><span class="line">for testmode in &quot;$&#123;testmodes[@]&#125;&quot;</span><br><span class="line">do</span><br><span class="line">    directios=(</span><br><span class="line">    &quot;&quot;</span><br><span class="line">    &quot;sync&quot;</span><br><span class="line">    &quot;direct&quot;</span><br><span class="line">    &quot;dsync&quot;</span><br><span class="line">    )</span><br><span class="line">    for directio in &quot;$&#123;directios[@]&#125;&quot;</span><br><span class="line">    do</span><br><span class="line">        date</span><br><span class="line">        echo 1 &gt; /proc/sys/vm/drop_caches</span><br><span class="line">        echo &quot;begin to run $testmode   $directio&quot;</span><br><span class="line">        sysbench fileio  --file-num=$SYSBENCH_FILE_NUM --file-block-size=$SYSBENCH_BLOCK_SIZE --file-total-size=$SYSBENCH_FILE_TOTAL_SIZE --file-test-mode=$testmode --file-io-mode=sync --file-extra-flags=$directio --file-fsync-all=$FSYNC --file-fsync-mode=fsync --file-fsync-freq=0 --file-merged-requests=0 --threads=$SYSBENCH_NUM_THREADS prepare</span><br><span class="line">        sysbench fileio --file-num=$SYSBENCH_FILE_NUM --file-block-size=$SYSBENCH_BLOCK_SIZE --file-total-size=$SYSBENCH_FILE_TOTAL_SIZE --file-test-mode=$testmode --file-io-mode=sync --file-extra-flags=$directio --file-fsync-all=$FSYNC --file-fsync-mode=fsync --file-fsync-freq=0 --file-merged-requests=0  --report-interval=10  --threads=$SYSBENCH_NUM_THREADS --time=$SYSBENCH_TIME run</span><br><span class="line">        sysbench fileio  --file-num=$SYSBENCH_FILE_NUM --file-block-size=$SYSBENCH_BLOCK_SIZE --file-total-size=$SYSBENCH_FILE_TOTAL_SIZE --file-test-mode=$testmode --file-io-mode=sync --file-extra-flags=$directio --file-fsync-all=$FSYNC --file-fsync-mode=fsync --file-fsync-freq=0 --file-merged-requests=0   cleanup</span><br><span class="line">        date</span><br><span class="line">        esynccho &quot;Finish one loop test&quot;</span><br><span class="line">    done</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">rm -rf test_file.*</span><br><span class="line"></span><br><span class="line">echo &quot;Finish all test&quot;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">常见磁盘性能测试</summary>
    
    
    
    <category term="Database" scheme="http://ilongda.com/categories/Database/"/>
    
    <category term="性能测试" scheme="http://ilongda.com/categories/Database/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    
    <category term="Database" scheme="http://ilongda.com/tags/Database/"/>
    
    <category term="性能测试" scheme="http://ilongda.com/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>DB性能测试-常用3套件-手把手一步一步跑tpcc</title>
    <link href="http://ilongda.com/2020/tpcc/"/>
    <id>http://ilongda.com/2020/tpcc/</id>
    <published>2020-07-05T11:42:57.000Z</published>
    <updated>2024-02-02T13:13:42.020Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>把过去的写的一篇笔记分享一下， 数据库最常用的测试三套件， sysbench – oltp 测试， tpch – olap 测试， tpcc – 事务性能测试。<br>本文手把手 一步一步 run tpcc</p><p>整个过程， 分为</p><ul><li>介绍</li><li>准备工作</li><li>编译</li><li>测试</li><li>疑难杂症<span id="more"></span></li></ul><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><span class="exturl" data-url="aHR0cDovL3d3dy50cGMub3JnL3RwY2Mv">http://www.tpc.org/tpcc/<i class="fa fa-external-link-alt"></i></span><br>TPCC有不同的运行方式，用来测试数据库的压力工具，模拟一个电商的业务，主要的业务有新增订单，库存查询，发货，支付等模块的测试。 详情可以参考 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2RvbWluby1zdWNjL3RwY2MtaGJhc2Uvd2lraS8lRTQlQjglQUQlRTYlOTYlODctVFBDLUMlRTclQUUlODAlRTQlQkIlOEI=">https://github.com/domino-succ/tpcc-hbase/wiki/中文-TPC-C简介<i class="fa fa-external-link-alt"></i></span></p><h2 id="模型简介"><a href="#模型简介" class="headerlink" title="模型简介"></a>模型简介</h2><p>在测试开始前，TPC-C Benchmark规定了数据库的初始状态，也就是数据库中数据生成的规则，其中ITEM表中固定包含10万种商品，仓库的数量可进行调整，假设WAREHOUSE表中有W条记录，那么：</p><ul><li>STOCK表中应有W×10万条记录(每个仓库对应10万种商品的库存数据)；</li><li>DISTRICT表中应有W×10条记录(每个仓库为10个地区提供服务)；</li><li>CUSTOMER表中应有W×10×3000条记录(每个地区有3000个客户)；</li><li>HISTORY表中应有W×10×3000条记录(每个客户一条交易历史)；</li><li>ORDER表中应有W×10×3000条记录(每个地区3000个订单)，并且最后生成的900个订单被添加到NEW-ORDER表中，每个订单随机生成5~15条ORDER-LINE记录。</li></ul><p>在测试过程中，每一个地区（DISTRICT）都有一个对应的终端（Terminal），模拟为用户提供服务。在每个终端的生命周期内，要循环往复地执行各类事务，每个事务的流程如图所示，当终端执行完一个事务的周期后，就进入下一个事务的周期，如下图所示。<br><img data-src="/img/tpcc.png" ></p><p>客户下单后，包含若干个订单明细（ORDER-LINE）的订单（ORDER）被生成，并被加入新订单（NEW-ORDER）列表。<br>客户对订单支付还会产生交易历史（HISTORY）。<br>每个订单(ORDER) 平均包含10条订单项(ORDER-LINE), 其中1% 需要从远程仓库中获取.<br>这些就是TPC-C模型中的9个数据表。其中，仓库的数量W可以根据系统的实际情况进行调整，以使系统性能测试结果达到最佳。</p><h2 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h2><p>TPCC用tpmC值（Transactions per Minute）来衡量系统最大有效吞吐量. 其中Transactions以NewOrder Transaction为准，即最终衡量单位为每分钟处理的订单数。</p><h2 id="事务类型"><a href="#事务类型" class="headerlink" title="事务类型"></a>事务类型</h2><p>该benchmark包含5类事务</p><ul><li>NewOrder: 新订单的生成从某一仓库随机选取5-15件商品, 创建新订单. 其中1%的事务需要回滚(即err).  一般来说新订单请求不可能超出全部事务请求的45% |</li><li>Payment : 订单付款更新客户账户余额, 反映其支付情况. 占比 43% </li><li>OrderStatus : 最近订单查询 随机显示一个用户显示其最有益条订单, 显示该订单内的每个商品状态. 占比4% </li><li>Delivery  : 配送, 模拟批处理交易更新该订单用户的余额, 把发货单从neworder中删除. 占比4% </li><li>StockLevel  : 库存缺货状态分析 , 占比4%</li></ul><h2 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h2><p>然后，终端模拟用户输入事务所需的参数，并等待一个输入时间（Keying Time）；等待结束后，事务执行正式开始，执行结束后记录事务的实际执行时间（txnRT），TPC-C对每类事务的执行时间都有一个最低要求，分别是：</p><ul><li>至少90%的NewOrder事务执行时间要低于5秒，</li><li>至少90%的Payment事务执行时间要低于5秒，</li><li>至少90%的OrderStatus事务执行时间要低于5秒，</li><li>至少90%的Payment事务执行时间要低于5秒，</li><li>至少90%的StockLevel事务执行时间要低于20秒；</li></ul><p>最后，终端模拟用户对结果的查看以及思考，等待一个思考时间（Thinking Time）；在思考时间结束后，进入下一个事务周期。 在整个测试过程结束后，用处理过的新订单事务总数量除以整个测试运行的分钟数并取整，就得到了tpmC的值。</p><h1 id="测试工具调研"><a href="#测试工具调研" class="headerlink" title="测试工具调研"></a>测试工具调研</h1><p>TPC-C测试常用的测试工具包括tpcc-mysql，benchmark-sql，Hammer DB，DBT2，sqlbench。这些工具对TPC-C标准的支持程度不尽相同。经过调研发现从DBT2改进来的开源的sqlbench工具是最接近标准要求的测试工具。因此我们首先对比不同工具对标准的支持情况，然后介绍使用sqlbench进行TPC-C测试的步骤。</p><h2 id="tpcc-mysql简介"><a href="#tpcc-mysql简介" class="headerlink" title="tpcc-mysql简介"></a>tpcc-mysql简介</h2><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL1BlcmNvbmEtTGFiL3RwY2MtbXlzcWw=">TPCC-MYSQL<i class="fa fa-external-link-alt"></i></span> 是percona基于TPC-C(下面简写成TPCC)衍生出来的产品，专用于MySQL基准测试。用来测试数据库的压力工具，模拟一个电商的业务，主要的业务有新增订单，库存查询，发货，支付等模块的测试。使用说明明文档（<span class="exturl" data-url="aHR0cHM6Ly93d3cucGVyY29uYS5jb20vYmxvZy8yMDEzLzA3LzAxL3RwY2MtbXlzcWwtc2ltcGxlLXVzYWdlLXN0ZXBzLWFuZC1ob3ctdG8tYnVpbGQtZ3JhcGhzLXdpdGgtZ251cGxvdC8lRUYlQkMlODklRTMlODAlODI=">https://www.percona.com/blog/2013/07/01/tpcc-mysql-simple-usage-steps-and-how-to-build-graphs-with-gnuplot/）。<i class="fa fa-external-link-alt"></i></span></p><h2 id="benchmark-sql简介"><a href="#benchmark-sql简介" class="headerlink" title="benchmark-sql简介"></a>benchmark-sql简介</h2><p><span class="exturl" data-url="aHR0cHM6Ly9zb3VyY2Vmb3JnZS5uZXQvcHJvamVjdHMvYmVuY2htYXJrc3FsLw==">benchmark-sql<i class="fa fa-external-link-alt"></i></span>是java语言实现TPCC工具，使用JDBC接口，支持Oracle、PostgreSQL、firebird和MySQL。</p><h2 id="HammerDB简介"><a href="#HammerDB简介" class="headerlink" title="HammerDB简介"></a>HammerDB简介</h2><p><span class="exturl" data-url="aHR0cDovL3d3dy5oYW1tZXJkYi5jb20vZG9jdW1lbnQuaHRtbA==">HammerDB<i class="fa fa-external-link-alt"></i></span>是Tcl语言实现TPCC&#x2F;TPCH工具，使用存储过程和Tcl包，支持Oracle、SQL Server、DB2、MySQL、PostgreSQL、Redis、Trafodion。支持Windows图形界面以及Tcl脚本脚本，功能比较完善。</p><h2 id="DBT2简介"><a href="#DBT2简介" class="headerlink" title="DBT2简介"></a>DBT2简介</h2><p><span class="exturl" data-url="aHR0cDovL29zZGxkYnQuc291cmNlZm9yZ2UubmV0Lw==">Databases Test 2<i class="fa fa-external-link-alt"></i></span>是由Open Source Development Lab开发的用于测试数据库性能的测试工具，虽然没有完全实现TPCC但是基本上也是模拟了OLTP的应用场景的，测试结果包括每秒处理的事务数、CPU使用率、IO以及内存的使用情况</p><h2 id="sqlbench简介"><a href="#sqlbench简介" class="headerlink" title="sqlbench简介"></a>sqlbench简介</h2><p><span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL3N3aWRhL3NxbGJlbmNo">sqlbench<i class="fa fa-external-link-alt"></i></span>源自DBT2，作者阿里巴巴 荣生(diancheng.wdc)。原来的DBT2把整个测试过程分成client和 driver 两个应用程序，每个terminal需要 2个线程。如果测试的warehouse较多需要占用机器大量资源。而sqlbench对这方面做了优化，合并了这两个应用程序，同时优 化了线程的使用，使用1个线程处理多个terminal，大大减少了机器资源的使用。使一台机器可以运行更多的warehouse。另外 DBT2外部依赖较多，如对R环境的依赖，sqlbench去掉了不必要的外部依赖，目前sqlbench只依赖测试数据库的客户端库。</p><h2 id="数据库支持"><a href="#数据库支持" class="headerlink" title="数据库支持"></a>数据库支持</h2><table><thead><tr><th>sqlbench</th><th>MySQL, PostgreSQL</th></tr></thead><tbody><tr><td>tpcc-mysql</td><td>MySQL</td></tr><tr><td>benchmark-sql</td><td>PostgreSQL, EnterpriseDB and Oracle, MySQL</td></tr><tr><td>HammerDB</td><td>Oracle Database, SQL Server, IBM Db2, MySQL, MariaDB, PostgreSQL and Redis</td></tr><tr><td>DBT2</td><td>MySQL, PostgreSQL</td></tr></tbody></table><h2 id="对sql执行方式的支持"><a href="#对sql执行方式的支持" class="headerlink" title="对sql执行方式的支持"></a>对sql执行方式的支持</h2><table><thead><tr><th>sqlbench</th><th>plain SQL，prepared statement，stored procedure</th></tr></thead><tbody><tr><td>tpcc-mysql</td><td>Prepared statement</td></tr><tr><td>benchmarksql</td><td>Prepared statement</td></tr><tr><td>HammerDB</td><td>Stored Procedure</td></tr><tr><td>DBT2</td><td>Plain SQL，prepared statement，stored procedure</td></tr></tbody></table><h2 id="对key-in-time和think-time的支持"><a href="#对key-in-time和think-time的支持" class="headerlink" title="对key-in time和think time的支持"></a>对key-in time和think time的支持</h2><p>TPC-C标准规定了每一中交易中的模拟用户输入和对输出结果的思考时间，这使得同一个terminal发起的SQL事务是非常低频率的操作。TPC-C标准通过这两个延迟时间限制了同一个terminal在给定的时间内能完成的交易数量，与此同时标准规定用一时间最多只有10个terminals访问同一个warehouse。经过计算1个warehouse能提供的最多TpmC为12.86。</p><table><thead><tr><th>sqlbench</th><th>YES</th></tr></thead><tbody><tr><td>tpcc-mysql</td><td>NO</td></tr><tr><td>benchmark-sql</td><td>NO</td></tr><tr><td>HammerDB</td><td>NO</td></tr><tr><td>DBT2</td><td>YES</td></tr></tbody></table><h2 id="对terminal和database-connection的解耦"><a href="#对terminal和database-connection的解耦" class="headerlink" title="对terminal和database connection的解耦"></a>对terminal和database connection的解耦</h2><p>TPC-C规定了terminal到事务处理引擎中间必须通过网络连接，但是这里所列出的所有工具都不支持这种架构。DBT2和sqlbench虽然不支持这种三层结构，但是支持terminal处理和DB连接用不同的线程分开，其他几个工具没有terminal的概念，直接通过db connection thread完成交易。</p><p><img data-src="https://intranetproxy.alipay.com/skylark/lark/0/2019/png/105349/1573401426816-e09d8730-610a-48a9-b18e-d8fff1fba88b.png#align=left&display=inline&height=383&name=image.png&originHeight=766&originWidth=1520&size=201206&status=done&style=none&width=760" alt="image.png"></p><table><thead><tr><th>sqlbench</th><th>Terminal和DB conneciton解耦，可以单独配置数量。Termial处理线程支持复用，缺省配置每个线程支持50个terminal。</th></tr></thead><tbody><tr><td>tpcc-mysql</td><td>没有terminal，只能配置db connection数量</td></tr><tr><td>benchmark-sql</td><td>没有terminal，只能配置db connection数量</td></tr><tr><td>HammerDB</td><td>没有terminal，只能配置db connection数量</td></tr><tr><td>DBT2</td><td>Terminal和DB conneciton解耦，可以单独配置数量</td></tr></tbody></table><h2 id="TPC-C标准中Home-Warehouse支持"><a href="#TPC-C标准中Home-Warehouse支持" class="headerlink" title="TPC-C标准中Home Warehouse支持"></a>TPC-C标准中Home Warehouse支持</h2><p>标准要求每一个terminal在整个测试运行周期内保持warehouse ID不变，即home warehouse不变。</p><table><thead><tr><th>sqlbench</th><th>支持terminal home warehouse</th></tr></thead><tbody><tr><td>tpcc-mysql</td><td>不支持，warehouse每个交易随机生成</td></tr><tr><td>benchmark-sql</td><td>不支持，warehouse每个交易随机生成</td></tr><tr><td>HammerDB</td><td>支持terminal home warehouse</td></tr><tr><td>DBT2</td><td>支持terminal home warehouse</td></tr></tbody></table><h2 id="Terminal上的可视信息交互"><a href="#Terminal上的可视信息交互" class="headerlink" title="Terminal上的可视信息交互"></a>Terminal上的可视信息交互</h2><p>标准定义了用户从terminal输入数据，然后交易结果的细节数据需要返回给terminal用户用于展示，这会带来额外的时延。所有工具都没有对terminal信息交互的支持。</p><h1 id="sqlbench"><a href="#sqlbench" class="headerlink" title="sqlbench"></a>sqlbench</h1><h2 id="prepare"><a href="#prepare" class="headerlink" title="prepare"></a>prepare</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install -y autoconf automake mysql mysql-devel postgresql-devel</span><br></pre></td></tr></table></figure><h2 id="compile"><a href="#compile" class="headerlink" title="compile"></a>compile</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/swida/sqlbench.git</span><br><span class="line">cd sqlbench</span><br><span class="line">aclocal</span><br><span class="line">autoconf</span><br><span class="line">autoheader</span><br><span class="line">automake --add-missing</span><br><span class="line">./configure --with-postgresql=yes --with-mysql=yes </span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure><h2 id="load-数据"><a href="#load-数据" class="headerlink" title="load 数据"></a>load 数据</h2><p>从 <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xvbmdkYWZlbmcvdGVzdC90cmVlL21hc3Rlci9zaGVsbC90cGNjL3NxbGJlbmNo">https://github.com/longdafeng/test/tree/master/shell/tpcc/sqlbench<i class="fa fa-external-link-alt"></i></span> 上把load.sh 脚本下载下来</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cd sqlbench</span><br><span class="line">cd src/scripts</span><br><span class="line">wget https://raw.githubusercontent.com/longdafeng/test/master/shell/tpcc/sqlbench/load.sh</span><br><span class="line">nohup ./load.sh ipxxxx portxxx userxxx passwordxxx dbnamexxx warehousexxx &gt; load.log 2&gt;&amp;1 &amp;</span><br><span class="line">tail -f load.log </span><br></pre></td></tr></table></figure><ol><li>必须使用ip， 建议不要使用域名， 因为使用域名，经常建立不了到数据库的链接</li><li>脚本是放到${sqlbench_source_dir}&#x2F;src&#x2F;scripts 下</li></ol><ul><li>ipxxxx     数据库的ip</li><li>portxxx    数据库的端口号</li><li>userxxx    数据库的用户名</li><li>password   数据库的密码</li><li>dbnamexxx  数据库的库名字</li><li>warehousexxx warehouse 的个数 ， 比如100</li></ul><h2 id="运行测试"><a href="#运行测试" class="headerlink" title="运行测试"></a>运行测试</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cd sqlbench</span><br><span class="line"># MySQL:</span><br><span class="line">nohup ./src/core/sqlbench -t mysql --dbname=tpcc --user=user --password=password --host=127.0.0.1 --port=3306 -w100 -c32 -l7200 -r1200 --sqlapi=storeproc &gt;run.log 2&gt;&amp;1 &amp;</span><br><span class="line">tail -f run.log</span><br></pre></td></tr></table></figure><p>这里:</p><p>• -t 指定PostgreSQL数据库 –dbname和–host为数据库的连接参数，其他没指定的使用默认参数<br>• -w 指定测试数据为100个warehouse<br>• -l 共运行测试时间为7200秒<br>• -r 其中ramp up的时间为1200秒<br>• -c 共使用32个数据库连接<br>sqlbench其他的常用参数包括：<br>• –no-thinktime 默认的TPC-C测试是有keying time和thinking time的，模拟真正的用户场景，可通过指定这个参数将相应 的时间设置成0，不控制时间间隔，产生最大压力<br>• –sqlapi 选择SQL执行的方式，可选：<br>• simple 为普通SQL方式<br>• extended 使用prepare&#x2F;bind&#x2F;execute方式，该方式先生成查询计划缓存起来，后面直接执行，效率更高<br>• storeproc 使用存储过程，这种方式与比extended相比还节省了与数据库服务器通信的开销<br>• -s与-e指定开始和结束的warehouse数，在更多warehouse时，可以使用这2个选项分配warehouse，分成多个sqlbench压测同 一个数据库<br>• –altered默认情况sqlbench下根据TPC-C标准生成terminal数（每个terminal代表一个user，每个warehouse 10个terminal， 也可以使用–tpw改变），这个参数直接指定了terminal个数，被这些warehouse平均分。<br>• –sleep指定每创建一个线程后sleep的时间，默认为1s<br>• -o 用来指定output目录，用来存储错误日志及测试结果文件<br>sqlbench的其他参数是用来定制TPC-C标准的各个部分的，包括keying time、thinking time的时间，各个事务所占比率，各个 表的数据量等，默认值都是遵从TPC-C标准的。</p><p>比如常用</p><ol><li><p>没有think time控制</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./src/core/sqlbench -t mysql --dbname=tpcc --user=user --password=password --host=$HOST --port=$PORT -w$WH -c$CONN -l7200 -r1200 --sqlapi=storeproc --no-thinktime --sleep=10</span><br></pre></td></tr></table></figure></li><li><p>有think time控制</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./src/core/sqlbench -t mysql --dbname=tpcc --user=user --password=password --host=$HOST --port=$PORT -w$WH -c$CONN -l7200 -r1200 --sqlapi=storeproc --sleep=10</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ol><h2 id="生成测试报告"><a href="#生成测试报告" class="headerlink" title="生成测试报告"></a>生成测试报告</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">src/utils/post_process -l mix.log</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">性能测试 -- DB性能测试-常用3套件-手把手一步一步跑tpcc</summary>
    
    
    
    <category term="Database" scheme="http://ilongda.com/categories/Database/"/>
    
    <category term="性能测试" scheme="http://ilongda.com/categories/Database/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    
    <category term="Database" scheme="http://ilongda.com/tags/Database/"/>
    
    <category term="性能测试" scheme="http://ilongda.com/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>DB性能测试-常用3套件-手把手一步一步跑sysbench</title>
    <link href="http://ilongda.com/2020/sysbench/"/>
    <id>http://ilongda.com/2020/sysbench/</id>
    <published>2020-06-28T11:42:57.000Z</published>
    <updated>2024-02-02T13:13:08.759Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>把过去的写的一篇笔记分享一下， 数据库最常用的测试三套件， sysbench – oltp 测试， tpch – olap 测试， tpcc – 事务性能测试。<br>本文手把手 一步一步 run sysbench</p><p>整个过程， 分为</p><ul><li>介绍</li><li>准备工作</li><li>编译</li><li>测试</li><li>疑难杂症<span id="more"></span></li></ul><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>下面引用老外的一段话来介绍一下sysbench</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sysbench is a scriptable multi-threaded benchmark tool based on LuaJIT. It is most frequently used for database benchmarks, but can also be used to create arbitrarily complex workloads that do not involve a database server.</span><br><span class="line"></span><br><span class="line">sysbench comes with the following bundled benchmarks:</span><br><span class="line"></span><br><span class="line">    * oltp_*.lua: a collection of OLTP-like database benchmarks</span><br><span class="line">    * fileio: a filesystem-level benchmark</span><br><span class="line">    * cpu: a simple CPU benchmark</span><br><span class="line">    * memory: a memory access benchmark</span><br><span class="line">    * threads: a thread-based scheduler benchmark</span><br><span class="line">    * mutex: a POSIX mutex benchmark</span><br></pre></td></tr></table></figure><p>今天我们最主要使用的oltp 系列测试</p><h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>安装相应的包</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum -y install gcc gcc-c++ autoconf automake make libtool bzr mysql-devel git mysql</span><br><span class="line">yum -y install make automake libtool pkgconfig libaio-devel</span><br><span class="line">yum -y install openssl-devel</span><br></pre></td></tr></table></figure><p>执行如下命令配置Sysbench client，使内核可以使用所有的CPU核处理数据包（默认设置为使用2个核），同时减少CPU核之间的上下文切换。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo sh -c &#x27;for x in /sys/class/net/eth0/queues/rx-*; do echo ffffffff&gt;$x/rps_cpus; done&#x27;</span><br><span class="line">sudo sh -c &quot;echo 32768 &gt; /proc/sys/net/core/rps_sock_flow_entries&quot;</span><br><span class="line">sudo sh -c &quot;echo 4096 &gt; /sys/class/net/eth0/queues/rx-0/rps_flow_cnt&quot;</span><br><span class="line">sudo sh -c &quot;echo 4096 &gt; /sys/class/net/eth0/queues/rx-1/rps_flow_cnt&quot;</span><br></pre></td></tr></table></figure><p>备注： 说明 ffffffff表示使用32个核。请根据实际配置修改，例如ECS为8核，则输入ff。</p><h1 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h1><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">git clone https://github.com/akopytov/sysbench.git</span><br><span class="line">##从Git中下载sysbench</span><br><span class="line"></span><br><span class="line">cd sysbench</span><br><span class="line">##打开sysbench目录</span><br><span class="line"></span><br><span class="line">git checkout 1.0.18</span><br><span class="line">##切换到sysbench 1.0.18版本， 也可以不用切换到1.0.18 版本上，直接使用master</span><br><span class="line"></span><br><span class="line">./autogen.sh</span><br><span class="line">##运行autogen.sh</span><br><span class="line"></span><br><span class="line">./configure --prefix=/usr --mandir=/usr/share/man</span><br><span class="line"></span><br><span class="line">make</span><br><span class="line">##编译</span><br><span class="line"></span><br><span class="line">make install</span><br></pre></td></tr></table></figure><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>sysbench 的测试 通常类似这样,  分为3个阶段， 一个prepare， 一个run， 一个cleanup</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600  oltp_write_only prepare</span><br><span class="line">##准备数据</span><br><span class="line"></span><br><span class="line">sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600   --threads=XXX --percentile=95 --report-interval=1 oltp_write_only run</span><br><span class="line">##运行workload</span><br><span class="line"></span><br><span class="line">sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600   --threads=XXX --percentile=95  oltp_write_only cleanup</span><br><span class="line">##清理</span><br></pre></td></tr></table></figure><p>命令解释</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">--mysql-host       IP</span><br><span class="line">--mysql-port       端口号</span><br><span class="line">--mysql-db         希望链接的数据库</span><br><span class="line">--mysql-user       用户名</span><br><span class="line">--mysql-password   密码</span><br><span class="line">--table_size       每张表初始化的数据数量</span><br><span class="line">--tables           初始化表的数量</span><br><span class="line">--threads          启动的线程</span><br><span class="line">--time             运行时间设为0表示不限制时间</span><br><span class="line">--report-interval  运行期间日志，单位为秒</span><br><span class="line">--events           最大请求数量，定义数量后可以不需要--time选项</span><br><span class="line">--rand-type        访问数据时使用的随机生成函数 可以选择&quot;special&quot;， &quot;uniform&quot;， &quot;gaussian&quot;， &quot;pareto&quot;， 默认special， 早期时uniform</span><br><span class="line">--skip_trx=on      在只读测试中可以选择打开或关闭事务， 默认是打开</span><br></pre></td></tr></table></figure><p>作者写了一个自动测试的脚本， 读者可以从<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xvbmdkYWZlbmcvdGVzdC90cmVlL21hc3Rlci9zaGVsbC9zeXNiZW5jaA==">https://github.com/longdafeng/test/tree/master/shell/sysbench<i class="fa fa-external-link-alt"></i></span>  将脚本下载下来<br>记得将 脚本放到 sysbench 源码目录下src&#x2F;lua 下面</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cd sysbench</span><br><span class="line">cd src/lua</span><br><span class="line">wget https://raw.githubusercontent.com/longdafeng/test/master/shell/sysbench/start-sysbench.sh </span><br><span class="line">wget https://raw.githubusercontent.com/longdafeng/test/master/shell/sysbench/start.sh</span><br><span class="line">nohup ./start.sh hostxxx portxxx userxxx passwordxxx dbxxx &gt; run.log 2&gt;&amp;1 &amp;</span><br><span class="line">tail -f run.log</span><br></pre></td></tr></table></figure><p>其中hostxxx, portxxx, userxxx, passwordxxx, dbxxx 修改为真实mysql的参数<br>这个脚本， 是设置不同大表大小， 设置不同随机参数， 设置不同的线程数， 设置是否打开或关闭事务， 依次运行oltp_read_only, oltp_write_only, oltp_read_write 3个集成测试，<br>在src&#x2F;lua 目录下， 还有很多单项测试, 比如insert, point_select, update_index, update_non_index, select_random_points, select_random_ranges 分别是针对不同的场景的测试</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@kudu lua]# ls *.lua</span><br><span class="line">bulk_insert.lua  oltp_common.lua  oltp_insert.lua        oltp_read_only.lua   oltp_update_index.lua      oltp_write_only.lua  select_random_points.lua</span><br><span class="line">empty-test.lua   oltp_delete.lua  oltp_point_select.lua  oltp_read_write.lua  oltp_update_non_index.lua  prime-test.lua       select_random_ranges.lua</span><br></pre></td></tr></table></figure><h1 id="疑难杂症"><a href="#疑难杂症" class="headerlink" title="疑难杂症"></a>疑难杂症</h1><h2 id="性能差"><a href="#性能差" class="headerlink" title="性能差"></a>性能差</h2><p>sysbench 是对cpu&#x2F;memory&#x2F;网络非常敏感的测试， 经常遇到 很多客户在测试的过程中，发现性能和预期的差距比较大， 深究后，发现， sysbench的肉机（客户端） 和目标测试数据不在同一个局域网或者一个vpc 内（云上客户）， 对于很多云数据库， 肉机和目标mysql 必须在同一个region， 并且是在同一个vpc， 并且在链接字符串的时候，必须使用私有的链接地址，不能使用公网的链接地址， 公网的链接地址会经过很多跳。</p><p>假设语句是：<br>sysbench oltp_read_write.lua –mysql-host&#x3D;127.0.0.1 –mysql-port&#x3D;3306 –mysql-db&#x3D;sbtest –mysql-user&#x3D;root –mysql-password&#x3D;123456 –table_size&#x3D;200000000 –tables&#x3D;1 –threads&#x3D;500 –events&#x3D;500000 –report-interval&#x3D;10 –time&#x3D;0</p><h2 id="no-such-built-in-test-file-or-module"><a href="#no-such-built-in-test-file-or-module" class="headerlink" title="no such built-in test, file or module"></a>no such built-in test, file or module</h2><p>如果执行的时候提示FATAL: Cannot find benchmark ‘oltp_read_write.lua’: no such built-in test, file or module</p><p>切换到sysbench的源码目录（sysbench.tar.gz解压路径）<br>find .&#x2F; -name oltp_read_write.lua<br>.&#x2F;src&#x2F;lua&#x2F;oltp_read_write.lua<br>接着切换到src&#x2F;lua 目录再执行语句</p><h2 id="“Can-not-connect-to-MySQL-server-Too-many-connections”"><a href="#“Can-not-connect-to-MySQL-server-Too-many-connections”" class="headerlink" title="“Can not connect to MySQL server. Too many connections”"></a>“Can not connect to MySQL server. Too many connections”</h2><p>#如果执行的时候命令行提示“Can not connect to MySQL server. Too many connections”-mysql 1040错误：<br>shell&gt;mysql -uroot -p****<br>mysql&gt;show variables like ‘max_connections’;(查看当前的最大连接数)<br>mysql&gt;set global max_connections&#x3D;1000;(设置最大连接数为1000，可以再次查看是否设置成功)<br>mysql&gt;show variables like ‘max_connections’;(查看当前的最大连接数)<br>mysql&gt;exit</p><h2 id="sysbench-无法运行"><a href="#sysbench-无法运行" class="headerlink" title="sysbench 无法运行"></a>sysbench 无法运行</h2> <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ldd /usr/bin/sysbench</span><br></pre></td></tr></table></figure><p>正常情况下， sysbench 依赖的所有library 应该都可以resolve 掉， 如果有的时候，没有找到依赖的library， 最常见的是没有找到mysql的library<br>需要安装</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum -y install mysql-devel mysql</span><br></pre></td></tr></table></figure><p>然后再重新编译sysben的源码</p><p>如果问题依旧存在<br>可以尝试， 手动创建连接</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">去根目录找一下：</span><br><span class="line">find / -name &quot;*mysqlclient_r*&quot;</span><br><span class="line">/usr/lib64/mysql/libmysqlclient_r.so.18</span><br><span class="line">/usr/lib64/mysql/libmysqlclient_r.so.18.1.0</span><br><span class="line">库文件是有的，不过带个数字后缀，给库文件建立软链接：</span><br><span class="line">ln -s /usr/lib64/mysql/libmysqlclient_r.so.18 /usr/lib64/mysql/libmysqlclient_r.so</span><br></pre></td></tr></table></figure><p>如果问题还是不能解决， 最后的办法就是从github 上下载mysql的源码， 先对mysql 源码进行编译，安装，然后再重新编译sysbench</p><pre><code># --with-mysql-includes选项指定mysql的include文件夹，里面是一些.h的头文件，比如mysql.h，未安装mysql-community-devel-version是没有include文件夹的# with-mysql-libs选项指定mysql的一些lib，里面是一些.a文件和.so文件，比如libmysqlclient.a，libmysqlclient.so# 比如./configure --prefix=/usr   --with-mysql-includes=/usr/include/mysql --with-mysql-libs=/usr/lib64/mysql</code></pre>]]></content>
    
    
    <summary type="html">性能测试 -- DB性能测试-常用3套件-手把手一步一步跑sysbench</summary>
    
    
    
    <category term="Database" scheme="http://ilongda.com/categories/Database/"/>
    
    <category term="性能测试" scheme="http://ilongda.com/categories/Database/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    
    <category term="Database" scheme="http://ilongda.com/tags/Database/"/>
    
    <category term="性能测试" scheme="http://ilongda.com/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>DB性能测试-常用3套件-手把手一步一步跑TPCH</title>
    <link href="http://ilongda.com/2020/TPCH/"/>
    <id>http://ilongda.com/2020/TPCH/</id>
    <published>2020-06-22T11:42:57.000Z</published>
    <updated>2024-02-02T13:13:53.602Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>把过去的写的一篇笔记分享一下， 数据库最常用的测试三套件， sysbench – oltp 测试， tpch – olap 测试， tpcc – 事务性能测试。<br>本文手把手 一步一步 run TPCH, 即使从来没有跑过数据库的，也可以直接上手运行TPCH, 本文以运行TPCH on MySQL,  如果读者想要运行tpch 到postgres 或者其他的数据， 可以先参考本博文，然后基于本博文，再到github上搜索相应数据库的TPCH 库 即可。</p><p>整个过程， 分为</p><ul><li>介绍</li><li>编译</li><li>数据生成</li><li>数据加载</li><li>性能测试</li><li>表结构介绍<span id="more"></span></li></ul><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>TPC现有的测试标准为：TPC-E、TPC-C、TPC-H、TPC-App。根据这4个测试基准，目前TPC主要包括的4个技术小组委员会：TPC-E 技术小组委员会、TPC-C 技术小组委员会、TPC-H技术小组委员会、TPC-App技术小组委员会。前期TPC使用过但目前已经停止使用的测试标准有：TPC-A、TPC-B（数据库处理能力测试标准）、TPC-D、TPC-R（决策支持系统测试标准，类TPC-H）、TPC-W（Web处理能力测试标准）。</p><p>TPC-H（商业智能计算测试） 是美国交易处理效能委员会(TPC,Transaction Processing Performance Council) 组织制定的用来模拟决策支持类应用的一个测试集.目前,在学术界和工业界普遍采用它来评价决策支持技术方面应用的性能. 这种商业测试可以全方位评测系统的整体商业计算综合能力，对厂商的要求更高，同时也具有普遍的商业实用意义，目前在银行信贷分析和信用卡分析、电信运营分析、税收分析、烟草行业决策分析中都有广泛的应用。</p><p>TPC-H 基准测试是由 TPC-D(由 TPC 组织于 1994 年指定的标准,用于决策支持系统方面的测试基准)发展而来的.TPC-H 用 3NF 实现了一个数据仓库,共包含 8 个基本关系,其数据量可以设定从 1G<del>3T 不等。TPC-H 基准测试包括 22 个查询(Q1</del>Q22),其主要评价指标是各个查询的响应时间,即从提交查询到结果返回所需时间.TPC-H 基准测试的度量单位是每小时执行的查询数( QphH@size)，其中 H 表示每小时系统执行复杂查询的平均次数，size 表示数据库规模的大小,它能够反映出系统在处理查询时的能力.TPC-H 是根据真实的生产运行环境来建模的,这使得它可以评估一些其他测试所不能评估的关键性能参数.总而言之,TPC 组织颁布的TPC-H 标准满足了数据仓库领域的测试需求,并且促使各个厂商以及研究机构将该项技术推向极限。</p><p>详细可以参考 <span class="exturl" data-url="aHR0cDovL3d3dy50cGMub3JnL3RwY19kb2N1bWVudHNfY3VycmVudF92ZXJzaW9ucy9wZGYvdHBjLWhfdjIuMTcuMy5wZGY=">tpch_reference<i class="fa fa-external-link-alt"></i></span></p><h1 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h1><p>下载源码包<span class="exturl" data-url="aHR0cDovL3d3dy50cGMub3JnL3RwY19kb2N1bWVudHNfY3VycmVudF92ZXJzaW9ucy9jdXJyZW50X3NwZWNpZmljYXRpb25zNS5hc3A=">tpch<i class="fa fa-external-link-alt"></i></span><br><img data-src="http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/7761866951/p70167.png" alt="tpch_download"></p><ol><li>打开dbgen目录。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd dbgen</span><br></pre></td></tr></table></figure></li><li>复制makefile文件。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cp makefile.suite Makefile</span><br></pre></td></tr></table></figure></li><li>修改Makefile文件中的CC、DATABASE、MACHINE、WORKLOAD等参数定义。<br>打开Makefile文件。<br>修改CC、DATABASE、MACHINE、WORKLOAD参数的定义。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">################</span><br><span class="line">## CHANGE NAME OF ANSI COMPILER HERE</span><br><span class="line">################</span><br><span class="line">CC      = gcc</span><br><span class="line"># Current values for DATABASE are: INFORMIX, DB2, ORACLE,</span><br><span class="line">#                                  SQLSERVER, SYBASE, TDAT (Teradata)</span><br><span class="line"># Current values for MACHINE are:  ATT, DOS, HP, IBM, ICL, MVS,</span><br><span class="line">#                                  SGI, SUN, U2200, VMS, LINUX, WIN32</span><br><span class="line"># Current values for WORKLOAD are:  TPCH</span><br><span class="line">DATABASE= MYSQL</span><br><span class="line">MACHINE = LINUX</span><br><span class="line">WORKLOAD = TPCH</span><br></pre></td></tr></table></figure>按ECS键，然后输入:wq退出并保存。</li><li>修改tpcd.h文件，并添加新的宏定义。<br>打开tpcd.h文件。<br>vim tpcd.h<br>添加如下宏定义。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#ifdef MYSQL</span><br><span class="line">#define GEN_QUERY_PLAN &quot;&quot;</span><br><span class="line">#define START_TRAN &quot;START TRANSACTION&quot;</span><br><span class="line">#define END_TRAN &quot;COMMIT&quot;</span><br><span class="line">#define SET_OUTPUT &quot;&quot;</span><br><span class="line">#define SET_ROWCOUNT &quot;limit %d;\n&quot;</span><br><span class="line">#define SET_DBASE &quot;use %s;\n&quot;</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure>按ECS键，然后输入:wq退出并保存。</li><li>对文件进行编译。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make</span><br></pre></td></tr></table></figure>编译完成后该目录下会生成两个可执行文件：</li></ol><ul><li>dbgen：数据生成工具。在使用InfiniDB官方测试脚本进行测试时，需要用该工具生成tpch相关表数据。</li><li>qgen：SQL生成工具。生成初始化测试查询，由于不同的seed生成的查询不同，为了结果的可重复性，请使用附件提供的22个查询。</li></ul><h1 id="生成数据"><a href="#生成数据" class="headerlink" title="生成数据"></a>生成数据</h1><h2 id="生成测试数据"><a href="#生成测试数据" class="headerlink" title="生成测试数据"></a>生成测试数据</h2><p>可以生成tpch 10g 也可以100g， 甚至1TB, 本例以100g 为例， 100g 的记录数在6亿条左右， 和普通一家中小型公司的大表规格差不多</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./dbgen -s 100</span><br><span class="line">mkdir tpch100</span><br><span class="line">mv *.tbl tpch100</span><br></pre></td></tr></table></figure><h2 id="生成查询sql"><a href="#生成查询sql" class="headerlink" title="生成查询sql"></a>生成查询sql</h2><ol><li>将qgen与dists.dss复制到queries目录下。<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp qgen queries</span><br><span class="line">cp dists.dss queries</span><br></pre></td></tr></table></figure></li><li>使用以下脚本生成查询。<br>在queries 目录下，创建脚本gen.sh<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">#!/usr/bin/bash</span><br><span class="line">for i in &#123;1..22&#125;</span><br><span class="line">do  </span><br><span class="line">  ./qgen -d $i -s 100 &gt; db&quot;$i&quot;.sql</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./gen.sh</span><br></pre></td></tr></table></figure><ol start="3"><li>查询sql 进行调整<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dos2unix *</span><br></pre></td></tr></table></figure>去掉生成文件中的”limit -1”, 去掉day 后面的(3), 以q1 为例， sql 如下</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">-- using default substitutions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">select</span><br><span class="line">        l_returnflag,</span><br><span class="line">        l_linestatus,</span><br><span class="line">        sum(l_quantity) as sum_qty,</span><br><span class="line">        sum(l_extendedprice) as sum_base_price,</span><br><span class="line">        sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,</span><br><span class="line">        sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,</span><br><span class="line">        avg(l_quantity) as avg_qty,</span><br><span class="line">        avg(l_extendedprice) as avg_price,</span><br><span class="line">        avg(l_discount) as avg_disc,</span><br><span class="line">        count(*) as count_order</span><br><span class="line">from</span><br><span class="line">        lineitem</span><br><span class="line">where</span><br><span class="line">        l_shipdate &lt;= date &#x27;1998-12-01&#x27; - interval &#x27;90&#x27; day (3)   --- 把(3) 去掉</span><br><span class="line">group by</span><br><span class="line">        l_returnflag,</span><br><span class="line">        l_linestatus</span><br><span class="line">order by</span><br><span class="line">        l_returnflag,</span><br><span class="line">        l_linestatus;</span><br><span class="line">limit -1;              ---  去掉这行</span><br></pre></td></tr></table></figure><h1 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h1><ol><li><p>下载加载脚本</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">mkdir load</span><br><span class="line">cd load</span><br><span class="line">wget https://raw.githubusercontent.com/longdafeng/test/master/shell/tpch/load.sh ./</span><br><span class="line">wget https://raw.githubusercontent.com/longdafeng/test/master/shell/tpch/polar.index.sh ./</span><br><span class="line">chmod +x *</span><br><span class="line">cp ../dss.ri  ../dss.ddl ./</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>因为这个测试里面带了polardb 的创建index 脚本， 读者如果不使用polardb，则可以不用下载polar.index.sh， 并修改load.sh 文件，去掉设置index 的步骤</p></li><li><p>修改dss.ri 脚本<br>dss.ri 主要是设置primary key 和foreign key</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">-- Sccsid:     @(#)dss.ri       2.1.8.1</span><br><span class="line">-- TPCD Benchmark Version 8.0</span><br><span class="line"></span><br><span class="line">CONNECT TO TPCD;           </span><br><span class="line"></span><br><span class="line">--ALTER TABLE TPCD.REGION DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.NATION DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.PART DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.SUPPLIER DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.PARTSUPP DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.ORDERS DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.LINEITEM DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.CUSTOMER DROP PRIMARY KEY;</span><br></pre></td></tr></table></figure><p>把 其中”CONNECT TO TPCD;  “删除掉， 把所有的”TPCD.” 给去除掉</p></li></ol><p>如果不想修改dss.ri, 可以直接下载现成的<span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xvbmdkYWZlbmcvdGVzdC90cmVlL21hc3Rlci9zaGVsbC90cGNo">dss.ri<i class="fa fa-external-link-alt"></i></span></p><ol start="3"><li>按照mysql 客户端<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install mysql -y</span><br></pre></td></tr></table></figure></li><li>开始加载<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup./load.sh hostxxx portxxx userxxx passwordxxx dbxxx &gt; load.log 2&gt;&amp;1 &amp;</span><br><span class="line">tail -f load.log</span><br></pre></td></tr></table></figure></li></ol><p>其中hostxxx 为db 地址<br>portxxx 为db 端口<br>userxxx 为用户名   — 需要提前创建好用户名， 对于云上用户， 还需要设置白名单， 把机器ip 白名单设置进去<br>passwordxxx 为用户密码<br>dbxxx 为 要创建的数据库名字，   因为脚本会自动加载在“生成数据” 一节中创建的目录（我们例子中是tpch100），因此数据库名也必须是上一节生成数据创建的目录</p><h1 id="开始测试"><a href="#开始测试" class="headerlink" title="开始测试"></a>开始测试</h1><p>下载 测试脚本  <span class="exturl" data-url="aHR0cHM6Ly9naXRodWIuY29tL2xvbmdkYWZlbmcvdGVzdC90cmVlL21hc3Rlci9weXRob24vdHBjaA==">https://github.com/longdafeng/test/tree/master/python/tpch<i class="fa fa-external-link-alt"></i></span> </p><p>配置配置文件example.cfg</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    &quot;host&quot;:&quot;xxxx&quot;                 // 数据库机器名</span><br><span class="line">    &quot;port&quot;:&quot;3306&quot;                 // 数据库端口号</span><br><span class="line">    &quot;username&quot;:&quot;xxxxx&quot;            // 数据库用户名</span><br><span class="line">    &quot;password&quot;:&quot;xxxx&quot;             // 数据库密码</span><br><span class="line">    &quot;database&quot;:&quot;xxxxx&quot;            // 数据库 库名</span><br><span class="line">    //input dir</span><br><span class="line">    &quot;input_dir&quot;:&quot;mysql&quot;           // 查询sql 存放的目录，如果是测试mysql 系列，则这里是mysql， 如果是pg，则需要生成pg的查询sql</span><br><span class="line">    </span><br><span class="line">    //output_dir</span><br><span class="line">    &quot;output_dir&quot;:&quot;polardb80&quot;      // 打印日志的目录</span><br><span class="line">    </span><br><span class="line">    //mysql_setting, set mysql variable</span><br><span class="line">    //&quot;mysql_setting&quot;: &quot;set max_parallel_degree=32;&quot;</span><br><span class="line">    &quot;mysql_setting&quot;: &quot;&quot;</span><br><span class="line"></span><br><span class="line">    //query per sql times</span><br><span class="line">    &quot;times_per_sql&quot;:&quot;1&quot;            // 每条sql 执行的次数， 会取平均值</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>运行脚本</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">nohup ./tpch.py -f example.cfg &gt; run.log 2&gt;&amp;1 &amp;</span><br><span class="line">tail -f run.log</span><br></pre></td></tr></table></figure><p>最后进入配置文件“output_dir” 目录下，查看result 文件即可</p>]]></content>
    
    
    <summary type="html">性能测试 -- DB性能测试-常用3套件-手把手一步一步跑TPCH</summary>
    
    
    
    <category term="Database" scheme="http://ilongda.com/categories/Database/"/>
    
    <category term="性能测试" scheme="http://ilongda.com/categories/Database/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
    
    <category term="Database" scheme="http://ilongda.com/tags/Database/"/>
    
    <category term="性能测试" scheme="http://ilongda.com/tags/%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>filesort 详细解析</title>
    <link href="http://ilongda.com/2020/mysql-filesort/"/>
    <id>http://ilongda.com/2020/mysql-filesort/</id>
    <published>2020-06-21T11:42:57.000Z</published>
    <updated>2024-02-02T13:08:57.941Z</updated>
    
    <content type="html"><![CDATA[<p>这篇文章介绍的非常好， 所以给大家推荐一下<br>【转载】<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L244OExwbw==">https://blog.csdn.net/n88Lpo<i class="fa fa-external-link-alt"></i></span></p><h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>排序（filesort）作为DBA绕不开的话题，也经常有朋友讨论它，比如常见的问题如下：</p><ul><li>排序的时候，用于排序的数据会不会如Innodb一样压缩空字符存储，比如varchar(30)，我只是存储了1个字符是否会压缩，还是按照30个字符计算？</li><li>max_length_for_sort_data&#x2F;max_sort_length 到底是什么含义？</li><li>original filesort algorithm（回表排序） 和 modified filesort algorithm（不回表排序） 的根本区别是什么？</li><li>为什么使用到排序的时候慢查询中的Rows_examined会更大，计算方式到底是什么样的？<br>在MySQL通常有如下算法来完成排序：</li><li>内存排序（优先队列 order by limit 返回少量行常用，提高排序效率，但是注意order by limit n,m 如果n过大可能会涉及到排序算法的切换）</li><li>内存排序（快速排序）</li><li>外部排序（归并排序）<br>但是由于能力有限本文不解释这些算法，并且本文不考虑优先队列算法的分支逻辑，只以快速排序和归并排序作为基础进行流程剖析。</li></ul><p>我们在执行计划中如果出现filesort字样通常代表使用到了排序，但是执行计划中看不出来下面问题：</p><ul><li>是否使用了临时文件。</li><li>是否使用了优先队列。</li><li>是original filesort algorithm（回表排序）还是modified filesort algorithm（不回表排序）。<br>如何查看将在后面进行描述。本文还会给出大量的排序接口供敢兴趣的朋友使用，也给自己留下笔记。</li></ul><span id="more"></span><h1 id="十四、全文总结"><a href="#十四、全文总结" class="headerlink" title="十四、全文总结"></a>十四、全文总结</h1><p>提前将总结列在这里，方便读者快速浏览， 本文写了很多，这里需要做一个详细的总结：<br>总结1 ：排序中一行记录如何组织？</p><ul><li><p>一行排序记录，由sort字段+addon字段 组成，其中sort字段为order by 后面的字段，而addon字段为需要访问的字段，比如‘select a1,a2,a3 from test order by a2,a3’，其中sort字段为‘a2,a3’，addon字段为‘a1,a2,a3’。sort字段中的可变长度字段不能打包（pack）压缩，比如varchar，使用的是定义的大小计算空间，注意这是排序使用空间较大的一个重要因素。</p></li><li><p>如果在计算sort字段空间的时候，某个字段的空间大小大于了max_sort_length大小则按照max_sort_length指定的大小计算。</p></li><li><p>一行排序记录，如果sort字段+addon字段 的长度大于了max_length_for_sort_data的大小，那么addon字段将不会存储，而使用sort字段+ref字段代替，ref字段为主键或者ROWID，这个时候就会使用original filesort algorithm（回表排序）的方式了。</p></li><li><p>如果addon字段包含可变字段比如varchar字段，则会使用打包（pack）技术进行压缩，节省空间。<br>可以参考第3、第4、第5、第6、第8节。<br>总结2：排序使用什么样的方法进行？</p></li><li><p>original filesort algorithm（回表排序）</p></li></ul><p>如果使用的是sort字段+ref字段进行排序，那么必须要回表获取需要的数据，如果排序使用了临时文件（也就是说使用外部归并排序，排序量较大）则会使用批量回表，批量回表会涉及到read_rnd_buffer_size参数指定的内存大小，主要用于排序和结果返回。如果排序没有使用临时文件（内存排序就可以完成，排序量较小）则采用单行回表。</p><p>*<br>modified filesort algorithm（不回表排序）</p><p>如果使用的是sort字段+addon字段进行排序，那么使用不回表排序，所有需要的字段均在排序过程中进行存储，addon字段中的可变长度字段可以进行打包（pack）压缩节省空间。其次sort字段和addon字段中可能有重复的字段，比如例2中，sort字段为a2、a3，addon字段为a1、a2、a3，这是排序使用空间较大的另外一个原因。<br>在OPTIMIZER_TRACE中可以查看到使用了那种方法，参考12节。<br>总结3：每次排序一定会分配sort_buffer_size参数指定的内存大小吗？</p><p>不是这样的，MySQL会做一个初步的计算，通过比较Innodb中聚集索引可能存储的行上限和sort_buffer_size参数指定大小内存可以容纳的行上限，获取它们小值进行确认最终内存分配的大小，目的在于节省内存空间。<br>在OPTIMIZER_TRACE中可以看到使用的内存大小，参考第8、第12节。<br>总结4：关于OPTIMIZER_TRACE中的examined_rows和慢查询中的Rows_examined有什么区别？</p><ul><li>慢查询中的Rows_examined包含了重复计数，重复的部分为where条件过滤后做了排序的部分。</li><li>OPTIMIZER_TRACE中的examined_rows不包含重复计数，为实际Innodb层扫描的行数。<br>可以参考11节。<br>总结5：外部排序临时文件的使用是什么样的？</li></ul><p>实际上一个语句的临时文件不止一个，但是它们都以MY开头，并且都放到了tmpdir目录下，lsof可以看到这种文件。</p><ul><li>临时文件1：用于存储内存排序的结果，以chunk为单位，一个chunk的大小就是sort buffer的大小。</li><li>临时文件2：以前面的临时文件1为基础，做归并排序。</li><li>临时文件3：将最后的归并排序结果存储，去掉sort字段，只保留addon字段（需要访问的字段）或者ref字段（ROWID或者主键），因此它一般会比前面2个临时文件小。<br>但是它们不会同时存在，要么 临时文件1和临时文件2存在，要么 临时文件2和临时文件3存在。对于临时文件的使用可以查看Sort_merge_passes，本值多少会侧面反应出外部排序量的大小。<br>可以参考第10节。<br>总结6：排序使用了哪种算法？</li></ul><p>虽然本文不涉及算法，但是内部排序有2种算法需要知道：</p><ul><li>内存排序（优先队列 order by limit 返回少量行常用，提高排序效率，但是注意order by limit n,m 如果n过大可能会涉及到排序算法的切换）</li><li>内存排序（快速排序）<br>在通过OPTIMIZER_TRACE可以查看是否使用使用了优先队列算法，参考12节。<br>总结7：“Creating sort index”到底是什么状态？</li></ul><p>我们前面讲的全部排序流程都会包含在这个状态下，包括：</p><ul><li>获取排序需要的数据（比如例子中全表扫描从Innodb层获取数据）</li><li>根据where条件过滤数据</li><li>内存排序</li><li>外部排序<br>总结8：如何避免临时文件过大的情况？</li></ul><p>首先应该考虑是否可以使用索引来避免排序，如果不能则需要考虑下面的要点：</p><ul><li>order by 后面的字段满足需求即可，尽可能的少。</li><li>order by 后面涉及的字段尽量为固定长度的字段类型，而不是可变字段类型如varchar。因为sort字段不能压缩。</li><li>不要过大的定义可变字段长度，应该合理定义，例如varchar（10）能够满足需求不要使用varchar（50），这些空间虽然在Innodb层存储会压缩，但是MySQL层确可能使用全长度（比如sort字段）。</li><li>在查询中尽量不要用（select *） 而使用需要查询的字段，这将会减少addon字段的个数，在我另外一个文章还讲述了（select *）的其他的缺点参考：<span class="exturl" data-url="aHR0cHM6Ly93d3cuamlhbnNodS5jb20vcC9jZTA2M2UyMDI0YWQ=">https://www.jianshu.com/p/ce063e2024ad<i class="fa fa-external-link-alt"></i></span></li></ul><h1 id="一、从一个问题出发"><a href="#一、从一个问题出发" class="headerlink" title="一、从一个问题出发"></a>一、从一个问题出发</h1><p>这是最近一个朋友遇到的案例，大概意思就是说我的表在Innodb中只有30G左右，为什么使用如下语句进行排序操作后临时文件居然达到了200多G，当然语句很变态，我们可以先不问为什么会有这样的语句，我们只需要研究原理即可，在本文的第13节会进行原因解释和问题重现。<br>临时文件如下：</p><p>下面是这些案例信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br></pre></td><td class="code"><pre><span class="line">show create table  t\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: t</span><br><span class="line">Create Table: CREATE TABLE `t` (</span><br><span class="line">  `ID` bigint(20) NOT NULL COMMENT &#x27;ID&#x27;,</span><br><span class="line">  `UNLOAD_TASK_NO` varchar(50) NOT NULL ,</span><br><span class="line">  `FORKLIFT_TICKETS_COUNT` bigint(20) DEFAULT NULL COMMENT &#x27;叉车票数&#x27;,</span><br><span class="line">  `MANAGE_STATUS` varchar(20) DEFAULT NULL COMMENT &#x27;管理状态&#x27;,</span><br><span class="line">  `TRAY_BINDING_TASK_NO` varchar(50) NOT NULL ,</span><br><span class="line">  `STATISTIC_STATUS` varchar(50) NOT NULL ,</span><br><span class="line">  `CREATE_NO` varchar(50) DEFAULT NULL ,</span><br><span class="line">  `UPDATE_NO` varchar(50) DEFAULT NULL ,</span><br><span class="line">  `CREATE_NAME` varchar(200) DEFAULT NULL COMMENT &#x27;创建人名称&#x27;,</span><br><span class="line">  `UPDATE_NAME` varchar(200) DEFAULT NULL COMMENT &#x27;更新人名称&#x27;,</span><br><span class="line">  `CREATE_ORG_CODE` varchar(200) DEFAULT NULL COMMENT &#x27;创建组织编号&#x27;,</span><br><span class="line">  `UPDATE_ORG_CODE` varchar(200) DEFAULT NULL COMMENT &#x27;更新组织编号&#x27;,</span><br><span class="line">  `CREATE_ORG_NAME` varchar(1000) DEFAULT NULL COMMENT &#x27;创建组织名称&#x27;,</span><br><span class="line">  `UPDATE_ORG_NAME` varchar(1000) DEFAULT NULL COMMENT &#x27;更新组织名称&#x27;,</span><br><span class="line">  `CREATE_TIME` datetime DEFAULT NULL COMMENT &#x27;创建时间&#x27;,</span><br><span class="line">  `UPDATE_TIME` datetime DEFAULT NULL COMMENT &#x27;更新时间&#x27;,</span><br><span class="line">  `DATA_STATUS` varchar(50) DEFAULT NULL COMMENT &#x27;数据状态&#x27;,</span><br><span class="line">  `OPERATION_DEVICE` varchar(200) DEFAULT NULL COMMENT &#x27;操作设备&#x27;,</span><br><span class="line">  `OPERATION_DEVICE_CODE` varchar(200) DEFAULT NULL COMMENT &#x27;操作设备编码&#x27;,</span><br><span class="line">  `OPERATION_CODE` varchar(50) DEFAULT NULL COMMENT &#x27;操作码&#x27;,</span><br><span class="line">  `OPERATION_ASSIST_CODE` varchar(50) DEFAULT NULL COMMENT &#x27;辅助操作码&#x27;,</span><br><span class="line">  `CONTROL_STATUS` varchar(50) DEFAULT NULL COMMENT &#x27;控制状态&#x27;,</span><br><span class="line">  `OPERATOR_NO` varchar(50) DEFAULT NULL COMMENT &#x27;操作人工号&#x27;,</span><br><span class="line">  `OPERATOR_NAME` varchar(200) DEFAULT NULL COMMENT &#x27;操作人名称&#x27;,</span><br><span class="line">  `OPERATION_ORG_CODE` varchar(50) DEFAULT NULL COMMENT &#x27;操作部门编号&#x27;,</span><br><span class="line">  `OPERATION_ORG_NAME` varchar(200) DEFAULT NULL COMMENT &#x27;操作部门名称&#x27;,</span><br><span class="line">  `OPERATION_TIME` datetime DEFAULT NULL COMMENT &#x27;操作时间&#x27;,</span><br><span class="line">  `OPERATOR_DEPT_NO` varchar(50) NOT NULL COMMENT &#x27;操作人所属部门编号&#x27;,</span><br><span class="line">  `OPERATOR_DEPT_NAME` varchar(200) NOT NULL COMMENT &#x27;操作人所属部门名称&#x27;,</span><br><span class="line">  `FORKLIFT_DRIVER_NAME` varchar(200) DEFAULT NULL ,</span><br><span class="line">  `FORKLIFT_DRIVER_NO` varchar(50) DEFAULT NULL ,</span><br><span class="line">  `FORKLIFT_DRIVER_DEPT_NAME` varchar(200) DEFAULT NULL ,</span><br><span class="line">  `FORKLIFT_DRIVER_DEPT_NO` varchar(50) DEFAULT NULL ,</span><br><span class="line">  `FORKLIFT_SCAN_TIME` datetime DEFAULT NULL ,</span><br><span class="line">  `OUT_FIELD_CODE` varchar(200) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`ID`),</span><br><span class="line">  KEY `IDX_TRAY_BINDING_TASK_NO` (`TRAY_BINDING_TASK_NO`),</span><br><span class="line">  KEY `IDX_OPERATION_ORG_CODE` (`OPERATION_ORG_CODE`),</span><br><span class="line">  KEY `IDX_OPERATION_TIME` (`OPERATION_TIME`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">desc </span><br><span class="line">SELECT </span><br><span class="line">    ID,</span><br><span class="line">    UNLOAD_TASK_NO,</span><br><span class="line">    FORKLIFT_TICKETS_COUNT,</span><br><span class="line">    MANAGE_STATUS,</span><br><span class="line">    TRAY_BINDING_TASK_NO,</span><br><span class="line">    STATISTIC_STATUS,</span><br><span class="line">    CREATE_NO,</span><br><span class="line">    UPDATE_NO,</span><br><span class="line">    CREATE_NAME,</span><br><span class="line">    UPDATE_NAME,</span><br><span class="line">    CREATE_ORG_CODE,</span><br><span class="line">    UPDATE_ORG_CODE,</span><br><span class="line">    CREATE_ORG_NAME,</span><br><span class="line">    UPDATE_ORG_NAME,</span><br><span class="line">    CREATE_TIME,</span><br><span class="line">    UPDATE_TIME,</span><br><span class="line">    DATA_STATUS,</span><br><span class="line">    OPERATION_DEVICE,</span><br><span class="line">    OPERATION_DEVICE_CODE,</span><br><span class="line">    OPERATION_CODE,</span><br><span class="line">    OPERATION_ASSIST_CODE,</span><br><span class="line">    CONTROL_STATUS,</span><br><span class="line">    OPERATOR_NO,</span><br><span class="line">    OPERATOR_NAME,</span><br><span class="line">    OPERATION_ORG_CODE,</span><br><span class="line">    OPERATION_ORG_NAME,</span><br><span class="line">    OPERATION_TIME,</span><br><span class="line">    OPERATOR_DEPT_NO,</span><br><span class="line">    OPERATOR_DEPT_NAME,</span><br><span class="line">    FORKLIFT_DRIVER_NAME,</span><br><span class="line">    FORKLIFT_DRIVER_NO,</span><br><span class="line">    FORKLIFT_DRIVER_DEPT_NAME,</span><br><span class="line">    FORKLIFT_DRIVER_DEPT_NO,</span><br><span class="line">    FORKLIFT_SCAN_TIME,</span><br><span class="line">    OUT_FIELD_CODE</span><br><span class="line">FROM</span><br><span class="line">    t</span><br><span class="line">GROUP BY id , UNLOAD_TASK_NO , FORKLIFT_TICKETS_COUNT , </span><br><span class="line">MANAGE_STATUS , TRAY_BINDING_TASK_NO , STATISTIC_STATUS , </span><br><span class="line">CREATE_NO , UPDATE_NO , CREATE_NAME , UPDATE_NAME , </span><br><span class="line">CREATE_ORG_CODE , UPDATE_ORG_CODE , CREATE_ORG_NAME , </span><br><span class="line">UPDATE_ORG_NAME , CREATE_TIME , UPDATE_TIME , DATA_STATUS , </span><br><span class="line">OPERATION_DEVICE , OPERATION_DEVICE_CODE , OPERATION_CODE , </span><br><span class="line">OPERATION_ASSIST_CODE , CONTROL_STATUS , OPERATOR_NO ,</span><br><span class="line">OPERATOR_NAME , OPERATION_ORG_CODE , OPERATION_ORG_NAME , </span><br><span class="line">OPERATION_TIME , OPERATOR_DEPT_NO , OPERATOR_DEPT_NAME , </span><br><span class="line">FORKLIFT_DRIVER_NAME , FORKLIFT_DRIVER_NO , </span><br><span class="line">FORKLIFT_DRIVER_DEPT_NAME , FORKLIFT_DRIVER_DEPT_NO ,</span><br><span class="line">FORKLIFT_SCAN_TIME , OUT_FIELD_CODE;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">+----+-------------+-------------------------+------------+------+---------------+------+---------+------+---------+----------+----------------+</span><br><span class="line">| id | select_type | table                   | partitions | type | possible_keys | key  | key_len | ref  | rows    | filtered | Extra          |</span><br><span class="line">+----+-------------+-------------------------+------------+------+---------------+------+---------+------+---------+----------+----------------+</span><br><span class="line">|  1 | SIMPLE      | t | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 5381145 |   100.00 | Using filesort |</span><br><span class="line">+----+-------------+-------------------------+------------+------+---------------+------+---------+------+---------+----------+----------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure><p>也许你会怀疑这个语句有什么用，我们先不考虑功能，我们只考虑为什么它会生成200G的临时文件这个问题。<br>接下来我将分阶段进行排序的流程解析，注意了整个排序的流程均处于状态‘Creating sort index’下面，我们以filesort函数接口为开始进行分析。</p><h1 id="二、测试案例"><a href="#二、测试案例" class="headerlink" title="二、测试案例"></a>二、测试案例</h1><p>为了更好的说明后面的流程我们使用2个除了字段长度不同，其他完全一样的表来说明，但是需要注意这两个表数据量很少，不会出现外部排序，如果涉及外部排序的时候我们需要假设它们数据量很大。其次这里根据original filesort algorithm和modified filesort algorithm进行划分，但是这两种方法还没讲述，不用太多理会。</p><ul><li>original filesort algorithm（回表排序）</li></ul><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show create table tests1 \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: tests1</span><br><span class="line">Create Table: CREATE TABLE `tests1` (</span><br><span class="line">  `a1` varchar(300) DEFAULT NULL,</span><br><span class="line">  `a2` varchar(300) DEFAULT NULL,</span><br><span class="line">  `a3` varchar(300) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from tests1;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| a    | a    | a    |</span><br><span class="line">| a    | b    | b    |</span><br><span class="line">| a    | c    | c    |</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">| c    | g    | g    |</span><br><span class="line">| c    | h    | h    |</span><br><span class="line">+------+------+------+</span><br><span class="line">8 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc select * from tests1 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">|  1 | SIMPLE      | tests1 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    8 |    12.50 | Using where; Using filesort |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure><ul><li>modified filesort algorithm（不回表排序）<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; desc select * from tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">|  1 | SIMPLE      | tests2 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    8 |    12.50 | Using where; Using filesort |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show create table tests2 \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: tests2</span><br><span class="line">Create Table: CREATE TABLE `tests2` (</span><br><span class="line">  `a1` varchar(20) DEFAULT NULL,</span><br><span class="line">  `a2` varchar(20) DEFAULT NULL,</span><br><span class="line">  `a3` varchar(20) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from tests2;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| a    | a    | a    |</span><br><span class="line">| a    | b    | b    |</span><br><span class="line">| a    | c    | c    |</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">| c    | g    | g    |</span><br><span class="line">| c    | h    | h    |</span><br><span class="line">+------+------+------+</span><br><span class="line">8 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc select * from tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">|  1 | SIMPLE      | tests2 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    8 |    12.50 | Using where; Using filesort |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">1 row in set, 1 warning (0.01 sec)</span><br></pre></td></tr></table></figure></li></ul><p>整个流程我们从filesort 函数接口开始讨论。下面第3到第10节为排序的主要流程。</p><h1 id="三、阶段1-确认排序字段及顺序"><a href="#三、阶段1-确认排序字段及顺序" class="headerlink" title="三、阶段1 确认排序字段及顺序"></a>三、阶段1 确认排序字段及顺序</h1><p>这里主要将排序顺序存入到Filesort 类的 sortorder中，比如我们例子中的order by a2,a3就是a2和a3列，主要接口为Filesort::make_sortorder，我们按照源码描述为sort字段（源码中为sort_length），显然我们在排序的时候除了sort字段以外，还应该包含额外的字段，到底包含哪些字段就与方法 original filesort algorithm（回表排序） 和 modified filesort algorithm（不回表排序）有关了，下面进行讨论。</p><h1 id="四、阶段2-计算sort字段的长度"><a href="#四、阶段2-计算sort字段的长度" class="headerlink" title="四、阶段2 计算sort字段的长度"></a>四、阶段2 计算sort字段的长度</h1><p>这里主要调用使用sortlength函数，这一步将会带入max_sort_length参数的设置进行判断，默认情况下max_sort_length 为1024字节。<br>这一步大概步骤为：</p><ol><li><p>循环每一个sort字段</p></li><li><p>计算每一个sort字段的长度：公式为 ≈ 定义长度 * 2</p></li></ol><p>比如这里例子中我定义了a1 varchar(300)，那么它的计算长度 ≈ 300 * 2（600），为什么是*2呢，这应该是和Unicode编码有关，这一步可以参考函数my_strnxfrmlen_utf8。同时需要注意这里是约等于，因为源码中还是其他的考虑，比如字符是否为空，但是占用不多不考虑了。<br>3. 带入max_sort_length参数进行计算</p><p>好了有了上面一个sort字段的长度，那么这里就和max_sort_length进行比较，如果这个这个sort字段大于max_sort_length的值，那么以max_sort_length设置为准，这步代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set_if_smaller(sortorder-&gt;length, thd-&gt;variables.max_sort_length);</span><br></pre></td></tr></table></figure><p>因此，如果sort字段的某个字段的超过了max_sort_length设置，那么排序可能不那么精确了。<br>到了这里每个sort字段的长度以及sort字段的总长度已经计算出来，比如前面给的两个不同列子中：</p><ul><li>（a2 varchar(300) a3 varchar(300) order by a2,a3）：每个sort字段约为300*2字节，两个字段的总长度约为1200字节。</li><li>（a2 varchar(20) a3 varchar(20) order by a2,a3）：每个sort字段约为20*2字节，两个字段的总长度约为80字节。<br>并且值得注意的是，这里是按照定义大小，如varchar(300) ，以300个字符来计算长度的，而不是我们通常看到的Innodb中实际占用的字符数量。这是排序使用空间大于Innodb实际数据文件大小的一个原因。</li></ul><p>下面我们以（a2 varchar(300) a3 varchar(300) order by a2,a3）为例实际看看debug的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">(gdb) p sortorder-&gt;field-&gt;field_name</span><br><span class="line">$4 = 0x7ffe7800fadf &quot;a3&quot;</span><br><span class="line">(gdb) p sortorder-&gt;length</span><br><span class="line">$5 = 600</span><br><span class="line">(gdb) p  total_length</span><br><span class="line">$6 = 1202（这里a2,a3 可以为NULL各自加了1个字节）</span><br><span class="line">(gdb) </span><br></pre></td></tr></table></figure><p>可以看出没有问题。<br>4. 循环结束，计算出sort字段的总长度。</p><p>后面我们会看到sort字段不能使用压缩（pack）技术。</p><h1 id="五、阶段3-计算额外字段的空间"><a href="#五、阶段3-计算额外字段的空间" class="headerlink" title="五、阶段3 计算额外字段的空间"></a>五、阶段3 计算额外字段的空间</h1><p>对于排序而言，我们很清楚除了sort字段以外，通常我们需要的是实际的数据，那么无外乎两种方式如下：</p><ul><li>original filesort algorithm：只存储rowid或者主键做为额外的字段，然后进行回表抽取数据。我们按照源码的描述，将这种关联回表的字段叫做ref字段（源码中变量叫做ref_length）。</li><li>modified filesort algorithm：将处于read_set（需要读取的字段）全部放到额外字段中，这样不需要回表读取数据了。我们按照源码的描述，将这些额外存储的字段叫做addon字段（源码中变量叫做addon_length）。<br>这里一步就是要来判断到底使用那种算法，其主要标准就是参数max_length_for_sort_data，其默认大小为1024字节，但是后面会看到这里的计算为（sort字段长度+addon字段的总和）是否超过了max_length_for_sort_data。其次如果使用了modified filesort algorithm算法，那么将会对addon字段的每个字段做一个pack（打包），主要目的在于压缩那些为空的字节，节省空间。<br>这一步的主要入口函数为Filesort::get_addon_fields下面是步骤解析。</li></ul><ol><li><p>循环本表全部字段</p></li><li><p>根据read_set过滤出不需要存储的字段</p></li></ol><p>这里如果不需要访问到的字段自然不会包含在其中，下面这段源码过滤代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if (!bitmap_is_set(read_set, field-&gt;field_index)) //是否在read set中</span><br><span class="line">      continue;</span><br></pre></td></tr></table></figure><ol start="3"><li>获取字段的长度</li></ol><p>这里就是实际的长度了比如我们的a1 varchar(300)，且字符集为UTF8，那么其长度≈ 300*3 （900）。<br>4. 获取可以pack（打包）字段的长度</p><p>和上面不同，对于int这些固定长度类型的字段，只有可变长度的类型的字段才需要进行打包技术。<br>5. 循环结束，获取addon字段的总长度，获取可以pack（打包）字段的总长度</p><p>循环结束后可以获取addon字段的总长度，但是需要注意addon字段和sort字段可能包含重复的字段，比如例2中sort字段为a2、a3，addon字段为a1、a2、a3。<br>如果满足如下条件：<br>addon字段的总长度+sort字段的总长度 &gt; max_length_for_sort_data<br>那么将使用original filesort algorithm（回表排序）的方式，否则使用modified filesort algorithm的方式进行。下面是这一句代码：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">  if (total_length + sortlength &gt; max_length_for_sort_data) //如果长度大于了max_length_for_sort_data 则退出了</span><br><span class="line">  &#123;</span><br><span class="line">    DBUG_ASSERT(addon_fields == NULL);</span><br><span class="line">    return NULL;</span><br><span class="line">//返回NULL值 不打包了 使用 original filesort algorithm（回表排序）</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>我们在回到第2节例子中的第1个案例，因为我们对a1,a2,a3都是需要访问的，且他们的大小均为varchar(300) UTF8，那么addon字段长度大约为300 * 3 * 3&#x3D;2700字节 ，其次我们前面计算了sort字段大约为1202字节，因此 2700+1202 是远远大于max_length_for_sort_data的默认设置1024字节的，因此会使用original filesort algorithm方式进行排序。</p><p>如果是第2节例子中的第2个案例呢，显然要小很多了（每个字段varchar（20）），大约就是20 * 3 * 3（addon字段）+82（sort字段） 它是小于1024字节的，因此会使用modified filesort algorithm的排序方式，并且这些addon字段基本都可以使用打包（pack）技术，来节省空间。但是需要注意的是无论如何（sort字段）是不能进行打包（pack）的，而固定长度类型不需要打包（pack）压缩空间。</p><h1 id="六、阶段4-确认每行的长度"><a href="#六、阶段4-确认每行的长度" class="headerlink" title="六、阶段4 确认每行的长度"></a>六、阶段4 确认每行的长度</h1><p>有了上面的就计算后每一行的长度（如果可以打包是打包前的长度），下面就是这个计算过程。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">if (using_addon_fields()) </span><br><span class="line">//如果使用了 打包技术  检测 addon_fields 数组是否存在  使用modified filesort algorithm算法 不回表排序</span><br><span class="line">  &#123;</span><br><span class="line">    res_length= addon_length; //总的长度  3个 varchar(300) uft8 为 3*300*3</span><br><span class="line">  &#125;</span><br><span class="line">  else //使用original filesort algorithm算法</span><br><span class="line">  &#123;</span><br><span class="line">    res_length= ref_length;   //rowid(主键长度) </span><br><span class="line">    /* </span><br><span class="line">      The reference to the record is considered </span><br><span class="line">      as an additional sorted field</span><br><span class="line">    */</span><br><span class="line">    sort_length+= ref_length;  //实际上就是rowid(主键) +排序字段长度  回表排序</span><br><span class="line">  &#125;</span><br><span class="line">  /*</span><br><span class="line">    Add hash at the end of sort key to order cut values correctly.</span><br><span class="line">    Needed for GROUPing, rather than for ORDERing.</span><br><span class="line">  */</span><br><span class="line">  if (use_hash)</span><br><span class="line">    sort_length+= sizeof(ulonglong);</span><br><span class="line"></span><br><span class="line">  rec_length= sort_length + addon_length; </span><br><span class="line">//modified filesort algorithm sort_length 为排序键长度 addon_lenth 为访问字段长度，original filesort algorithm rowid(主键) +排序字段长度 ，因为addon_length为0</span><br></pre></td></tr></table></figure><p>好了我们稍微总结一下：</p><ul><li>original filesort algorithm：每行长度为sort字段的总长度+ref字段长度（主键或者rowid）。</li><li>modified filesort algorithm：每行的长度为sort字段的总长度+addon字段的长度（需要访问的字段总长度）。<br>当然到底使用那种算法参考上一节。但是要注意了对于varchar这种可变长度是以定义的大小为准了，比如UTF8 varchar（300）就是300*3&#x3D; 900 而不是实际存储的大小，而固定长度没有变化。</li></ul><p>好了，还是回头看看第2节的两个例子，分别计算它们的行长度：</p><ul><li>例子1：根据我们的计算，它将使用original filesort algorithm排序方式，最终的计算行长度应该为（sort字段长度+rowid长度）及 ≈ 1202+6 字节，下面是debug的结果：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(gdb) p rec_length</span><br><span class="line">$1 = 1208</span><br></pre></td></tr></table></figure></li><li>例子2：根据我们的计算，它将使用modified filesort algorithm排序方式，最终计算行长度应该为（sort字段长度+addon字段长度）及 ≈ 82 + 20 * 3 * 3 （结果为262），注意这里是约等于没有计算非空等因素和可变长度因素，下面是debug的结果：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">(gdb) p rec_length</span><br><span class="line">$2 = 266</span><br></pre></td></tr></table></figure>可以看出误差不大。</li></ul><h1 id="七、阶段5-确认最大内存分配"><a href="#七、阶段5-确认最大内存分配" class="headerlink" title="七、阶段5 确认最大内存分配"></a>七、阶段5 确认最大内存分配</h1><p>这里的分配内存就是参数sort_buffer_size大小有关了。但是是不是每次都会分配至少sort_buffer_size大小的内存的呢？其实不是，MySQL会判断是否表很小的情况，也就是做一个简单的运算，目的在于节省内存的开销，这里我们将来描述。</p><ol><li>大概计算出Innodb层主键叶子结点的行数</li></ol><p>这一步主要通过（聚集索引叶子结点的空间大小&#x2F;聚集索引每行大小 * 2）计算出一个行的上限，调入函数ha_innobase::estimate_rows_upper_bound，源码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"> num_rows= table-&gt;file-&gt;estimate_rows_upper_bound(); </span><br><span class="line">//上限来自于Innodb 叶子聚集索引叶子结点/聚集索引长度 *2</span><br></pre></td></tr></table></figure><p>然后将结果存储起来，如果表很小那么这个值会非常小。<br>2.根据前面计算的每行长度计算出sort buffer可以容下的最大行数</p><p>这一步将计算sort buffer可以容纳的最大行数如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ha_rows keys= memory_available / (param.rec_length + sizeof(char*));</span><br><span class="line">//可以排序的 行数 sort buffer 中最大 可以排序的行数</span><br></pre></td></tr></table></figure><p>3.对比两者的最小值，作为分配内存的标准</p><p>然后对比两个值以小值为准，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">param.max_keys_per_buffer= (uint) min(num_rows &gt; 0 ? num_rows : 1, keys);</span><br><span class="line">//存储行数上限 和 可以排序 行数的 小值</span><br></pre></td></tr></table></figure><p>4.根据结果分配内存</p><p>分配如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">table_sort.alloc_sort_buffer(param.max_keys_per_buffer, param.rec_length);</span><br></pre></td></tr></table></figure><p>也就是根据总的计算出的行长度和计算出的行数进行分配。</p><h1 id="八、阶段6-读取数据，进行内存排序"><a href="#八、阶段6-读取数据，进行内存排序" class="headerlink" title="八、阶段6 读取数据，进行内存排序"></a>八、阶段6 读取数据，进行内存排序</h1><p>到这里准备工作已经完成了，接下就是以行为单位读取数据了，然后对过滤掉where条件的剩下的数据进行排序。如果需要排序的数据很多，那么等排序内存写满后会进行内存排序，然后将排序的内容写入到排序临时文件中，等待下一步做外部的归并排序。作为归并排序而言，每一个归并的文件片段必须是排序好的，否则归并排序是不能完成的，因此写满排序内存后需要做内存排序。如果写不满呢，那么做一次内存排序就好了。下面我们来看看这个过程，整个过程集中在find_all_keys函数中。</p><ol><li>读取需要的数据</li></ol><p>实际上在这一步之前还会做read_set的更改，因为对于original filesort algorithm（回表排序）的算法来讲不会读取全部需要的字段，为了简单起见不做描述了。</p><p>这一步就是读取一行数据了，这里会进入Innodb层读取数据，具体流程不做解释了，下面是这一行代码：<br>error&#x3D; file-&gt;ha_rnd_next(sort_form-&gt;record[0]); &#x2F;&#x2F;读取一行数据<br>2. 将Rows_examined 加1</p><p>这里这个指标对应的就是慢查中的Rows_examined了，这个指标在有排序的情况下会出现重复计算的情况，但是这里还是正确的，重复的部分后面再说。<br>3. 过滤掉where条件</p><p>这里将会过滤掉where条件中不满足条件的行，代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if (!error &amp;&amp; !qep_tab-&gt;skip_record(thd, &amp;skip_record) &amp;&amp; !skip_record) </span><br><span class="line">//这里做where过滤条件 的比较 </span><br></pre></td></tr></table></figure><ol start="4"><li>将行数据写入到sort buffer中</li></ol><p>这一步将会把数据写入到sort buffer中，需要注意这里不涉及排序操作，只是存储数据到内存中。其中分为了2部分：</p><ul><li>写入sort字段。如果是original filesort algorithm那么rowid（主键）也包含在其中了。</li><li>写入addon字段，这是modified filesort algorithm才会有的，在写入之前还会调用Field::pack对可以打包（pack）的字段进行压缩操作。对于varchar字段的打包函数就是Field_varstring::pack，简单的说存储的是实际的大小，而非定义的大小。<br>整个过程位于find_all_keys-&gt;Sort_param::make_sortkey 函数中。这一步还涉及到了我们非常关心的一个问题，到底排序的数据如何存储的问题，需要仔细阅读。</li></ul><p>下面我们就debug一下第2节中两个例子的不同存储方式。既然要去看内存中的数据，我们只要看它最终拷贝的内存数据是什么就好了，那么真相将会大白，我们只需要将断点放到find_all_keys函数上，做完一行数据的Sort_param::make_sortkey操作后看内存就行了，如下：</p><ul><li>例子1（字段都是varchar（300））：它将使用original filesort algorithm（回表排序）的方式，最终应该存储的是sort字段（a2，a3）+rowid。</li></ul><p>排序的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from test.tests1 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">+------+------+------+</span><br><span class="line">3 rows in set (9.06 sec)</span><br></pre></td></tr></table></figure><p>我们以第二行为查看目标<br>由于篇幅的关系，我展示其中的一部分，因为这里大约有1200多个字节，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">(gdb) x/1300bx start_of_rec</span><br><span class="line">0x7ffe7ca79998: 0x01    0x00    0x45    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799a0: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799a8: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799b0: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799b8: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799c0: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799c8: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>这后面还有大量的0X20 0X00<br>我们看到了大量的0X20 0X00，这正是占位符号，实际有用的数据也就只有0x45 0x00这两个字节了，而0x45正是我们的大写字母E，也就是数据中的e，这和比较字符集有关。这里的0X20 0X00占用了大量的空间，我们最初计算sort 字段大约为1200字节，实际上只有少量的几个字节有用。<br>这里对于sort字段而言，比实际存储的数据大得多。</p><ul><li>例子2（字段都是varchar（20））：它将使用modified filesort algorithm，最终应该存储的是sort字段（a2，a3）+addon字段（需要的字段，这里就是a1，a2，a3）<br>排序的结果如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from test.tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">+------+------+------+</span><br></pre></td></tr></table></figure>我们以第一行为查看目标<br>这里数据不大，通过压缩后只有91个字节了，我们整体查看如下：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">(gdb) p rec_sz</span><br><span class="line">$6 = 91</span><br><span class="line">(gdb) x/91x start_of_rec </span><br><span class="line">0x7ffe7c991bc0: 0x01    0x00    0x44    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7c991bc8: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7c991bd0: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7c991bd8: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7c991be0: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7c991be8: 0x20    0x01    0x00    0x44    0x00    0x20    0x00    0x20</span><br><span class="line">0x7ffe7c991bf0: 0x00    0x20    0x00    0x20    0x00    0x20    0x00    0x20</span><br><span class="line">0x7ffe7c991bf8: 0x00    0x20    0x00    0x20    0x00    0x20    0x00    0x20</span><br><span class="line">0x7ffe7c991c00: 0x00    0x20    0x00    0x20    0x00    0x20    0x00    0x20</span><br><span class="line">0x7ffe7c991c08: 0x00    0x20    0x00    0x20    0x00    0x20    0x00    0x20</span><br><span class="line">0x7ffe7c991c10: 0x00    0x20    0x07    0x00    0x00    0x01    0x62    0x01</span><br><span class="line">0x7ffe7c991c18: 0x64    0x01    0x64</span><br></pre></td></tr></table></figure>这就是整行记录了，我们发现对于sort字段而言没有压缩，依旧是0x20 0x00占位，而对于addon字段（需要的字段，这里就是a1，a2，a3）而言，这里小了很多，因为做了打包（pack）即：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">0x01 0x62：数据b</span><br><span class="line"></span><br><span class="line">0x01 0x64：数据d</span><br><span class="line"></span><br><span class="line">0x01 0x64：数据d</span><br></pre></td></tr></table></figure>而0x01应该就是长度了。<br>不管怎么说，对于sort字段而言依旧比实际存储的数据大很多。</li></ul><ol start="5"><li>如果sort buffer存满，对sort buffer中的数据进行排序，然后写入到临时文件</li></ol><p>如果需要排序的数据量很大的话，那么sort buffer肯定是不能容下的，因此如果写满后就进行一次内存排序操作，然后将排序好的数据写入到外部排序文件中去，这叫做一个chunk。外部文件的位置由tmpdir参数指定，名字以MY开头，注意外部排序通常需要2个临时文件，这里是第1个用于存储内存排序结果的临时文件，以chunk的方式写入。如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">if (fs_info-&gt;isfull()) //如果sort buffer满了  并且sort buffer已经排序完成</span><br><span class="line">        &#123;</span><br><span class="line">          if (write_keys(param, fs_info, idx, chunk_file, tempfile)) //写入到物理文件 完成内存排序   如果内存不会满这里不会做 会在create_sort_index 中排序完成</span><br><span class="line">          &#123;</span><br><span class="line">            num_records= HA_POS_ERROR;</span><br><span class="line">            goto cleanup;</span><br><span class="line">          &#125;</span><br><span class="line">          idx= 0;</span><br><span class="line">          indexpos++;</span><br><span class="line">        &#125;    </span><br></pre></td></tr></table></figure><p>最终会调入write_keys函数进行排序和写入外部排序文件，这里核心就是先排序，然后循环每条排序文件写入到外部排序文件。下面我来验证一下写入临时文件的长度，我将第2节中的例子2数据扩大了N倍后，让其使用外部文件排序，下面是验证结果，断点write_keys即可：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1161        if (my_b_write(tempfile, record, rec_length))</span><br><span class="line">(gdb) p rec_length</span><br><span class="line">$8 = 91</span><br></pre></td></tr></table></figure><p>可以每行的长度还是91字节（打包压缩后），和前面看到的长度一致，说明这些数据会完完整整的写入到外部排序文件，这显然会比我们想象的大得多。<br>好了到这里数据已经找出来了，如果超过sort buffer的大小，外部排序需要的结果已经存储在临时文件1了，并且它是分片（chunk）存储到临时文件的，它以MY开头。</p><h1 id="九、阶段7-排序方式总结输出"><a href="#九、阶段7-排序方式总结输出" class="headerlink" title="九、阶段7 排序方式总结输出"></a>九、阶段7 排序方式总结输出</h1><p>这里对上面的排序过程做了一个阶段性的总结，代码如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Opt_trace_object(trace, &quot;filesort_summary&quot;)</span><br><span class="line">    .add(&quot;rows&quot;, num_rows)</span><br><span class="line">    .add(&quot;examined_rows&quot;, param.examined_rows)</span><br><span class="line">    .add(&quot;number_of_tmp_files&quot;, num_chunks)</span><br><span class="line">    .add(&quot;sort_buffer_size&quot;, table_sort.sort_buffer_size())</span><br><span class="line">    .add_alnum(&quot;sort_mode&quot;,</span><br><span class="line">               param.using_packed_addons() ?</span><br><span class="line">               &quot;&lt;sort_key, packed_additional_fields&gt;&quot; :</span><br><span class="line">               param.using_addon_fields() ?</span><br><span class="line">               &quot;&lt;sort_key, additional_fields&gt;&quot; : &quot;&lt;sort_key, rowid&gt;&quot;); </span><br></pre></td></tr></table></figure><p>我们解析一下：</p><ul><li>rows：排序的行数，也就是应用where过滤条件后剩下的行数。</li><li>examined_rows：Innodb层扫描的行数，注意这不是慢查询中的Rows_examined，这里是准确的结果，没有重复计数。</li><li>number_of_tmp_files：外部排序时，用于保存结果的临时文件的chunk数量，每次sort buffer满排序后写入到一个chunk，但是所有chunk共同存在于一个临时文件中。</li><li>sort_buffer_size：内部排序使用的内存大小，并不一定是sort_buffer_size参数指定的大小。</li><li>sort_mode：这里解释如下</li></ul><ol><li>sort_key, packed_additional_fields：使用了modified filesort algorithm（不回表排序） ，并且有打包（pack）的字段，通常为可变字段比如varchar。</li><li>sort_key, additional_fields：使用了modified filesort algorithm（不回表排序），但是没有需要打包（pack）的字段，比如都是固定长度字段。</li><li>sort_key, rowid：使用了original filesort algorithm（回表排序）。</li></ol><h1 id="十、阶段8-进行最终排序"><a href="#十、阶段8-进行最终排序" class="headerlink" title="十、阶段8 进行最终排序"></a>十、阶段8 进行最终排序</h1><p>这里涉及2个部分如下：</p><ul><li>如果sort buffer不满，则这里开始进行排序，调入函数save_index。</li><li>如果sort buffer满了，则进行归并排序，调入函数merge_many_buff-&gt;merge_buffers，最后调入merge_index完成归并排序。<br>对于归并排序来讲，这里可能会生成另外2个临时文件用于存储最终排序的结果，它们依然以MY开头，且依然是存储在tmpdir参数指定的位置。因此在外部排序中将可能会生成3个临时文件，总结如下：</li><li>临时文件1：用于存储内存排序的结果，以chunk为单位，一个chunk的大小就是sort buffer的大小。</li><li>临时文件2：以前面的临时文件1为基础，做归并排序。</li><li>临时文件3：将最后的归并排序结果存储，去掉sort字段，只保留addon字段（需要访问的字段）或者ref字段（ROWID或者主键），因此它一般会比前面2个临时文件小。<br>但是它们不会同时存在，要么 临时文件1和临时文件2存在，要么 临时文件2和临时文件3存在。<br>这个很容易验证，将断点放到merge_buffers和merge_index上就可以验证了，如下：<br>临时文件1和临时文件2同时存在：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@gp1 test]# lsof|grep tmp/MY</span><br><span class="line">mysqld     8769     mysql   70u      REG              252,3   79167488    2249135 /mysqldata/mysql3340/tmp/MYt1QIvr (deleted)</span><br><span class="line">mysqld     8769     mysql   71u      REG              252,3   58327040    2249242 /mysqldata/mysql3340/tmp/MY4CrO4m (deleted)</span><br></pre></td></tr></table></figure>临时文件2和临时文件3共同存在：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@gp1 test]# lsof|grep tmp/MY</span><br><span class="line">mysqld     8769     mysql   70u      REG              252,3     360448    2249135 /mysqldata/mysql3340/tmp/MYg109Wp (deleted)</span><br><span class="line">mysqld     8769     mysql   71u      REG              252,3   79167488    2249242 /mysqldata/mysql3340/tmp/MY4CrO4m (deleted)</span><br></pre></td></tr></table></figure>但是由于能力有限对于归并排序的具体过程我并没有仔细学习了，这里给一个大概的接口。注意这里每次调用merge_buffers将会增加Sort_merge_passes 1次，应该是归并的次数，这个值增量的大小可以侧面反映出外部排序使用临时文件的大小。</li></ul><h1 id="十一、排序的其他问题"><a href="#十一、排序的其他问题" class="headerlink" title="十一、排序的其他问题"></a>十一、排序的其他问题</h1><p>这里将描述2个额外的排序问题。<br>1、original filesort algorithm（回表排序）的回表</p><p>最后对于original filesort algorithm（回表排序）排序方式而言，可能还需要做一个回表获取数据的操作，这一步可能会用到参数read_rnd_buffer_size定义的内存大小。<br>比如我们第2节中第1个例子将会使用到original filesort algorithm（回表排序），但是对于回表操作有如下标准：</p><ul><li>如果没有使用到外部排序临时文件则说明排序量不大，则使用普通的回表方式，调入函数rr_from_pointers，也就是单行回表方式。</li><li>如果使用到了使用到外部排序临时文件则说明排序量较大，需要使用到批量回表方式，这个时候大概的步骤就是读取rowid（主键）排序，然后批量回表，这将会在read_rnd_buffer_size指定的内存中完成，调入函数rr_from_cache。这也是一种优化方式，因为回表一般是散列的，代价很大。<br>2、关于排序中Rows_examined的计算</li></ul><p>首先这个值我说的是慢查询的中的Rows_examined，在排序中会出现重复计数的可能，前面第8节已经说明了一下，这个值在第8节还是正确的，但是最后符合where条件的数据在返回的时候还会调用函数evaluate_join_record，结果Rows_examined会增加符合where条件的行数。还是以我们第2节的两个例子为例：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from test.tests1 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">+------+------+------+</span><br><span class="line">3 rows in set (5.11 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test.tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">+------+------+------+</span><br><span class="line">3 rows in set (5.28 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc select * from tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">|  1 | SIMPLE      | tests2 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    8 |    12.50 | Using where; Using filesort |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line">8 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc select * from tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">|  1 | SIMPLE      | tests2 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    8 |    12.50 | Using where; Using filesort |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">1 row in set, 1 warning (0.01 sec)</span><br></pre></td></tr></table></figure><p>慢查询如下，不要纠结时间（因为我故意debug停止了一会），我们只关注Rows_examined，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"># Time: 2019-12-23T12:03:26.108529+08:00</span><br><span class="line"># User@Host: root[root] @ localhost []  Id:     4</span><br><span class="line"># Schema:   Last_errno: 0  Killed: 0</span><br><span class="line"># Query_time: 5.118098  Lock_time: 0.000716  Rows_sent: 3  Rows_examined: 11  Rows_affected: 0</span><br><span class="line"># Bytes_sent: 184</span><br><span class="line">SET timestamp=1577073806;</span><br><span class="line">select * from test.tests1 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line"># Time: 2019-12-23T12:03:36.138274+08:00</span><br><span class="line"># User@Host: root[root] @ localhost []  Id:     4</span><br><span class="line"># Schema:   Last_errno: 0  Killed: 0</span><br><span class="line"># Query_time: 5.285573  Lock_time: 0.000640  Rows_sent: 3  Rows_examined: 11  Rows_affected: 0</span><br><span class="line"># Bytes_sent: 184</span><br><span class="line">SET timestamp=1577073816;</span><br><span class="line">select * from test.tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br></pre></td></tr></table></figure><p>我们可以看到Rows_examined都是11，为什么是11呢？显然我们要扫描总的行数为8（这里是全表扫描，表总共8行数据），然后过滤后需要排序的结果为3条数据，这3条数据会重复计数一次。因此就是8+3&#x3D;11，也就是说有3条数据重复计数了。</p><h1 id="十二、通过OPTIMIZER-TRACE查看排序结果"><a href="#十二、通过OPTIMIZER-TRACE查看排序结果" class="headerlink" title="十二、通过OPTIMIZER_TRACE查看排序结果"></a>十二、通过OPTIMIZER_TRACE查看排序结果</h1><p>要使用OPTIMIZER_TRACE只需要“SET optimizer_trace&#x3D;”enabled&#x3D;on”;”，跑完语句后查看information_schema.OPTIMIZER_TRACE即可。</p><p>前面第9节我们解释了排序方式总结输出的含义，这里我们来看看具体的结果，我们还是以第2节的2个例子为例：</p><ul><li>例1：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&quot;filesort_priority_queue_optimization&quot;: &#123;</span><br><span class="line">  &quot;usable&quot;: false,</span><br><span class="line">  &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;filesort_execution&quot;: [</span><br><span class="line">],</span><br><span class="line">&quot;filesort_summary&quot;: &#123;</span><br><span class="line">  &quot;rows&quot;: 3,</span><br><span class="line">  &quot;examined_rows&quot;: 8,</span><br><span class="line">  &quot;number_of_tmp_files&quot;: 0,</span><br><span class="line">  &quot;sort_buffer_size&quot;: 1285312,</span><br><span class="line">  &quot;sort_mode&quot;: &quot;&lt;sort_key, rowid&gt;&quot;</span><br></pre></td></tr></table></figure></li><li>例2：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&quot;filesort_priority_queue_optimization&quot;: &#123;</span><br><span class="line">  &quot;usable&quot;: false,</span><br><span class="line">  &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;filesort_execution&quot;: [</span><br><span class="line">],</span><br><span class="line">&quot;filesort_summary&quot;: &#123;</span><br><span class="line">  &quot;rows&quot;: 3,</span><br><span class="line">  &quot;examined_rows&quot;: 8,</span><br><span class="line">  &quot;number_of_tmp_files&quot;: 0,</span><br><span class="line">  &quot;sort_buffer_size&quot;: 322920,</span><br><span class="line">  &quot;sort_mode&quot;: &quot;&lt;sort_key, packed_additional_fields&gt;&quot;</span><br></pre></td></tr></table></figure>现在我们清楚了，这些总结实际上是在执行阶段生成的，需要注意几点如下：</li><li>这里的examined_rows和慢查询中的Rows_examined不一样，因为这里不会有重复计数，是准确的。</li><li>这里还会说明是否使用了优先队列排序即“filesort_priority_queue_optimization”部分。</li><li>通过“sort_buffer_size”可以发现，这里并没有分配参数sort_buffer_size指定的大小，节约了内存，这在第7节说明了。<br>其他指标在第9节已经说明过了，不在描述。</li></ul><h1 id="十三、回到问题本身"><a href="#十三、回到问题本身" class="headerlink" title="十三、回到问题本身"></a>十三、回到问题本身</h1><p>好了，大概的流程我描述了一遍，这些流程都是主要流程，实际上的流程复杂很多。那么我们回到最开始的案例上来。他的max_sort_length和max_length_for_sort_data均为默认值1024。<br>案例中的group by实际就是一个排序操作，我们从执行计划可以看出来，那么先分析一下它的sort字段。很显然group by 后的都是sort字段，其中字段CREATE_ORG_NAME其定义为 varchar（1000），它的占用空间为（1000 * 2）及2000字节，但是超过了max_sort_length的大小，因此为1024字节，相同的还有UPDATE_ORG_NAME字段也是varchar（1000），也会做同样处理，其他字段不会超过max_sort_length的限制，并且在第5节说过sort 字段是不会进行压缩的。</p><p>我大概算了一下sort字段的全部大小约为 （3900 * 2) 字节，可以看到一行数据的sort字段基本达到了8K的容量，而addon字段的长度（未打包压缩前）会更大，显然超过max_length_for_sort_data的设置，因此对于这样的排序显然不可能使用modified filesort algorithm（不回表排序了），使用的是original filesort algorithm（回表排序），因此一行的记录就是（sort 字段+主键）了，主键大小可以忽略，最终一行记录的大小就是8K左右，这个值通常会远远大于Innodb压缩后存储varchar字段的大小，这也是为什么本例中虽然表只有30G左右但是临时文件达到了200G以上的原因了。<br>好了，我们来重现一下问题，我们使用第2节的例1，我们将其数据增多，原理上我们的例1会使用到original filesort algorithm（回表排序）的方式，因为这里sort字段（a2，a3）的总长度+addon字段（a1，a2，a3）的长度约为300 * 2 * 2+300 * 3 * 3 这显示大于了max_length_for_sort_data的长度， 因此这个排序一行的长度就是sort字段（a2，a3）+ref字段（ROWID），大约就是300 * 2 * 2+6&#x3D;1206字节了。 下面是这个表的总数据和Innodb文件大小（我这里叫做bgtest5表）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show create table bgtest5 \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: bgtest5</span><br><span class="line">Create Table: CREATE TABLE `bgtest5` (</span><br><span class="line">  `a1` varchar(300) DEFAULT NULL,</span><br><span class="line">  `a2` varchar(300) DEFAULT NULL,</span><br><span class="line">  `a3` varchar(300) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br><span class="line">1 row in set (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT COUNT(*) FROM bgtest5;</span><br><span class="line">+----------+</span><br><span class="line">| COUNT(*) |</span><br><span class="line">+----------+</span><br><span class="line">|    65536 |</span><br><span class="line">+----------+</span><br><span class="line">1 row in set (5.91 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc select * from bgtest5  order by a2,a3;</span><br><span class="line">+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+----------------+</span><br><span class="line">| id | select_type | table   | partitions | type | possible_keys | key  | key_len | ref  | rows  | filtered | Extra          |</span><br><span class="line">+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+----------------+</span><br><span class="line">|  1 | SIMPLE      | bgtest5 | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 66034 |   100.00 | Using filesort |</span><br><span class="line">+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+----------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure><p>注意这里是全表排序了，没有where过滤条件了，下面是这个表ibd文件的大小：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@gp1 test]# du -hs bgtest5.ibd</span><br><span class="line">11M     bgtest5.ibd</span><br><span class="line">[root@gp1 test]# </span><br></pre></td></tr></table></figure><p>下面我们就需要将gdb的断点打在merge_many_buff，我们的目的就是观察临时文件1的大小，这个文件前面说过了是存储内存排序结果的，如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@gp1 test]# lsof|grep tmp/MY</span><br><span class="line">mysqld     8769     mysql   69u      REG              252,3   79101952    2249135 /mysqldata/mysql3340/tmp/MYzfek5x (deleted)</span><br></pre></td></tr></table></figure><p>可以看到这个文件的大小为79101952字节，即80M左右，这和我们计算的总量1206（每行大小） * 65535（行数） 约为 80M 结果一致。这远远超过了ibd文件的大小11M，并且要知道，随后还会生成一个大小差不多的文件来存储归并排序的结果如下：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@gp1 test]# lsof|grep tmp/MY</span><br><span class="line">mysqld     8769     mysql   69u      REG              252,3   79167488    2249135 /mysqldata/mysql3340/tmp/MYzfek5x (deleted)</span><br><span class="line">mysqld     8769     mysql   70u      REG              252,3   58327040    2249242 /mysqldata/mysql3340/tmp/MY8UOLKa (deleted)</span><br></pre></td></tr></table></figure><p>因此得到证明，排序的临时文件远远大于ibd文件的现象是可能出现的。</p>]]></content>
    
    
    <summary type="html">MySQL 技术讲解 -- filesort 详细解析</summary>
    
    
    
    <category term="Database" scheme="http://ilongda.com/categories/Database/"/>
    
    <category term="MySQL" scheme="http://ilongda.com/categories/Database/MySQL/"/>
    
    
    <category term="Database" scheme="http://ilongda.com/tags/Database/"/>
    
    <category term="MySQL" scheme="http://ilongda.com/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>聚簇索引介绍</title>
    <link href="http://ilongda.com/2020/mysql-cluster-index/"/>
    <id>http://ilongda.com/2020/mysql-cluster-index/</id>
    <published>2020-06-14T11:42:57.000Z</published>
    <updated>2024-02-02T13:08:39.507Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>【转载】<span class="exturl" data-url="aHR0cDovL3d3dy5tYW5vbmdqYy5jb20vZGV0YWlsLzE3LXNzdXRoZXhidXpiam1sYi5odG1s">http://www.manongjc.com/detail/17-ssuthexbuzbjmlb.html<i class="fa fa-external-link-alt"></i></span><br>本文章向大家介绍Mysql聚簇索引和非聚簇索引，主要包括Mysql聚簇索引和非聚簇索引使用实例、应用技巧、基本知识点总结和需要注意事项，具有一定的参考价值，需要的朋友可以参考一下。</p><h1 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h1><p>聚簇索引并不是一种单独的索引类型，而是一种数据存储方式，具体的细节依赖于实现方式，InnoDB的聚簇索引实际上在同一个结构中保存了B+Tree索引和数据行。</p><p>当表中有聚簇索引时，它的数据实际上存储在索引的叶子页中（叶子页中包含了行的全部数据）。而没有聚簇索引时B+Tree叶子页存放的是指向数据的指针。（页是mysql存储引擎最小的存储单元，InnoDB每个页默认大小为16k）可以理解为 有聚簇索引时，数据和对应的叶子页在同一页中，没有聚簇索引时，叶子页和对应的数据不在同一页中。</p><p>InnoDB存储引擎通过主键聚集数据(聚簇索引)，如果没有定义主键，InnoDB会选择一个唯一的非空索引代替。如果没有唯一索引，InnoDB会隐式定义一个主键来作为聚簇索引。InnoDB 只聚集在同一个页面中的记录。包含相邻健值的页面可能相距甚远。</p><span id="more"></span><p>MyISAM中主键索引和其他索引 都指向物理行 (非聚簇索引)</p><p>下图展示了聚簇索引是如何存放的（图片来自《高性能MySQL(第三版)》）：</p><h2 id="聚簇索引和非举措索引的区别："><a href="#聚簇索引和非举措索引的区别：" class="headerlink" title="聚簇索引和非举措索引的区别："></a>聚簇索引和非举措索引的区别：</h2><p>聚簇索引，索引的顺序就是数据存放的顺序（物理顺序），只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。一张数据表只能有一个聚簇索引。（一个数据页中数据物理存储是有序的）</p><p>非聚簇索引通过叶子节点指针找到数据页中的数据，所以非聚簇索引是逻辑顺序。</p><h2 id="聚集索引的优点："><a href="#聚集索引的优点：" class="headerlink" title="聚集索引的优点："></a>聚集索引的优点：</h2><p>数据存放的顺序和索引顺序一致,可以把相关数据保存在一起。例如实现电子邮箱时，可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘 I&#x2F;O。<br>数据访问更快，聚簇索引将索引和数据保存在同一个B-Tree中，因此从举措索引中获取数据通常比非聚簇索引查找更快。<br>使用覆盖索引扫描的查询可以直接使用页节点中的主键值（二级索引(非聚簇索引) 的叶子节点保存的不是指向行的物理位置的指针，而是行的主键值）。<br>（PS:覆盖索引：Mysql 可以使用索引来直接获取列的数据，这样就不需要查到索引后，然后通过叶子节点的指针回表读取数据行，如果索引的叶子节点中已经包含了或者说覆盖 所有需要查询的字段的值，那么就没有必要再回表查询了，这种称之为“覆盖索引”）</p><h2 id="聚簇索引的缺点："><a href="#聚簇索引的缺点：" class="headerlink" title="聚簇索引的缺点："></a>聚簇索引的缺点：</h2><pre><code>聚簇数据提高了IO性能，如果数据全部放在内存中，则访问的顺序就没那么重要了插入速度严重依赖插入顺序。按主键的顺序插入是速度最快的。但如果不是按照主键顺序加载数据，则需在加载完成后最好使用optimize table重新组织一下表更新聚簇索引列的代价很高。因为会强制innod将每个被更新的行移动到新的位置基于聚簇索引的表在插入新行，或主键被更新导致需要移动行的时候，可能面临页分裂的问题。页分裂会导致表占用更多的磁盘空间。聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或由于页分裂导致数据存储不连续的时非聚集索引比想象的更大，因为二级索引的叶子节点包含了引用行的主键列非聚集索引访问需要两次索引查找(非聚集索引中叶子节点保存的行指针指向的是行的主键值)，对于innodb自适应哈希索引可以减少这样的重复工作</code></pre><p>聚簇索引尽量选择有序的列（如AUTO_INCREMENT自增列）,这样可以保证数据行是顺序写入，对于根据主键做关联操作的性能也会更好。</p><p>最好避免随机的（不连续且值的分布范围非常大）聚簇索引，特别是对于I&#x2F;O密集型的应用。</p><p>从性能角度考虑，使用UUID来做聚簇索引会很糟糕，它使得聚簇索引的插入变得完全随机，这是最坏的情况，是的数据没有任何聚集的特性。</p><p>总结下使用类似UUID这种随机的聚簇索引的缺点：<br>UUID字段长，索引占用的空间更大。<br>写入是乱序的，InnoDB不得不频繁的做页分裂操作，以便新的行分配空间，页分裂会导致移动大量数据，一次插入最少需要修改三个页而不是一个页。<br>写入的目标页可能已经刷到磁盘上并从缓存中移除，或者还没有被加载到缓存中，InnoDB在插入之前不得不先找到并从磁盘读取目标页到内存中，这将导致大量的随机IO。<br>频繁的页分裂，页会变的稀疏并被不规则的填充，会产生空间碎片。<br><span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vbGVhcm4tb250aGV3YXkvcC8xMjE1MDUyMS5odG1s">https://www.cnblogs.com/learn-ontheway/p/12150521.html<i class="fa fa-external-link-alt"></i></span></p><p>MySQL的InnoDB索引数据结构是B+树，主键索引叶子节点的值存储的就是MySQL的数据行，普通索引的叶子节点的值存储的是主键值，这是了解聚簇索引和非聚簇索引的前提</p><p>什么是聚簇索引？<br>很简单记住一句话：找到了索引就找到了需要的数据，那么这个索引就是聚簇索引，所以主键就是聚簇索引，修改聚簇索引其实就是修改主键。</p><p>什么是非聚簇索引？<br>索引的存储和数据的存储是分离的，也就是说找到了索引但没找到数据，需要根据索引上的值(主键)再次回表查询,非聚簇索引也叫做辅助索引。</p><p>clustered index（MySQL官方对聚簇索引的解释）<br>The InnoDB term for a primary key index. InnoDB table storage is organized based on the values of the primary key columns, to speed up queries and sorts involving the primary key columns. For best performance, choose the primary key columns carefully based on the most performance-critical queries. Because modifying the columns of the clustered index is an expensive operation, choose primary columns that are rarely or never updated.<br>注意标黑的那段话，聚簇索引就是主键的一种术语</p><p>一个例子<br>下面我们创建了一个学生表，做三种查询，来说明什么情况下是聚簇索引，什么情况下不是。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">create table student (</span><br><span class="line">    id bigint,</span><br><span class="line">    no varchar(20) ,</span><br><span class="line">    name varchar(20) ,</span><br><span class="line">    address varchar(20) ,</span><br><span class="line">    PRIMARY KEY (`branch_id`) USING BTREE,</span><br><span class="line">    UNIQUE KEY `idx_no` (`no`) USING BTREE</span><br><span class="line">)ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC;</span><br></pre></td></tr></table></figure><p>　　第一种，直接根据主键查询获取所有字段数据，此时主键是聚簇索引，因为主键对应的索引叶子节点存储了id&#x3D;1的所有字段的值。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select * from student where id = 1</span><br></pre></td></tr></table></figure><p>　　第二种，根据编号查询编号和名称，编号本身是一个唯一索引，但查询的列包含了学生编号和学生名称，当命中编号索引时，该索引的节点的数据存储的是主键ID，需要根据主键ID重新查询一次，所以这种查询下no不是聚簇索引</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select no,name from student where no = &#x27;test&#x27;</span><br></pre></td></tr></table></figure><p>　　第三种，我们根据编号查询编号（有人会问知道编号了还要查询？要，你可能需要验证该编号在数据库中是否存在），这种查询命中编号索引时，直接返回编号，因为所需要的数据就是该索引，不需要回表查询，这种场景下no是聚簇索引</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">select no from student where no = &#x27;test&#x27;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>主键一定是聚簇索引，MySQL的InnoDB中一定有主键，即便研发人员不手动设置，则会使用unique索引，没有unique索引，则会使用数据库内部的一个行的id来当作主键索引,其它普通索引需要区分SQL场景，当SQL查询的列就是索引本身时，我们称这种场景下该普通索引也可以叫做聚簇索引，MyisAM引擎没有聚簇索引。</p><p>原文链接：<span class="exturl" data-url="aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3hpbmdkdWFuNTE1My9hcnRpY2xlL2RldGFpbHMvMTA2MTg5MzQwLw==">https://blog.csdn.net/xingduan5153/article/details/106189340/<i class="fa fa-external-link-alt"></i></span></p><p>　　推荐：<span class="exturl" data-url="aHR0cHM6Ly93d3cuY25ibG9ncy5jb20vamlhbmdkcy9wLzgyNzY2MTMuaHRtbA==">https://www.cnblogs.com/jiangds/p/8276613.html<i class="fa fa-external-link-alt"></i></span></p><h1 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h1><p>1、缺省情况下建立的索引是非聚簇索引，但有时它并不是最佳的。在非群集索引下，数据在物理上随机存放在数据页上。合理的索引设计要建立在对各种查询的分析和预测上。一般来说：<br>　　a.有大量重复值、且经常有范围查询（ &gt; ,&lt; ，&gt; &#x3D;,&lt; &#x3D;）和order by、group by发生的列，可考<br>　　虑建立聚集索引；<br>　　b.经常同时存取多列，且每列都含有重复值可考虑建立组合索引；<br>　　c.组合索引要尽量使关键查询形成索引覆盖，其前导列一定是使用最频繁的列。索引虽有助于提高性能但不是索引越多越好，恰好相反过多的索引会导致系统低效。用户在表中每加进一个索引，维护索引集合就要做相应的更新工作。<br>2、ORDER BY和GROPU BY使用ORDER BY和GROUP BY短语，任何一种索引都有助于SELECT的性能提高。<br>3、多表操作在被实际执行前，查询优化器会根据连接条件，列出几组可能的连接方案并从中找出系统开销最小的最佳方案。连接条件要充份考虑带有索引的表、行数多的表；内外表的选择可由公式：外层表中的匹配行数*内层表中每一次查找的次数确定，乘积最小为最佳方案。<br>4、任何对列的操作都将导致表扫描，它包括数据库函数、计算表达式等等，查询时要尽可能将操作移至等号右边。<br>5、IN、OR子句常会使用工作表，使索引失效。如果不产生大量重复值，可以考虑把子句拆开。拆开的子句中应该包含索引。</p>]]></content>
    
    
    <summary type="html">MySQL 技术讲解 -- 聚簇索引介绍</summary>
    
    
    
    <category term="Database" scheme="http://ilongda.com/categories/Database/"/>
    
    <category term="MySQL" scheme="http://ilongda.com/categories/Database/MySQL/"/>
    
    
    <category term="Database" scheme="http://ilongda.com/tags/Database/"/>
    
    <category term="MySQL" scheme="http://ilongda.com/tags/MySQL/"/>
    
  </entry>
  
</feed>
