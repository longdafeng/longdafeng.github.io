<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>新年愿望</title>
    <url>/2020/New-Year-Wish/</url>
    <content><![CDATA[<p>忽然之间， 发现已经到了2020年， 回首2019年立下的flag， 似乎一大半都还没有完成， 就来到了2020年。<br>2020 拥有2个20， 在中国传统习惯中， 好事成双，大家都喜欢偶数的东西， 同时20又是10的倍数，就更吉利。 看到2020年这么吉利的数字， 也祝愿自己新的一年， 顺顺利利， 开开心心。 </p>
<p>今天，打开朋友圈， 发现一堆朋友，都跑步或健身， 似乎在这新的一年中， 大家都更积极面对生活，期待拥有一个更棒的身体。 </p>
<p>最后立一个心愿清单吧：</p>
<ol>
<li>儿子身体棒棒， 个子长得高一点。</li>
<li>每周带儿子和老婆， 做一次家庭运动。</li>
<li>今年写完50篇博文</li>
<li>看完12本书 （4本技术， 4本修心， 4本育儿）</li>
<li>争取练出6块腹肌。 </li>
<li>每天12点前睡觉</li>
</ol>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>10周年纪念</title>
    <url>/2020/10years/</url>
    <content><![CDATA[<h1 id="随谈"><a href="#随谈" class="headerlink" title="随谈"></a>随谈</h1><img data-src="/img/10years.png" >
<span id="more"></span>

<p>今天是入职阿里的10周年， 对于阿里，对于职业生涯， 有无数感慨， 还没有到10周年的时候，提醒自己写一篇总结， 终于到了10周年， 写下一点点感触， 更多的可能是感谢。</p>
<p>当年入职阿里的时候， 我说我会在阿里至少干5年， 因为过去都是2年跳一次，2年跳一次， 5年实际上是一个不短的旅程。 当时的hr （我记得是杨排风还是谁）特别高兴，回答道： 你有这个心在阿里愿意待5年特别好， 不过世事无常， 但不要给自己束缚太多， 也许2年或3年后，就会有很多变化，而且变化可能超出你的接受范围。每当想起这段交流， 我都忍不住对自己说， 哈哈，你都待了快10年， 早就完成当初的承诺了。 </p>
<p>待了这么多家公司，以前年少不经事， 总是忍不住不停吐槽公司， 后来见的多了， 当前自己觉得糟的公司，未必如想的那么糟， 自己一心向往的公司，也未必如梦中那么美好， 只有适合自己和不适合自己的公司。 李一男， 这么金光闪闪的神人， 离开华为后， 也是一路跌跌撞撞， 最终才找到自己的落脚点。 </p>
<p>感谢阿里， 也感谢这个黄金时代， 感谢自己搭载这阿里这周大船，乘风破浪， 如果不是阿里， 自己也就只是一个普普通通的打工仔， 可能依旧奋斗在温饱线上， 至少，阿里让自己从一个屌丝转身成为一个中产阶级家庭， 阿里这个大家庭， 虽然有的时候， 相互pk， 相互投诉，相互较劲， 但也给了一个舞台给我们展示自己的才华， 虽然， 很多时候， 自己的表演比较逊色， 有时候都觉得自己太弱了， 但站在公司的角度， 给一个足够的舞台，这已经是一家公司给予个人最大的支持。天高任鸟飞，其实很多时候， 自己翅膀不够硬，即使够硬了，不一定有足够的空间。古代士为知己者死，女为悦己者容，似乎就是类似思想。另外有的时候，自己管不住自己的一张嘴， 喜欢喷天，喷地， 喷一切， 自己的无知，以前在内网吐槽无数次， 但老板和同事都很包容自己， 感谢他们的包容。一家公司就是由无数的人组成， 这些人的言谈举止就决定了这家公司的风格， 上面最大的老板可能会将公司定一个基调，但真正这些基调的执行或落实，都是身边一个一个鲜活的人来展现。 感谢老板的信任， 很多决策其实有很多风险，但老板都坚定的支持， 也感谢身边的同事和团队的伙伴， 你们总是让一切由不可能变为可能。   </p>
<p>感谢阿里成就了自己， 而自己也将人生最宝贵的青春奉献给了阿里， 自己从一个青涩青年， 成长为一个油腻大叔， 从一个典型的程序员，到一个很小的管理者。 阿里已经深深在我的行为做事上烙上阿里的痕迹， 就像华为之于老华为人一样，阿里和华为都是极具中国特色的公司。 </p>
<p>当写到这里， 突然感觉像离职感谢信， 哈哈， 也许忍不住感谢， 一感谢，就像极了离职感谢信。 </p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>《OceanBase开发者手册》之一 如何编译OceanBase源码</title>
    <url>/2021/build_ob/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文将指导用户如何编译OceanBase, 本文大部分内容来自 <a href="https://github.com/oceanbase/oceanbase">https://github.com/oceanbase/oceanbase</a> .  </p>
<p>《OceanBase开发者手册》 主要指导开发者如何参与到OceanBase 的研发, 铺平参与OceanBase 开发的准备工作遇到的问题, 当前章节大概这几篇文章, 未来可能会增加部分文章, 目前OceanBase 源码参考OceanBase 开源官网的<a href="https://open.oceanbase.com/articles/8600129">《开源数据库OceanBase源码解读》 系列</a> :</p>
<ol>
<li>如何编译OceanBase源码</li>
<li>如何设置IDE开发环境</li>
<li>如何成为OceanBase Contributor</li>
<li>如何修改OceanBase文档</li>
<li>如何debug OceanBase</li>
<li>如何运行测试</li>
<li>如何修bug<br>​<span id="more"></span>
​</li>
</ol>
<h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h2 id="OS-compatibility-list"><a href="#OS-compatibility-list" class="headerlink" title="OS compatibility list"></a>OS compatibility list</h2><table>
<thead>
<tr>
<th>OS</th>
<th>Ver.</th>
<th>Arch</th>
<th>Compilable</th>
<th>Package Deployable</th>
<th>Compiled Binary Deployable</th>
<th>Mysqltest Passed</th>
</tr>
</thead>
<tbody><tr>
<td>Alibaba Cloud Linux</td>
<td>2.1903</td>
<td>x86_64</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>CentOS</td>
<td>7.2, 8.3</td>
<td>x86_64</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Debian</td>
<td>9.8, 10.9</td>
<td>x86_64</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Fedora</td>
<td>33</td>
<td>x86_64</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>MacOS</td>
<td>any</td>
<td>x86_64</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
</tr>
<tr>
<td>openSUSE</td>
<td>15.2</td>
<td>x86_64</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>OpenAnolis</td>
<td>8.2</td>
<td>x86_64</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>SUSE</td>
<td>15.2</td>
<td>x86_64</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>Ubuntu</td>
<td>16.04, 18.04, 20.04</td>
<td>x86_64</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
<tr>
<td>UOS</td>
<td>20</td>
<td>x86_64</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
<td>✅</td>
</tr>
</tbody></table>
<h2 id="How-to-build"><a href="#How-to-build" class="headerlink" title="How to build"></a>How to build</h2><p>This document will show how to build oceanbase. </p>
<h3 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h3><p>Before building, you need to confirm that your device has installed the necessary software.</p>
<h4 id="Redhat-based-including-CentOS-Fedora-OpenAnolis-RedHat-UOS-etc"><a href="#Redhat-based-including-CentOS-Fedora-OpenAnolis-RedHat-UOS-etc" class="headerlink" title="Redhat based (, including CentOS, Fedora, OpenAnolis, RedHat, UOS, etc.)"></a>Redhat based (, including CentOS, Fedora, OpenAnolis, RedHat, UOS, etc.)</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">yum install git wget rpm* cpio make glibc-devel glibc-headers binutils</span><br></pre></td></tr></table></figure>

<h4 id="Debian-based-including-Debian-Ubuntu-etc"><a href="#Debian-based-including-Debian-Ubuntu-etc" class="headerlink" title="Debian based (, including Debian, Ubuntu, etc.)"></a>Debian based (, including Debian, Ubuntu, etc.)</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">apt-get install git wget rpm rpm2cpio cpio make build-essential binutils</span><br></pre></td></tr></table></figure>

<h4 id="SUSE-based-including-SUSE-openSUSE-etc"><a href="#SUSE-based-including-SUSE-openSUSE-etc" class="headerlink" title="SUSE based (, including SUSE, openSUSE, etc.)"></a>SUSE based (, including SUSE, openSUSE, etc.)</h4><figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">zypper install git wget rpm cpio make glibc-devel binutils</span><br></pre></td></tr></table></figure>

<h3 id="debug-mode"><a href="#debug-mode" class="headerlink" title="debug mode"></a>debug mode</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bash build.sh debug --init --make</span><br></pre></td></tr></table></figure>

<h3 id="release-mode"><a href="#release-mode" class="headerlink" title="release mode"></a>release mode</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bash build.sh release --init --make</span><br></pre></td></tr></table></figure>

<h3 id="RPM-packages"><a href="#RPM-packages" class="headerlink" title="RPM packages"></a>RPM packages</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">bash build.sh rpm --init &amp;&amp; <span class="built_in">cd</span> build_rpm &amp;&amp; make -j16 rpm</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>OceanBase</category>
      </categories>
      <tags>
        <tag>OceanBase</tag>
      </tags>
  </entry>
  <entry>
    <title>DB性能测试-常用3套件-手把手一步一步跑TPCH</title>
    <url>/2020/TPCH/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>把过去的写的一篇笔记分享一下， 数据库最常用的测试三套件， sysbench – oltp 测试， tpch – olap 测试， tpcc – 事务性能测试。<br>本文手把手 一步一步 run TPCH, 即使从来没有跑过数据库的，也可以直接上手运行TPCH, 本文以运行TPCH on MySQL,  如果读者想要运行tpch 到postgres 或者其他的数据， 可以先参考本博文，然后基于本博文，再到github上搜索相应数据库的TPCH 库 即可。</p>
<p>整个过程， 分为</p>
<ul>
<li>介绍</li>
<li>编译</li>
<li>数据生成</li>
<li>数据加载</li>
<li>性能测试</li>
<li>表结构介绍<span id="more"></span></li>
</ul>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>TPC现有的测试标准为：TPC-E、TPC-C、TPC-H、TPC-App。根据这4个测试基准，目前TPC主要包括的4个技术小组委员会：TPC-E 技术小组委员会、TPC-C 技术小组委员会、TPC-H技术小组委员会、TPC-App技术小组委员会。前期TPC使用过但目前已经停止使用的测试标准有：TPC-A、TPC-B（数据库处理能力测试标准）、TPC-D、TPC-R（决策支持系统测试标准，类TPC-H）、TPC-W（Web处理能力测试标准）。</p>
<p>TPC-H（商业智能计算测试） 是美国交易处理效能委员会(TPC,Transaction Processing Performance Council) 组织制定的用来模拟决策支持类应用的一个测试集.目前,在学术界和工业界普遍采用它来评价决策支持技术方面应用的性能. 这种商业测试可以全方位评测系统的整体商业计算综合能力，对厂商的要求更高，同时也具有普遍的商业实用意义，目前在银行信贷分析和信用卡分析、电信运营分析、税收分析、烟草行业决策分析中都有广泛的应用。</p>
<p>TPC-H 基准测试是由 TPC-D(由 TPC 组织于 1994 年指定的标准,用于决策支持系统方面的测试基准)发展而来的.TPC-H 用 3NF 实现了一个数据仓库,共包含 8 个基本关系,其数据量可以设定从 1G<del>3T 不等。TPC-H 基准测试包括 22 个查询(Q1</del>Q22),其主要评价指标是各个查询的响应时间,即从提交查询到结果返回所需时间.TPC-H 基准测试的度量单位是每小时执行的查询数( QphH@size)，其中 H 表示每小时系统执行复杂查询的平均次数，size 表示数据库规模的大小,它能够反映出系统在处理查询时的能力.TPC-H 是根据真实的生产运行环境来建模的,这使得它可以评估一些其他测试所不能评估的关键性能参数.总而言之,TPC 组织颁布的TPC-H 标准满足了数据仓库领域的测试需求,并且促使各个厂商以及研究机构将该项技术推向极限。</p>
<p>详细可以参考 <a href="http://www.tpc.org/tpc_documents_current_versions/pdf/tpc-h_v2.17.3.pdf">tpch_reference</a></p>
<h1 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h1><p>下载源码包<a href="http://www.tpc.org/tpc_documents_current_versions/current_specifications5.asp">tpch</a><br><img data-src="http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/zh-CN/7761866951/p70167.png" alt="tpch_download"></p>
<ol>
<li>打开dbgen目录。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd dbgen</span><br></pre></td></tr></table></figure></li>
<li>复制makefile文件。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp makefile.suite Makefile</span><br></pre></td></tr></table></figure></li>
<li>修改Makefile文件中的CC、DATABASE、MACHINE、WORKLOAD等参数定义。<br>打开Makefile文件。<br>修改CC、DATABASE、MACHINE、WORKLOAD参数的定义。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">################</span><br><span class="line">## CHANGE NAME OF ANSI COMPILER HERE</span><br><span class="line">################</span><br><span class="line">CC      = gcc</span><br><span class="line"># Current values for DATABASE are: INFORMIX, DB2, ORACLE,</span><br><span class="line">#                                  SQLSERVER, SYBASE, TDAT (Teradata)</span><br><span class="line"># Current values for MACHINE are:  ATT, DOS, HP, IBM, ICL, MVS,</span><br><span class="line">#                                  SGI, SUN, U2200, VMS, LINUX, WIN32</span><br><span class="line"># Current values for WORKLOAD are:  TPCH</span><br><span class="line">DATABASE= MYSQL</span><br><span class="line">MACHINE = LINUX</span><br><span class="line">WORKLOAD = TPCH</span><br></pre></td></tr></table></figure>
按ECS键，然后输入:wq退出并保存。</li>
<li>修改tpcd.h文件，并添加新的宏定义。<br>打开tpcd.h文件。<br>vim tpcd.h<br>添加如下宏定义。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#ifdef MYSQL</span><br><span class="line">#define GEN_QUERY_PLAN &quot;&quot;</span><br><span class="line">#define START_TRAN &quot;START TRANSACTION&quot;</span><br><span class="line">#define END_TRAN &quot;COMMIT&quot;</span><br><span class="line">#define SET_OUTPUT &quot;&quot;</span><br><span class="line">#define SET_ROWCOUNT &quot;limit %d;\n&quot;</span><br><span class="line">#define SET_DBASE &quot;use %s;\n&quot;</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure>
按ECS键，然后输入:wq退出并保存。</li>
<li>对文件进行编译。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">make</span><br></pre></td></tr></table></figure>
编译完成后该目录下会生成两个可执行文件：</li>
</ol>
<ul>
<li>dbgen：数据生成工具。在使用InfiniDB官方测试脚本进行测试时，需要用该工具生成tpch相关表数据。</li>
<li>qgen：SQL生成工具。生成初始化测试查询，由于不同的seed生成的查询不同，为了结果的可重复性，请使用附件提供的22个查询。</li>
</ul>
<h1 id="生成数据"><a href="#生成数据" class="headerlink" title="生成数据"></a>生成数据</h1><h2 id="生成测试数据"><a href="#生成测试数据" class="headerlink" title="生成测试数据"></a>生成测试数据</h2><p>可以生成tpch 10g 也可以100g， 甚至1TB, 本例以100g 为例， 100g 的记录数在6亿条左右， 和普通一家中小型公司的大表规格差不多</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./dbgen -s 100</span><br><span class="line">mkdir tpch100</span><br><span class="line">mv *.tbl tpch100</span><br></pre></td></tr></table></figure>

<h2 id="生成查询sql"><a href="#生成查询sql" class="headerlink" title="生成查询sql"></a>生成查询sql</h2><ol>
<li>将qgen与dists.dss复制到queries目录下。<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp qgen queries</span><br><span class="line">cp dists.dss queries</span><br></pre></td></tr></table></figure></li>
<li>使用以下脚本生成查询。<br>在queries 目录下，创建脚本gen.sh<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/usr/bin/bash</span><br><span class="line">for i in &#123;1..22&#125;</span><br><span class="line">do  </span><br><span class="line">  ./qgen -d $i -s 100 &gt; db&quot;$i&quot;.sql</span><br><span class="line">done</span><br></pre></td></tr></table></figure></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./gen.sh</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>查询sql 进行调整<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dos2unix *</span><br></pre></td></tr></table></figure>
去掉生成文件中的”limit -1”, 去掉day 后面的(3), 以q1 为例， sql 如下</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- using default substitutions</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">select</span><br><span class="line">        l_returnflag,</span><br><span class="line">        l_linestatus,</span><br><span class="line">        sum(l_quantity) as sum_qty,</span><br><span class="line">        sum(l_extendedprice) as sum_base_price,</span><br><span class="line">        sum(l_extendedprice * (1 - l_discount)) as sum_disc_price,</span><br><span class="line">        sum(l_extendedprice * (1 - l_discount) * (1 + l_tax)) as sum_charge,</span><br><span class="line">        avg(l_quantity) as avg_qty,</span><br><span class="line">        avg(l_extendedprice) as avg_price,</span><br><span class="line">        avg(l_discount) as avg_disc,</span><br><span class="line">        count(*) as count_order</span><br><span class="line">from</span><br><span class="line">        lineitem</span><br><span class="line">where</span><br><span class="line">        l_shipdate &lt;= date &#x27;1998-12-01&#x27; - interval &#x27;90&#x27; day (3)   --- 把(3) 去掉</span><br><span class="line">group by</span><br><span class="line">        l_returnflag,</span><br><span class="line">        l_linestatus</span><br><span class="line">order by</span><br><span class="line">        l_returnflag,</span><br><span class="line">        l_linestatus;</span><br><span class="line">limit -1;              ---  去掉这行</span><br></pre></td></tr></table></figure>

<h1 id="加载数据"><a href="#加载数据" class="headerlink" title="加载数据"></a>加载数据</h1><ol>
<li><p>下载加载脚本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir load</span><br><span class="line">cd load</span><br><span class="line">wget https://raw.githubusercontent.com/longdafeng/test/master/shell/tpch/load.sh ./</span><br><span class="line">wget https://raw.githubusercontent.com/longdafeng/test/master/shell/tpch/polar.index.sh ./</span><br><span class="line">chmod +x *</span><br><span class="line">cp ../dss.ri  ../dss.ddl ./</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>因为这个测试里面带了polardb 的创建index 脚本， 读者如果不使用polardb，则可以不用下载polar.index.sh， 并修改load.sh 文件，去掉设置index 的步骤</p>
</li>
<li><p>修改dss.ri 脚本<br>dss.ri 主要是设置primary key 和foreign key</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- Sccsid:     @(#)dss.ri       2.1.8.1</span><br><span class="line">-- TPCD Benchmark Version 8.0</span><br><span class="line"></span><br><span class="line">CONNECT TO TPCD;           </span><br><span class="line"></span><br><span class="line">--ALTER TABLE TPCD.REGION DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.NATION DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.PART DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.SUPPLIER DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.PARTSUPP DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.ORDERS DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.LINEITEM DROP PRIMARY KEY;</span><br><span class="line">--ALTER TABLE TPCD.CUSTOMER DROP PRIMARY KEY;</span><br></pre></td></tr></table></figure>
<p>把 其中”CONNECT TO TPCD;  “删除掉， 把所有的”TPCD.” 给去除掉</p>
</li>
</ol>
<p>如果不想修改dss.ri, 可以直接下载现成的<a href="https://github.com/longdafeng/test/tree/master/shell/tpch">dss.ri</a></p>
<ol start="3">
<li>按照mysql 客户端<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install mysql -y</span><br></pre></td></tr></table></figure></li>
<li>开始加载<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nohup./load.sh hostxxx portxxx userxxx passwordxxx dbxxx &gt; load.log 2&gt;&amp;1 &amp;</span><br><span class="line">tail -f load.log</span><br></pre></td></tr></table></figure></li>
</ol>
<p>其中hostxxx 为db 地址<br>portxxx 为db 端口<br>userxxx 为用户名   — 需要提前创建好用户名， 对于云上用户， 还需要设置白名单， 把机器ip 白名单设置进去<br>passwordxxx 为用户密码<br>dbxxx 为 要创建的数据库名字，   因为脚本会自动加载在“生成数据” 一节中创建的目录（我们例子中是tpch100），因此数据库名也必须是上一节生成数据创建的目录</p>
<h1 id="开始测试"><a href="#开始测试" class="headerlink" title="开始测试"></a>开始测试</h1><p>下载 测试脚本  <a href="https://github.com/longdafeng/test/tree/master/python/tpch">https://github.com/longdafeng/test/tree/master/python/tpch</a> </p>
<p>配置配置文件example.cfg</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line"></span><br><span class="line">    &quot;host&quot;:&quot;xxxx&quot;                 // 数据库机器名</span><br><span class="line">    &quot;port&quot;:&quot;3306&quot;                 // 数据库端口号</span><br><span class="line">    &quot;username&quot;:&quot;xxxxx&quot;            // 数据库用户名</span><br><span class="line">    &quot;password&quot;:&quot;xxxx&quot;             // 数据库密码</span><br><span class="line">    &quot;database&quot;:&quot;xxxxx&quot;            // 数据库 库名</span><br><span class="line">    //input dir</span><br><span class="line">    &quot;input_dir&quot;:&quot;mysql&quot;           // 查询sql 存放的目录，如果是测试mysql 系列，则这里是mysql， 如果是pg，则需要生成pg的查询sql</span><br><span class="line">    </span><br><span class="line">    //output_dir</span><br><span class="line">    &quot;output_dir&quot;:&quot;polardb80&quot;      // 打印日志的目录</span><br><span class="line">    </span><br><span class="line">    //mysql_setting, set mysql variable</span><br><span class="line">    //&quot;mysql_setting&quot;: &quot;set max_parallel_degree=32;&quot;</span><br><span class="line">    &quot;mysql_setting&quot;: &quot;&quot;</span><br><span class="line"></span><br><span class="line">    //query per sql times</span><br><span class="line">    &quot;times_per_sql&quot;:&quot;1&quot;            // 每条sql 执行的次数， 会取平均值</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>运行脚本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nohup ./tpch.py -f example.cfg &gt; run.log 2&gt;&amp;1 &amp;</span><br><span class="line">tail -f run.log</span><br></pre></td></tr></table></figure>

<p>最后进入配置文件“output_dir” 目录下，查看result 文件即可</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>《OceanBase开发者手册》之三 如何成为OceanBase Contributor</title>
    <url>/2021/contribute_to_ob/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>本文将指导用户如何成为OceanBase Contributor, 即使是一个小白, 也可以成为contributor. </p>
<p>《OceanBase开发者手册》 主要指导开发者如何参与到OceanBase 的研发, 铺平参与OceanBase 开发的准备工作遇到的问题, 当前章节大概这几篇文章, 未来可能会增加部分文章, 目前OceanBase 源码参考OceanBase 开源官网的<a href="https://open.oceanbase.com/articles/8600129">《开源数据库OceanBase源码解读》 系列</a> :</p>
<ol>
<li>如何编译OceanBase源码</li>
<li>如何设置IDE开发环境</li>
<li>如何成为OceanBase Contributor</li>
<li>如何修改OceanBase文档</li>
<li>如何debug OceanBase</li>
<li>如何运行测试</li>
<li>如何修bug<br>​<span id="more"></span>
​</li>
</ol>
<h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><ol>
<li>在<a href="https://github.com/">https://github.com</a> 上注册一个用户, 如果已经有了一个账户, 则跳过此步骤<ol>
<li>因为现在github 不允许通过用户名和密码提交代码, 需要用户自己 创建token 来提交代码, <a href="https://docs.github.com/cn/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token">https://docs.github.com/cn/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token</a> ,  用新的token 来代替过去的密码来提交.</li>
</ol>
</li>
<li>fork <a href="https://github.com/oceanbase/oceanbase">https://github.com/oceanbase/oceanbase</a> 到自己github账户下</li>
</ol>
<img data-src="/img/ob/contributor1.png" >

<p>如果已经fork 了代码, 在github 点击<br><img data-src="/img/ob/contributor2.png" ></p>
<ol start="3">
<li>准备编译环境, 参考文档  <a href="https://github.com/oceanbase/oceanbase/wiki/how_to_build">how-to-build</a></li>
</ol>
<h2 id="代码编写"><a href="#代码编写" class="headerlink" title="代码编写"></a>代码编写</h2><ol>
<li><p>下载代码到本地, </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># git clone https://github.com/$&#123;用户&#125;/oceanbase</span><br></pre></td></tr></table></figure>
<p>备注:  ${用户} 为用户的名字</p>
</li>
<li><p>在<a href="https://github.com/oceanbase/oceanbase/issues">https://github.com/oceanbase/oceanbase/issues</a> 上找一个简单的issue,</p>
</li>
</ol>
<p>推荐找一个拼写错误的issue, 修改这些issue 比较简单, 容易上手.<br> <a href="https://github.com/oceanbase/oceanbase/issues?q=is:issue+is:open+label:typos">https://github.com/oceanbase/oceanbase/issues?q=is%3Aissue+is%3Aopen+label%3Atypos</a><br>​</p>
<p>创建对应的分支</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># git checkout -b issue$&#123;issue_number&#125;</span><br></pre></td></tr></table></figure>
<p>备注: ${issue_number} 为issue 的编号<br>​</p>
<ol start="3">
<li><p>在IDE 中修改代码, 推荐使用vscode, 并且vscode 使用远程链接功能. </p>
</li>
<li><p>修改完代码后, 进行编译</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#bash build.sh debug --init --make</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>大概等待10分钟</p>
</li>
<li><p>开始单元测试, 如果只是修改注释, 修改文档, 则不需要进行单元测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># cd build_debug/unittest/</span><br><span class="line">#make -j 4</span><br><span class="line">#./run_tests.sh</span><br></pre></td></tr></table></figure>
<p>整个过程, 需要1个小时</p>
</li>
</ol>
<h2 id="代码提交"><a href="#代码提交" class="headerlink" title="代码提交"></a>代码提交</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># git status</span><br><span class="line"></span><br><span class="line"># 位于分支 master</span><br><span class="line"># 尚未暂存以备提交的变更：</span><br><span class="line">#   （使用 &quot;git add &lt;file&gt;...&quot; 更新要提交的内容）</span><br><span class="line">#   （使用 &quot;git checkout -- &lt;file&gt;...&quot; 丢弃工作区的改动）</span><br><span class="line">#</span><br><span class="line">#	修改：      ../../src/$&#123;修改文件&#125;</span><br><span class="line">#</span><br><span class="line">修改尚未加入提交（使用 &quot;git add&quot; 和/或 &quot;git commit -a&quot;）</span><br></pre></td></tr></table></figure>
<p>备注: ${修改文件}为修改文件<br>然后 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git add $&#123;修改文件&#125;</span><br><span class="line">git commit -m &quot;fixed $&#123;issue_number&#125;, xxxxxxx&quot;</span><br><span class="line">git push origin issue$&#123;issue_number&#125;</span><br></pre></td></tr></table></figure>
<p>备注: ${issue_number}为issue的编号<br>commit的comments 需要带上”fixed ${issue_number}”, 这样可以将issue number 和pull request 关联起来<br>然后<br>​</p>
<p>创建pull request<br><img data-src="/img/ob/contributor3.png" ></p>
<p>即可,<br>​</p>
<p>创建pull request 后, 需要 签署CLA, 如果已经签署了, 类似这样<br><img data-src="/img/ob/contributor4.png" ><br>​</p>
<p>后续等待 OceanBase 的官方进行approve</p>
<h2 id="其他注意事项"><a href="#其他注意事项" class="headerlink" title="其他注意事项"></a>其他注意事项</h2><h3 id="注意切换分支"><a href="#注意切换分支" class="headerlink" title="注意切换分支"></a>注意切换分支</h3><p>当同时修改几个bug时， 每提交一个pull request 后， 就switch 到master上, 避免每个pull request 相互之间影响。 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git checkout master</span><br></pre></td></tr></table></figure>

<h3 id="发生冲突"><a href="#发生冲突" class="headerlink" title="发生冲突"></a>发生冲突</h3><p>自己的fork 的master 分支有可能会与远程master分支出现冲突， 这个时候， 在自己的fork 分支上， 把冲突commit 给删掉， 然后merge remote 的分支</p>
<ol>
<li>删除提交记录</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git reset --soft HEAD~i</span><br></pre></td></tr></table></figure>
<p>i代表要恢复到多少次提交前的状态，如指定i &#x3D; 2，则恢复到最近两次提交前的版本。–soft代表只删除服务器记录，不删除本地。</p>
<ol start="2">
<li>执行<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git push origin master --force</span><br></pre></td></tr></table></figure>
master代表当前分支</li>
</ol>
]]></content>
      <categories>
        <category>OceanBase</category>
      </categories>
      <tags>
        <tag>OceanBase</tag>
      </tags>
  </entry>
  <entry>
    <title>哥本哈根两日游</title>
    <url>/2020/copenhagen/</url>
    <content><![CDATA[<h1 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h1><p>哥本哈根挺好玩的， 即使完全不做攻略，也基本上可以玩的很happy， 很多玩的地方都集中在古城区， 在古城区很轻松就可以呆上一天， 另外坐上公交就可以到四处转转，比如美人鱼的地方，在那里可以看很多漂亮的公园。</p>
<p>强烈建议，先去tourist 中心购买哥本哈根卡， 持有哥本哈根卡，就可以免费走，免费看， 免费看87个展览馆，性价比极高。<br>整个北欧，艺术氛围非常浓厚，随处可见雕塑，建筑也是五彩缤纷，有非常多的展览馆或艺术馆，展览馆内保存着各式各样的雕塑和油画， 很多喜爱画画的人，拿着画具，找到一个博物馆，找一个雕塑，一呆就是一天。</p>
<p>我们在隔壁哈根，玩了下面几个地方，觉得推荐指数排序从高到低：</p>
<ol>
<li>嘉士伯艺术中心</li>
<li>christians 皇宫</li>
<li>thorvaldsens 博物馆</li>
<li>丹麦国家博物馆</li>
<li>天文馆&#x2F;tivoli 游乐场 – 适合小孩去玩，</li>
<li>美人鱼</li>
</ol>
<p>还有许多非常不错的地方，我们没有去，  比如amalienborg， 丹麦艺术与设计博物馆</p>
<span id="more"></span>

<h2 id="嘉士伯艺术中心"><a href="#嘉士伯艺术中心" class="headerlink" title="嘉士伯艺术中心"></a>嘉士伯艺术中心</h2><p>嘉士伯艺术中心，是我见过雕塑最多的展馆，格式雕塑，很多雕塑都可以追溯到罗马时期，甚至更早。<br>这里随便摘选几个<br><img data-src="/img/copenhagen/c0.jpeg" ><br><img data-src="/img/copenhagen/c1.jpeg" ><br><img data-src="/img/copenhagen/c2.jpeg" ><br><img data-src="/img/copenhagen/c3.jpeg" ><br><img data-src="/img/copenhagen/c4.jpeg" ><br>雕塑太多了，油画部分还没有来得及参观</p>
<h2 id="christians-皇宫"><a href="#christians-皇宫" class="headerlink" title="christians 皇宫"></a>christians 皇宫</h2><p>皇宫也是非常值得推荐参观游览的，</p>
<img data-src="/img/copenhagen/p0.jpeg" >
 一进门就是与众不同的柱子

<img data-src="/img/copenhagen/p1.jpeg" >

<p>王位<br><img data-src="/img/copenhagen/p2.jpeg" ><br><img data-src="/img/copenhagen/p3.jpeg" ></p>
<p>大厅，大厅中还有许许多多的画像，每一幅画像背后都寓有含义，可惜听不懂丹麦语， 旁边导游的讲解实在无法理解。只能贴2张图吧。<br><img data-src="/img/copenhagen/p4.jpeg" ><br><img data-src="/img/copenhagen/p5.jpeg" ></p>
<p>还展示了皇宫的家具和餐具，其中餐具非常精美<br><img data-src="/img/copenhagen/p6.jpeg" ></p>
<h2 id="thorvaldsens-博物馆"><a href="#thorvaldsens-博物馆" class="headerlink" title="thorvaldsens 博物馆"></a>thorvaldsens 博物馆</h2><p>Thorvaldsens 是一个天才艺术家， 从小自学成才， 当时雕塑有很多教条主义，而thorvaldsens凭借自己的天性追求艺术，雕塑了无数的精美作品， 而且更牛掰的是，自己死后就葬在展览馆的中央，四周环绕他的作品， 让世人敬仰和崇拜。</p>
<p>很多素描的，找一幅雕塑，一画就是一下午<br><img data-src="/img/copenhagen/t1.jpeg" ><br><img data-src="/img/copenhagen/t2.jpeg" ><br><img data-src="/img/copenhagen/t3.jpeg" ><br><img data-src="/img/copenhagen/t4.jpeg" ><br><img data-src="/img/copenhagen/t5.jpeg" ></p>
<h1 id="国家博物馆"><a href="#国家博物馆" class="headerlink" title="国家博物馆"></a>国家博物馆</h1><p>国家博物馆，展示丹麦的历史，从古到现在，从石器时代到青铜，到钢铁，再到现在，中间穿插很多宗教信仰的艺术品</p>
<img data-src="/img/copenhagen/h1.jpeg" >
<img data-src="/img/copenhagen/h2.jpeg" >
<img data-src="/img/copenhagen/h3.jpeg" >
<img data-src="/img/copenhagen/h4.jpeg" >


<h1 id="街拍"><a href="#街拍" class="headerlink" title="街拍"></a>街拍</h1><p>市政厅和世界之钟<br><img data-src="/img/copenhagen/a1.jpeg" ></p>
<p>安徒生雕像<br><img data-src="/img/copenhagen/a2.jpeg" ></p>
<p>市政厅前雕塑<br><img data-src="/img/copenhagen/a0.jpeg" ></p>
<p>安徒生童话之美人鱼<br><img data-src="/img/copenhagen/a8.jpeg" ></p>
<p>皇宫外景<br><img data-src="/img/copenhagen/a3.jpeg" ><br><img data-src="/img/copenhagen/a4.jpeg" ></p>
<p>吉菲昂喷泉<br><img data-src="/img/copenhagen/a5.jpeg" ><br><img data-src="/img/copenhagen/a6.jpeg" ><br>皇家图书馆<br><img data-src="/img/copenhagen/a7.jpeg" ></p>
]]></content>
      <categories>
        <category>travel</category>
      </categories>
      <tags>
        <tag>travel</tag>
      </tags>
  </entry>
  <entry>
    <title>The Dataflow Model： Google Dataflow 编程模型</title>
    <url>/2016/dataflow/</url>
    <content><![CDATA[<h1 id="插曲"><a href="#插曲" class="headerlink" title="插曲"></a>插曲</h1><p>《The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing》 2015年，这篇文章就发布了， 每次快速扫描， 理解上总是有些遗漏， 最近，决定将他翻译一下， 仔细阅读一下.<br>补充一下，2.4及之后的章节自己看了，但是没有翻译， copy一下同事默岭的翻译（版权归默岭所有哦）。</p>
<h1 id="为什么重新设计dataflow-编程模型"><a href="#为什么重新设计dataflow-编程模型" class="headerlink" title="为什么重新设计dataflow 编程模型"></a>为什么重新设计dataflow 编程模型</h1><ol>
<li>一份代码运行在不同的引擎， 现有很多google的业务方， 使用lambda架构， 实时部分使用millwheel做一些计算，不能保证完全正确， 然后通过离线flumejava作业不停的矫正数据。 （吐槽一句， millwheel 论文里面说自己的强一致多么牛x， 最后在dataflow 论文里面被打脸， 不过，millwheel里面提到的强一致设计是可以保证强一致，但成本非常高）。 业务方只需要实现一次代码，就可以在不同的引擎上切换，按照自己的业务需求。</li>
<li>会话窗口需求， 需要支持session window</li>
<li>trigger， accumulate和retraction 需求， 一些业务方使用watermark来标记数据已经完成，但经常有数据延迟到达，因此，需要处理迟到的数据。 整个设计需要考虑： 1. 支持增量处理， accumulate和retraction； 2， trigger机制， 一份相同的数据，根据不同的准确性和扩展性要求，选择不同的模式，从而达到不同的结果。</li>
<li>水位线百分位触发器， 比如， 部分节点处理特别缓慢， 成为job的长尾， 拖慢了整个项目的进度。 另一个需求是， 很多时候，只需要达到一个很高的准确行就好了，而不是100%准备。 这样，只需要通过percentile watermark trigger， 就可以确定是否要提前终止长尾任务或提前计算。 </li>
<li>时间trigger， 在google 推荐系统中， 使用大量google 基础设施建立用户行为画像， 这些用户行为画像会被用来根据兴趣来做推荐。注意的是， 这些系统使用处理时间进行数据驱动， 因为，这些系统需要经常更新，并且查看局部view 数据比等待直到当watermark 来了计算完整view 更重要。也就是说，对于一些时效要求高的系统， 必须具备根据处理时间来进行驱动的。</li>
<li>数据驱动 &amp; 组合trigger， 在MillWheel的论文中，我们描述了一种用来检测谷歌网站搜索查询趋势的异常探测系统。当我们为模型设计触发器的时候，这种微分异常探测系统启发我们设计了数据驱动触发器。这种微分探测器检测网站检索流，通过统计学估计来计算搜索查询请求量是否存在一个毛刺。如果系统认为一个毛刺即将产生，系统将发出一个启动型号。当他们认为毛刺已经消除，那么他们会发出一个停止信号。尽管我们可以采用别的方式来触发计算，比如说Trill的Punctuations，但是对于异常探测你可能希望一旦系统确认有异常即将发生，系统应该立即输出这个判断。Punctuations的使用事实上把流处理系统转换成了微批次处理系统，引入了额外的延迟。在调查过一些用户场景后，我们认为Punctuations不完全适合我们。因此我们在模型中引入了可定制化数据驱动触发器。同时这个场景也驱使我们支持触发器组合，因为在现实场景中，一个系统可能在处理多种微分计算，需要根据定义的一组逻辑来支持多种多样的输出。图9中的AtCount触发器是数据驱动触发器的例子，而图10-14使用了组合触发器。</li>
</ol>
<span id="more"></span>

<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>无限，乱序， global-scale 的数据处理需求不断增长， 与此同时，消费者提出复杂的业务需求，如event-time ordering, window特性，并且追求越快越好。 实际上， 一个系统很难完全从正确性，latency和成本上完全满足所有需求， 因此，不同的系统带来不同的解决方案，不同的tradeoff。 </p>
<p>数据处理的未来是无边界数据处理。 尽管有边界数据的处理永远都有着重要地位并且有用武之地，但是语义上它会被无边界数据处理模型所涵盖。一方面，无边界数据处理技术发展上步履蹒跚，另一方面对于数据进行处理并消费的要求在不断提高，比如说，需要对按事件发生时间对数据处理，或者支持非对齐窗口等。要发展能够支撑未来业务需要的数据处理系统，当前存在的系统和模型是一个非常好的基础，但我们坚持相信如果要完善地解决用户对无边界数据处理的需求，我们必须根本地改变我们的思维。</p>
<p>根据我们多年在谷歌处理大规模无边界数据的实践经验，我们相信我们提出的模型一个非常好的进展。它支持非对齐，事件发生时间窗口。这些都是当前用户所需要的。它提供了灵活的窗口触发机制，支持窗口累积和撤回，把关注点从寻求等待数据的完整性变为自动适应现实世界中持续变更的数据源。它对批处理，微批次，流处理提供了统一的抽象，允许数据开发人员灵活从三者中选择。同时，它避免了单一系统容易把系统本身的构建蔓延到数据处理抽象层面中去的问题。它的灵活性让数据开发者能根据使用场景恰当地平衡数据处理的准确性，成本和延迟程度。对于处理多样化的场景和需求来说，这一点很关键。最后，通过把数据处理的逻辑划分为计算什么，在哪个事件发生时间范围内计算，在什么处理时间点触发计算，如何用新的结果订正之前的数据处理结果让整个数据处理逻辑透明清晰。我们希望其他人能够认同这个模型并且和我们一起推进这个复杂而又令人着迷的领域的发展。</p>
<p>Dataflow 提出一种基础的方式来满足这些需求。 dataflow 并没有将无限的数据切分成有限的数据集，相反地，假定永远不清楚什么时候数据已经结束， 当新数据来时， 老的数据做retracted， 唯一的解决这个问题的方式是通过一个原则性的抽象来对 正确性／latency／cost 做一个合理的tradeoff。</p>
<p>本文提出一种方式 dataflow model， 详细的语法，核心原则，model validation（实践开发中对模型的检验）。 </p>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>现代数据处理系统是一个复杂和令人兴奋的领域， 从最开始的MapReduce 到它的后继者 hadoop，pig，hive，spark，包括各种sql 社区的流引擎，然而，现存的现代计算系统仍然存在一些基础缺点。</p>
<p>举个例子： 一个streaming video提供商 想要统计 他要支付多少money给内容提供商，并对广告商收取多少费用。这个平台需要支持在线和离线的数据，  video 提供商需要知道每天收取广告商多少money，同时汇总video和广告的各种统计参数， 同时，他想基于历史数据运行一些离线实验。广告／内容 提供商也想知道 他们哪些video／广告被看过，看的频率，看的时长，以及观看者的分类。更关键，他们也想知道他们收费／支付多少money，他们期望越快越好拿到这些信息， 这样他们可以尽快调整预算，投标，改变策略。 因为涉及到money， 因此准确性是基本要求。</p>
<p>数据处理系统天然很复杂，但video 提供商还是期望一个简单并具备伸缩性的编程模型。 他们同样要求系统能够处理全球 scale的离散数据。</p>
<p>这个use case是每个video的观看时间和观看时长， 观看者是谁， 哪些内容或广告被看过。 然而，现有的系统依旧不能满足这些需求。 </p>
<ul>
<li>MR&#x2F;FlumeJava&#x2F;Spark&#x2F;hive&#x2F;pig&#x2F;  延迟不能满足需求</li>
<li>Aurora&#x2F;TelegraphCQ&#x2F;Niagara&#x2F;Esper, 在容错性上不行或者代价比较大</li>
<li>storm&#x2F;samza&#x2F;pulsar 不支持exactly-once 语义， pulsar 具备一定的scalable，并且支持high-level session的非对齐window的概念</li>
<li>tigon 不支持window 语义</li>
<li>spark-streaming&#x2F;sonora&#x2F;trident 只支持处理时间或tuple时间的window</li>
<li>sqlstream 必须强顺序性</li>
<li>flink， event－time触发机制有些限制， </li>
<li>CEDR&#x2F;Trill 可以提供准时的触发和增量模型， 但window语义不能完全表达session， 另外定期的打标（punctuation）不足够</li>
<li>mill wheel 和spark streaming底层是够scalable／fault－tolerant／low－latency，但缺乏应用层编程框架， 在event－time session上还有欠缺</li>
<li>lamada架构能够满足这些需求， 但需要维护2套系统</li>
<li>summingbird通过提供一套复杂的接口来抽象batch和streaming， 为了让某些类型计算可以在2套系统上运行，增加了大量的限制， 同样需要维护2套系统。</li>
</ul>
<p>上面这些问题并不是无解问题，随着时间推移， 这些系统的开发者会克服这些缺陷。但有一个观念上的错误， 这些系统对于输入的数据上， 认为输入的数据在某个时间点上是complete。我们认为这是一个基本错误， 现实中存在海量，乱序的dataset冲突和消费者的时效要求。因此需要一个简单但powerful的框架，在解决用户的需求的同时来平衡正确性／时延／成本。我们相信任何一个想要大量应用的解决方案必须 简单但强大， 并且以一个合适的成本很好平衡正确性和latency。 最近，我们是时候超越现有流行计算引擎语义， 正确的设计并构建batch， micro-batch和streaming 系统， 这些系统能够提供相同的正确性，3者并能广泛使用在无限的数据处理中。 </p>
<p>本文核心是一个统一的模型：</p>
<ul>
<li>在一个无限，乱序的数据源， 进行计算， 并支持event-time 顺序的结果， 根据feature 执行window操作， 并优化正确性，latency和成本。</li>
<li>对pipeline 实现以4个维度进行分解， 提供clarity（清晰）， composability（可组合性）和flexibility<ul>
<li><b>what</b> result are being computed</li>
<li><b>where</b> in event time they are being computed </li>
<li><b>when</b> in processing time they are materialized</li>
<li><b> How</b> earlier results relate to later refinements</li>
</ul>
</li>
<li>将逻辑数据处理与底层的物理实现独立开， 从而通过选择batch， micro-batch或streaming 引擎，来选择不同的侧重点， 正确性／延迟／成本。</li>
</ul>
<p>具体上， 本文讨论：</p>
<ul>
<li>windowing model， 支持unaligned event-time window, 展示一组简单的api 创建和使用window</li>
<li>triggering model， 根据流水线的runtime 特性来决定输出结果次数， 使用一个powerful并且flexible 声明式API 来描述trigger 语义。</li>
<li>增量处理模型incremental processing model， 集成retraction／update到 windowing／triggering 模型上</li>
<li>scalable implementation, 在mill wheel 流引擎和flumejava batch 引擎上，重新实现cloud dataflow， 包含一个open-source 的sdk</li>
<li>一组核心原则， 指导这种模型的设计</li>
<li>简单讨论google 在海量，无限，乱序数据处理的经验</li>
</ul>
<p>最后值得提一下， 这个模型也没有神奇的地方， 现有强一致的batch，micro-batch，streaming或lambda系统中不切实际的东西仍然存在， cpu&#x2F;ram&#x2F;disk 限制依旧存在。这个模型是一种框架， 这个框架可以相对简单表达并行计算， 用一种独立底层引擎的方式， 同样它也提供能力切入精确latency， 切入正确性因数据和资源导致的实际问题。 它的目标是简化构建实际，海量数据处理流水线。</p>
<h2 id="unbounded-bounded-vs-streaming-batch"><a href="#unbounded-bounded-vs-streaming-batch" class="headerlink" title="unbounded&#x2F;bounded vs streaming&#x2F;batch"></a>unbounded&#x2F;bounded vs streaming&#x2F;batch</h2><p>当描述 无限／有限数据集时， 我们倾向使用字符unbounded／bounded， 而不是stream／batch 上， 因为后面会暗示特定的执行引擎。 batch系统可以重复执行来处理unbounded数据集， 同样好的设计streaming 系统同样可以处理bounded 数据。 这个角度上， streaming和batch系统的区别是不相干的。</p>
<h2 id="windowing"><a href="#windowing" class="headerlink" title="windowing"></a>windowing</h2><p>window 将数据集切成有限的块，并作为一组数据来处理。 当处理无限数据（unbounded）时， 一些operation（aggregation， outer join， time-bouunded operation）需要window，然后另外一些operation（filter，mapping， inner join 等）没有需求。 对于有限数据集， window基本上是可选的， 尽管在一些场景中语义上是有帮助。 window一般是基于时间的， 不过一些系统支持基于tuple的window， 它实际上是在逻辑时间领域上的基于时间window， 并且按顺序的元素在逻辑时间上连续增长。 window 有可能是aligned（window time应用在所有数据上）， 有可能unalign（window of time 应用在部分数据上）。 下图展示了3种window类型。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/windowtype.jpg" >
</div> 

<h3 id="Fixed-window-tumbling-window"><a href="#Fixed-window-tumbling-window" class="headerlink" title="Fixed window&#x2F;tumbling window"></a>Fixed window&#x2F;tumbling window</h3><p>定义一个静态的window大小，比如小时或天window。 他们一般是aligned， 每个window 贯穿对应时间的数据。 有的时候，为了分摊window完成时的压力， 系统会shift window以一个随机值。</p>
<h3 id="sliding-window"><a href="#sliding-window" class="headerlink" title="sliding window"></a>sliding window</h3><p>定义一个window size和slide 时间， 比如window为小时，滑动为分钟。当滑动时间小于窗口大小时，会有一些overlap。 划窗（sliding window）一般也是aligned。 fixed window其实就是划窗的一种特殊场景，sliding 大小等于窗口大小。</p>
<h3 id="session-window"><a href="#session-window" class="headerlink" title="session window"></a>session window</h3><p>session window是某段时间，数据是活跃的。 通常会定义个timeout gap。 event 时间跨度小于timeout 时间的event 会组成一个session。 session通常是unaligned。 在本例中， window 2 只应用在key 1， window 3 只应用在key 2， window 1和4 应用在key 3上。</p>
<h2 id="时间领域-time-domains"><a href="#时间领域-time-domains" class="headerlink" title="时间领域 time domains"></a>时间领域 time domains</h2><p>有2种时间领域。 </p>
<ul>
<li><b>event time</b>, event 本身出现的时间， 比如系统clock time， 当系统产生这个event的时间</li>
<li><b>process time</b> 在流水线中 处理的时间， 比如系统当前时间。 注意，并没有假设系统中所有的时间同步。</li>
</ul>
<p>event time 从来不变，process time 不停会变， 因为event会随着流转整个pipeline而导致时间会不停向前走。</p>
<p>在处理过程中， 因为系统的真实使用（communication dely， 调度算法， 用于处理时间， 流水线序列化 等等）导致这两种时间发生差异并且动态变化。 全局进度metrics比如打标（punctuations）或者watermark，提供一个好方式展示这种差异。 我们采用像millwheel的watermark， 它是一种时间戳，在event time上的下限值，小于这个时间戳的都已经被处理. 完成的概念并不兼容正确性， 我们因此并不依赖watermark（来保证正确性）。 系统常常使用一种有用的方式， 系统会认为截止到一个指定的event time前所有的数据已经接收， 因此应用既可以visualizing skew（可视化时间差），又可以监控系统整体的健康和进度， 同时如果不依赖完全正确性的情况下，可以做一些决策，比如常见的垃圾回收。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/timeskew.jpg" >
</div> 

<p>在理想情况下， time domain skew（process time和event time 差异）是为0， 只要event一出现，系统会处理event。 现实并非如此美好， 如上图所示， 从12点开始， watermark都滞后一段时间。 上图在分布式系统中是非常正常的现象， 并且在考虑提供准确性和可重复的result时， 必须要考虑这种情况。</p>
<h1 id="dataflow-model"><a href="#dataflow-model" class="headerlink" title="dataflow model"></a>dataflow model</h1><p>这章将介绍dataflow model，并解释为什么语义对batch， micro-batch，streaming是通用的。 我们将展示dataflow java sdk （它从flumejava api 演化而来）</p>
<h2 id="core-primitives"><a href="#core-primitives" class="headerlink" title="core primitives"></a>core primitives</h2><p>开始之前，先想想经典batch 模型的基本元素。 dataflow sdk 有2个核心 transform 操作在(key, value).</p>
<h3 id="ParDo"><a href="#ParDo" class="headerlink" title="ParDo"></a>ParDo</h3><p>ParDo 是普通的并发处理。 将输入的数据传递给用户的代码， 每个input可能产生0或多个output elements。 在无限数据中， pardo 操作每个input上元素，可能转化为无限的数据。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/pardo.jpg" >
</div> 

<h3 id="GroupByKey"><a href="#GroupByKey" class="headerlink" title="GroupByKey"></a>GroupByKey</h3><div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/pardo.jpg" >
</div> 

<p>GroupByKey 在发送结果到下游进行reduce前，收集一个key的所有数据。 如果输入数据是无限的，系统不知道什么时候结束。 常见的解决方案是window 这些数据。</p>
<h2 id="windowing-1"><a href="#windowing-1" class="headerlink" title="windowing"></a>windowing</h2><p>系统重新定义GroupByKey operation 为 GroupByKeyAndWindow. 第一个要做的是支持unaligned window， 因为有可能有2个key 视图。第一个key是它简单把所有window strategies处理为unaligned 并让底层实现对aligned case使用相关优化。 第二个key是window可以切分为2个相关的操作：</p>
<ul>
<li>Set<Window> AssignWindows(T datum), 它分配这个元素到0个或多个window上，  这是基本的bucket操作</li>
<li>Set<Window> MergeWindows(Set<Window> windows)， 在grouping时 merge window。 当数据到达并被group 一起时， 可以在时间上进行构建数据驱动的window。</li>
</ul>
<p>对于任何给定的window strategy， 这两种operation是紧密相关。 滑窗assignment需要滑窗merging， session window assignment需要session window merging。 </p>
<p>为了天然支持event-time window, 修改数据结构为(key, value, event time, window), 每个元素都会带event-time并被初始化到全局window， covering 所有的event time， 这种方式match 默认的标准batch 方式。</p>
<h3 id="window-assignment"><a href="#window-assignment" class="headerlink" title="window assignment"></a>window assignment</h3><p>window assignment会copy一份新的元素， 每个元素会分配自己的window。 举例来说， 如下图所示，划窗中window为2分钟长度和移动步长为1分钟。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/windowassign.jpg" >
</div> 

<p> window 同它的元素关联起来， 这表示， 在流水线使用grouping之前的任何地方都可以做window assignment操作。 这很重要， 在一个合成转换中（如Sum.integersPerKey()）有可能将grouping 操作隐藏在下游的什么地方。</p>
<h3 id="window-merging"><a href="#window-merging" class="headerlink" title="window merging"></a>window merging</h3><p>windows merging是GroupByKeyAndWindow的一部分。 如下例所示：</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/windowmerge.jpg" >
</div> 

<p>上图中， 做session window， session window的timeout为30分钟。 一开始都放在全局window中。 AssignWindows 会把每个元素放到一个window中（在它自己的timestamp 延伸30分钟）。 然后开始GroupByKeyAndWindow， 实际上它进行了5步组合操作：</p>
<ul>
<li>DropTimestamps， 丢掉元素的timestamp，因为window是从现在到后面（30分钟），后续的计算只关系窗口</li>
<li>GroupByKey, 按key 进行group(value, window)</li>
<li>MergeWindows, 按照一个key merge 一组window。 实际的merge逻辑由window strategy 来决定。 因为v1 和v4 overlap了， 所以merge 它们到一个新的，更大的session</li>
<li>GroupAlsoByWindow， 对每个key，按照window进行group 操作。 v1和v4是相同window，因此group在一起</li>
<li>ExpandToElements， 将每个group 扩展为(key, value, event time, window)，在本例，设置timestamp为window的结束时间。 任何timestamp 大于或等于 window中最早event的timestamp都是有效的，符合watermark正确性。</li>
</ul>
<h3 id="api"><a href="#api" class="headerlink" title="api"></a>api</h3><p>下例中：</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/apisimple.jpg" >
</div> 

<p>在求和之前，增加一个Window.into 来生成时长30分钟的session window</p>
<h2 id="Triggers-／-Incremental-Processing"><a href="#Triggers-／-Incremental-Processing" class="headerlink" title="Triggers ／ Incremental Processing"></a>Triggers ／ Incremental Processing</h2><p>构建unaligned／event-time window是一种改进，但有2个缺点：</p>
<ul>
<li>需要支持tuple- 和processing-time-based 的window， 否则会退到和其他系统一样。</li>
<li>需要知道什么时候emit 一个window的result。 因为event-time是乱序， 需要某种signal 告诉我们window 完成了。</li>
</ul>
<p>下一节介绍如何解决第一个问题。 对于第二个问题解决方案，最初倾向使用如watermark 这样的全局event-time 进度metric。 然后watermark 对于正确性存在2个缺点：</p>
<ul>
<li>有的时候太快， 意味着有些数据晚于watermark到达。 对于分布式系统，很难获得一个完美的event-time watermark， 如果用户想要100%的正确性，很难通过它来达到。</li>
<li>太慢， 因为它是一个全局进度metric， 因为一个慢的数据可能就拖慢整个pipeline的watermark。 即使是健康的变化少的pipleline， 基线仍然有可能是几分钟甚至更多。 因此，使用watermark作为emit window signal容易导致高的latency。</li>
</ul>
<p>假定单独watermark是不够的， 一个可用的方式是lambda架构的高效sidesteps（步进）， 它并没有解决完成问题，但更快提供正确答案。 他提供像streaming流水线一样的更好的低延迟结果，一旦batch pipleline运行则可以保证最终一致性和正确性。如果我们想要通过单个流水线达到同样的效果， 我们需要为任何一个window提供多个答案。 我们称这种特性为trigger， 设定一个说明，什么时候为任何一个window trigger输出结果。</p>
<p>trigger是一种机制， 当接收到内部或外部的信号输出GroupByKeyAndWindow 的结果。 他们补充window 模型， 他们通过不同的时间轴影响了系统行为：</p>
<ul>
<li>windowing 用event time 决定什么地方进行grouped。</li>
<li>triggering 用processing time 来决定什么时候输出结果</li>
</ul>
<p>dataflow 预定义了一套trigger 实现 来trigger 完成评估（比如 watermark， 包括百分比watermark， 他提供有用的语义来处理在batch和streaming引擎延迟的数据，当用户更关注快速处理小比例的数据而不是最后一块数据）。基于processing time， 基于数据到达情况（记录数，字节数，data punctuations， 数据匹配模式等）。 dataflow 同样支持嵌入trigger到 逻辑联合（and／or）， loops，sequences 和其他这种构建。 除此之外， 用户可以定义他们自己的trigger， 可以基于底层的primitives（watermark timer， processing timer， data arrival， composition support）或任何外部相关signal。<br>除了控制什么时候emit result， trigger系统控制一个window的多个pane如何相互关联， 通过3种定义模型：</p>
<ul>
<li>discarding, window 内容会被丢弃， 后面的结果不会影响前面的结果。 当下游消费者期望大量的trigger是相互独立时（比如，对inject 到系统的数据做一个sum计算）， 这种模型是有用的。尽管联合和交换的操作可以潜入到dataflow的Combiner 里面， 这是在缓存数据的最有效方式， dela的效率会最小化。在我们的video session例子中， 这样是不够的， 因为要求下游消费者拼装(stitch)部分数据。</li>
<li>accumulating， window的数据会存到存储中， 后面的结果会对之前的结果进行矫正。 当接收一个window的多个结果时， 下游消费者期望后面的结果能够覆盖之前的结果， 这种方式会非常有用。另外在lambda架构中这种方式很高效， streaming 流水线产生的低延迟的结果会被后面batch 流水线运行的结果给覆盖掉。 在我们的vedio session 例子中， 这种方式可能够用， 如果我们简单计算session，然后更新到支持更新的存储中（比如数据库或kv store）</li>
<li>accumulating 和retraction， 在accumulating语义上， 一个emitted 拷贝值仍然会存储到持久化存储中。 当后面又触发window trigger， 之前值的retraction会首先发送出去， 紧接着新的计算值。 当流水线中存在多个串行的GroupByKeyAndWindow操作时很有必要这种模式， 一个window产生的多个结果， 因为由一个window产生的多个结果在下游做group的key上结束（没理解这句话什么意思）。那种情况下， 第二个grouping的操作将会产生错误的结果， 除非那些key被通知一个retraction， 从而原始值的影响会被去掉。 dataflow Combiner 的相反操作uncombine 支持retraction。对于video session例子来说，这种方式是最理想的。</li>
</ul>
<h2 id="example"><a href="#example" class="headerlink" title="example"></a>example</h2><p>考虑下例中，做整数求和：</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/apisimple.jpg" >
</div> 

<p>我们假设从某个数据源我们观察到了10个数据点，每个数据点都是一个比较小的整数。我们会考虑有边界输入源和无边界输入源两种情况。为了画图简单，我们假设这些数据点的键是一样的，而生产环境里我们这里所描述的数据处理是多个键并行处理的。图5展示了数据在我们关心的两个时间轴上的分布。X轴是事件发生时间（也就是事件发生的时间），而Y轴是处理时间（即数据管道观测到数据的时间）。（译者注：圆圈里的数值是从源头采样到的数值）除非是另有说明，所有例子假设数据的处理执行都是在流处理引擎上。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/exampleinput.jpg" >
</div> 

<p>很多例子都要考虑水位线，因此我们的图当中也包括了理想的水位线，也包括了实际的水位线。直的虚线代表了理想的水位线，即，事件发生时间和数据处理时间不存在任何延迟，所有的数据一产生就马上消费了。不过考虑到分布式系统的不确定性，这两个时间之间有偏差是非常普遍的。在图5中，实际的水位线（黑色弯曲虚线）很好的说明了这一点。另外注意由于实际的水位线是猜测获得的，因此有一个迟到比较明显的数据点落在了水位线的后面。</p>
<p>如果我们在传统的批处理系统中构建上述的对数据进行求和的数据处理管道，那么我们会等待所有的数据到达，然后聚合成一个批次（因为我们现在假设所有的数据拥有同样的键），再进行求和，得到了结果51。如图6所示黑色的长方形是这个运算的示意图。长方形的区域代表求和运算涵盖的处理时间和参与运算的数据的事件发生时间区间。长方形的上沿代表计算发生，获得结果的管道处理时间点。因为传统的批处理系统不关心数据的事件发生时间，所有的数据被涵盖在一个大的全局性窗口中，因此包含了所有事件发生时间内的数据。而且因为管道的输出在收到所有数据后只计算一次，因此这个输出包含了所有处理时间的数据（译者注：处理时间是数据系统观察到数据的时间，而不是运算发生时的时间）。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/classicbatch.jpg" >
</div> 

<p>注意上图中包含了水位线。尽管在传统批处理系统中不存在水位线的概念，但是在语义上我们仍然可以引入它。批处理的水位线刚开始时一直停留不动。直到系统收到了所有数据并开始处理，水位线近似平行于事件发生时间轴开始平移，然后一直延伸到无穷远处。我们之所以讨论这一点，是因为如果让流处理引擎在收到所有数据之后启动来处理数据，那么水位线进展和传统批处理系统是一模一样的。（译者注：这提示我们其实水位线的概念可以同样适用于批处理）</p>
<p>现在假设我们要把上述的数据处理管道改造成能够接入无边界数据源的管道。在Dataflow模型中，默认的窗口触发方式是当水位线移过窗口时吐出窗口的执行结果。但如果对一个无边界数据源我们使用了全局性窗口，那么窗口就永远不会触发（译者注：因为窗口的大小在不停地扩大）。因此，我们要么用其他的触发器触发计算（而不是默认触发器），或者按某种别的方式开窗，而不是一个唯一的全局性窗口。否则，我们永远不会获得计算结果输出。</p>
<p>我们先来尝试改变窗口触发方式，因为这会帮助我们产生概念上一致的输出（一个全局的包含所有时间的按键进行求和），周期性地输出更新的结果。在这个例子中，我们使用了Window.trigger操作，按处理时间每分钟周期性重复触发窗口的计算。我们使用累积的方式对窗口结果进行修正（假设结果输出到一个数据库或者KV数据库，因而新的结果会持续地覆盖之前的计算结果）。这样，如图7所示，我们每分钟（处理时间）产生更新的全局求和结果。注意图中半透明的输出长方形是相互重叠的，这是因为累积窗格处理机制计算时包含了之前的窗口内容。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/globalaccumulate.jpg" >
</div> 

<p>如果我们想要求出每分钟的和的增量，那么我们可以使用窗格的抛弃模式，如图8所示。注意这是很多流处理引擎的处理时间窗口的窗口计算模式。窗格不再相互重合，因此窗口的结果包含了相互独立的时间区域内的数据.</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/globaldiscard.jpg" >
</div> 

<p>另外一种更健壮的处理时间窗口的实现方式，是把数据摄入时的数据到达时间作为数据的事件发生时间，然后使用eventtime window。这样的另一个效果是系统对流入系统的数据的事件发生时间非常清楚，因而能够生成完美的水位线，不会存在迟到的数据。如果数据处理场景中不关心真正的事件发生时间，或者无法获得真正的事件发生时间，那么采用这种方式生成事件发生时间是一种非常低成本且有效的方式。</p>
<p>在我们讨论其他类型的窗口前，我们先来考虑下另外一种触发器。一种常见的窗口模式是基于记录数的窗口。我们可以通过改变触发器为每多少条记录到达触发一次的方式来实现基于记录数的窗口。图9是一个以两条记录为窗口大小的例子。输出是窗口内相邻的两条记录之和。更复杂的记录数窗口（比如说滑动记录数窗口）可以通过定制化的窗口触发器来支持。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/globaldiscardatcount.jpg" >
</div> 

<p>我们接下来考虑支持无边界数据源的其他选项，不再仅仅考虑全局窗口。一开始，我们来观察固定的2分钟窗口，累积窗格。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/unboundfixedwindow.jpg" >
</div> 

<p>水位线触发器是指当水位线越过窗口底线时窗口被触发。我们这里假设批处理和流处理系统都实现了水位线（详见3.1）。Repeat代表的含义是如何处理迟到的数据。在这里Repeat意味着当有迟于水位线的记录到达时，窗口都会立即触发再次进行计算，因为按定义，此时水位线早已经越过窗口底线了。</p>
<p>图10-12描述了上述窗口在三种不同的数据处理引擎上运行的情况。首先我们来观察下批处理引擎上这个数据处理管道如何执行的。受限于我们当前的实现，我们认为数据源现在是有边界的数据源，而传统的批处理引擎会等待所有的数据到来。之后，我们会根据数据的事件发生时间处理，在模拟的水位线到达后窗口计算触发吐出计算结果。整个过程如图10所示</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/fixedbatch.jpg" >
</div> 

<p>然后来考虑一下微批次引擎，每分钟做一次批次处理。系统会每分钟收集输入的数据进行处理，反复重复进行。每个批次开始后，水位线会从批次的开始时间迅速上升到批次的结束时间（技术上来看基本上是即刻完成的，取决于一分钟内积压的数据量和数据处理管道的吞吐能力）。这样每轮微批次完成后系统会达到一个新的水位线，窗口的内容每次都可能会不同（因为有迟到的数据加入进来），输出结果也会被更新。这种方案很好的兼顾了低延迟和结果的最终准确性。如图11所示：</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/fixedmicrobatch.jpg" >
</div> 

<p>接下来考虑数据管道在流处理引擎上的执行情况，如图12所示。大多数窗口在水位线越过它们之后触发执行。注意值为9的那个数据点在水位线之后到达。不管什么原因（移动设备离线，网络故障分区等），系统并没有意识到那一条数据并没有到达，仍然提升了水位线并触发了窗口计算。当值为9的那条记录到达后，窗口会重新触发，计算出一个新的结果值。</p>
<p>如果说我们一个窗口只有一个输出，而且针对迟到的数据仅做一次的修正，那么这个计算方式还是不错的。不过因为窗口要等待水位线进展，整体上的延迟比起微批次系统可能要更糟糕，这就是我们之前在2.3里所说的，单纯依赖水位线可能引起的问题（水位线可能太慢）</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/fixedstream.jpg" >
</div>

<p>如果我们想降低整体的延迟，那么我们可以提供按数据处理时间的触发器进行周期性的触发，这样我们能够尽早得到窗口的计算结果，并且在随后得到周期性的更新，直到水位线越过窗口边界。参见图13。这样我们能够得到比微批次系统更低的延迟，因为数据一到达就进入了窗口随后就可能被触发，而不像在微批次系统里必须等待一个批次数据完全到达。假设微批次系统和流处理系统都是强一致的，那么我们选择哪种引擎，就是在能接受的延迟程度和计算成本之间的选择（对微批次系统也是批大小的选择）。这就是我们这个模型想要达到的目标之一。参见图13：固定窗口，流处理，部分窗格</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/fixedstreampartial.jpg" >
</div>

<p>作为最后一个例子，我们来看一下如何支持之前提到的视频会话需求（为了保持例子之间的一致性，我们继续把求和作为我们的计算内容。改变成其他的聚合函数也是很容易的）。我们把窗口定义为会话窗口，会话超时时间为1分钟，并且支持retraction操作。这个例子也体现了我们把模型的四个维度拆开之后带来的灵活的可组合性（计算什么，在哪段事件发生时间里计算，在哪段处理时间里真正触发计算，计算产生的结果后期如何进行修正）。也演示了对之前的计算结果可以进行撤回是一个非常强力的工具，否则可能会让下游之前接收到的数据无法得到修正。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/dataflow/sessionretraction.jpg" >
</div>

<p>在这个例子中，我们首先接收到了数据5 和数据7。由于5和7之间事件发生时间大于1分钟，因此被当做了两个会话。在第一次窗口被触发时，产生了两条计算结果，和分别为5和7。在第二个因处理时间引起的窗口触发时，我们接收到了数据3,4,3，并且第一个3和上一个7之间时间大于1分钟，因此被分组到一个新的会话窗口，窗口触发计算并输出了计算结果10。紧接着，数据8到达了。数据8的到达使得数据7,3,4,3,8合并成了一个大窗口。当水位线越过数据点8后，新窗口计算被触发。触发后需要先撤回之前两个小窗口的计算结果，撤回方式是往下游发送两条键为之前的两个会话标记，值为-7和-10的记录，然后发送一个新的值为25的新窗口计算结果。同样，当值为9的记录迟于水位线到达后，之前的所有7条记录都合并成了一个会话，因此要对之前的会话再次进行撤回。值为-5和-25的记录又被发送往下游，新的值为39的会话记录随后也被发往下游。</p>
<p>同样的操作在处理最后3条值为3,8,1的记录时也会发生，先是输出了结果值3，随后回撤了这个计算结果，输出了合并会话后的结果值12。</p>
<h1 id="3-实现和设计"><a href="#3-实现和设计" class="headerlink" title="3. 实现和设计"></a>3. 实现和设计</h1><h2 id="3-1-实现"><a href="#3-1-实现" class="headerlink" title="3.1 实现"></a>3.1 实现</h2><p>我们已经用FlumeJava实现了这个模型，使用MillWheel作为底层的流执行引擎；在本文写作的时候，针对公有云服务Cloud Dataflow的重新实现也接近完成。由于这些系统要么是谷歌的内部系统，要么是共有云服务，因此为简洁起见，实现的细节我们略掉了。可以提及的让人感兴趣的一点是，核心的窗口机制代码，触发机制代码是非常通用的，绝大部分都同时适用于批处理引擎实现和流处理引擎实现。这个实现本身也值得在将来进行更进一步的分析。</p>
<h2 id="3-2-设计原则"><a href="#3-2-设计原则" class="headerlink" title="3.2 设计原则"></a>3.2 设计原则</h2><p>尽管我们很多的设计其实是受到3.3节所描述的真实业务场景启发，我们在设计中也遵从了一系列的核心原则。这些原则我们认为是这个模型必须要遵循的。</p>
<ul>
<li>永远不要依赖任何的数据完整性标记（译者注：如水位标记）</li>
<li>灵活性，要能覆盖已知的多样化的使用用例，并且覆盖将来可能的使用用例</li>
<li>对于每个预期中的执行引擎，（模型抽象）不但要正确合理，而且要有额外的附加价值</li>
<li>鼓励实现的透明性</li>
<li>支持对数据在它们产生的上下文中进行健壮的分析。<br>可以这么说，下述的使用案例决定了模型的具体功能，而这些设计原则决定了模型整体的特征和框架。我们认为这两者是我们设计的模型具有完全性，普遍性的根本原因。</li>
</ul>
<h2 id="3-3-业务场景"><a href="#3-3-业务场景" class="headerlink" title="3.3 业务场景"></a>3.3 业务场景</h2><p>在我们设计Dataflow模型的过程中，我们考虑了FlumeJava和MillWheel系统在这些年遇到的各种真实场景。那些良好工作的设计，我们保留到了模型中，而那些工作不那么良好的设计激励我们采用新的方法重新设计。下面我们简单介绍一些影响过我们设计的场景。</p>
<h3 id="3-3-1-大规模数据回写和Lambda架构；统一模型"><a href="#3-3-1-大规模数据回写和Lambda架构；统一模型" class="headerlink" title="3.3.1 大规模数据回写和Lambda架构；统一模型"></a>3.3.1 大规模数据回写和Lambda架构；统一模型</h3><p>有一些团队在MillWheel上跑日志链接作业。这其中有一个特别大的日志链接处理作业在MillWheel上按流模式运行，而另外一个单独的FlumeJava批处理作业用来对流处理作业的结果进行大规模的回写。一个更好的设计是使用一个统一的模型，对数据处理逻辑只实现一次，但是能够在流处理引擎和批处理引擎不经修改而同时运行。这是第一个激发我们思考去针对批处理，微批次处理和流处理建立一个统一模型的业务场景。这也是图10-12所展示的。</p>
<p>另外一个激发我们设计统一模型的场景是Lambda架构的使用。尽管谷歌大多数数据处理的场景是由批处理系统和流处理系统分别单独承担的，不过有一个MillWheel的内部客户在弱一致性的模式下运行他们的流处理作业，用一个夜间的MR作业来生产正确的结果。他们发现他们的客户不信任弱一致性的实时结果，被迫重新实现了一个系统来支持强一致性，这样他们就能提供可靠的，低延时的数据处理结果。这个场景进一步激励我们能支持灵活地选择不同的执行引擎。</p>
<h3 id="3-3-2-非对齐窗口：会话"><a href="#3-3-2-非对齐窗口：会话" class="headerlink" title="3.3.2 非对齐窗口：会话"></a>3.3.2 非对齐窗口：会话</h3><p>从一开始我们就知道我们需要支持会话；事实上这是我们窗口模型对现有模型而言一个重大的贡献。会话对谷歌来说是一个非常重要的使用场景（也是MillWheel创建的原因之一）。会话窗口在一系列的产品域中都有应用，如搜索，广告，分析，社交和YouTube。基本上任何关心把用户的分散活动记录进行相互关联分析都需要通过会话来进行处理。因此，支持会话成为我们设计中的最重要考虑。如图14所示，支持会话在Dataflow中是非常简单的。</p>
<h3 id="3-3-3-支付：触发器，累加和撤回"><a href="#3-3-3-支付：触发器，累加和撤回" class="headerlink" title="3.3.3 支付：触发器，累加和撤回"></a>3.3.3 支付：触发器，累加和撤回</h3><p>有两个在MillWheel上跑支付作业的团队遇到的问题对模型的一部分也有启发作用。当时我们的设计实践是使用水位线作为数据完全到达的指标。然后写额外的逻辑代码来处理迟到的数据或者更改源头数据。由于缺乏一个支持更新和撤回的系统，负责资源利用率方案的团队最终放弃了我们的平台，构建了自己独立的解决方案（他们最后使用的模型和我们同时设计开发的模型事实上非常类似）。另一个支付团队的数据源头有少部分缓慢到达的数据，造成了水位线延迟，这给他们带来了大问题。这些系统上的缺陷成为我们对现有系统需要进行改良设计的重要动因，并且把我们的考虑点从保证数据的完整性转移到了对迟到数据的可适应性。对于这个场景的思考总结带来了两个方面：一个方面是能够精确，灵活地确定何时将窗口内容物化的触发器（如7-14所示），对同样的输入数据集也可以使用多种多样地结果输出模式进行处理。另外一方面是通过累积和撤回能够支持增量处理。（图14）</p>
<h3 id="3-3-4-统计计算：水位线触发器"><a href="#3-3-4-统计计算：水位线触发器" class="headerlink" title="3.3.4 统计计算：水位线触发器"></a>3.3.4 统计计算：水位线触发器</h3><p>很多MillWheel作业用来进行汇总统计（如平均延迟）。对这些作业来说，100%的准确性不是必须的，但是在合理的时间范围内得到一个接近完整的统计是必须的。考虑到对于结构化的输入（如日志文件），使用水位线就能达到很高程度的准确度。这些客户发现使用单次的的基于水位线的触发器就可以获得高度准确的统计。水位线触发器如图12所示。</p>
<p>我们有一些滥用检测的作业运行在MillWheel中。滥用检测是另外一种快速处理大部分数据比缓慢处理掉所有数据要远远更有价值的场景。因此，他们会大量地使用水位线百分位触发器。这个场景促使我们在模型中加入了对水位线百分位触发器的支持。</p>
<p>与此相关的，批处理作业中的一个痛点是部分处理节点的缓慢进度会成为执行时间中的长尾，拖慢整个进度。除了可以通过动态平衡作业来缓解这个问题，FlumeJava也支持基于整体完成百分度来选择是否终止长尾节点。用统一模型来描述批处理中遇到的这个场景的时候，水位线百分位触发器可以很自然地进行表达，不需要在引入额外的定制功能、定制接口。</p>
<h3 id="3-3-5-推荐：处理时间触发器"><a href="#3-3-5-推荐：处理时间触发器" class="headerlink" title="3.3.5 推荐：处理时间触发器"></a>3.3.5 推荐：处理时间触发器</h3><p>另外一种我们考虑过的场景是从大量的谷歌数据资产中构建用户活动树（本质上是会话树）。这些树用来根据用户的兴趣来做推荐。在这些作业中我们使用处理时间作为触发器。这是因为，对于用户推荐来说，周期性更新的，即便是基于不完备数据的用户活动树比起持续等待水位线越过会话窗口边界（即会话结束）获得完全的数据要有意义的多。这也意味着由于部分少量数据引起的水位线进展延迟不影响基于其他已经到达的数据进行计算并获得有效的用户活动树。考虑到这种场景，我们包含了基于处理时间的触发器（如图7和图8所示）</p>
<h3 id="3-3-6-异常探测：数据驱动和组合触发器"><a href="#3-3-6-异常探测：数据驱动和组合触发器" class="headerlink" title="3.3.6 异常探测：数据驱动和组合触发器"></a>3.3.6 异常探测：数据驱动和组合触发器</h3><p>在MillWheel的论文中，我们描述了一种用来检测谷歌网站搜索查询趋势的微分异常探测数据处理管道。当我们为模型设计触发器的时候，这种微分异常探测系统启发我们设计了数据驱动触发器。这种微分探测器检测网站检索流，通过统计学估计来计算搜索查询请求量是否存在一个毛刺。如果系统认为一个毛刺即将产生，系统将发出一个启动型号。当他们认为毛刺已经消除，那么他们会发出一个停止信号（译者注：可能会对接系统自动对系统扩容或缩容）。尽管我们可以采用别的方式来触发计算，比如说Trill的标点符(Punctuations)，但是对于异常探测你可能希望一旦系统确认有异常即将发生，系统应该立即输出这个判断。标点符的使用事实上把流处理系统转换成了微批次处理系统，引入了额外的延迟。在调查过一些用户场景后，我们认为标点符不完全适合我们。因此我们在模型中引入了可定制化数据驱动触发器。同时这个场景也驱使我们支持触发器组合，因为在现实场景中，一个系统可能在处理多种微分计算，需要根据定义的一组逻辑来支持多种多样的输出。图9中的AtCount触发器是数据驱动触发器的例子，而图10-14使用了组合触发器。</p>
]]></content>
      <categories>
        <category>BigData</category>
        <category>流计算</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>DataFlow</tag>
        <tag>Stream Process</tag>
      </tags>
  </entry>
  <entry>
    <title>《F1 Query -- Declarative Querying at Scale》</title>
    <url>/2018/f1/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>论文是很早以前看的， 后来把笔记梳理一下。<br>F1 就是一套胶水系统， 将oltp和olap 系统粘在一起提供一个统一接口层和服务层， 类似数据库里面的HTAP系统， 但数据库htap系统往往是自身提供oltp和olap 服务， 而f1 是通过不同的系统来达到htap的效果。<br>F1 有一个背景就是现有很多数据库系统，如spanner， bigquery， dremel， 如果让应用无缝的在这么多系统中切换，一套接口，一套服务完成所有的事情。<br>今天的 TiDB 有一点点f1 的味道， 上层tidb server + tikv， tispark +  tiflash，不过tidb 朝着tidb server + tikv&#x2F;tiflash的方向演进， 融合程度更高一些， 不过f1 在oltp 上主要是依赖spanner 来完成。<br>曾经的hybriddb 更类似f1 这种架构。 </p>
<p>坦白讲： 这种胶水系统没有什么前途， 对于oltp 业务， 对时延是非常敏感， 增加一层胶水系统， 不仅让时延增长很多，而且带来不确定性， 动不动抖动一下， 这些对oltp都是无法接受的， 因此粘合的场景是大数据的和olap的业务， 对于中小型企业， 大数据的系统太复杂， 一个olap 就够用，看看aws 上redshift 大行其道，就知道这个事实， 如果粘合多个olap，那就更不现实， 哪家公司没事干运行一大堆各式各样的olap系统， olap系统基本上就是赢者通吃， 没有那么多一个业务要跑好几个olap系统的， 所以这种胶水系统是没有什么前途的。 最后，google自己的员工透露到现在为止f1 已经事实上失败了。 </p>
<p>架构图：<br><img data-src="/assets/f1_arc.png" alt="f1_arc"></p>
<span id="more"></span>

<h2 id="需求"><a href="#需求" class="headerlink" title="需求"></a>需求</h2><ol>
<li>存储计算分离， 从架构上就可以看出计算层和存储层已经分离</li>
<li>可以支持跨机房部署， 不过跨机房部署，很多时候是依赖底层的存储系统来完成， 比如spanner 本身就可以支持跨机房</li>
<li>同时支持 oltp 尤其是点查， olap， 以及大型的etl请求</li>
<li>可以很容易提高并发度来支持大数据量的计算。 </li>
<li>支持UDF&#x2F;UDAF&#x2F;TVF</li>
</ol>
<h2 id="模块介绍"><a href="#模块介绍" class="headerlink" title="模块介绍"></a>模块介绍</h2><ul>
<li>F1 master,  对worker&#x2F;节点 进行监控， 对查询进行监控</li>
<li>F1 Server<ul>
<li>对于oltp 查询（点查）， 负责查询的执行， 个人理解， 做一个转义层，转成底层spanner的请求</li>
<li>对于olap的请求， 其实就是类似前端节点功能， 负责一些sql 解析，生成执行计划，查询catalog之类的工作</li>
</ul>
</li>
<li>F1 worker: 就是计算节点， 类似mpp数据库的worker节点</li>
<li>F1 server&#x2F;worker 是无状态的，不存数据， master节点会进行实时监控， 并且做failover 和扩容和缩容</li>
<li>catakig service ：  各种异构的数据的元数据存放在这里， 对用户展示一个统一视图</li>
<li>batch metadata： batch execution 模式下，任务的元信息，如执行计划</li>
<li>udf server， 一个比较有意思的模块， <ul>
<li>在执行引擎以外，专门存储udf， 执行引擎和udf server 进行rpc 进行交互</li>
<li>可以对执行引擎做一些保护， 资源隔离之类的事情</li>
</ul>
</li>
<li>存储系统：<ul>
<li>可以是spanner， 这些主要是针对oltp的</li>
<li>分布式 file system （colossus）， file system</li>
<li>其他的data source</li>
</ul>
</li>
</ul>
<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><ul>
<li>SQL : 兼容sql 2011， 共用在dremel， bigquery， spanner， 可以多个应用迁移</li>
<li>数据写入<ul>
<li>默认是分布式文件系统</li>
<li>可以export 到指定存储</li>
<li>支持session 级别临时表</li>
</ul>
</li>
<li>执行模式<ul>
<li>central execution： 小查询， 单线程执行， 直接在server 就干了</li>
<li>batch execution： 超大查询， 生成mapreduce 任务&#x2F;flumejava sql 任务，放到后台大数据平台进行计算<ul>
<li>执行非常类似spark方式， 一个stage 一个stage 执行，前一个stage 落盘， 当stage 挂了可以只重启单stage</li>
</ul>
</li>
<li>distributed execution： 普通olap 执行， 分布式执行， server 起到前端功能， 执行在worker 节点进行执行</li>
</ul>
</li>
</ul>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>磁盘性能测试</title>
    <url>/2020/fileio/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>心血来潮，想测试一下阿里云的essd 和阿里云的本地ssd 性能， 不巧的是阿里云ecs 的存储， 有几种类型， essd， ssd 云盘， 高效云盘 和本地盘nvme 盘<br>最终测试下来确实nvme 盘的性能最好。</p>
<p>测试工具： 本文用sysbench 进行测试， 以前读书的时候使用过iometer 进行测试， sysbench 测试参数更多， 对iops 的测试效果更丰富， iometer 偏重吞吐量的测试。 </p>
<span id="more"></span>


<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>参考之前的博文， 学会如何安装sysbench</p>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>测试脚本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">SYSBENCH_FILE_TOTAL_SIZE=16G</span><br><span class="line">SYSBENCH_FILE_NUM=16</span><br><span class="line">SYSBENCH_NUM_THREADS=16</span><br><span class="line">FSYNC=off</span><br><span class="line">SYSBENCH_BLOCK_SIZE=4096</span><br><span class="line">SYSBENCH_TIME=60</span><br><span class="line"></span><br><span class="line">#  --file-num=N                  number of files to create [128]</span><br><span class="line">#  --file-block-size=N           block size to use in all IO operations [16384]</span><br><span class="line">#  --file-total-size=SIZE        total size of files to create [2G]</span><br><span class="line">#  --file-test-mode=STRING       test mode &#123;seqwr, seqrewr, seqrd, rndrd, rndwr, rndrw&#125;</span><br><span class="line">#  --file-io-mode=STRING         file operations mode &#123;sync,async,mmap&#125; [sync]</span><br><span class="line">#  --file-extra-flags=[LIST,...] list of additional flags to use to open files &#123;sync,dsync,direct&#125; []</span><br><span class="line">#  --file-fsync-freq=N           do fsync() after this number of requests (0 - don&#x27;t use fsync()) [100]</span><br><span class="line">#  --file-fsync-all[=on|off]     do fsync() after each write operation [off]</span><br><span class="line">#  --file-fsync-end[=on|off]     do fsync() at the end of test [on]</span><br><span class="line">#  --file-fsync-mode=STRING      which method to use for synchronization &#123;fsync, fdatasync&#125; [fsync]</span><br><span class="line">#  --file-merged-requests=N      merge at most this number of IO requests if possible (0 - don&#x27;t merge) [0]</span><br><span class="line">#  --file-rw-ratio=N             reads/writes ratio for combined test [1.5]</span><br><span class="line"></span><br><span class="line">testmodes=(</span><br><span class="line">    &quot;seqwr&quot; </span><br><span class="line">    &quot;seqrewr&quot; </span><br><span class="line">    &quot;seqrd&quot;</span><br><span class="line">    &quot;rndrd&quot;</span><br><span class="line">    &quot;rndwr&quot; </span><br><span class="line">    &quot;rndrw&quot;</span><br><span class="line">    )</span><br><span class="line">for testmode in &quot;$&#123;testmodes[@]&#125;&quot;</span><br><span class="line">do</span><br><span class="line">    directios=(</span><br><span class="line">    &quot;&quot;</span><br><span class="line">    &quot;sync&quot;</span><br><span class="line">    &quot;direct&quot;</span><br><span class="line">    &quot;dsync&quot;</span><br><span class="line">    )</span><br><span class="line">    for directio in &quot;$&#123;directios[@]&#125;&quot;</span><br><span class="line">    do</span><br><span class="line">        date</span><br><span class="line">        echo 1 &gt; /proc/sys/vm/drop_caches</span><br><span class="line">        echo &quot;begin to run $testmode   $directio&quot;</span><br><span class="line">        sysbench fileio  --file-num=$SYSBENCH_FILE_NUM --file-block-size=$SYSBENCH_BLOCK_SIZE --file-total-size=$SYSBENCH_FILE_TOTAL_SIZE --file-test-mode=$testmode --file-io-mode=sync --file-extra-flags=$directio --file-fsync-all=$FSYNC --file-fsync-mode=fsync --file-fsync-freq=0 --file-merged-requests=0 --threads=$SYSBENCH_NUM_THREADS prepare</span><br><span class="line">        sysbench fileio --file-num=$SYSBENCH_FILE_NUM --file-block-size=$SYSBENCH_BLOCK_SIZE --file-total-size=$SYSBENCH_FILE_TOTAL_SIZE --file-test-mode=$testmode --file-io-mode=sync --file-extra-flags=$directio --file-fsync-all=$FSYNC --file-fsync-mode=fsync --file-fsync-freq=0 --file-merged-requests=0  --report-interval=10  --threads=$SYSBENCH_NUM_THREADS --time=$SYSBENCH_TIME run</span><br><span class="line">        sysbench fileio  --file-num=$SYSBENCH_FILE_NUM --file-block-size=$SYSBENCH_BLOCK_SIZE --file-total-size=$SYSBENCH_FILE_TOTAL_SIZE --file-test-mode=$testmode --file-io-mode=sync --file-extra-flags=$directio --file-fsync-all=$FSYNC --file-fsync-mode=fsync --file-fsync-freq=0 --file-merged-requests=0   cleanup</span><br><span class="line">        date</span><br><span class="line">        esynccho &quot;Finish one loop test&quot;</span><br><span class="line">    done</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">rm -rf test_file.*</span><br><span class="line"></span><br><span class="line">echo &quot;Finish all test&quot;</span><br></pre></td></tr></table></figure>

]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>《OceanBase开发者手册》之五 如何debug OceanBase</title>
    <url>/2021/debug_ob/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>《OceanBase开发者手册》 主要指导开发者如何参与到OceanBase 的研发, 铺平参与OceanBase 开发的准备工作遇到的问题, 当前章节大概这几篇文章, 未来可能会增加部分文章, 目前OceanBase 源码参考OceanBase 开源官网的<a href="https://open.oceanbase.com/articles/8600129">《开源数据库OceanBase源码解读》 系列</a> :</p>
<ol>
<li>如何编译OceanBase源码</li>
<li>如何设置IDE开发环境</li>
<li>如何成为OceanBase Contributor</li>
<li>如何修改OceanBase文档</li>
<li>如何debug OceanBase</li>
<li>如何运行测试</li>
<li>如何修bug<br>​</li>
</ol>
<p>本文将介绍如何debug OceanBase, 如何debug OceanBase, 推荐几种方式:</p>
<ol>
<li>使用vscode 远程debug OceanBase</li>
<li>使用gdb 本地debug OceanBase</li>
<li>在linux 环境下, 使用CLion 本地debug OceanBase</li>
</ol>
<span id="more"></span>
<p>​</p>
<h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2><p>debug OceanBase 有一个重要的步骤, 就是弄到oceanbase 的启动参数, 每台机器有每台机器的硬件配置, 也会导致启动参数是不一样的. 但做法基本类似. </p>
<ol>
<li>用OBD (<a href="https://github.com/oceanbase/obdeploy">https://github.com/oceanbase/obdeploy</a>) 安装部署一套环境 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. 单机部署并且是联网环境, 请参考文档https://open.oceanbase.com/quickStart</span><br><span class="line">2. 分布式环境或者离线部署, 请参考文档 https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.1/deploy-the-distributed-oceanbase-cluster</span><br></pre></td></tr></table></figure></li>
<li>成功部署环境后, 编译debug 版本OceanBase 参考之前文档 《如何编译OceanBase源码》</li>
<li>捕获oceanbase 的启动参数 (通过‘ps -ef|grep observer’).</li>
<li>(可选)在分布式环境下, 用编译好的binary observer 去替换 用obd 安装部署的observer</li>
</ol>
<p>我在我的单机测试环境下, 我用OBD安装部署OceanBase后, 我的OceanBase的启动参数是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">observer -r xxx.xxx.xxx.xxx:2882:2881 -o __min_full_resource_pool_memory=268435456,enable_syslog_recycle=True,enable_syslog_wf=True,max_syslog_file_count=4,memory_limit=69G,system_memory=27G,cpu_count=19,datafile_size=1029G,clog_disk_utilization_threshold=95,clog_disk_usage_limit_percentage=98 -z zone1 -p 2881 -P 2882 -n obcluster -c 1 -d /home/xxxxxxx/observer/store -i em1 -l INFO</span><br></pre></td></tr></table></figure>


<h2 id="vscode-调试"><a href="#vscode-调试" class="headerlink" title="vscode 调试"></a>vscode 调试</h2><ol>
<li><p>搭建remote 链接环境</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1.1 建立开发机到测试机的信任登录, 参考 文档 https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.1/optional-set-password-free-ssh-logon</span><br><span class="line">1.2 搭建vscode 的remote debug 环境  “Remote-SSH: Connect to Host...”, 参考文章 https://blog.csdn.net/zbbzb/article/details/102957076/ 进行配置</span><br></pre></td></tr></table></figure>
</li>
<li><p>remote ssh 连接远程机器 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Ctril + p</span><br><span class="line">选择Remote-SSH:Connect to Host</span><br></pre></td></tr></table></figure>
</li>
<li><p>打开对应的源码目录</p>
</li>
<li><p>参考之前文章 介绍 《如何编译OceanBase源码》</p>
</li>
<li><p>设置debug 启动参数, 在菜单栏  “Run” –&gt; “Add Configuration”, 如果之前已经设置过, 修改启动参数就是 菜单栏 “Run” –&gt; “Open Configurations”</p>
</li>
</ol>
<p>我的 配置是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    // Use IntelliSense to learn about possible attributes.</span><br><span class="line">    // Hover to view descriptions of existing attributes.</span><br><span class="line">    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387</span><br><span class="line">    &quot;version&quot;: &quot;0.2.0&quot;,</span><br><span class="line">    &quot;configurations&quot;: [</span><br><span class="line">    </span><br><span class="line">        &#123;</span><br><span class="line">            &quot;name&quot;: &quot;observer&quot;,</span><br><span class="line">            &quot;type&quot;: &quot;cppdbg&quot;,</span><br><span class="line">            &quot;request&quot;: &quot;launch&quot;,</span><br><span class="line">            &quot;program&quot;: &quot;$&#123;OB_SRC_DIR&#125;/build_debug/src/observer/observer&quot;,</span><br><span class="line">            &quot;args&quot;: [&quot;-r&quot;, &quot;$&#123;IP&#125;:2882:2881&quot;, &quot;-o&quot;, &quot;__min_full_resource_pool_memory=268435456,enable_syslog_recycle=True,enable_syslog_wf=True,max_syslog_file_count=4,memory_limit=69G,system_memory=27G,cpu_count=19,datafile_size=1029G,clog_disk_utilization_threshold=95,clog_disk_usage_limit_percentage=98&quot;, &quot;-z&quot;, &quot;zone1&quot;, &quot;-p&quot;, &quot;2881&quot;, &quot;-P&quot;, &quot;2882&quot;, &quot;-n&quot;, &quot;obcluster&quot;, &quot;-c&quot;, 1, &quot;-d&quot;, &quot;/home/XXX/observer/store&quot;, &quot;-i&quot;, &quot;em1&quot;, &quot;-l&quot;, &quot;INFO&quot;],</span><br><span class="line">            &quot;stopAtEntry&quot;: true,</span><br><span class="line">            &quot;cwd&quot;: &quot;$&#123;OB_SRC_DIR&#125;&quot;,</span><br><span class="line">            &quot;environment&quot;: [],</span><br><span class="line">            &quot;externalConsole&quot;: false,</span><br><span class="line">            &quot;MIMode&quot;: &quot;gdb&quot;,</span><br><span class="line">            &quot;setupCommands&quot;: [</span><br><span class="line">                &#123;</span><br><span class="line">                    &quot;description&quot;: &quot;Enable pretty-printing for gdb&quot;,</span><br><span class="line">                    &quot;text&quot;: &quot;-enable-pretty-printing&quot;,</span><br><span class="line">                    &quot;ignoreFailures&quot;: true</span><br><span class="line">                &#125;</span><br><span class="line">            ]</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>备注: 这个里面有arg的参数来自于第一步的准备工作中获取的启动参数, 每台机器有每台机器的配置, 笔者的参数如下, 其中:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. $&#123;OB_SRC_DIR&#125; 为源码目录, $&#123;IP&#125; 为observer 的绑定ip</span><br><span class="line">2. 需要设置“cwd”, 为$&#123;OB_SRC_DIR&#125;</span><br><span class="line">3. 建议设置“stopAtEntry” 为true</span><br><span class="line">4. 在args 参数中, 其中 -d 设置的目录 &quot;/home/xxxxx/observer/store&quot;, 需要设置为真实的参数</span><br><span class="line">5. 在args 参数中, 其中-i 设置的设备名称 &quot;em1&quot;, 为ip 对应的设备名称</span><br></pre></td></tr></table></figure>

<ol start="6">
<li>开始debug, 点击菜单 “Run” –&gt; “Start Debugging”.</li>
</ol>
<h2 id="直接用gdb-本地调试"><a href="#直接用gdb-本地调试" class="headerlink" title="直接用gdb 本地调试"></a>直接用gdb 本地调试</h2><ol>
<li><p>登录remote 机器, 并进入${OB_SRC_DIR} 源码目录</p>
</li>
<li><p>参考之前文章 介绍 《如何编译OceanBase源码》</p>
</li>
<li><p>修改 用户目录下的.gdbinit, 添加下面一行, 其中${OB_SRC_DIR}需要换成OB 源码根目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">add-auto-load-safe-path $&#123;OB_SRC_DIR&#125;/.gdbinit</span><br></pre></td></tr></table></figure>
</li>
<li><p>vi ${OB_SRC_DIR}&#x2F;.gdbinit</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">file build_debug/src/observer/observer</span><br><span class="line">set args &quot;-r&quot;, &quot;XXX.XXX.XXX.XXX:2882:2881&quot;, &quot;-o&quot;, &quot;__min_full_resource_pool_memory=268435456,enable_syslog_recycle=True,enable_syslog_wf=True,max_syslog_file_count=4,memory_limit=69G,system_memory=27G,cpu_count=19,datafile_size=1029G,clog_disk_utilization_threshold=95,clog_disk_usage_limit_percentage=98&quot;, &quot;-z&quot;, &quot;zone1&quot;, &quot;-p&quot;, &quot;2881&quot;, &quot;-P&quot;, &quot;2882&quot;, &quot;-n&quot;, &quot;obcluster&quot;, &quot;-c&quot;, 1, &quot;-d&quot;, &quot;/home/longda/observer/store&quot;, &quot;-i&quot;, &quot;em1&quot;, &quot;-l&quot;, &quot;INFO&quot;</span><br><span class="line">b main</span><br><span class="line">r</span><br></pre></td></tr></table></figure></li>
</ol>
<p>备注: 这个里面有args的参数来自于第一步的准备工作中获取的启动参数, 每台机器有每台机器的配置, 笔者的参数如下, 其中:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1. $&#123;OB_SRC_DIR&#125; 为源码目录, $&#123;IP&#125; 为observer 的绑定ip</span><br><span class="line">2. 需要设置“cwd”, 为$&#123;OB_SRC_DIR&#125;</span><br><span class="line">3. 当前的工作目录必须是$&#123;OB_SRC_DIR&#125;</span><br><span class="line">4. 在args 参数中, 其中 -d 设置的目录 &quot;/home/xxxxx/observer/store&quot;, 需要设置为真实的参数</span><br><span class="line">5. 在args 参数中, 其中-i 设置的设备名称 &quot;em1&quot;, 为ip 对应的设备名称</span><br></pre></td></tr></table></figure>

<ol start="5">
<li>推荐使用tui<br>tui是gdb自带的图形界面，比较直观，这里简单说一下切换方法和常用命令<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1、gdb -tui + (可执行程序)  直接进入tui图形界面</span><br><span class="line"></span><br><span class="line">2、gdb进入后，使用命令focus进入tui图形界面，或者使用快捷键：Ctl+x+a (注意按键顺序，记忆：x：focus，a：another)</span><br><span class="line"></span><br><span class="line">3、在tui中使用相同的快捷键Ctl+x+a返回到gdb原生界面</span><br><span class="line"></span><br><span class="line">4、在gdb中↑和↓切换上一个命令和下一个命令，但是在tui中只是控制代码视图。想达到切换命令的目的，使用Ctl+n （记忆：next）和Ctl+p（记忆：previous），这其实就是gdb的原生快捷键</span><br></pre></td></tr></table></figure></li>
<li>在源码目录下, 敲入gdb 即可启动gdb debug</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gdb </span><br></pre></td></tr></table></figure>


<h2 id="clion-本地调试"><a href="#clion-本地调试" class="headerlink" title="clion 本地调试"></a>clion 本地调试</h2><p>clion 看源码非常方便， symbol 跳转非常友好， 而且天然code format 支持clang-format。 不过， 我没有试过clion 远程debug， 只试过本地clion debug， 不过如果想用clion 本地debug oceanbase， 则开发机器得运行linux。<br>clion 是debug 中最舒服的方式， 但也是最复杂的方式， 要求也非常高</p>
<ol>
<li>参考之前文章 介绍 《如何编译OceanBase源码》</li>
<li>配置 clion的cmake<img data-src="/img/ob/clion_debug1.png" ></li>
</ol>
<p>详情步骤参考图片所示， 需要说明的是， </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;Build Directory&quot; 需要设置为“build_debug”</span><br><span class="line">&quot;CMake options&quot; 需要设置为“$&#123;OB_SRC_DIR&#125; -DCMAKE_BUILD_TYPE=Debug”, 其中$&#123;OB_SRC_DIR&#125; 需要修改为真实的目录全路径</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>等待几分钟生成cmake 生成结束后， 点击菜单“Run” –》 “Edit configurations”, 也可以类似下面图片， 进行选择编译目标observer</li>
</ol>
<img data-src="/img/ob/clion_debug2.JPG" >

<ol start="4">
<li><p>点击菜单“Build” –》 “Build observer”， 编译observer</p>
</li>
<li><p>修改启动参数， 点击菜单“Run” –》 “Edit configurations”， 出现界面后</p>
</li>
</ol>
<img data-src="/img/ob/clion_debug3.JPG" >

<p>在我的机器上”Program Arguements” 为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-r $&#123;ip&#125;:2882:2881 -o __min_full_resource_pool_memory=268435456,enable_syslog_recycle=True,enable_syslog_wf=True,    max_syslog_file_count=4,memory_limit=8G,system_memory=4G,cpu_count=16,datafile_size=44G,clog_disk_utilization_threshold=95,clog_disk_usage_limit_percentage=98 -z zone1 -p 2881 -P 2882 -n obcluster -c 1 -d $&#123;data_dir&#125; -i $&#123;devname&#125; -l INFO</span><br></pre></td></tr></table></figure>
<p>${ip} : 为本机ip</p>
<p>${data_dir}: 为数据目录</p>
<p>${devname}： 为ip 所对应的网卡名称， 通常为eth0 或lo</p>
<p>在“Woring Directory”必须为${OB_SRC_DIR}</p>
<ol start="6">
<li><p>打开文件src&#x2F;observer&#x2F;main.cpp, 在main 函数下断点</p>
</li>
<li><p>启动debug， 点击菜单”Run” –&gt; “Debug Observer”</p>
</li>
</ol>
]]></content>
      <categories>
        <category>OceanBase</category>
      </categories>
      <tags>
        <tag>OceanBase</tag>
      </tags>
  </entry>
  <entry>
    <title>HashCorp Reading Notes</title>
    <url>/2022/hashcorp-read-notes/</url>
    <content><![CDATA[<h1 id="随谈"><a href="#随谈" class="headerlink" title="随谈"></a>随谈</h1><p>万字 大文章 <a href="https://mp.weixin.qq.com/s/Y2A7-Ui2nzUgodkEbgR6lQ">https://mp.weixin.qq.com/s/Y2A7-Ui2nzUgodkEbgR6lQ</a></p>
<p>有很多理念,还是比较认同的:</p>
<span id="more"></span>

<ol>
<li>技术挑战 放到 开源里面做,  这一点不是很认同, 我认为, 开源解决的是规模小的需求, 或者某个特定的的非常common的问题, 而当规模上来后, 是需要商业化来解决, 或者当需求变得复杂, 需要一系列的措施来解决, 是需要商业化的技术方案来解决. </li>
<li>个人或者小的团队, 就应该免费使用, 这个逻辑基本成立. 跨团队协作的需求, 商业化机会比较大</li>
<li>要把价格门槛低的核心产品做的简单易用，同时又要兼顾未来组织内部对产品的复杂需求。 – 这个很认同</li>
<li>即使某些功能在开源中有，但是这些功能无法从一个完整的use case level来解决企业面对的问题。  真实操作中, 会将这个放大. </li>
<li>讨论放到一个具体的use case,而不是某一个功能，这样对于sales也会更好沟通</li>
<li>开源公司要拿到一些客户订单并不难。但是这里说到市场和销售，核心是repeatable&#x2F;scalable。</li>
<li>利用开源形成事实标准，是企业最牢固的隐形护城河。</li>
<li>开源模式下，sales最大的挑战就是公司自己的开源产品。</li>
<li>开源模式的S&amp;M (Sales &amp; Marketing)花费应该比传统软件公司要少呀。但是Hashicorp S&amp;M&#x2F;Rev 比例超过60%，在整个public SaaS公司中，算是比较高的了. 时代在变, 有很多开源运作的成本, 处于技术和品牌交叉的, 这块如果放在marketing, 自然markteing的成本会大幅上升, 而且这个会成为趋势. </li>
<li>开源天生就是global的生意。– Hashicorp和Confluent的国际业务发展都很快。两家商业化都是5年左右的时间，都已经有35%的收入来自美国以外。</li>
<li>渠道玩得溜溜的 – Hashicorp在开始商业化以后第二年就开始大力发展partners, 三四年的时间，已经建立起来一个170+ ISVs，超过450个integration partner的网络</li>
<li>面对大客户，只是交给对方工具远远不够。 – 最先进的enterprise software公司，输出的不仅是工具，更是工具背后的方法论(当然，输出方法论的成本也是不低的)。  – 于这样一个大工程，你不能光是提供一系列工具，还要向他们展示the way to get there.  – 工具类产品比拼的往往不是单纯的性能，而是工具背后的代表新的生产方式的方法论。把best practice抽象成方法论，难度可不比工程上的性能提升要小。一旦让这个方法论成为事实标准，才是真正的护城河。</li>
<li>护城河绝不是单纯把产品做成大而全的平台，把一堆60-70分的产品盲目堆砌起来。</li>
<li>Hashicorp的S-1中，把这个模式进一步细化为adopt, land, expand, and extend。其实本质也是PLG里的套路：</li>
</ol>
<ul>
<li>用社区&#x2F;marketing促进Adopt</li>
<li>用简单易上手的产品+初始低价降低初始Landing的门槛</li>
<li>基于Usage实现自然增长Expand</li>
<li>最后用product portfolio在每个cohort中Extend</li>
</ul>
<ol start="15">
<li>在SaaS land&amp;expand这个模式中，不可缺少的一环就是usage-based pricing。– 看看现在HCP上几个产品的pricing,你也许会发现一个问题，就是这个pricing unit的设计其实很有讲究。– 你设定的pricing unit除了要计算方便之外，必须避免Usage is discouraged when customers feel the marginal cost of consumption</li>
<li>etl 公司, Airbyte（<a href="https://github.com/airbytehq/airbyte%EF%BC%89">https://github.com/airbytehq/airbyte）</a>,  – 刚刚close了B轮融资$150M, 估值已经飙升到$1.5Bn！不到20个月，已经刷刷刷地三轮融了$181M</li>
<li>在SaaS模式已经被广泛接受的年代，后来者迅速开发Cloud版本抢占“基层”市场，几乎是个定式，只会到来得越来越快。</li>
<li>Win developer’s mind and heart! hashcorp – 他们旗下的repo加起来超过220k stars </li>
<li>几乎没有哪个成功的开源社区，早期的时候没有在线下做大量后来看起来完全不scalable的事情。  纯粹误解: Github一上线，HN、Reddit各种线上宣传一下，回答问题和PR，然后做好技术和performance，社区啊用户啊就应该自己围过来了么？</li>
<li>首先，Meetup不可少，抓住各种community抱大腿。– 一开始靠身边的亲朋好友宣传，速度当然很慢。后来，两位创始人很积极到各种Seattle当地的社区meetup、Ruby社区、QCon,DevOpsDay等等，在各种活动上寻找刷脸的机会</li>
<li>Hashicorp就开始全方位建立自己的社区，其中最重要的就是HUG - Hashicorp User Groups. 这个分散在世界各地的自发性组织，如今已经有37k+的会员，遍及53个国家。各种自发的Meetup和活动，不断深化与开发者的关系</li>
<li>Hashicorp对于Conference的投入格外重视。</li>
<li>特别重要的是，主动出击，在一线跟早期用户深度交流。</li>
<li>你要能叫出你的项目前100个用户的名字！</li>
<li>社区不是最终目的。M小姐认为，终极目标，还是成为行业的事实标准. – 要实现这一点，产品设计、社区搭建，以及商业伙伴的合作，是不可割裂的整体。</li>
<li>从产品设计上来说：不要憋大招，第一个产品只要能prove idea就可以。</li>
<li>简单对比了几个比较顶尖的开源项目Star数和Contributor的比例，很有意思的发现是，这个比例惊人的相似，几乎都在0.03！</li>
<li>有些开源公司将社群运营看成了一个纯粹marketing的“用户社区”，忽视了开源这个复杂生态中，每个stakeholder的重要性。– 要能在商业有起色之前，有如此热血的坚持，真爱是必要条件。</li>
<li>产品设计的一套方法论, 首先，永远被摆在第一位的，Built for workflow, not technologies. – 他们将workflow拆解成三个部分：People, process, tools. – 设计一个workflow产品&#x2F;工具的时候，很多人只是看着工具本身的功能，而没有想到，这里面对人的技能的要求是怎样的，对IT流程的假设是self-service还是工单系统，这些随着环境和具体技术的变化，有什么可以抽象出来保持一致的？</li>
<li>尊重技术，但是更要重视human element. 就像前面说的Cloud Operation Model.他们发现你不能直接把最终的牛逼哄哄的最佳实践给客户，向客户展现your way to get there，就要接受在这个过程中一些不那么完美的方案。</li>
<li>跟很多开源公司很像，Hashicorp也遵循transparent operation的理念，将公司的很多管理细则、决策原则等等，都公开在网上. 这个挺难的, 刚开始还比较容易, 当商业化逐渐深入, 很多事情反而扑朔迷离. </li>
<li>两家公司都非常非常强调writing以及Over communication! 这个不错.</li>
</ol>
<img data-src="/assets/640.png" >
<img data-src="/assets/640-2.png" >
<img data-src="/assets/640-3.png" >
<img data-src="/assets/640-4.png" >
<img data-src="/assets/640-5.png" >
<img data-src="/assets/640-6.png" >
<img data-src="/assets/640-7.png" >
<img data-src="/assets/640-8.png" >
<img data-src="/assets/640-9.png" >
<img data-src="/assets/640-10.png" >
<img data-src="/assets/640-11.png" >
<img data-src="/assets/640-12.png" >


]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>投诉godaddy</title>
    <url>/2016/hello-world/</url>
    <content><![CDATA[<p>原博客下面文章， 因为godaddy 删除了个人空间，导致5年的博文，毁于一旦，真是吐血三升， 很多美好的回忆，已付之东流。</p>
<p>强烈谴责godaddy, 没有任何责任感， 而且多次投诉godaddy无果。</p>
<p>如果有条件，还是建议在阿里云上购买虚拟机，自建网站</p>
]]></content>
  </entry>
  <entry>
    <title>赫尔辛基之旅</title>
    <url>/2020/helsinki/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>赫尔辛基是芬兰的首都， 也是芬兰最大的港口城市， 也是芬兰经济、政治、文化、旅游和交通中心，世界著名的国际大都市。该市已连续多年被评为全球最宜居的城市之一。 该市同时也是全球幸福感最高的城市之一。</p>
<p>相对北欧的其他几个国家而言，人文和艺术的氛围略微逊色一下，但整体而言，还是极具北欧风格，很多建筑颜色分明，街道五彩缤纷。 导游推荐了几个地方， </p>
<ol>
<li>西贝柳斯公园</li>
<li>岩石教堂</li>
<li>红白教堂</li>
<li>购物， 因为芬兰有最高的退税率， 因此这里的lv 号称是全球最便宜的lv 专卖店。</li>
</ol>
<p>个人感觉，赫尔辛基最好的方式是白天玩一天，晚上做dfds 游轮去瑞典斯德哥尔摩， 即欣赏了傍晚的港湾，有省一晚的酒店。<br>因为飞猪给我们定的酒店是当地为数不多的5星酒店之一，而且位于市中心，所以，我们最终还是入住酒店，然后第二天再启程到挪威的奥斯陆。</p>
<span id="more"></span>

<h2 id="西贝柳斯公园"><a href="#西贝柳斯公园" class="headerlink" title="西贝柳斯公园"></a>西贝柳斯公园</h2><p>西贝柳斯公园，景色其实不错，旁边是波罗的海，而西贝柳斯公园内的两座雕像是园内的最大亮点，最显眼的一座由600根空心钢管组成，呈波浪状排列，约有6.5米高，酷似一架巨型管风琴，风吹过之时，这架“管风琴”会发出悦耳玄妙的声音，与周边的花草树木交相应和。这座抽象派的雕塑作品由芬兰著名的雕塑家埃拉·希尔图宁设计，以此来表现西贝柳斯交响乐的精髓所在。这座管风琴雕塑亦已成为赫尔辛基的地标性建筑。</p>
<p>位于管风琴附近的第二座雕像是西贝柳斯本人的头像，于1967年西贝柳斯逝世10周年之际完成。这尊音乐大师的金属头像被镶嵌在一旁的红色岩石上，供人瞻仰缅怀。<br><img data-src="/img/helsinki/xibei.jpg" ></p>
<p>餐馆西贝柳斯背后有一些故事，推荐读者网上去搜一些西贝柳斯的故事。<br>管风琴在风的吹动下，会发出呜呜的声音，象征着芬兰人反抗压迫的呐喊。</p>
<h2 id="岩石教堂"><a href="#岩石教堂" class="headerlink" title="岩石教堂"></a>岩石教堂</h2><p>岩石教堂，非常漂亮， 和欧洲绝大部分教堂都是完全不一样，他更像一个音乐厅， 我摘一段话<br>“岩石教堂又名坦佩利奥基奥教堂，位于赫尔辛基市中心坦佩利岩石广场，由建筑师苏马连宁兄弟精心设计，是世界上唯一建在岩石中的教堂，也是赫尔辛基最著名和不错过的景点之一。</p>
<p>历史背景<br>岩石教堂建成于1969年2月，事实上在此处修建教堂的方案早在1930年已经存在，但是由于二战爆发，被迫搁浅。战后通过公开募集选择了现在的方案。人们来到这里都会为这座别具创意的杰作惊叹不已，难以想象一整块坚硬的岩石内部是如何被打造成一座教堂的。</p>
<p>建筑之美<br>当你站在教堂外，映入眼帘的是一块巨大的岩石，看不到一般教堂所具有的尖顶和钟楼，甚至都注意不到教堂的所在，只有一个直径20多米的淡蓝色铜制圆形拱顶暴露在岩石的最上面。这是因为教堂修建于一块巨大的岩石中，将岩石挖开后于上方修建了玻璃顶棚，实现自然采光，而教堂的外墙就是岩石本身。<br>教堂入口设计成隧道，内部墙面仍为原有的岩石，整座教堂如同着陆的飞碟一般，非常奇特。屋顶采用圆顶设计，有一百条放射状的梁柱支撑，同时镶上透明玻璃，有了自然采光后丝毫感觉不到身处岩石内部。”</p>
<p>岩石教堂又名坦佩利奥基奥教堂，位于赫尔辛基市中心坦佩利岩石广场，由建筑师苏马连宁兄弟精心设计，是世界上唯一建在岩石中的教堂，也是赫尔辛基最著名和不错过的景点之一。</p>
<img data-src="/img/helsinki/rock.jpg" >
<img data-src="/img/helsinki/rock1.jpg" >


<h2 id="乌斯别斯基东正教堂"><a href="#乌斯别斯基东正教堂" class="headerlink" title="乌斯别斯基东正教堂"></a>乌斯别斯基东正教堂</h2><p>乌斯别斯基东正教堂, 是我这几天参观教堂中， 内部装饰最华丽的一个教堂， 教堂离我们住的比较近， 走过去就到了</p>
<img data-src="/img/helsinki/red2.jpeg" >
<img data-src="/img/helsinki/red1.jpeg" >
<img data-src="/img/helsinki/red3.jpeg" >

<p>这里引述蚂蜂窝上一段介绍<br>芬兰首都赫尔辛基的乌斯别斯基大教堂建于1862至1868年间，外观的金绿圆顶和红砖墙很为醒目，具有俄罗斯的建筑风格。教堂的颜色和式样都充满着神秘的色彩。乌斯别斯基东正教教堂位于赫尔辛基市中心，它的十三个金顶，与古雅红砖外墙，在赫尔辛基城市轮廓间，突显一抹俄罗斯在芬兰宗教上所留下的遗痕。显眼的金圆顶和红砖砌成的教堂显得格外凝重，旁边两棵大树与教堂交相辉映，正好是俄罗斯风情渗入芬兰历史的见证。精雕细琢的拱顶和花岗岩石柱是乌斯本斯基大教堂的两大特色，教堂内部的绘画都是由俄国画家完成的，完全保留了传统东正教堂的艺术风格。</p>
<h2 id="议会广场-赫尔辛基大教堂"><a href="#议会广场-赫尔辛基大教堂" class="headerlink" title="议会广场&#x2F;赫尔辛基大教堂"></a>议会广场&#x2F;赫尔辛基大教堂</h2><p>其实议会广场&#x2F;赫尔辛基大教堂 参观点并不多，教堂内部和乌斯别斯基东教堂相对，逊色非常多， 就教堂前的广场略有可看。这个教堂又称白教堂</p>
<img data-src="/img/helsinki/white2.jpeg" >
<img data-src="/img/helsinki/white1.jpeg" >


<h2 id="芬兰国家博物馆"><a href="#芬兰国家博物馆" class="headerlink" title="芬兰国家博物馆"></a>芬兰国家博物馆</h2><p>做电车，随便逛， 突然发现来到了芬兰国家博物馆， 于是就进去逛了一把， 芬兰国家博物馆，主要是介绍芬兰的历史和发展过程，相对而言，没有什么艺术展品，可观赏性要略微逊色一下， 不过也是一个kill time的好时光。</p>
<img data-src="/img/helsinki/museum.jpg" >


<h2 id="电车环城游"><a href="#电车环城游" class="headerlink" title="电车环城游"></a>电车环城游</h2><p>在芬兰可以直接买票， 票在2个小时内都是有效，随便做，于是最好的方式就是环城电车游。</p>
<img data-src="/img/helsinki/daughter.jpeg" >
阿曼达雕像, 波罗的海女儿
<img data-src="/img/helsinki/music.jpeg" >
国家音乐厅门前
<img data-src="/img/helsinki/light.jpeg" >
最火的网红餐厅前， 玻璃屋前的街景



]]></content>
      <categories>
        <category>travel</category>
      </categories>
      <tags>
        <tag>travel</tag>
      </tags>
  </entry>
  <entry>
    <title>深度分析Twitter Heron</title>
    <url>/2015/heron/</url>
    <content><![CDATA[<p>2015年6月1号， Twitter 对外宣讲了他们的Heron系统， 从ppt和论文中，看起来完爆storm。昨天，抽空把论文，仔细读了一遍， 把个人笔记和心得分享一下：</p>
<h1 id="最后总结："><a href="#最后总结：" class="headerlink" title="最后总结："></a>最后总结：</h1><p>Heron更适合超大规模的机器， 超过1000台机器以上的集群。 在稳定性上有更优异的表现， 在性能上，表现一般甚至稍弱一些，在资源使用上，可以和其他编程框架共享集群资源，但topology级别会更浪费一些资源。</p>
<p>而从应用的角度，应用更偏向于大应用，小应用的话，会多一点点资源浪费， 对于大应用，debug-ability的重要性逐渐提升。 另外对于task的设计， task会走向更重更复杂， 而JStorm的task是向更小更轻量去走。</p>
<p>未来JStorm可以把自动降级策略引入， 通过实现阿里妈妈的ASM， debug-ability应该远超过storm， 不会逊色于Heron， 甚至更强。</p>
<span id="more"></span>
<h1 id="现状："><a href="#现状：" class="headerlink" title="现状："></a>现状：</h1><p>所有的老的生产环境的topology已经运行在Heron上， 每天大概处理几十T的数据， billions of消息</p>
<h2 id="为什么要重新设计Heron："><a href="#为什么要重新设计Heron：" class="headerlink" title="为什么要重新设计Heron："></a>为什么要重新设计Heron：</h2><p>【题外话】这里完全引用作者吐槽的问题， 不少问题，其实JStorm已经解决</p>
<ul>
<li><p>debug-ability 很差， 出现问题，很难发现问题， 多个task运行在一个系统进程中， 很难定位问题。需要一个清晰的逻辑计算单元到物理计算单元的关系</p>
</li>
<li><p>需要一种更高级的资源池管理系统</p>
<ul>
<li><p>可以和其他编程框架共享资源， 说白了，就是类似yarn&#x2F;mesos， 而在Twitter就是Aurora</p>
</li>
<li><p>更简单的弹性扩容和缩容 集群</p>
</li>
<li><p>因为不同task，对资源需求是不一样的， 而storm会公平对待每个worker， 因此会存在worker浪费内存问题。当worker内存特别大时， 进行jstack或heap dump时，特别容易引起gc，导致被supervisor干掉</p>
</li>
<li><p>经常为了避免性能故障，常常进行超量资源分配， 原本100个core，分配了200个</p>
</li>
</ul>
</li>
<li><p>认为Storm设计不合理的地方</p>
<ul>
<li><p>一个executor 存在2个线程， 一个执行线程， 一个发送线程， 并且一个executor运行多个task， task的调度完全依赖来源的tuple， 很不方便确认哪个task出了问题。</p>
</li>
<li><p>因为多种task运行在一个worker中， 无法明确出每种task使用的资源， 也很难定位出问题的task，当出现性能问题或其他行为时， 常用就是重启topology， 重启后就好了，因为task进行了重新调度</p>
</li>
<li><p>日志打到同一个文件中，也很难查找问题，尤其是当某个task疯狂的打印日志时</p>
</li>
<li><p>当一个task挂掉了，直接会干掉worker，并强迫其他运行好的task被kill掉</p>
</li>
<li><p>最大的问题是，当topology某个部分出现问题时， 会影响到topology其他的环节</p>
</li>
<li><p>gc引起了大量的问题</p>
</li>
<li><p>一条消息至少经过4个线程， 4个队列， 这会触发线程切换和队列竞争问题</p>
</li>
<li><p>nimbus功能太多， 调度&#x2F;监控&#x2F;分发jar&#x2F;metric report， 经常会成为系统的bottleneck</p>
</li>
<li><p>storm的worker没有做到资源保留和资源隔离， 因此存在一个worker会影响到另外的worker。 而现有的isolation调度会带来资源浪费问题。 Storm on Yarn也没有完全解决这个问题。</p>
</li>
<li><p>zookeeper成为系统的瓶颈， 当集群规模增大时。 有些系统为了降低zk心态，新增了tracker，但tracker增加了系统运维难度。</p>
</li>
<li><p>nimbus是系统单点</p>
</li>
<li><p>缺乏反压机制</p>
<ul>
<li><p>当receiver忙不过来时， sender就直接扔弃掉tuple，</p>
</li>
<li><p>如果关掉acker机制， 那无法量化drop掉的tuple</p>
</li>
<li><p>因为上游worker执行的计算就被扔弃掉。</p>
</li>
<li><p>系统会变的难以预测(less predictable.)</p>
</li>
</ul>
</li>
<li><p>常常出现性能问题， 导致tuple fail， tuple replay， 执行变慢</p>
<ul>
<li><p>不良的replay， 任意一个tuple失败了，都会导致整个tuple tree fail， 不良的设计时（比如不重要的tuple失败），会导致tuple轻易被重发</p>
</li>
<li><p>当内存很大时，长时间的gc，导致处理延时，甚至被误杀</p>
</li>
<li><p>队列竞争</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="Heron设计"><a href="#Heron设计" class="headerlink" title="Heron设计"></a>Heron设计</h1><h2 id="设计原则："><a href="#设计原则：" class="headerlink" title="设计原则："></a>设计原则：</h2><ul>
<li><p>兼容老的storm api</p>
</li>
<li><p>实现2种策略， At most once&#x2F;At least once</p>
</li>
</ul>
<h2 id="架构："><a href="#架构：" class="headerlink" title="架构："></a>架构：</h2><p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1skzsMVXXXXX6aFXXXXXXXXXX" alt="architecture"></p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1y_zyMVXXXXb.aXXXXXXXXXXX" alt="topology"></p>
<h2 id="调度器"><a href="#调度器" class="headerlink" title="调度器"></a>调度器</h2><p>Aurora是一个基于mesos的通用service scheduler， Hero基于Aurora 实现了一套Topology Scheduler， 并且这个调度器已经提供了一定的抽象，可以移植到yarn&#x2F;mesos&#x2F;ec2（我的理解应该稍加修改就可以运行在其他通用型调度器上）</p>
<p>第一个container 运行 Topology Manager（TM）， 其他的container 内部会运行一个Stream manager&#x2F;Metrics Manager 和多个Heron Instance。 这里一个container类似一个docker感念，表示一个资源集合，是Aurora的调度单元， 多个container可以运行在一台机器上， 分配多少container由Aurora根据现有资源情况进行分配， 另外一个container设置了cgroup。 从逻辑或角色上，这里的container相当于jstorm中的worker。</p>
<h2 id="Topology-Manager"><a href="#Topology-Manager" class="headerlink" title="Topology Manager"></a>Topology Manager</h2><ul>
<li><p>tm伴随整个topology生命周期， 提供topology状态的唯一contact （类似yarn的app master）</p>
</li>
<li><p>可以一主多备， 大家抢占zk 节点， 谁胜出，谁为master， 其他为standby</p>
</li>
</ul>
<h2 id="Stream-manager（SM）"><a href="#Stream-manager（SM）" class="headerlink" title="Stream manager（SM）"></a>Stream manager（SM）</h2><p>最大的改变就是源自Stream manager， Stream manager就相当于一个container的tuple的总线（hub）。 所有的Hero Instance（HI）都连接SM进行send&#x2F;receive</p>
<p>如果container内部一个HI 发送数据到另外一个HI，走的是本地快速通道。</p>
<h2 id="Backpressure-反压机制"><a href="#Backpressure-反压机制" class="headerlink" title="Backpressure 反压机制"></a>Backpressure 反压机制</h2><p>当下游处理速度变慢后，通过反压机制，可以通知上游进行减速， 避免数据因buffer被塞满而丢失，并因此带来资源浪费。</p>
<h3 id="TCP-反压："><a href="#TCP-反压：" class="headerlink" title="TCP 反压："></a>TCP 反压：</h3><p>当一个HI 处理慢了后，则该HI的接收buffer会被填满， 紧接着本地SM的sending buffer被填满， ? 然后会传播到其他的SM和上游HI。</p>
<p>这个机制很容易实现，但在实际使用中，存在很多问题。因为多个HI 共用SM， 不仅将上游的HI 降速了，也把下游的HI 降速。从而整个topology速度全部下架，并且长时间的降级。</p>
<h3 id="Spout-反压"><a href="#Spout-反压" class="headerlink" title="Spout 反压"></a>Spout 反压</h3><p>这个机制是结合TCP 反压机制， 一旦SM 发现一个或多个HI 速度变慢，立刻对本地spout进行降级， 停止从这些spout读取数据。并且受影响的SM 会发送一个特殊的start backpressure message 给其他的sm，要求他们对spout进行本地降级。一旦出问题的HI 恢复速度后，本地的SM 会发送 stop backpressure message 解除降级。</p>
<h3 id="Stage-by-Stage-反压"><a href="#Stage-by-Stage-反压" class="headerlink" title="Stage-by-Stage 反压"></a>Stage-by-Stage 反压</h3><p>这个类似spout反压，但是一级一级向上反压。</p>
<h3 id="结果"><a href="#结果" class="headerlink" title="结果"></a>结果</h3><p>Heron最后采用的是spout反压， 因为实现比较简单，而且降级响应非常迅速。 并且可以很快定位到那个HI 处理速度慢了。 每个socket channel都绑定了一个buffer， 当buffer 的 queue size超过警戒水位时，触发反压，减少时，接触反压。</p>
<p>这种机制，不会丢弃tuple，除了机器宕机。</p>
<p>topology可以设置打开或关闭。</p>
<h2 id="Heron-Instance"><a href="#Heron-Instance" class="headerlink" title="Heron Instance"></a>Heron Instance</h2><p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1g7vOMVXXXXX1XVXXXXXXXXXX" alt="topology"></p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1I8P3MVXXXXXPXXXXXXXXXXXX" alt="hi"></p>
<ul>
<li><p>一个task 一个进程，</p>
</li>
<li><p>所有的进程之间通信都是使用protocol buffer</p>
</li>
<li><p>一个gateway线程， 一个执行线程。 gateway线程负责和外围通信， sm&#x2F;mm。 执行线程和现有storm的执行线程非常类似。执行线程会收集所有的metrics，然后发送给gateway线程。</p>
</li>
<li><p>这个data-in&#x2F;data-out队列会限定大小， 当data-in 队列满了的时候， gateway线程停止从local SM 读取数据。同理如果data-out队列满，gateway会认为local SM不想接受更多的数据。 执行线程就不再emit或执行更多的tuple。</p>
</li>
<li><p>data-in&#x2F;data-out队列大小不是固定， 如果是固定时， 当网络颠簸时，会导致内存中大量数据堆积无法发送出去，并触发GC, 并导致进一步的降级。因此是动态调整， 定期调整队列大小。 如果队列的capacity超过阀值时， 对其进行减半。这个操作持续进行指导队列的capacity维持在一个稳定的水位或0。这种方式有利避免GC的影响。 当队列的capcity小于某个阀值时， 会缓慢增长到配置大小或最大capacity值。</p>
</li>
</ul>
<h2 id="Metrics-manager（mm）"><a href="#Metrics-manager（mm）" class="headerlink" title="Metrics manager（mm）"></a>Metrics manager（mm）</h2><p>收集所有的metrics，包括系统的和用户的metrics， 也包含SM的。 mm会发送metrics 给monitor系统(类似ganglia系统)，同样也会给TM.</p>
<h2 id="流程："><a href="#流程：" class="headerlink" title="流程："></a>流程：</h2><ul>
<li><p>提交任务， Aurora分配必要的资源和在一些机器上调度container</p>
</li>
<li><p>TM 在一个container上运行起来，并注册到ZK</p>
</li>
<li><p>每个container的SM 查询ZK 找到TM， 向TM 发送心跳。</p>
</li>
<li><p>当所有的SM 连上TM后， TM 执行分配算法， 不同的compoent到不同的container。 这个阶段叫物理执行计划（类似SQL解析和执行过程）。并将执行计划放到ZK。</p>
</li>
<li><p>SM 下载执行计划，并开始相互之间进行连接， 与此同时， 启动HI, hi开始发现container，下载他们的执行计划，并开始执行</p>
</li>
<li><p>整个topology完成初始化，开始正式的发送和接收数据。</p>
</li>
</ul>
<h3 id="三种failure-case"><a href="#三种failure-case" class="headerlink" title="三种failure case"></a>三种failure case</h3><h4 id="进程挂了"><a href="#进程挂了" class="headerlink" title="进程挂了"></a>进程挂了</h4><ul>
<li><p>如果TM 挂了， container会重启TM， TM 会从ZK 上重新下载执行计划。如果有一主多备，则备机会被promotion。 所有SM 会切到新的TM</p>
</li>
<li><p>如果SM 挂了， container依旧会重启TM, 并从ZK 下载执行计划， 并检查是否有变化。其他的SM 会连到新的SM</p>
</li>
<li><p>如果HI 挂了， 重启并下载执行计划，并重新执行。</p>
</li>
</ul>
<h1 id="外围系统"><a href="#外围系统" class="headerlink" title="外围系统"></a>外围系统</h1><p>外围系统就介绍一下Heron Tracker</p>
<h2 id="Heron-Tracker"><a href="#Heron-Tracker" class="headerlink" title="Heron Tracker"></a>Heron Tracker</h2><p>负责收集topology的信息， 类似一个gateway的角色。 通过watch zk，发现新的TM， 并获取topology的一些原数据。是一种Aurora service， 提供load balance在多个instance之间。</p>
<p>可以提供REST API。可以获取</p>
<ul>
<li><p>逻辑和物理执行计划</p>
</li>
<li><p>各种metrics， 系统的和用户的</p>
</li>
<li><p>日志link</p>
</li>
</ul>
<h2 id="Heron-UI-VIZ"><a href="#Heron-UI-VIZ" class="headerlink" title="Heron UI&#x2F;VIZ"></a>Heron UI&#x2F;VIZ</h2><p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1k7DYMVXXXXbgXpXXXXXXXXXX" alt="ui"></p>
<p>UI 提供传统的UI 方式。</p>
<p>VIZ 提供全新的UI， 可以看到更多的metrics， 曲线和健康检查。比UI 炫酷很多。</p>
<p>性能报告和测试过程：</p>
<p>了解整个系统架构和工作流程后， 后面的性能测试报告， 没有看了， 也差不多有个概念了。</p>
<h1 id="个人思考和总结："><a href="#个人思考和总结：" class="headerlink" title="个人思考和总结："></a>个人思考和总结：</h1><h2 id="相对于JStorm，-Heron把角色剥离的更清晰明了。"><a href="#相对于JStorm，-Heron把角色剥离的更清晰明了。" class="headerlink" title="相对于JStorm， Heron把角色剥离的更清晰明了。"></a>相对于JStorm， Heron把角色剥离的更清晰明了。</h2><ul>
<li>调度器</li>
</ul>
<p>scheduler 负责container的调度，这个调度非常的纯粹，可以直接复用yarn&#x2F;mesos&#x2F;， 现有的TM 其实就是nimbus，唯一一点变化就是这个TM 只负责自己topology的信息， 不是负责所有topology。这个TM 就相当于yarn下的app master， 非常适合目前主流的调度系统。 当集群规模非常大的时候， 并且每个应用都比较大的时候， 这个架构会非避免nimbus成为瓶颈。 不过storm-on-yarn模式下， 可能通过一个nimbus管理一个小的逻辑集群，也可以解决这个问题， 并且当topology 比较小的时候， 可以通过大家公用一个nimbus，节省一些资源。</p>
<ul>
<li>container</li>
</ul>
<p>这里特别要把container拿出来仔细说一下， 这个container是Auron的一个资源单元。如果将Auron类似JStorm的worker， 你就会发现角色和架构是多么的类似。</p>
<pre><code>* container和jstorm的worker都可以设置cgroup，达到一定的资源隔离

* container内部的SM/MM 其实就类似jstorm worker内部drainer/dispatcher/metricsreport线程。
</code></pre>
<p>但container 相对jstorm 的worker 还有一些其他的优缺点：</p>
<p>优点：</p>
<pre><code>* 这个粒度可以控制的更自由， 这个container 可以控制cpu 到更多的核，更多的内存上限。 但jstorm的worker 基本上最多10个核， 而且当内存太大，在core dump和gc的时候压力会比较大。

* container还带一定的supervisor的功能，当container内部任何进程挂了， container都会负责把它重启， 因此整个系统的心态逻辑会非常的简单。 ?Auron &lt;–&gt; container, ? ?Container &lt;– &gt; tm/sm/mm/hi. ?整个系统的心跳压力模型会更简单， 心跳压力（对ZK）也更小
</code></pre>
<h2 id="性能："><a href="#性能：" class="headerlink" title="性能："></a>性能：</h2><p>ppt和文档里面说性能有15倍以上的提升， 这个在某些设置下是可以达到这种效果， 但通常情况性能应该比JStorm还要差一点点。</p>
<p>如何达到这种效果呢，</p>
<ul>
<li><p>前提条件是， grouping方式不是选择localOrShuffle或者localFirst</p>
</li>
<li><p>就是把container设置的尽可能的大， 最好是独占一台机器。这样SM和SM 之间的通信就会大幅减少， 而一个container内部的HI 通信走内部通道。因此会有更多的HI走内部通道。而jstorm&#x2F;storm， worker比较多的时候， worker和worker之间会创建netty connection， 更多的netty connection会带来更多的内存消耗和线程切换。 尤其是worker数超过200个以上时。</p>
</li>
</ul>
<p>但为什么说通常情况下，性能应该还要比JStorm差一点点呢。</p>
<p>因为在生产环境， container 是不可能占有这么多资源， 否则Auron的调度太粗粒度，一台机器只跑一个大container， 会导致更严重的资源浪费。正常情况下， 一个container绑定2 ～ 4个核， 这个时候，和一个普通的jstorm worker没有什么区别， 但jstorm worker内部task之间数据传输的效率会远远高于Heron， 因为Heron的HI 之间即使是走进程间通信方式, 也逃脱不了序列化和反序化的动作， 这个动作肯定会耗时， 更不用说IPC 之间的通信效率和进程内的通信效率。</p>
<h2 id="资源利用率："><a href="#资源利用率：" class="headerlink" title="资源利用率："></a>资源利用率：</h2><p>Heron 可以非常精准的控制资源使用情况， 能够保证， 申请多少资源，就会用多少资源。 在大集群这个级别会节省资源，在topology级别浪费资源。</p>
<p>如果JStorm-on-yarn这种系统下， 因为每个逻辑集群会超量申请一些资源， 因此资源可能会多有少量浪费。无法做到像Heron一样精准。 如果改造nimbus成为topology level 类似TM（腾讯在jstorm基础上实现了这个功能）， 这个问题就可以很好的解决。在普通standalone的JStorm模式下， jstorm不会浪费资源， 但因为Standalone，导致这些机器不能被其他编程框架使用， 因此也可以说浪费一定的资源。 但这种情况就是 资源隔离性– 资源利用率的一种平衡， 现在这种根据线上运行情况，浪费程度可以接受。</p>
<p>在topology这个粒度进行比较时， Heron应该会消耗掉更多的资源。 最大的问题在于， Heron中一个task就是一个process， 论文中没有描叙这个process的公共线程， 可以肯定的是， 这个process比如还有大量的公共线程， 比如ZK-client&#x2F;network-thread&#x2F;container-heartbeat-thread， 一个task一个process，这种设计，相对于一个worker跑更多的task而言，肯定浪费了更多的CPU 和内存。</p>
<p>至于吐槽在Storm和JStorm，超量申请资源问题， 比如一个topology只要100 个cpu core能完成， 申请了600个core， 这个问题，在jstorm中是绝对不存在的， jstorm的cgroup设置是share + limit方式， 也就是上限是600 core，但topology如果用不到600个core， 别的topology可以抢占到cpu core。 在内存方面， jstorm的worker 内存申请量，是按照worker最大内存申请， 但现代操作系统早就做到了， 给你一个上限， 当你用不了这么多的时候， 其他进程可以抢占。</p>
<h2 id="在稳定性和debug-ability这点上："><a href="#在稳定性和debug-ability这点上：" class="headerlink" title="在稳定性和debug-ability这点上："></a>在稳定性和debug-ability这点上：</h2><p>Heron 优势非常大， 主要就是通过2点:</p>
<ul>
<li><p>自动降级策略， 也就是论文说的backpressure， 这个对于大型应用是非常有效的， 也很显著提高稳定性。</p>
</li>
<li><p>一个task一个process， 这个结合降级策略，可以非常快速定位到出错的task， 另外因为一个task 一个process， task之间的影响会非常快， 另外也避免了一个进程使用过大的内存，从而触发严重的GC 问题。</p>
</li>
</ul>
<h1 id="最后总结：-1"><a href="#最后总结：-1" class="headerlink" title="最后总结："></a>最后总结：</h1><p>Heron更适合超大规模的机器， 超过1000台机器以上的集群。 在稳定性上有更优异的表现， 在性能上，表现一般甚至稍弱一些，在资源使用上，可以和其他编程框架共享资源，但topology级别会更浪费一些资源。</p>
<p>另外应用更偏向于大应用，小应用的话，会多一点点资源浪费， 对于大应用，debug-ability的重要性逐渐提升。 另外对于task的设计， task会走向更重更复杂， 而JStorm的task是向更小更轻量去走。</p>
<p>未来JStorm可以把自动降级策略引入， 通过实现阿里妈妈的ASM， debug-ability应该远超过storm， 不会逊色于Heron， 甚至更强。</p>
<h1 id="其他流式编程框架"><a href="#其他流式编程框架" class="headerlink" title="其他流式编程框架"></a>其他流式编程框架</h1><p>1.S4 Distributed Stream Computing Platform.?<a href="http://incubator.apache.org/s4/">http://incubator.apache.org/s4/</a></p>
<ol start="2">
<li><p>Spark Streaming. <a href="https://spark.apache.org/streaming/">https://spark.apache.org/streaming/</a>?</p>
</li>
<li><p>Apache Samza. <a href="http://samza.incubator.apache.org/">http://samza.incubator.apache.org</a></p>
</li>
<li><p>Tyler Akidau, Alex Balikov, Kaya Bekiroglu, Slava Chernyak, Josh?Haberman, Reuven Lax, Sam McVeety, Daniel Mills, Paul?Nordstrom, Sam Whittle: MillWheel: Fault-Tolerant Stream?Processing at Internet Scale.?PVLDB 6(11): 1033-1044 (2013)</p>
</li>
</ol>
<p>5.?Mohamed H. Ali, Badrish Chandramouli, Jonathan Goldstein,Roman Schindlauer: The Extensibility Framework in Microsoft?StreamInsight.?ICDE?2011: 1242-1253</p>
<ol start="6">
<li><p>Rajagopal Ananthanarayanan, Venkatesh Basker, Sumit Das, Ashish?Gupta, Haifeng Jiang, Tianhao Qiu, Alexey Reznichenko, Deomid?Ryabkov, Manpreet Singh, Shivakumar Venkataraman: Photon:?Fault-tolerant and Scalable Joining of Continuous Data Streams.?SIGMOD?2013: 577-588</p>
</li>
<li><p>DataTorrent.?<a href="https://www.datatorrent.com/">https://www.datatorrent.com</a></p>
</li>
<li><p>Simon Loesing, Martin Hentschel, Tim Kraska, Donald Kossmann:?Stormy: An Elastic and Highly Available Streaming Service in the?Cloud. EDBT&#x2F;ICDT Workshops 2012: 55-60</p>
</li>
</ol>
]]></content>
      <categories>
        <category>BigData</category>
        <category>流计算</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Stream Process</tag>
        <tag>Heron</tag>
      </tags>
  </entry>
  <entry>
    <title>《华为崛起》</title>
    <url>/2020/huawei/</url>
    <content><![CDATA[<h1 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h1><p>今年年初， 买书的时候，无意中看到《华为崛起》， 介绍的挺有意思的， 于是买了一本看看， 买了很久但一直没有看， 拖了很久， 终于看完了， 忍不住写点总结吧， 免得左边耳朵进，右边耳朵出。<br>华为从一家这么小的公司，最后成长成为差不多中国最大的民营企业， 而且很多年前, 营收和研发投入就是互联网三巨头bat 的总和， 绝对值得去学习和研究一下(现在互联网叫bat， 其实叫hat 更合适)。 这本书讲了很多华为成长过程中，发生的一些事和决策，可以从中思考一下，为什么华为成功了，而巨大中华中，其他的几乎没有多少声音了。<br>另外，绝对要吐槽一下作者， 全文无处不在的拍马屁， 有的地方，简直要吐了。这本书组织管理介绍比较浅， 很多组织管理的思考充斥着对任老板和管理层的拍马屁。</p>
<p>创业的朋友，推荐读一下这本书， 带着问题 “为什么华为能成功”？ 读下去，相信会有很多收获。 而我没有什么体感，只能站在第三者的角度去看， 所以聊的深度比较浅， 大家就当博君一笑。</p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>华为大概分了几个阶段， 每一次都是破茧成蝶，突破天花板</p>
<ol>
<li>创业之战</li>
<li>成长之战</li>
<li>生存之战</li>
<li>大象狂奔</li>
</ol>
<span id="more"></span>

<h1 id="创业之战"><a href="#创业之战" class="headerlink" title="创业之战"></a>创业之战</h1><p>创业的时候， 选择了暴利行业的电信行业， 这个是最大的关键点， 如果不是选择这个暴利行业， 否则根本没有钱去支撑后续一系列的研发和快速扩张， 包括允许了一定的战略决策失误。 今天，对于创业的朋友来说，就是一个常说的词， 蓝海和红海， 只有下海到蓝海中， 才有更多的机会，更多的容错性（反脆弱）。 而怎样找到一个蓝海， 就是需要发现问题。</p>
<h1 id="成长之战"><a href="#成长之战" class="headerlink" title="成长之战"></a>成长之战</h1><p>最早代理交换机， 只要有路子，能拿到货， 转手一下， 就有大把钞票。 有的时候，经常有些热门的交换机，根本拿不到， 任老板于是决定自己去研发，避免自己被人卡脖子。 但凡做事的人， 都会希望自己能把握关键点，降低风险， 这个其实没有什么好吹的。 但老任比较牛b的是，就是坚持，在一系列研发失败后， 最后赌了一把大的， all in 了光纤交换机，而且一下就搞万门交换机，选择了一个非常正确的方向， 这个非常有魄力。 另外，当时第一款产品出来时， 找到第一个关键客户 – 义乌电信局时， 真的是客户第一， 研发所有人员都蹲现场， 现场有问题，现场解决问题， 第一时间解决所有问题， 和义乌电信局成了命运共同体， 一荣皆荣， 一损俱损。 这种手法，是甲方和乙方的最高境界， 也给了华为一个真正的练兵场， 帮助华为打开了局面。</p>
<p>一家小公司成长起来，非常依赖老板的战略决策， 赌对了就飞黄腾达，赌错了，就树倒猢狲散，做大事的人，往往赌性比较重， 但当公司长大后， 却要防止这种错误的决策, 需要一种机制来防止决策失误， 类似阿里的合伙人，华为的轮值董事等。另外一种防止决策错误的思路是， 客户第一。 华为在客户第一上，做的真是贯穿到骨子里。</p>
<h1 id="生存之战"><a href="#生存之战" class="headerlink" title="生存之战"></a>生存之战</h1><p>在2003年的时候， 任正非中间打算将华为打包价75亿美金卖掉， 想想这背后的导火索，肯定就是华为遭遇了生存危机。<br>这个生存危机， 第一 港湾之战， 第二 思科之战。<br>港湾之战， 李一男 林立山头， 最初任老板的想法是，让李一男 帮助华为补位， 做一些华为的配合工作，但在巨大利益面前， 谁能抵挡的， 哪个公司不想成为巨头， 所以不要挑战人性， 利益面前，人是会变的。 第二个就是港湾就是华为的山寨版， 做事方式和华为一模一样， 这种方式，如果不斩草除根， 不彻底干掉， 哪怕自损800 也要灭敌1000， 否则就是放虎归山。<br>同样，思科在攻击华为时， 就是害怕自己担负 垄断罪名时， 放了华为一把， 明知华为未来不可阻挡，还是舍不得肉。 这个里面， 华为策略， 小输就是赢， 站的高度还是非常高。<br>2个形成鲜明对比， 一个是宁可自损800也要1000，也要斩草除根， 另外一个舍不得孩子，套不住狼。 最终的结果，大家也看到，永远铭记，从长远思考问题。<br>在2003年时， 挡住饮鸩止渴（挡住小灵通的诱惑），从未来着手布局， 还是高人一等。</p>
<h1 id="大象狂奔"><a href="#大象狂奔" class="headerlink" title="大象狂奔"></a>大象狂奔</h1><p>采取农村包围城市， 先从一些贫瘠的土地开始播种， 从别人不要的残羹冷炙着手， 深挖梁，缓称王。<br>在一些难啃的国家中， 组建合资公司， 这种做法还是相当smart。<br>在手机业务上， 从默默无闻到巨头， 每一步都是一步一个脚印。<br>布局海思半导体， 最初应该是无奈之举， 但海思半导体却成了华为的一个神来之笔。 </p>
<h1 id="组织管理"><a href="#组织管理" class="headerlink" title="组织管理"></a>组织管理</h1><p>全书介绍管理上，包装了各种理论， 什么军事管理， 机械主义， 自适应平衡（有个具体的理论，但忘记了名字， 差不多就是每个组织或模块是在一个动态环境中， 需要不停的流入资源&#x2F;人，然后也不断输出资源&#x2F;人，有一点点优胜略汰）。其实背后：</p>
<ol>
<li>钱， 2. 权， 3. 精神统一 （客户第一， 奋斗者为本）<br>不同阶段，应用这3点用了不同的手段。</li>
</ol>
<h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>今天的华为，俨然一个巨无霸， 不可能一家公司在所有领域都是寡头， 所以，还是需要资源重组，集中优势兵力布局未来主航道， 另外也要给合作伙伴留一条路吧。</p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>漫步九寨沟</title>
    <url>/2021/jiuzhaigou/</url>
    <content><![CDATA[<h1 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h1><p>在大学的时候, 就常常听到朋友各种介绍九寨沟, 记得大学毕业那年, 同寝室的室友玩了一次毕业旅行, 去了趟九寨沟, 表达了对九寨沟略有失望, 这也让我对九寨沟一直没有强烈的诉求, 也没有说专程去四川玩一下九寨沟, 不过,因为老婆这次非常想去四川玩, 就提了一嘴是不是可以顺便去看看九寨沟, 现在回想起来, 幸好提了一嘴, 否则去了四川没有去九寨沟, 真的就少了点什么. </p>
<p>引用一段九寨沟的介绍</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">九寨沟位于四川省西北部岷山山脉南段的阿坝藏族羌族自治州九寨沟县漳扎镇境内，地处岷山南段弓杆岭的东北侧。距离成都市400多千米，系长江水系嘉陵江上游白水江源头的一条大支沟。 九寨沟自然保护区地势南高北低，山谷深切，高差悬殊。北缘九寨沟口海拔仅2000米，中部峰岭均在4000米以上，南缘达4500米以上，主沟长30多公里。</span><br><span class="line">九寨沟是世界自然遗产、国家重点风景名胜区、国家AAAAA级旅游景区、国家级自然保护区、国家地质公园、世界生物圈保护区网络，也是中国第一个以保护自然风景为主要目的的自然保护区。</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="攻略"><a href="#攻略" class="headerlink" title="攻略"></a>攻略</h2><p>去九寨沟, 其实不需要什么攻略, 建议就2点: </p>
<ol>
<li>记得提前在网上预定门门票; </li>
<li>建议直接飞到离九寨沟最近的机场, 然后乘车, 建议是包车, 自己租车会比较累.</li>
</ol>
<p>我们是先飞到成都, 然后开车到九寨沟, 正好是10.1 长假期间, 我们从成都开到九寨沟, 从早上8点出发, 中间吃饭休息几次, 一直堵一直堵, 直到晚上10点才到了酒店, 400公里, 在车上的时间超过了12个小时, 以后打死都不会在这种高速免费节假日的第一天或最后一天上高速. </p>
<img data-src="/img/jiuzhaigou/jiuzhai1.jpg" >
<img data-src="/img/jiuzhaigou/19.jpg" >

<span id="more"></span>

<h1 id="行程"><a href="#行程" class="headerlink" title="行程"></a>行程</h1><p>推荐行程路线是在入口做公交, 一直坐到剑崖, 然后慢慢往下走, 如果下一个站点远就做车, 一路玩到诺日朗瀑布, 然后换公交去五彩池, 看完五彩池, 然后再坐车回到诺日朗, 在沿途玩耍犀牛海, 树正瀑布, 卧龙湾, 双龙海等等. </p>
<img data-src="/img/jiuzhaigou/map.jpg" >

<p>最前面的天鹅海, 芳草海, 箭竹海, 一路风景美不胜收, 边走边拍<br><img data-src="/img/jiuzhaigou/1.jpg" ><br><img data-src="/img/jiuzhaigou/2.jpg" ><br><img data-src="/img/jiuzhaigou/3.jpg" ><br><img data-src="/img/jiuzhaigou/4.jpg" ><br><img data-src="/img/jiuzhaigou/5.jpg" ><br><img data-src="/img/jiuzhaigou/6.jpg" ><br><img data-src="/img/jiuzhaigou/7.jpg" ><br><img data-src="/img/jiuzhaigou/8.jpg" ><br><img data-src="/img/jiuzhaigou/9.jpg" ></p>
<img data-src="/img/jiuzhaigou/12.jpg" >

<p>金铃海<br><img data-src="/img/jiuzhaigou/10.jpg" ><br><img data-src="/img/jiuzhaigou/11.jpg" ><br><img data-src="/img/jiuzhaigou/16.jpg" ></p>
<p>熊猫海瀑布<br><img data-src="/img/jiuzhaigou/14.jpg" ></p>
<p>镜海<br><img data-src="/img/jiuzhaigou/18.jpg" ><br><img data-src="/img/jiuzhaigou/15.jpg" ></p>
<p>诺日朗瀑布<br><img data-src="/img/jiuzhaigou/17.jpg" ></p>
<p>长海, 到长海的时候, 正天降冰雹, 花生大小的冰雹砸下来, 噼里啪啦的作响<br><img data-src="/img/jiuzhaigou/21.jpg" ></p>
<p>著名的五色池, 5色池还是颜色非常丰富<br><img data-src="/img/jiuzhaigou/20.jpg" ><br><img data-src="/img/jiuzhaigou/19.jpg" ></p>
<p>后续沿途步行了3小时, 因为是从山上往下走, 也没有那么累, 所以还好, 沿途欣赏了犀牛海, 老虎海, 树正群海, 树正瀑布, 卧龙海, 双龙海, 最后</p>
<img data-src="/img/jiuzhaigou/22.jpg" >
<img data-src="/img/jiuzhaigou/23.jpg" >
<img data-src="/img/jiuzhaigou/24.jpg" >
<img data-src="/img/jiuzhaigou/25.jpg" >
最后一个景点, 芦苇海
<img data-src="/img/jiuzhaigou/26.jpg" >]]></content>
      <categories>
        <category>travel</category>
      </categories>
      <tags>
        <tag>travel</tag>
      </tags>
  </entry>
  <entry>
    <title>小谈跳槽</title>
    <url>/2016/jump/</url>
    <content><![CDATA[<h1 id="小谈-跳槽"><a href="#小谈-跳槽" class="headerlink" title="小谈 跳槽"></a>小谈 跳槽</h1><p>最近看一个帖子《阿里70w vs IBM 40W》， 帖子里面充斥着阿里和IBM 各种出差补助的争吵， 实在无语， 忍不住，利用周末的时间，总结自己的想法， 抛砖引玉一下， 欢迎各位朋友一起探讨。<br>跳槽其实是一个非常大的话题，可以从梦想，从性格，从经历，从专业等各个维度长篇大论一番，另外每个人都有自己的经历，从而都有自己的解读， 没有哪一种是完全正确的，也没有哪一种是完全错误的，而我只能说，将我的理解表达出来，如果你有更多的想法，不妨也探讨一下。</p>
<span id="more"></span>

<h1 id="跳槽的本质"><a href="#跳槽的本质" class="headerlink" title="跳槽的本质"></a>跳槽的本质</h1><p>任何一次跳槽，都是自己人生中的一次选择， 这次选择都会对自己的人生产生一定的影响， 但每次选择出发点都是期望让自己的职业生涯向前一步或者家庭幸福感向前一步。</p>
<p>如果选择了家庭幸福感， 那在跳槽的权重中，家庭的因素自然放在首要位置。</p>
<p>如果选择了职业生涯，这次选择有没有让自己工作成就感更上一层楼。当工作成就感增强时，会感觉工作的动力源源不断涌现， 这就是为什么出现那么多的工作狂人的缘故。关于职业生涯，强烈建议拜读一下《你为什么没有好工作》， 里面有前辈很深刻的总结和理解。</p>
<p>但无论是选择家庭幸福感还是职业生涯，得先问自己，这是一次中长期的跳槽，还是一次短暂的旅途。但无论是短期旅途还是中长期跳槽， 是不是和自己长远的一个目标吻合。</p>
<h1 id="跳槽的权衡"><a href="#跳槽的权衡" class="headerlink" title="跳槽的权衡"></a>跳槽的权衡</h1><h2 id="薪水"><a href="#薪水" class="headerlink" title="薪水"></a>薪水</h2><p>谈跳槽，不可避免会涉及到薪水。<br>马云曾用2句话，很精辟的解释了为什么跳槽，无非2个原因：</p>
<ol>
<li>干的不爽</li>
<li>钱少了</li>
</ol>
<p>背后也说明了， 薪水其实能摆平跳槽中的很多问题。<br>当你很在意薪水时，如果这次跳槽，薪水离自己的预期有很大差距，建议不要跳， 因为一开始，就注定了心情不好， 这个不好的状态会维持到你下一次涨薪前， 又会让你对下一次涨薪充满期待，当期待越高时，也越容易失望。因此，薪水绝对会影响一个人的心情。<br>当你开始关注薪水之外的东西时，薪水的比重会逐渐降低。</p>
<p>记得第一次跳槽时， 老板的老板对我说，薪水不要看的太重， 多几千少几千都不是问题的关键，关键是你自己有没有机会成长更多。</p>
<h2 id="未来和当前："><a href="#未来和当前：" class="headerlink" title="未来和当前："></a>未来和当前：</h2><p>随着年纪和阅历不断增加，跳槽会看薪水之外越来越多的东西，也就是马老师的 “干的不爽”， 很多时候就归结于5个字 “未来和当前”<br>未来：</p>
<ol>
<li>自己职业的未来， 这次跳槽能否带来自己职业的提升， 视野，技术，能力能否有提升， 或者有一个更好的职位，通俗一点更好的坑， 专业的讲，更好的卡位。</li>
<li>公司的未来，<br>2.1 公司的未来有没有可能给一个平台给自己更好的展示，<br>2.2 另外这个公司的文化， 适不适合自己， 很多人忽视这个因素，但往往这个因素会影响一个人能不能长久的在一个公司呆下去。<br>家庭：</li>
<li>会给自己家庭带来什么变化， 一个稳定的工作，必然需要一个稳定的家庭<br>1.1 如果有提升，比如，原来的异地分居，现在合二为一， 那就是加分项<br>1.2 如果有冲击， 这个冲击是否能够接受， 比如异地跳槽或者夫妻分居， 当冲击出现时， 得仔细思考家庭，</li>
</ol>
<h2 id="创业"><a href="#创业" class="headerlink" title="创业"></a>创业</h2><p>随着现在政府口号 “大众创业，万众创新”的口号，很多事情，跳槽的过程中，遭遇了创业的问题：<br>创业就相当于一次跳槽过程，通常这次跳槽（创业）的结果是以失败告终，但收获了自己人生的阅历。<br>创业的人，往往需要足够强的脑力和体力，去面对所有已知或未知， 足够的能力去面对折腾，因此创业第一步需要分析自己的性格是否偏好创业，对于一些性格成熟稳重（赌性比较少），偏好安逸的人，建议到大公司工作，可能更适合一些。当然打算创业的原因太多，这里无法一一列举。</p>
<p>附带一句：<br>创业和情商是没有直接关系的，任何情况下（无论是创业还是在大公司工作，抑或小公司工作），都需要高情商。高情商的人，成功的概率永远都会比普通人高出一大截。， </p>
<h1 id="跳槽一点小技巧"><a href="#跳槽一点小技巧" class="headerlink" title="跳槽一点小技巧"></a>跳槽一点小技巧</h1><p>跳槽很多时候都是自己去选择公司，选择团队， 而不是被动接受外界猎头的鼓动。 自己心中有个大致概念，自己能去哪些公司，已经想去哪些公司。</p>
<p>如果你开始迈出跳槽的一步， 很简单， 搜索你想去公司的猎头， 发封邮件给他，如果有回复后，附上一份简历。 同样，也可以搜索这家公司的员工， 也可以发邮件给他，向他求助， 任何一家公司都非常欢迎内部推荐，因为，更可靠和成本更低。</p>
<p>至于跳槽过程中的技巧， 基本上属于术的范畴， 有很多文章，都有很多介绍， 这里有2个策略吧：<br>（1）一定需要临时抱佛脚， 临阵抹枪，不抹也光， 你准备的越多，机会的大门也向你敞开的越多<br>（2）尽可能的诚实</p>
<h1 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h1><p>跳槽永远都是一个 围城 的故事， 城外的人拼命想进来， 城内的人拼命想出去。 当前所在的公司， 绝不是你想象中的那么不堪， 新进入的公司，也绝不是梦中的那么美好， 没有一家十全十美的公司， 所以在跳槽的第一步，就要想清楚，自己想要什么，自己想改变什么？</p>
<p>作为老板其实不喜欢跳槽太多的人。</p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>《刻意练习》读后感</title>
    <url>/2018/keyilianxi/</url>
    <content><![CDATA[<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/keyilianxi.jpg" >
</div>

<p>《刻意练习》</p>
<p>鲁肃推荐的一本书， 非常有意思，值得推荐。 </p>
<p>成功都是靠大量不断提升的训练， 而刻意练习就是有针对性的训练。<br>在2000年， 英国科学家 对伦敦的出租车司机进行观察，出租车司机需要每天记住地图和所有标志性的建筑，用核磁共振观察16位出租车司机和普通50位男性相比，储存记忆的海马体要明显大很多。另外，对79名刚参加出租车考试的司机进行观察，在刚开始考试时， 大家的海马体在一个水平线上， 几年后， 79名中的41名仍然是出租车司机，另外38名中途放弃了， 结果这41名出租车司机的海马体要明显大于非出租车的38名非司机。</p>
<span id="more"></span>

<p>几种错误的观点：</p>
<ol>
<li>天才并不是天生的（或者基因决定的）。 拥有完美音高的人的概率是万分之1， 常识认为拥有完美音高的人都是天才是天生的， 莫扎特具有完美音高， 被认为是天生就是音乐天才。 但仔细分析， 莫扎特出生在音乐世界，3岁开始就接受高强度音乐训练， 让他拥有完美音高。 同样，2014年日本东京进行一次科学实验， 对24个普通的2～6岁小孩进行音乐训练（识别和弦），结果在一年半的时间内， 意外发现，这24个小朋友都被培养成拥有完美音高的人，也就是一个普通的人只要接受专业训练都可以发展某些看似天才的能力。</li>
<li>一万小时理论， 重复性的一万小时训练，当技能达到一定水准后（无意识状态后），再进行重复性的训练，并不能带来技能的提升，甚至技能后退。 比如开车，当学会开车后， 并且开了一年后，开车变成一种条件反射后， 再开多久的车，技术也没有多少进步，甚至后退。</li>
</ol>
<p>只有针对性的练习才能达到提高的目的</p>
<ol>
<li>要有目标，  只有有了目标，训练才会有了方向性， 一个大的目标可以拆解成为很多小的目标。</li>
<li>练习需要专注， 只有专注，才能突破自己</li>
<li>练习需要不断反馈，  哪些做的好，哪些做的不好，需要不断调整练习，克服不足。</li>
<li>练习需要不断挑战自己， 强迫自己走出舒适区。 如果持续不断待在舒适区， 就永远无法进步，大脑有偏爱稳定性的倾向。 离开舒适区，才能获得更大潜能。</li>
</ol>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>认知革命读后感</title>
    <url>/2017/knowledgerevolution/</url>
    <content><![CDATA[<p>认知革命</p>
<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>花了半天，快速学习了认知革命的课程，不能保证能理解李善友所表达的所有观点， 只能说按照我现有的知识体系，对他的理论有一个消化和吸收。<br>他有几个核心观点，<br>（1）第一性原理<br>（2）认知世界的方式<br>（3）科学革命<br>（4）非连续性。 </p>
<h1 id="第一性原理"><a href="#第一性原理" class="headerlink" title="第一性原理"></a>第一性原理</h1><p>第一性原理， 我个人非常赞同这个观点， 其实就是哲学中的现象和本质说， 只不过换了一个角度来演绎这个说法， 另外在李善友的观点中， 第一性原理是需要建立在认知世界方式中演绎归纳法的基础上， 认知世界的方式中演绎法，需要一个假设的前提， 这个前提是一个具备自证清白的共识，这个共识就是第一性原理。 我个人观点，这是哲学中现象和本质 这一理论的另外一个说法而已。</p>
<p>在我们今天人类的发展历史上， 所有的科学进步都是为了一个目标， 如何让人类变得更懒， 更舒适。 曾经paypal 的创始人Peter Thiel就说过关于创新的一段话（原话已经忘记，但意思应该差不多）， 所有的创业第一原则，就是让人们更懒去完成一些事情， 另外，乔布斯信奉的 大道至简（简单就是美） 的产品理念， 其实，就是让用户不要去花时间去思考什么是好的。今天我们程序员开发， 为什么进行模块化，分层化， 就是将每个成果固化，方便别人快速使用。 我们开源一个技术， 就是让别人不要再花时间再去重复建设， 直接站在别人的肩膀上工作。另外，比如，像浏览器之争， 今天google chrome 浏览器做到浏览器的第一把座椅， 就是google chrome 是最快的浏览器（至少号称是最快的）， 对于浏览器的众多需求中， 没有一个需求是能和性能相比， 人们永远都是追求更高，更快， 更远。</p>
<p>对比今天的产品设计， 如果我们面向用户， 那我们在思考用户的需求中， 哪些是最核心的需求， 哪些是第二原则， 哪些是末等公民。同样，如果我们中间件推出一些产品如果面向程序员， 帮助程序员开发程序， 那我们第一需求是什么， 第一需求就是如何帮助程序员更快的开发程序，帮助他们用更短的代价完成业务目标。 从技术语言的发展上， 从早期c 到c++， 再到java， 再到python， scala， go， 语言的层次愈来愈高， 一份需求需要的代码数量也变得越来越少。 </p>
<h1 id="认知世界的方式"><a href="#认知世界的方式" class="headerlink" title="认知世界的方式"></a>认知世界的方式</h1><p>在李善友的观点中， 认知世界， 有3种方式， 1. 归纳法， 2. 演绎法， 3. 带假设的归纳法； 归纳法就是通过大量的结果，来抽象出一个事务的内在联系，是一个证明在前，假设在后的逻辑思维， 由果去推因，这种思维会遭遇一个坑， 就是归纳出来的理论，只能证伪，不能存真， 只能用来验证一些东西，而不适合去做为普遍真理；而演绎法， 通过一些假设，再加上一些已知的规律， 由假设一步一步来推导结果， 是一个假设在前， 证明在后的观点， 由因去推果， 这种思维其实是更符合逻辑思维， 符合世界是由本质来推导出原因的过程， 不过这种思维会遭遇一个悖论， 演绎法需要一个证明的起点， 就是能够自证清白的原理，也就是第一性原理，当第一性原理不存在或无法自证清白时，就无法完成整个演绎； 因为2种理论都会有一些瑕疵， 因此李善友提出了一个补充，就是带假设的归纳法。</p>
<p>对世界的认知方式上， 从逻辑思维角度出发， 演绎论会更全面更严谨； 归纳法会直接，更快速。 对于我们it 工程师来说， 结合第一性原理和科学革命原来来思考， 很多的事情都是要抓住事物的本质， 少受一些干扰项干扰， 当现有的做法是从大量的结果中抽象出一套规律时， 我们需要研究是不是需要从客户的最本质需求上去思考，如何一步一步完成客户最大的痛点。 </p>
<h1 id="科学革命"><a href="#科学革命" class="headerlink" title="科学革命"></a>科学革命</h1><p>科学革命，在李善友的名词中， 有一个叫范式转换， 就是 只有管道更替， 创新是新的范式出现， 对过去很多东西，是一个颠覆性思考， 或者是完全换道考虑。 就像intel 从存储器转到cpu领域， 苹果推出iphone， 所谓 “重新定义手机”， 对过去的功能机一种完全全新的革命。</p>
<p>我对这种观点认为， 科学革命是一种颠覆性的创新， 这种创新其实很难， 也是非常少见的。 但有几点，需要注意</p>
<ol>
<li>自我革命的勇气，  当意识到一种新的创新出现时， 必须有勇气自我革命， 就是腾讯 就说过， 微信就是要革qq的命， 如果害怕革命， 当别人完成自我蜕变时， 自己就沦为鱼肉， 比如柯达， 当数码出现时，没有及时抛弃传统胶片，最终被市场抛弃。</li>
<li>这个事情大的创新都是非常非常难的， 只能从几个角度去努力尝试创新， 从认知世界的方式出发， 从用户最本质的需求上， 从另外一个赛道上全新去演绎一件事情， 会有更多的思路。 另外个人观点是， 博采众家之长， 把一个领域的成功经验移植到另外一个领域， 从而对这个领域进行全新的改变。 就像《三体》里面说的降维攻击。</li>
</ol>
<h1 id="非连续性"><a href="#非连续性" class="headerlink" title="非连续性"></a>非连续性</h1><p>李善友的观点是 “世界是由非连续性节点组成，而人类的认知是由连续性的节点来贯穿， 在一些非连续的节点之间穿插连续的桥梁， 而这些桥梁就是人类解决问题的各种手段”。 我觉得这个观点可能正确， 但没有什么大的价值。 对于一个程序员来说， 这个世界无论是连续还是非连续性的， 在计算机的世界里面都是非连续性的， 需要一些手段将他们连贯起来。 任何一个曲线都是由一串的节点贯穿起来。 </p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>《FusionInsight LibrA Huawei’s Enterprise Cloud Data Analytics Platform》解读</title>
    <url>/2020/libr/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>2018年华为在vldb 上发表了论文《FusionInsight LibrA: Huawei’s Enterprise Cloud Data Analytics Platform》。 这篇论文罗列了LibrA 的架构和很多powerful的功能， 整体看下来， 特别亮瞎眼睛的功能到没有，但在工程的角度，介绍很多很接地气的做法， 比起很多列一大堆数据公式， 一大堆机器学习的算法论文，可读性更强， 也更好理解数据库的实现和优化。 </p>
<img data-src="/img/libr-arch.png" >

<p>FusionInsight MPPDB, 又称Libr, 后来又改名为高斯200， 是针对olap 分析的一款mppdb 数据库。 高斯200 是高斯部门很成功的一款产品。从2012年开始研发， 2014年第一代原型研发出来， 现在已经在全球大量使用， 包括最大的金融企业工行。并且以用户为导向，实现了很多powerful的功能，如在线扩容， 自动tuning， sql on hdfs， 智能jit 编译执行（llvm code gen）， 提供行列混存， 数据压缩特性， 智能workload管理， 为提高高可用增加重试失败request， 用sctp 协议替换tcp协议以提高scalability等等。 </p>
<span id="more"></span>

<h1 id="发展史"><a href="#发展史" class="headerlink" title="发展史"></a>发展史</h1><p>最早的原型是基于postgres-xc来实现, 采用share nothing 架构， 支持ansi 2008 sql 语法标准。 2014年第一代原型，完成向量化执行， 并行线程执行， 并且主要用于分布式存储的元数据分析。 </p>
<p>第二代推广给金融和电信领域用户， 第二代以后以用户需求为导向， 增加很多实用的功能， 如系统可用性， 自动tuning， query 异构数据（尤其云上）， 利用新硬件等。 </p>
<p>2016年开始支持sql-on-hadoop, 可以让mpp engine跑在hadoop上， 而不用把数据从hdfs迁移到libr上， 用户对这个需求十分强烈，并让libr 在2016年成为FusionInsight 的产品。 </p>
<p>2017年Libr 上云， 四大特性， 1. 系统可用性； 2. 自动tuning； 3. 可以query 大量异构数据模型；4. 充分利用新硬件。 </p>
<h1 id="功能介绍"><a href="#功能介绍" class="headerlink" title="功能介绍"></a>功能介绍</h1><ol>
<li>高可用， 增加节点或升级，通过在线扩容或在线升级， 很少影响客户业务。 系统可以线性扩容， 以支持几百台机器去处理高并发ad-hoc。</li>
<li>自动tuning， oracle的自驱动数据库强调了数据库的自我管理和自我tuning， 利用机器学习对runtime的反馈进行自我tuning。 </li>
<li>异构存储， 客户存有各种现成的数据， DataLake 变得流行， 2016年提供SQL-ON-HADOOP 后， 这个功能大受欢迎。 </li>
<li>支持新硬件， 现代机器配置大内存， 数据库可以reside in 内存， fast io device如ssd， optane。 </li>
<li>通过在执行引擎上使用jit 动态编译 code generate 的方式来对query 进行加速。 query 产生的特定的runtime机器码可以省掉传统的解析开销（理论上还有大量的出入栈和虚函数调用等开销）， 最后对结果进行分析， jit 编译效果由编译带来的开销和优化的可执行代码带来性能提升 来决定。<br>支持行存和列存 混存。 </li>
<li>向量化执行引擎使用了最新的simd 指令集。</li>
</ol>
<h1 id="事务支持"><a href="#事务支持" class="headerlink" title="事务支持"></a>事务支持</h1><ol>
<li>datanode 是分区来管理， 支持本地acid 语义。跨分区一致性由二阶段提交和全局事务管理器来进行管理。 </li>
<li>创新的使用了gtm-lite, 分布式事务管理， 单分区事务可以被加速， 因为避免了获取中心事务id 和全局snapshot。 </li>
<li>支持read committed 事务隔离级别。</li>
</ol>
<h1 id="高可用强化"><a href="#高可用强化" class="headerlink" title="高可用强化"></a>高可用强化</h1><h2 id="连接优化"><a href="#连接优化" class="headerlink" title="连接优化"></a>连接优化</h2><p>如果使用tcp&#x2F;ip 协议， 当几百台机器互联是， connection 急剧增加， 如1000个node集群， node 之间的连接会超过1百万（1000个节点 * 100 个并发 * 10个exchange operator）， 研发了一种新的协议， 每个数据交换的提供方和消费方组成一个虚拟连接。 多个虚拟连接可以共享一个物理连接， libr 选择了sctp协议， 它支持可靠传输， 一个物理连接上可以支持64k的逻辑连接， 并且支持带外流控。 </p>
<h2 id="分组模式"><a href="#分组模式" class="headerlink" title="分组模式"></a>分组模式</h2><p>高可用主动模式和同步机制， 节省存储空间至关重要， 当备机挂了后， 会启动一个节点只做log-copy操作来提升可用性， 当备机挂了， 主节点依旧可执行bulk load和dml。 </p>
<h2 id="资源管理器"><a href="#资源管理器" class="headerlink" title="资源管理器"></a>资源管理器</h2><p>workload 管理器， 管理query的并发书， 做了限流功能， 分为3个部分， 资源池， workload组和一个controler。 资源池管理内存和磁盘i&#x2F;o， 设置各种阀值来决定是否执行。workload group 用于分配请求的query到资源池。 用应用名来标示query（估计资源分组）。</p>
<p>控制器，评估query的cost和系统当前的可用资源来决定是否运行query， 当不满足时，query 进入等待队列。 资源的预申请和反馈用于追踪系统的可用资源。 </p>
<h2 id="在线扩容"><a href="#在线扩容" class="headerlink" title="在线扩容"></a>在线扩容</h2><img data-src="/img/libr-redistribute.png" >

<p>在线扩容， 最大的问题是如何将数据分布到新的节点， 通常是对distribute key 进行计算来决定（hash算法， round-robin， modulo算法）， 通常这些算法会依赖节点数， 数据重新分布需要恢复一致性和在分配算法和实际数据位置。 hash算法可能导致数据倾向， 导致有些节点out of space， 这种情况下，需要采用新的hash 算法来进行平衡。 简单的一种做法是使用影子表， 原始表可以继续被查询， 直到 数据被分布到新的节点， 分布属性是不含新节点。 一种让数据可被访问，在重分布过程中， 使用random算法替换hash 算法。 这种方式会让性能下降， 相关查询（collocation join）不支持，另外写或修改也是不允许的。 </p>
<p>librA 使用shadow table， 但没有让表只读， 让表append-only， 并阻止存储空间的recycle。 这种方式可以很快识别哪些record是新增的，哪些是历史的， 创建一个表存储删除的数据， 然后lock 表， apply append的delta， 再apply delete的delta， 于此同时， shadow table 会增加一列隐藏列rowid。 这样好处可以一个minibatchi 接着一个minibatch 执行， 并且支持重来和resume。 </p>
<p>算法。</p>
<ol>
<li>创建T的影子表。</li>
<li>Mark t as append-only</li>
<li>disable garbage collect on T</li>
<li>create delete-delat D for delete on T</li>
<li>redistribute a segment from T 到 S</li>
<li>apply D on S, 并且重试D  当apply D完时</li>
<li>提交修改</li>
<li>重复执行执行，直到T的数据小于一个阀值</li>
<li>Lock T, 重复5 和6</li>
<li>在catalog中， Switch T as S, </li>
<li>提交修改</li>
<li>rebuild index</li>
</ol>
<h1 id="自动tuning"><a href="#自动tuning" class="headerlink" title="自动tuning"></a>自动tuning</h1><ol>
<li>基于 data exchange 的cbo来生成mpp 的plan</li>
<li>cbo 基于vector 执行和多种文件系统如orc</li>
<li>query rewrite engine, 在olap系统中添加一些额外的 rewrite 很关键</li>
<li>基于机器学习的cutting edge 技术</li>
<li>早期的优化器的机器学习是基于统计学， 需要大量的资源投入， 不通的数据来源不同的数据格式又要求合适的精度带来很大的挑战。</li>
<li>可选捕获执行参数，为后续类似提供精确参考， 这种方式比传统数据收集方式代价要小。</li>
</ol>
<h1 id="SPM"><a href="#SPM" class="headerlink" title="SPM"></a>SPM</h1><img data-src="/img/libr-spm.png" >

<p>执行器可选捕获执行计划到plan store。 每一个步骤 scan， join， aggregation， 并预估和实际获取的row counts， 一般情况下， 预估值和真实值是有很大出入的。 plan store 另外一个功能是用于sql 审计和离线分析。 </p>
<ol>
<li>优化器从plan store中获取statics 用于cbo而不是自己评估的， 如果没有找到，则使用自己评估的<br>plan store 类似一个cache，可以通过api来高效获取数据。 </li>
<li>plan store的cache 封装不同步骤的信息，保护step type， step prediction和input descritption。 </li>
<li>早期， 对于scan和join做了statics learning。这个阶段称为selectivity matching.</li>
<li>除了抽取之前存取的谓词， 自动tuning可以用于类似谓词。 可以收集predicate selectivity的反馈到谓词cache(不同之前的plan store cache)中， 并用它来评估类似的情况。 许多机器学习或statics learning 算法技术可用在这个阶段， 我们称这第二个learning为similarity selectivity。similarity selectivity模型最初用于复杂的predicate 如x》y+ c， x和y都是column，而c是常数。 在date field经常碰到这种情况 如tpch中。 这种predicates 给query 优化带来一种挑战并且他们是一种好的candidates 来做similarity selectivity。 libra 使用knn（k nearest neighbors）来获取similarity selectivity。</li>
</ol>
<h1 id="SQL-ON-Hadoop"><a href="#SQL-ON-Hadoop" class="headerlink" title="SQL-ON-Hadoop"></a>SQL-ON-Hadoop</h1><img data-src="/img/libr-sql-on-hadoop.png" >
通过pq foreign data wrapper来访问hdfs， bypass hadoop mr 框架， 引入一个调度器， 动态吧文件的分片分配到mpp的节点上进行计算， 一个hdfs目录被影射到db的外表，这个外表支持分区表。 因为hdfs的分区是基于目录的， 优化器可用做一些优化操作从而跳过一些分区而减少io操作。 
支持orc或parque 格式， 这些格式内部保护一些index，充分利用这些信息。 
hdfs 客户常常有2个额外的要求， 1. dml和acid 支持； 2. 要求更好的性能（需要知道data collocation）


<h2 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h2><ol>
<li><p>优化器可用做谓词下推优化操作，减少io。<br>query engine支持向量化执行。<br>使用动态 多维 runtime 过滤 从start join 到分区裁剪。</p>
</li>
<li><p>better data collocation<br>商业数据库通过一致性hash算法来达到data collocation， 标准db 一般要求数据shuffle在join或group by之后。</p>
</li>
</ol>
<p>2种data collocation<br>mppdb 和hdfs node之间的data collocation， mapp datanode 读取hdfs的data 通过快速的本地读接口。 </p>
<p>table collocation在hdfs node， table 被分区到hdfs 不同的data node上，执行co-located join和group 来减少网络shuffle</p>
<p>当把数据通过mppdb data node 导到hdfs上， 用一个本地描述的table 来记录每个节点每个文件的ownership。 datanode 序列号数据到特定的pax 格式文件（orc&#x2F;parquet）到hdfs。 这个本地table 由一列组成， 如blockid， min&#x2F;max 一个block每个列， 删除列的bitmap。 </p>
<p>通过hdfs hint 来尽可能本地访问。 </p>
<h2 id="DML"><a href="#DML" class="headerlink" title="DML"></a>DML</h2><p>block map 决定了block中row的可见性， 先把数据插到row base的delta table， 当delta table到了一定量，刷hdfs （orc&#x2F;parquet）， 如果在delta table删除数据，则直接删除数据， 如果数据在pax file时删除，在block map的bitmap中，标记这个行被删除， 当删除的行超过一定阀值， 执行compaction操作。 </p>
<p> # 未完待续<br>后续讲了一下优化器的优化<br>以后有机会补充一下 </p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>OLAP</tag>
      </tags>
  </entry>
  <entry>
    <title>Google Millwheel</title>
    <url>/2016/millwheel/</url>
    <content><![CDATA[<h1 id="插曲"><a href="#插曲" class="headerlink" title="插曲"></a>插曲</h1><p>google millwheel 《MillWheel: Fault-Tolerant Stream Processing at Internet Scale》， 论文应该2012年就推出来了， 以前总是快速扫一遍， 每次阅读都有一些不同的收获， 这次终于仔细拜读一下， 顺便将它翻译了一遍。</p>
<h1 id="设计目标"><a href="#设计目标" class="headerlink" title="设计目标"></a>设计目标</h1><ul>
<li>提供一种编程模型，可以满足复杂的计算逻辑而无需使用者是分布式计算专家<ul>
<li>framework能处理任何一条边或一个节点发生故障</li>
<li>可以保证数据处理仅被处理一次， 采用冥等的方式</li>
<li>用一种合适的粒度进行checkpoint， 从而可以避免外部sender 缓冲数据的buffer在多个checkpoint 之间长时间等待</li>
</ul>
</li>
<li>能够同时高效满足scalability和容错性</li>
<li>按照论文描述， 可以支持多语言</li>
</ul>
<h1 id="个人总结："><a href="#个人总结：" class="headerlink" title="个人总结："></a>个人总结：</h1><p>这篇论文，大篇幅介绍的如何做容错和扩展性， 扩展性很多时候是依赖容错性来做系统伸缩。 整体而言，扩展性和容错性应该非常不错， 但成本比较高，因为对持久化层需求很大， 而且比较偏好mini-batch设计，非常倾向去做window的aggregate， 另外对这个系统时延，感觉会在秒级以上。微软scope streaming 感觉和这个系统有很大的相似性， 不过scope 比较强调确定性（determinacy）。<br>整个设计里面一些亮点：</p>
<ul>
<li>整个dag中，组件（compuation）之间是完全解耦， 因此，可以自由对一个computation做迁移，扩容，合并。不过，这些都依赖底层的exactly-once 框架。 </li>
<li>系统数据传输都是通过rpc， 而非消息中间件， 并且组件（computation）之间可以自由订阅， 这一点超越了samza和scope。 </li>
<li>数据结构是(key, bytes[], timestamp)， 这个数据结构在后来的dataflow中发生了变化<ul>
<li>key 非常重要， 目前是对key 做group by， 相同的key保证在一个进程中串行执行， 并且每个用户自己写key-extractor 函数。 并且后续的所有操作／context，都是基于对应的key， 比如checkpoint，状态更新， 发送／更新 timer／low wwatermark。</li>
<li>bytes[], 用户自己选择序列化和反序列化</li>
<li>timestamp 完全由用户来确定，</li>
</ul>
</li>
<li>exactly-once<ul>
<li>当timer 来到时， 会做checkpoint， 这个checkpoint， 会在一个原子操作中， 把这次checkpoint的输入数据id 和输出数据 和状态更新， timer 全部更新到bigtable 中的一行， 如果有外部状态更新，用户需要自己保证冥等</li>
<li>后台存储更新需要一个sequencer， 拥有了sequencer token后，才能做数据库更新操作， 保证一个key，永远只有一个single-writer。</li>
<li>接收数据后，需要ack给发送方， 这样发送方可以做 input record id的清理工作。</li>
<li>系统会对输入消息进行去重</li>
</ul>
</li>
<li>low watermark<ul>
<li>通过一个外部全局系统injector来做lower watermark， 会订阅injector 来获取lower watermark。 </li>
<li>每个worker 从injector处获取输入源的low watermark，然后根据自己的工作状态，计算出自己的low watermark， 然后汇报给injector</li>
</ul>
</li>
</ul>
<span id="more"></span>

<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>基于模型的流式系统， 类似异常探测器，依赖于基于历史数据的预测，他们的模型必须当数据来临时，时刻更新. 按某个维度进行扩容这些系统不应该带来同等增量的成本增加。</p>
<p>Millwheel 定位于这样一个编程模型，定制于流式，低延时系统。用户实现dag节点中的应用逻辑， 这些dag可以用来定义任意并且动态topology，数据在dag中持续流动， millwheel 保证任何节点或dag中的任何边发生故障时，数据依然正确。作为系统容错性的一部分， 保证每一条record发送到它的消费者. Millwheel 提供api，通过一种幂等性方式，从用户的视角，保证record exactly-once。Millwhell用一个合适粒度（频率）对过程进行checkpoint， 消灭因为checkpoint之间长时间间隔，需要在外部senders上cache发送数据buffer的需求。</p>
<p>其他的流式系统并不提供容错，versatility(多功能性)，scalability的结合。Spark streaming和sonora 在高效checkpoint上做的很出色，但限制了用户代码可使用的operator的空间。S4 并不提供一定容错性。Storm 不能保证exactly-once, trident 要求严格的事务顺序。尝试对一些批处理模型，比如hadoop mapreduce为了达到低延时，会牺牲flexibility， 比如某些operator依赖的spark streaming rdd。Streaming sql 系统提供简洁的solution来解决常见的stream问题， 但要想直观抽象或复杂的应用逻辑还是必须使用特定语言而不是描叙语言比如sql.</p>

<p>我们提供一种流式系统编程模型和millwheel 的实现：</p>
<ul>
<li>定义一种编程模型， 允许用户创建一个复杂的流式系统而不需要丰富分布式系统的经验</li>
<li>millwheel的高效实现了scalable和容错性， 持久化状态。</li>
<li>按照论文描述， 可以支持多语言</li>
</ul>
<h1 id="设计需求"><a href="#设计需求" class="headerlink" title="设计需求"></a>设计需求</h1><p>google的zeitgeist 用于跟踪web queries的趋势。为了展示millwhell的feature， 我们examine the zeitgeist的要求。Zeitgeist 接受不间断的search queries， 执行异常探测， 尽可能快的输出哪些queries是突发（尖峰刺，spike），哪些queries是快速下滑（dip）。 系统为每个query建立一个历史模型，并对traffic做一个预期判断， 这个判断并不会引起反面影响。尽可能快的识别突发（spike）query或跌落(dip)query是非常重要的。Zeitgeist帮助google提供热点跟踪服务，google热点跟踪服务主要依赖新鲜信息。基本流水线如图所示
![img](http://img3.tbcdn.cn/5476e8b07b923/TB1BoC4NVXXXXckXXXXXXXXXXXX)
图1: 输入是持续不断的查询，输出是spiking或diping的查询
</p>

<p>为了实现zeitgeist系统，合并record到每秒间隔的bucket， 并且比较实际traffic 和基于模型推测的预期流量。 假如持续出现数量不一致， 那么我们可以很确定这个query是spiking或dipping。同时， 我们用新数据更新模型并且存储他们以备将来使用。

<h2 id="Persistent-storage"><a href="#Persistent-storage" class="headerlink" title="Persistent storage"></a>Persistent storage</h2><p>注意这个实现需要短期和长期的storage。 一个spike可能仅仅持续几秒钟，因此只依赖一个小时间窗口的state， 然而模型数据会几个月持续不断更新</p>
<h2 id="Low-watermarks"><a href="#Low-watermarks" class="headerlink" title="Low watermarks"></a>Low watermarks</h2><p>一些zeitgeist用户对探测traffic中的dips很感兴趣， 指一个query的容量是非同寻常的低（比如埃及政府关闭了internet）。在一个输入数据来自世界各地的分布式系统中，数据的到达时间并不严格对应数据的产生时间，因此识别出一个t&#x3D;1296167641的突然查询是因为在线路上delay了，还是根本就不存在。millwhere通过low watermark来跟踪这个问题， low watermark显示所有数据到某个时刻都已经到达。在系统中，low watermark跟踪所有的pending events。在这个例子中， 如果low watermark 提前过去时间t并且没有查询来临， 可以认为这些查询根本就不存在，而不是在网络上的延迟。 这种语义避免了要求在输入数据源上的单调递增，因为在真实环境中，乱序是很正常的。</p>
<h2 id="防止重复"><a href="#防止重复" class="headerlink" title="防止重复"></a>防止重复</h2><p>重复的record 会导致误认为错误的spike, 另外有一些计费的用户。millwheel在框架层面提供exactly-once， 而非业务方自己去处理这种问题。</p>
<h2 id="总结-millwheel需求："><a href="#总结-millwheel需求：" class="headerlink" title="总结 millwheel需求："></a>总结 millwheel需求：</h2><ul>
<li>数据需要尽可能快的被推送到consumer</li>
<li>持久化状态抽象需要被集成到系统一致性模型中，并可以被用户使用</li>
<li>乱序的数据可以被优雅处理</li>
<li>系统产生单调递增的low watermark</li>
<li>时延不受扩容影响</li>
<li>系统应该提供exactly-once的delivery能力</li>
</ul>
<h1 id="系统概况"><a href="#系统概况" class="headerlink" title="系统概况"></a>系统概况</h1><p>millwheel实际上就是一系列用户定义的transform操作组成的dag 图， 我们称这些transform为compuation操作，任何一个transform都能并行运行在任意的机器上。因此，用户无需考虑在一个合适范围内负载平衡。</p>
<p>在millwheel里面的输入和输出都是用(key, value, timestamp)来表示, key 是含有语义含义的元数据字段，value是任意的字符串，代表整个record。用户代码运行的context被限定到一个特定的key，每个computation根据自己的逻辑为每个输入源定义key。 比如， zeitgeist中某些computation为了计算每个query的统计信息，会选择搜索字段作为key，而另外一些compuation为了统计基于地理位置的统计信息，会选择地理位置为key。 而triple里面的timestamp可以由用户随意定义（但通常都是墙钟时间），而mill wheel根据timestamp来计算低水位。如果一个用户想要aggregate search term的每秒统计值， 他就需要assign timestamp 为这个search被处理的时间。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/key.jpg" >
</div>

<p>一个compuation的output可以成为另外一个computation的输入，从而形成一个pipeline。用户可以动态增加或删除一个compuation到这个topology中而无需重启这个topology。一个compuation可以任意处理records，新建，修改，删除，过滤等操作。</p>
<p>millwheel提供框架api来冥等处理record。 用户只需要使用系统提供的通信和state抽象，所有failure和重试都被隐藏在系统内部。这样可以让用户代码简单，并只专注用户自己的逻辑。在一个computation context中，用户可以获取一个per-key和per-computation的持久化store，这样就可以基于key的aggregation。这种设计依赖下面的基本原则：</p>
<p><b>分发保障</b>：所有因处理record而产生的内部update都会自动基于per－key做checkpoint并保证exactly－once delivery。这种特性不需要依赖外部存储。</p>
<h1 id="核心概念"><a href="#核心概念" class="headerlink" title="核心概念"></a>核心概念</h1><p>数据在一个dag中分发，每一个环节都独立操作和emit数据。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/api.jpg" >
</div>



<h2 id="computation："><a href="#computation：" class="headerlink" title="computation："></a>computation：</h2><p>用户代码运行在compuation中。 当接受到数据时，会调用compuation，会触发用户定义的一些操作，比如连接外部存储， 输出数据或操作其它millwhell的数据。如果连接外部存储，则用户来保证操作外部存储的行为具有冥等性。computation在一个单key的context中执行，但key之间是相互不可知的。如下图所示， 另外一个key的所有操作是串行的，但多个不同的key可以并行被处理</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/key-serial.jpg" >
</div>


<h2 id="key"><a href="#key" class="headerlink" title="key"></a>key</h2><p>key是mill wheel中不同record aggregate和comparison最重要的抽象，系统中每一个record，消费者需要定义一个key－extraction 函数, 这个key-extraction函数会分配一个key给这个record。 用户代码运行在某个key的context下，只能允许访问这个key相关的stat。 举例来说， 在zeitgeist系统中，一个好的选择key的方式是使用search text， 从而，我们可以基于query 的text来进行counts和query模型的aggregate。同样不同的系统，可以使用不同的key-extract函数来处理相同的数据源来获取不同的key。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/key-extract.jpg" >
</div>

<h2 id="streams"><a href="#streams" class="headerlink" title="streams:"></a>streams:</h2><p>streams 表示mill wheel内不同computation的分发机制。一个computation订阅零个或多个input，然后产生一个或多个stream， 系统保证分发正确性。每个stream内每个consumer有自己key-extract 函数，一份stream可以被多个consumer订阅. streams 根据名字来唯一标识，任何computation可以消费任何stream， 也可以产生records到任何stream。</p>
<h2 id="persistent-stat（持久化状态）："><a href="#persistent-stat（持久化状态）：" class="headerlink" title="persistent stat（持久化状态）："></a>persistent stat（持久化状态）：</h2><p>millwheel里面的持久化状态是基于per－key的透明字符串。用户提供序列号和反序列化函数，可以使用类似protocol buffer这种方便的机制来做。persistent stat存在高可用的存储中，从而保证数据一致性，并对终端用户完全透明。常见状态使用，比如一个时间窗口的record或等待join的数据的计数器aggregate。</p>
<h2 id="low-watermark（低水位）："><a href="#low-watermark（低水位）：" class="headerlink" title="low watermark（低水位）："></a>low watermark（低水位）：</h2><p>computation的low watermark 限制了接受record 的timestamp 的一定范围。</p>
<p><b>定义</b>： millwheel 提供一个基于数据流水线的low watermarks的迭代定义。 对于一个computation a， 设定为最老的work的timestamp对应最老的未完成的record。定义low watermark为：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">min（最老a的工作， c的低水位（c 输出数据到a））。</span><br></pre></td></tr></table></figure>
<p>如果没有输入数据，则低水位值等同于oldest work 值。<br>低水位值由injectors （从外部系统获取数据，并发送到millwheel）进行seed，经常用外部系统监控pending work 作为评估手段， computation 期望少量的late records（小于低水位）。zeitgeist处理late records的方法就是知己丢弃这种数据， 但会跟踪有多少数据被丢弃掉了（一般在0.001%）。 一些流水线当接受到晚到的数据，可以根据这个进行反向矫正。系统保证一个computation的低水位单调递增，即使对于晚到的数据。</p>
<p>通过等待compuation 的低水位（提前一定值），用户可以有一个完整的picture 关于他们的到低水位时间的数据，就像之前zeitgeist的dip 探测系统展示的一样。当分配timestamp到新的或aggregate的record， 取决于用户去选择一个时间戳，只要不小于来源record的timestamp。通过millwheel低水位可以测量进度。如图所示：</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/key-extract.jpg" >
</div>

<p>上图中，watermark像record一样前进。 pending works在时间轴上面，完成的在时间轴下面。新到的数据为pending work， 带着时间戳值提前于低水位值，数据可以乱序执行，低水位值反映出系统所有的pending work</p>
<h2 id="timers"><a href="#timers" class="headerlink" title="timers"></a>timers</h2><p>timers 是一个基于key的编程hook， 由一定的墙钟时间或低水位值进行触发。 timer 由一个computation的context创建并运行。用户来决定是使用墙钟还是低水位，比如邮件提醒系统使用墙钟，或者基于window进行aggregate的分析系统是基于low watermark。一旦设定，保障以时间戳的递增的顺序触发timer。timer会在持久化存储中记录日志并保障当机器故障时能够重启恢复。 当触发一个timer， 它运行一定的用户函数并像普通输入数据一样需要保障exactly-once。 zeitgeist的dips简单实现就是用一个指定时间的bucket的终止时间设置一个低水位timer， 并当监控的流量低于预测的模型时汇报一个dip。<br>timer的使用是可选的， 用户无timer barrier需求时可以直接跳过。 举例来说， zeitgeist 能够探测spiking 查询而无需timers， 发现一个spike 无需完整的数据视图。 如果观察的流量已经超过预测模型的预测值， 延迟的数据会加到总数据中并增加spike的大小。</p>
<h1 id="api"><a href="#api" class="headerlink" title="api"></a>api</h1><p>如下图所示， 提供借口访问所有的抽象（状态，timer和输出）。一旦设定，这些代码会自动在framework中运行。 用户无需构建任何per-key的locking语义， 系统是基于key的序列化执行。 </p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/computation-api.jpg" >
</div>

<h2 id="computation-api"><a href="#computation-api" class="headerlink" title="computation api"></a>computation api</h2><p>用户代码的2大入口点是ProcessRecord和ProcessTimer， 当数据来了会触发ProcessRecord，当timer 超时时触发ProcessTimer。这些构成了应用的compation。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/computation-run.jpg" >
</div>

<p>在这些hook（ProcessRecord和ProcessTimer）执行过程中， 系统提供api 获取或控制 per-key 状态， 产生record和设置timer。 如下图所示， 展示了这些接口之间交互。 注意并没有错误恢复的逻辑，因为由框架自动进行错误恢复。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/api-interactive.jpg" >
</div>

<h2 id="injector／low-watermark-api"><a href="#injector／low-watermark-api" class="headerlink" title="injector／low watermark api"></a>injector／low watermark api</h2><p>在系统层面， 每一个computation会为所有自己的pending work(处理中或队列中等待的deliver)计算一个低水位值。可以分配一个timestamp值给持久化state 。这样系统可以自动roll up，为了提供一种透明的timers 的api 语义， 用户很少直接和低水位值进行交互，但通过分配给record的timestamp间接计算出他们。</p>
<p><b>injector</b>：injector从外部获取数据，并发送到millwheel中。因为injector会为流水线其他部分seed low watermark，injector可以publish 一个injector low watermark到他的output streams中， 而其他subscriber可以获取他们。举例来说， 一个injector分析日志文件， 可以通过计算未完成文件的最小创建时间来计算low watermark。<br>一个injector可以跨进程运行，因此这些进程的低水位aggregate值会作为injector的低水位。 用户设定一组injector进程，从而防止injector单点故障。 实际上，常见的类型如日志，pubsub service等都有现成的injector， 用户无需再实现。如果一个injector 违反低水位语义并且发送一个迟于低水位的record， 用户代码可以决定丢弃这个record或者不对它进行现成aggregate的update。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/injector.jpg" >
</div>

<h1 id="容错性"><a href="#容错性" class="headerlink" title="容错性"></a>容错性</h1><h2 id="分发保障"><a href="#分发保障" class="headerlink" title="分发保障"></a>分发保障</h2><p>大部分millwheel 编程模型的概念性简洁让用户代码无需冥等，但却可以达到冥等的效果， 让用户不用担心这些问题（数据可靠性问题）。</p>
<h2 id="发送保障"><a href="#发送保障" class="headerlink" title="发送保障"></a>发送保障</h2><h3 id="exactly-once-delivery"><a href="#exactly-once-delivery" class="headerlink" title="exactly-once delivery"></a>exactly-once delivery</h3><p>当computation接收到一个record后：</p>
<ul>
<li>record会被检查是否和之前分发的重复，重复的会被丢弃。</li>
<li>用户代码只处理输入的数据， 会产生timer／state／production的变化。</li>
<li>pending changes会被提交到backing store</li>
<li>发送者是acked的</li>
<li>会发送pending downstream productions</li>
</ul>
<p>作为一个优化，上述的操作可能被合并到对多个record的一个checkpoint。发送会不断重试直到他们被ack，这样可以保证at-least-once. 因为机器或网络故障，需要重试机制。然而， 这会带来一种问题， receiver在ack前crash了，即使它已经被成功处理并持久化它的状态。 这种情况下，当sender发送多次时，我们需要防止重复处理数据。<br>当computation产生一个数据（production）时，系统会分配一个唯一的id 给record。通过这个唯一id 可以识别重复的record。 如果相同record后面重发了， 会把它和jounaled id进行比较，然后扔弃并ack这个重复record。因为我们不能存储所有的重复数据到内存中，我们使用bloom filter来提供一个快速判断。对于boolm filter miss的event， 我们需要从backing store去进一步判断这个record是否是重复的。当所有内部sender完成发送时， 会做record id 垃圾回收。 对于经常发送late data的injector， 系统垃圾回收会额外delay一个对应的slake value。然而，exactly－once的数据会被几分钟被清理掉。</p>
<h3 id="strong-production"><a href="#strong-production" class="headerlink" title="strong production"></a>strong production</h3><p>因为millwheel是乱序处理record， 系统会在发送产生数据前，在原子状态更新里面进行checkpoint 生产数据。称这种checkpoint方式为strong production。举例来说， 一个computation 根据墙钟时间做aggregate并发送count结果给下游； 如果没有checkpoint， 对于一个产生window count 的computation，在存储它的状态前crash。一旦这个computation重启回来， 它可能接受到另外的record在产生相同aggregate，产生一个record在字节上是不同于之前的window但实际上是相同的window。为了正确处理这种逻辑， 下游的消费者需要一个复杂的冲突解决方案。在millwheel使用一个简单可行的solution， 因为用户的逻辑已经被系统保证为冥等来运行。<br>millwheel 会用bigtable在作为storage 系统，它高效实现blind write（直写， 和read-modify-write相反），像日志一样来进行checkpoint。 当一个进程重启后， checkpoint会被加载到内存中并被replay。 checkpoint一旦数据发送成功后（production successful）会被删除。</p>
<h3 id="weak-production-和冥等"><a href="#weak-production-和冥等" class="headerlink" title="weak production 和冥等"></a>weak production 和冥等</h3><p>通过strong production， exactly-once delivery， token使用从而让计算冥等。然而，一些compuation已经冥等了， 可以不需要这些措施，因为这些措施会消耗资源和加大latency。因此，用户可以自己控制disable strong production或exactly-once delivery 。 系统层面，disable exactly－once可以简单允许重复record 来实现，但禁止strong production需要注意性能影响。</p>
<p>对于weak production， 不是在发送数据前进行checkpoint 产生数据， 在持久化state之前，乐观的发送给下游。这会带来一个新问题， 流水线的完成时间会被大幅翻倍，尤其是连续stage，因为他们在等待下游的ack records。 这种情况会大大增加端到端的latency因为流水线深度增加。 举例来说，我们假设在某个分钟有1%的概率机器会出现故障， 至少出现一次failure的可能性就会按照流水线的深度大大提高，假设流水线深度是5， 那每分钟出现失败的概率就是5%。为了降低这种失败概率， 通过checkpoint 小比例的产生数据（production）， 允许这些stage 可以ack 他们的sender （说白了，就是strong production就是每个stage 做checkpoint， week production就是 在发送前做checkpoint，并且要求下游能够做数据去重）。 通过选择性checkpoint 这种方式，millwheel可以即提高端到端的latency并减少整体的资源消耗量。</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/weekproduction.jpg" >
</div>

<p>当流水线是冥等的computation时，上述的方案是可行的， 因为重试不会影响正确性并且downstream production会是重试不可知。 真实的冥等例子就是无状态的filter， 重发的数据不会影响结果。</p>
<h2 id="state-manipulation（状态控制）"><a href="#state-manipulation（状态控制）" class="headerlink" title="state manipulation（状态控制）"></a>state manipulation（状态控制）</h2><p>在millwheel 用户状态存储中， 有2种状态， hard state 会被持久化到backing 存储上，而soft state 则包含任何在内存中cache或aggregate。 millwheel 会提供下面保证：</p>
<ul>
<li>系统不能丢失数据</li>
<li>更新state必须遵守exactly-once语义</li>
<li>系统中所有的持久化的数据必须是在任何时间点都是一致性的</li>
<li>低水位必须反映系统中所有pending state</li>
<li>timer必须按某个key顺序被触发。</li>
</ul>
<p>为了避免在持久化状态时的不一致， millwheel会封装所有的基于key的update到一个原子操作中。 在任何一个时间点，有可能因为非预期事件或处理失败导致中断处理。就像前面所述， exactly-once 数据在相同的操作中被更新， 增加它到基于per－key 一致性封装中。<br>因为工作会在不同机器之间迁移， 对于数据一致性的主要威胁是僵死的writer和网络里残留的写操作到backing store。为了跟踪这些问题， 我们attach 一个sequencer token到每一个write， backing store的代理， 在允许commit write前做检查。新worker在开始工作之前使所有现存的sequencer失效， 因此没有残留的更新能够成功。这个sequencer是一种类似lease 加强机制， 类似Centrifuge系统。 因此，我们可以保证， 对于一个指定的key， 在一个时间点，仅仅一个worker能被更新那个key相关内容。<br>这种single－writer 同样对于soft state非常关键， 但事务无法保证single-writer。 以pending timer来说， 如下图所示：</p>
<div align="center" style="width: 480px; height: auto;  text-align: center;" >
        <img data-src="/img/millwheel/softstage.jpg" >
</div>

<p>当僵死进程b 触发一个延迟写的transaction 作为response 给a， 在transaction 开始， 新的b， b-prime 执行初始化扫描timer， 当扫描结束， transaction 执行并且a 接收ack， 这样b-prime 就出在一个非一致状态。 就会永远丢失一个timer， 并且这个timer触发的更新操作就会被延迟， 因此，对于一些延迟敏感的系统，这些是不可接受的。</p>
<p>更进一步， 相同的情况会在checkpoint的production（输出）下会出现， 因为跳过一个backing store的初始化scan使它变的对系统不可知。 这个production将不会对低水位有操作直到它被发现。在一个中间时间，millwheel有可能汇报一个错误的低水位给consumer。 更近一步，因为低水位时单调递增，millwheel不能纠正这个错误值。因为违背low watermark原则，各种检查会出现， 包括发送非完善timer和非结束window 输出。</p>
<p>为了快速从失效状态中恢复， millwheel中每个computation worker 可以以一个合适的粒度做checkpoint。 millwheel的soft state状态一致性可以最小化意外失效。 可以执行异步扫描时，允许computation继续处理input。</p>
<h1 id="系统实现"><a href="#系统实现" class="headerlink" title="系统实现"></a>系统实现</h1><h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>millwheel是一个分布式系统， 所有的computation运行在一台或多台机器上， 数据流通过rpc进行相互通信。 每台机器上， millwheel 排列输入work并管理进程级别元数据， 分配合适的用户computation到进程上。</p>
<p>由master进行调度或负载平衡，  master 将每个computation 切分成一组key intervals，并分配这批key intervals到一组机器上。 当cpu或内存负载大时， 对key intervals做迁移或split，或merge， 每一个interval分配一个sequencer， 当发生改变（迁移，split， merge）时，将老的sequencer失效。</p>
<p>对于持久化状态， 使用bigtable或spanner系统， 提供原子行更新操作。 一个key的timer， pending production（输出）和持久化状态全部存在一行数据中。</p>
<p>当一个interval发生迁移时， millwheel从backing store中扫描元数据从而进行恢复。 初始化扫描存储在内存中，pending timer和checkpointed的production（输出）， 从而和后端存储在状态上是一致的。 这种方式 通过single-writer 语义来实现。</p>
<h2 id="low-watermark"><a href="#low-watermark" class="headerlink" title="low watermark"></a>low watermark</h2><p>为了保证数据一致性， 由一个全局可靠的子系统来实现low watermark。 millwheel 通过一个中央控制系统（带授权）来完成lower mark， 它会跟踪所有的lower watermark并打日志到持久化层， 防止进程失效时产生错误值。<br>每个进程aggregate 当前自己工作的timestamp 信息，并汇报中央控制系统， 它们包括所有的checkpointed或pending的production（输出），pending的timer或持久化状态。 每个进程可以在内存中高效完成这个动作，而无须执行代价昂贵的后段存储查询。 因为进程时基于key interval进行分配的， 因此low watermark也是bucket到key interval中并发送到中央控制系统。<br>为了正确计算系统的low watermark， 中央控制系统可以访问所有的low watermark信息。 当aggregate per-process的更新时， 它通过build 一个 low watermark的interval map为一个compuation，从而跟踪一个compuation的完成信息。当任何interval丢失时， 对应失效interval的low watermark 不变直到汇报一个新的值。 中央控制系统然后广播low watermark值到系统所有的computation。</p>
<p>消费者可以订阅数据的所有sender的lower watermark，然后计算它所有输入数据的low watermark的最小值。 这个计算最小值的工作在worker中执行，而非中央控制系统，是因为一致性， 中央控制系统的lower watermark是所有worker的最小值，但非输入worker的最小值。同样的，中央控制系统的lower watermark不会修改worker的lower watermark。<br>为了保持一致性， 所有的low watermark更新需要sequencer， 类似single-writer 到所有跟新到key interval state， 这些sequencer保证仅仅这个key的最新owner才能更新它的lower watermark值。 为了扩展性， 这个授权可以在机器之间share。</p>
]]></content>
      <categories>
        <category>BigData</category>
        <category>流计算</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>DataFlow</tag>
        <tag>Stream Process</tag>
      </tags>
  </entry>
  <entry>
    <title>《OceanBase开发者手册》之四 如何修改OceanBase文档</title>
    <url>/2021/modify_ob_docs/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>《OceanBase开发者手册》 主要指导开发者如何参与到OceanBase 的研发, 铺平参与OceanBase 开发的准备工作遇到的问题, 当前章节大概这几篇文章, 未来可能会增加部分文章, 目前OceanBase 源码参考OceanBase 开源官网的<a href="https://open.oceanbase.com/articles/8600129">《开源数据库OceanBase源码解读》 系列</a> :</p>
<ol>
<li>如何编译OceanBase源码</li>
<li>如何设置IDE开发环境</li>
<li>如何成为OceanBase Contributor</li>
<li>如何修改OceanBase文档</li>
<li>如何debug OceanBase</li>
<li>如何运行测试</li>
<li>如何修bug<br>​</li>
</ol>
<p>在OceanBase 修改文档的过程, 和修改代码的过程完全一样, 可以参考《如何成为OceanBase Contributor》直接修改文档, 如果不做文档修改的预览, 比如直接修改少量的错别字, 可以直接修改, 但如果增加大段文字或新增文章, 建议做预览一下. 那在这种情况下, 需要看看, 修改的效果如何. 可以安装mkdocs, 对修改的效果进行预览. </p>
<span id="more"></span>
<p>​</p>
<h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h1 id="Build-documentation-with-MkDocs"><a href="#Build-documentation-with-MkDocs" class="headerlink" title="Build documentation with MkDocs"></a>Build documentation with MkDocs</h1><p>OceanBase documentation is built with <a href="https://www.mkdocs.org/">MkDocs</a>. You can check <a href="mkdocs.yml"><code>mkdocs.yml</code></a> for more information.<br>Please install MkDocs according to <a href="https://www.mkdocs.org/user-guide/installation/">the installation documents of MkDocs</a></p>
<h2 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h2><p>Before installing dependencies, please make sure you have installed a recent version of Python 3 and pip.</p>
<p>Then you can run the following command in your terminal at current directory:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ pip install -r requirements.txt</span><br><span class="line">$ pip install mkdocs-material</span><br></pre></td></tr></table></figure>
<h2 id="Build-the-documentation"><a href="#Build-the-documentation" class="headerlink" title="Build the documentation"></a>Build the documentation</h2><p>You can build the documentation by running the following command:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ mkdocs build</span><br></pre></td></tr></table></figure>

<p>This will create a new directory to store the output files, which is <code>site/</code> by default.</p>
<h2 id="Start-a-server-locally"><a href="#Start-a-server-locally" class="headerlink" title="Start a server locally"></a>Start a server locally</h2><p>You can start a server locally by running the following command:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ mkdocs serve</span><br></pre></td></tr></table></figure>
<p>Open up <a href="http://127.0.0.1:8000/">http://127.0.0.1:8000/</a> in your browser, and you’ll see the default home page.</p>
<h2 id="Modify-pages"><a href="#Modify-pages" class="headerlink" title="Modify pages"></a>Modify pages</h2><h3 id="Edit-a-page"><a href="#Edit-a-page" class="headerlink" title="Edit a page"></a>Edit a page</h3><p>If you want to modify the content of a page, you can edit the markdown file in <code>docs/</code> directory directly.</p>
<h3 id="Modify-the-layout-of-pages"><a href="#Modify-the-layout-of-pages" class="headerlink" title="Modify the layout of pages"></a>Modify the layout of pages</h3><p>To modify the layout of pages, you need to edit <code>mkdocs.yml</code>.</p>
<p>For configuration details, see <a href="https://www.mkdocs.org/user-guide/configuration/">MkDocs User Guide</a>.</p>
<p>Note the following rules when editing documents:</p>
<ul>
<li>All paths in <code>nav</code> must be relative to the <code>docs_dir</code>, which is <code>docs</code> by default. So here <code>./</code> is equivalent to <a href="docs">docs</a>.</li>
<li>All internal links must be relative paths, as MkDocs only supports regular Markdown linking syntax.</li>
</ul>
]]></content>
      <categories>
        <category>OceanBase</category>
      </categories>
      <tags>
        <tag>OceanBase</tag>
      </tags>
  </entry>
  <entry>
    <title>监控工具总结</title>
    <url>/2021/monitor_tool/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>将过去使用的几个监控工具分享一下， 也方便自己以后查找。 </p>
<ul>
<li><a href="/knowledge/tools/monitor_tools/sar.html">sar， Linux 上最为全面的系统性能分析工具之一</a></br></li>
<li><a href="/knowledge/tools/monitor_tools/pidstat.html">pidstat， 系统资源监控工具之一</a></br></li>
<li><a href="/knowledge/tools/monitor_tools/iostat.html">iostat， IO性能分析工具之一</a></br></li>
<li><a href="/knowledge/tools/monitor_tools/network.html">network 监控与分析工具</a></br></li>
<li><a href="/knowledge/tools/monitor_tools/perf.html">perf， 性能分析工具之一</a></br></li>
<li><a href="/knowledge/tools/monitor_tools/trace.html">trace系统</a></br></li>
<li><a href="/knowledge/tools/monitor_tools/vmstat.html">vmstat， 内存监控工具之一</a></br></li>
<li><a href="/knowledge/tools/monitor_tools/memory.html">内存监控与分析工具</a></br></li>
<li><a href="/knowledge/tools/monitor_tools/java_gc.html">对java gc 性能调优</a></br></li>
<li><a href="/knowledge/tools/monitor_tools/java_mem.html">java memory 监控与分析</a></br></li>
</ul>
]]></content>
      <categories>
        <category>monitor tools</category>
      </categories>
      <tags>
        <tag>monitor</tag>
      </tags>
  </entry>
  <entry>
    <title>Mac 下 clion 单机debug mysql</title>
    <url>/2019/mysql-build/</url>
    <content><![CDATA[<p>最近花了几天的时间搭建和编译MySQL 环境</p>
<p>因为电脑之前安装过很多软件， 很多环境已经有一些混乱， 给编译和debug MySQL 带来很多坑。 踩过的坑，远超过网上的描述，还好在同事的帮助下和自己摸索，慢慢搞定。</p>
<span id="more"></span>
<h1 id="前期准备："><a href="#前期准备：" class="headerlink" title="前期准备："></a>前期准备：</h1><ol>
<li><p>安装软件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">brew install autoconf automake m4 libtool make cmake bison gcc openssl</span><br></pre></td></tr></table></figure></li>
<li><p>检查&#x2F;etc&#x2F;hosts<br>检查&#x2F;etc&#x2F;hosts 里面是否有localhost， 如果没有，增加127.0.0.1 localhost localhost.localdomain 到localhost， 否则， 在debug mysql 时，会出现 protobuffer 找不到host 错误。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo vi /etc/hosts</span><br></pre></td></tr></table></figure>
</li>
<li><p>检查环境变量<br> 将一些环境变量 CPPFLAGS&#x2F;LDFLAGS&#x2F;LIBRARY_PATHLD_LIBRARY_PATH&#x2F;LIBTOOL&#x2F;LIBTOOLIZE&#x2F;CC&#x2F;GCC 清空掉。<br>之前，因为安装Anaconda2 导致系统有一大堆变量。 另外因为编译过其他软件，修改了大量的编译相关的环境变量， 这些都给我们埋坑。</p>
</li>
</ol>
<p>检查一下文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/.bashrc</span><br><span class="line">~/.bash_profile</span><br><span class="line">/etc/profile</span><br><span class="line">/etc/bashrc</span><br></pre></td></tr></table></figure>
<p>找到这些环境设置文件，将这些环境变量给注释掉。</p>
<ol start="4">
<li>升级xcode 到最新</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">lldb --version</span><br><span class="line">lldb-1001.0.12.1</span><br><span class="line">  Swift-5.0</span><br></pre></td></tr></table></figure>
<p>xcode 如果没有升级到最新， 编译时会出现protobuffer 编译错误。</p>
<h1 id="编译："><a href="#编译：" class="headerlink" title="编译："></a>编译：</h1><ol>
<li>下载源码</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/mysql/mysql-server</span><br></pre></td></tr></table></figure>

<p>可以选择一个稳定版， 比如8.0.16</p>
<ol start="2">
<li><p>clion 导入 mysql 代码</p>
</li>
<li><p>配置cmake</p>
</li>
</ol>
<img data-src="/img/clion_cmake.jpg" >


<img data-src="/img/clion_cmake2.jpg" >

<p>cmake 配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-DCMAKE_INSTALL_PREFIX=&quot;/Users/longda/work/data/mysql/mysql&quot; -DSYSCONFDIR=&quot;/Users/longda/work/data/mysql/mysql&quot;  -DMYSQL_DATADIR=&quot;/Users/longda/work/data/mysql/data&quot;   -DWITH_DEBUG=1                -DWITH_DEBUG_SYNC=1      -DCMAKE_C_FLAGS_RELWITHDEBINFO=&quot;-O0 -g&quot; -DCMAKE_CXX_FLAGS_RELWITHDEBINFO=&quot;-O0 -g&quot; -DINSTALL_LAYOUT=STANDALONE        -DMYSQL_MAINTAINER_MODE=0          -DWITH_EMBEDDED_SERVER=0           -DWITH_EXTRA_CHARSETS=all          -DDEFAULT_CHARSET=utf8mb4          -DWITH_MYISAM_STORAGE_ENGINE=1     -DWITH_INNOBASE_STORAGE_ENGINE=1   -DWITH_PARTITION_STORAGE_ENGINE=0  -DWITH_CSV_STORAGE_ENGINE=0        -DWITH_ARCHIVE_STORAGE_ENGINE=0    -DWITH_BLACKHOLE_STORAGE_ENGINE=0  -DWITH_FEDERATED_STORAGE_ENGINE=0  -DWITH_PERFSCHEMA_STORAGE_ENGINE=0 -DWITH_EXAMPLE_STORAGE_ENGINE=0    -DWITH_TEMPTABLE_STORAGE_ENGINE=1  -DBUILD_TESTING=ON                 -DUSE_CTAGS=0                      -DENABLE_DTRACE=0                  -DENABLED_PROFILING=1              -DENABLED_LOCAL_INFILE=1 -DDOWNLOAD_BOOST=1 -DWITH_BOOST=/Users/longda/work/company/taobao/tools/boost/ -DOPENSSL_ROOT_DIR=/usr/local/Cellar/openssl/1.0.2r -DMYSQL_SERVER_SUFFIX=&quot;rds-dev&quot;</span><br></pre></td></tr></table></figure>

<img data-src="/img/clion_cmake3.png" >

<img data-src="/img/clion_cmake4.jpg" >
## 编译：

<p>用 command + f9, 执行编译， 一般情况下 编译是成功的</p>
<h2 id="开始debug"><a href="#开始debug" class="headerlink" title="开始debug"></a>开始debug</h2><ol>
<li>初始化mysql data 目录<br>编译成功后， 在目录cmake-build-debug(或者cmake-build-cmake)下 执行</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./bin/mysqld --initialize-insecure --basedir=/Users/longda/work/data/mysql/mysq --datadir=/Users/longda/work/data/mysql/mysq/data</span><br></pre></td></tr></table></figure>
<p>以insecure的方式初始化MySQL密码为空</p>
<p>&#x2F;Users&#x2F;longda&#x2F;work&#x2F;data&#x2F;mysql&#x2F;mysq 为mysql 的binary 目录， 可以根据实际情况进行设置</p>
<ol start="2">
<li>下断点调试<br>最后， 打开sql&#x2F;main.cc， 下断点 既可以调试</li>
</ol>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>聚簇索引介绍</title>
    <url>/2020/mysql-cluster-index/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>【转载】<a href="http://www.manongjc.com/detail/17-ssuthexbuzbjmlb.html">http://www.manongjc.com/detail/17-ssuthexbuzbjmlb.html</a><br>本文章向大家介绍Mysql聚簇索引和非聚簇索引，主要包括Mysql聚簇索引和非聚簇索引使用实例、应用技巧、基本知识点总结和需要注意事项，具有一定的参考价值，需要的朋友可以参考一下。</p>
<h1 id="基本介绍"><a href="#基本介绍" class="headerlink" title="基本介绍"></a>基本介绍</h1><p>聚簇索引并不是一种单独的索引类型，而是一种数据存储方式，具体的细节依赖于实现方式，InnoDB的聚簇索引实际上在同一个结构中保存了B+Tree索引和数据行。</p>
<p>当表中有聚簇索引时，它的数据实际上存储在索引的叶子页中（叶子页中包含了行的全部数据）。而没有聚簇索引时B+Tree叶子页存放的是指向数据的指针。（页是mysql存储引擎最小的存储单元，InnoDB每个页默认大小为16k）可以理解为 有聚簇索引时，数据和对应的叶子页在同一页中，没有聚簇索引时，叶子页和对应的数据不在同一页中。</p>
<p>InnoDB存储引擎通过主键聚集数据(聚簇索引)，如果没有定义主键，InnoDB会选择一个唯一的非空索引代替。如果没有唯一索引，InnoDB会隐式定义一个主键来作为聚簇索引。InnoDB 只聚集在同一个页面中的记录。包含相邻健值的页面可能相距甚远。</p>
<span id="more"></span>
<p>MyISAM中主键索引和其他索引 都指向物理行 (非聚簇索引)</p>
<p>下图展示了聚簇索引是如何存放的（图片来自《高性能MySQL(第三版)》）：</p>
<h2 id="聚簇索引和非举措索引的区别："><a href="#聚簇索引和非举措索引的区别：" class="headerlink" title="聚簇索引和非举措索引的区别："></a>聚簇索引和非举措索引的区别：</h2><p>聚簇索引，索引的顺序就是数据存放的顺序（物理顺序），只要索引是相邻的，那么对应的数据一定也是相邻地存放在磁盘上的。一张数据表只能有一个聚簇索引。（一个数据页中数据物理存储是有序的）</p>
<p>非聚簇索引通过叶子节点指针找到数据页中的数据，所以非聚簇索引是逻辑顺序。</p>
<h2 id="聚集索引的优点："><a href="#聚集索引的优点：" class="headerlink" title="聚集索引的优点："></a>聚集索引的优点：</h2><p>数据存放的顺序和索引顺序一致,可以把相关数据保存在一起。例如实现电子邮箱时，可以根据用户 ID 来聚集数据，这样只需要从磁盘读取少数的数据页就能获取某个用户的全部邮件。如果没有使用聚簇索引，则每封邮件都可能导致一次磁盘 I&#x2F;O。<br>数据访问更快，聚簇索引将索引和数据保存在同一个B-Tree中，因此从举措索引中获取数据通常比非聚簇索引查找更快。<br>使用覆盖索引扫描的查询可以直接使用页节点中的主键值（二级索引(非聚簇索引) 的叶子节点保存的不是指向行的物理位置的指针，而是行的主键值）。<br>（PS:覆盖索引：Mysql 可以使用索引来直接获取列的数据，这样就不需要查到索引后，然后通过叶子节点的指针回表读取数据行，如果索引的叶子节点中已经包含了或者说覆盖 所有需要查询的字段的值，那么就没有必要再回表查询了，这种称之为“覆盖索引”）</p>
<h2 id="聚簇索引的缺点："><a href="#聚簇索引的缺点：" class="headerlink" title="聚簇索引的缺点："></a>聚簇索引的缺点：</h2><pre><code>聚簇数据提高了IO性能，如果数据全部放在内存中，则访问的顺序就没那么重要了
插入速度严重依赖插入顺序。按主键的顺序插入是速度最快的。但如果不是按照主键顺序加载数据，则需在加载完成后最好使用optimize table重新组织一下表
更新聚簇索引列的代价很高。因为会强制innod将每个被更新的行移动到新的位置
基于聚簇索引的表在插入新行，或主键被更新导致需要移动行的时候，可能面临页分裂的问题。页分裂会导致表占用更多的磁盘空间。
聚簇索引可能导致全表扫描变慢，尤其是行比较稀疏，或由于页分裂导致数据存储不连续的时
非聚集索引比想象的更大，因为二级索引的叶子节点包含了引用行的主键列
非聚集索引访问需要两次索引查找(非聚集索引中叶子节点保存的行指针指向的是行的主键值)，对于innodb自适应哈希索引可以减少这样的重复工作
</code></pre>
<p>聚簇索引尽量选择有序的列（如AUTO_INCREMENT自增列）,这样可以保证数据行是顺序写入，对于根据主键做关联操作的性能也会更好。</p>
<p>最好避免随机的（不连续且值的分布范围非常大）聚簇索引，特别是对于I&#x2F;O密集型的应用。</p>
<p>从性能角度考虑，使用UUID来做聚簇索引会很糟糕，它使得聚簇索引的插入变得完全随机，这是最坏的情况，是的数据没有任何聚集的特性。</p>
<p>总结下使用类似UUID这种随机的聚簇索引的缺点：<br>UUID字段长，索引占用的空间更大。<br>写入是乱序的，InnoDB不得不频繁的做页分裂操作，以便新的行分配空间，页分裂会导致移动大量数据，一次插入最少需要修改三个页而不是一个页。<br>写入的目标页可能已经刷到磁盘上并从缓存中移除，或者还没有被加载到缓存中，InnoDB在插入之前不得不先找到并从磁盘读取目标页到内存中，这将导致大量的随机IO。<br>频繁的页分裂，页会变的稀疏并被不规则的填充，会产生空间碎片。<br><a href="https://www.cnblogs.com/learn-ontheway/p/12150521.html">https://www.cnblogs.com/learn-ontheway/p/12150521.html</a></p>
<p>MySQL的InnoDB索引数据结构是B+树，主键索引叶子节点的值存储的就是MySQL的数据行，普通索引的叶子节点的值存储的是主键值，这是了解聚簇索引和非聚簇索引的前提</p>
<p>什么是聚簇索引？<br>很简单记住一句话：找到了索引就找到了需要的数据，那么这个索引就是聚簇索引，所以主键就是聚簇索引，修改聚簇索引其实就是修改主键。</p>
<p>什么是非聚簇索引？<br>索引的存储和数据的存储是分离的，也就是说找到了索引但没找到数据，需要根据索引上的值(主键)再次回表查询,非聚簇索引也叫做辅助索引。</p>
<p>clustered index（MySQL官方对聚簇索引的解释）<br>The InnoDB term for a primary key index. InnoDB table storage is organized based on the values of the primary key columns, to speed up queries and sorts involving the primary key columns. For best performance, choose the primary key columns carefully based on the most performance-critical queries. Because modifying the columns of the clustered index is an expensive operation, choose primary columns that are rarely or never updated.<br>注意标黑的那段话，聚簇索引就是主键的一种术语</p>
<p>一个例子<br>下面我们创建了一个学生表，做三种查询，来说明什么情况下是聚簇索引，什么情况下不是。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">create table student (</span><br><span class="line">    id bigint,</span><br><span class="line">    no varchar(20) ,</span><br><span class="line">    name varchar(20) ,</span><br><span class="line">    address varchar(20) ,</span><br><span class="line">    PRIMARY KEY (`branch_id`) USING BTREE,</span><br><span class="line">    UNIQUE KEY `idx_no` (`no`) USING BTREE</span><br><span class="line">)ENGINE=InnoDB DEFAULT CHARSET=utf8 ROW_FORMAT=DYNAMIC;</span><br></pre></td></tr></table></figure>
<p>　　第一种，直接根据主键查询获取所有字段数据，此时主键是聚簇索引，因为主键对应的索引叶子节点存储了id&#x3D;1的所有字段的值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select * from student where id = 1</span><br></pre></td></tr></table></figure>
<p>　　第二种，根据编号查询编号和名称，编号本身是一个唯一索引，但查询的列包含了学生编号和学生名称，当命中编号索引时，该索引的节点的数据存储的是主键ID，需要根据主键ID重新查询一次，所以这种查询下no不是聚簇索引</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select no,name from student where no = &#x27;test&#x27;</span><br></pre></td></tr></table></figure>
<p>　　第三种，我们根据编号查询编号（有人会问知道编号了还要查询？要，你可能需要验证该编号在数据库中是否存在），这种查询命中编号索引时，直接返回编号，因为所需要的数据就是该索引，不需要回表查询，这种场景下no是聚簇索引</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">select no from student where no = &#x27;test&#x27;</span><br></pre></td></tr></table></figure>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>主键一定是聚簇索引，MySQL的InnoDB中一定有主键，即便研发人员不手动设置，则会使用unique索引，没有unique索引，则会使用数据库内部的一个行的id来当作主键索引,其它普通索引需要区分SQL场景，当SQL查询的列就是索引本身时，我们称这种场景下该普通索引也可以叫做聚簇索引，MyisAM引擎没有聚簇索引。</p>
<p>原文链接：<a href="https://blog.csdn.net/xingduan5153/article/details/106189340/">https://blog.csdn.net/xingduan5153/article/details/106189340/</a></p>
<p>　　推荐：<a href="https://www.cnblogs.com/jiangds/p/8276613.html">https://www.cnblogs.com/jiangds/p/8276613.html</a></p>
<h1 id="索引优化"><a href="#索引优化" class="headerlink" title="索引优化"></a>索引优化</h1><p>1、缺省情况下建立的索引是非聚簇索引，但有时它并不是最佳的。在非群集索引下，数据在物理上随机存放在数据页上。合理的索引设计要建立在对各种查询的分析和预测上。一般来说：<br>　　a.有大量重复值、且经常有范围查询（ &gt; ,&lt; ，&gt; &#x3D;,&lt; &#x3D;）和order by、group by发生的列，可考<br>　　虑建立聚集索引；<br>　　b.经常同时存取多列，且每列都含有重复值可考虑建立组合索引；<br>　　c.组合索引要尽量使关键查询形成索引覆盖，其前导列一定是使用最频繁的列。索引虽有助于提高性能但不是索引越多越好，恰好相反过多的索引会导致系统低效。用户在表中每加进一个索引，维护索引集合就要做相应的更新工作。<br>2、ORDER BY和GROPU BY使用ORDER BY和GROUP BY短语，任何一种索引都有助于SELECT的性能提高。<br>3、多表操作在被实际执行前，查询优化器会根据连接条件，列出几组可能的连接方案并从中找出系统开销最小的最佳方案。连接条件要充份考虑带有索引的表、行数多的表；内外表的选择可由公式：外层表中的匹配行数*内层表中每一次查找的次数确定，乘积最小为最佳方案。<br>4、任何对列的操作都将导致表扫描，它包括数据库函数、计算表达式等等，查询时要尽可能将操作移至等号右边。<br>5、IN、OR子句常会使用工作表，使索引失效。如果不产生大量重复值，可以考虑把子句拆开。拆开的子句中应该包含索引。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>filesort 详细解析</title>
    <url>/2020/mysql-filesort/</url>
    <content><![CDATA[<p>这篇文章介绍的非常好， 所以给大家推荐一下<br>【转载】<a href="https://blog.csdn.net/n88Lpo">https://blog.csdn.net/n88Lpo</a></p>
<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>排序（filesort）作为DBA绕不开的话题，也经常有朋友讨论它，比如常见的问题如下：</p>
<ul>
<li>排序的时候，用于排序的数据会不会如Innodb一样压缩空字符存储，比如varchar(30)，我只是存储了1个字符是否会压缩，还是按照30个字符计算？</li>
<li>max_length_for_sort_data&#x2F;max_sort_length 到底是什么含义？</li>
<li>original filesort algorithm（回表排序） 和 modified filesort algorithm（不回表排序） 的根本区别是什么？</li>
<li>为什么使用到排序的时候慢查询中的Rows_examined会更大，计算方式到底是什么样的？<br>在MySQL通常有如下算法来完成排序：</li>
<li>内存排序（优先队列 order by limit 返回少量行常用，提高排序效率，但是注意order by limit n,m 如果n过大可能会涉及到排序算法的切换）</li>
<li>内存排序（快速排序）</li>
<li>外部排序（归并排序）<br>但是由于能力有限本文不解释这些算法，并且本文不考虑优先队列算法的分支逻辑，只以快速排序和归并排序作为基础进行流程剖析。</li>
</ul>
<p>我们在执行计划中如果出现filesort字样通常代表使用到了排序，但是执行计划中看不出来下面问题：</p>
<ul>
<li>是否使用了临时文件。</li>
<li>是否使用了优先队列。</li>
<li>是original filesort algorithm（回表排序）还是modified filesort algorithm（不回表排序）。<br>如何查看将在后面进行描述。本文还会给出大量的排序接口供敢兴趣的朋友使用，也给自己留下笔记。</li>
</ul>
<span id="more"></span>

<h1 id="十四、全文总结"><a href="#十四、全文总结" class="headerlink" title="十四、全文总结"></a>十四、全文总结</h1><p>提前将总结列在这里，方便读者快速浏览， 本文写了很多，这里需要做一个详细的总结：<br>总结1 ：排序中一行记录如何组织？</p>
<ul>
<li><p>一行排序记录，由sort字段+addon字段 组成，其中sort字段为order by 后面的字段，而addon字段为需要访问的字段，比如‘select a1,a2,a3 from test order by a2,a3’，其中sort字段为‘a2,a3’，addon字段为‘a1,a2,a3’。sort字段中的可变长度字段不能打包（pack）压缩，比如varchar，使用的是定义的大小计算空间，注意这是排序使用空间较大的一个重要因素。</p>
</li>
<li><p>如果在计算sort字段空间的时候，某个字段的空间大小大于了max_sort_length大小则按照max_sort_length指定的大小计算。</p>
</li>
<li><p>一行排序记录，如果sort字段+addon字段 的长度大于了max_length_for_sort_data的大小，那么addon字段将不会存储，而使用sort字段+ref字段代替，ref字段为主键或者ROWID，这个时候就会使用original filesort algorithm（回表排序）的方式了。</p>
</li>
<li><p>如果addon字段包含可变字段比如varchar字段，则会使用打包（pack）技术进行压缩，节省空间。<br>可以参考第3、第4、第5、第6、第8节。<br>总结2：排序使用什么样的方法进行？</p>
</li>
<li><p>original filesort algorithm（回表排序）</p>
</li>
</ul>
<p>如果使用的是sort字段+ref字段进行排序，那么必须要回表获取需要的数据，如果排序使用了临时文件（也就是说使用外部归并排序，排序量较大）则会使用批量回表，批量回表会涉及到read_rnd_buffer_size参数指定的内存大小，主要用于排序和结果返回。如果排序没有使用临时文件（内存排序就可以完成，排序量较小）则采用单行回表。</p>
<p>*<br>modified filesort algorithm（不回表排序）</p>
<p>如果使用的是sort字段+addon字段进行排序，那么使用不回表排序，所有需要的字段均在排序过程中进行存储，addon字段中的可变长度字段可以进行打包（pack）压缩节省空间。其次sort字段和addon字段中可能有重复的字段，比如例2中，sort字段为a2、a3，addon字段为a1、a2、a3，这是排序使用空间较大的另外一个原因。<br>在OPTIMIZER_TRACE中可以查看到使用了那种方法，参考12节。<br>总结3：每次排序一定会分配sort_buffer_size参数指定的内存大小吗？</p>
<p>不是这样的，MySQL会做一个初步的计算，通过比较Innodb中聚集索引可能存储的行上限和sort_buffer_size参数指定大小内存可以容纳的行上限，获取它们小值进行确认最终内存分配的大小，目的在于节省内存空间。<br>在OPTIMIZER_TRACE中可以看到使用的内存大小，参考第8、第12节。<br>总结4：关于OPTIMIZER_TRACE中的examined_rows和慢查询中的Rows_examined有什么区别？</p>
<ul>
<li>慢查询中的Rows_examined包含了重复计数，重复的部分为where条件过滤后做了排序的部分。</li>
<li>OPTIMIZER_TRACE中的examined_rows不包含重复计数，为实际Innodb层扫描的行数。<br>可以参考11节。<br>总结5：外部排序临时文件的使用是什么样的？</li>
</ul>
<p>实际上一个语句的临时文件不止一个，但是它们都以MY开头，并且都放到了tmpdir目录下，lsof可以看到这种文件。</p>
<ul>
<li>临时文件1：用于存储内存排序的结果，以chunk为单位，一个chunk的大小就是sort buffer的大小。</li>
<li>临时文件2：以前面的临时文件1为基础，做归并排序。</li>
<li>临时文件3：将最后的归并排序结果存储，去掉sort字段，只保留addon字段（需要访问的字段）或者ref字段（ROWID或者主键），因此它一般会比前面2个临时文件小。<br>但是它们不会同时存在，要么 临时文件1和临时文件2存在，要么 临时文件2和临时文件3存在。对于临时文件的使用可以查看Sort_merge_passes，本值多少会侧面反应出外部排序量的大小。<br>可以参考第10节。<br>总结6：排序使用了哪种算法？</li>
</ul>
<p>虽然本文不涉及算法，但是内部排序有2种算法需要知道：</p>
<ul>
<li>内存排序（优先队列 order by limit 返回少量行常用，提高排序效率，但是注意order by limit n,m 如果n过大可能会涉及到排序算法的切换）</li>
<li>内存排序（快速排序）<br>在通过OPTIMIZER_TRACE可以查看是否使用使用了优先队列算法，参考12节。<br>总结7：“Creating sort index”到底是什么状态？</li>
</ul>
<p>我们前面讲的全部排序流程都会包含在这个状态下，包括：</p>
<ul>
<li>获取排序需要的数据（比如例子中全表扫描从Innodb层获取数据）</li>
<li>根据where条件过滤数据</li>
<li>内存排序</li>
<li>外部排序<br>总结8：如何避免临时文件过大的情况？</li>
</ul>
<p>首先应该考虑是否可以使用索引来避免排序，如果不能则需要考虑下面的要点：</p>
<ul>
<li>order by 后面的字段满足需求即可，尽可能的少。</li>
<li>order by 后面涉及的字段尽量为固定长度的字段类型，而不是可变字段类型如varchar。因为sort字段不能压缩。</li>
<li>不要过大的定义可变字段长度，应该合理定义，例如varchar（10）能够满足需求不要使用varchar（50），这些空间虽然在Innodb层存储会压缩，但是MySQL层确可能使用全长度（比如sort字段）。</li>
<li>在查询中尽量不要用（select *） 而使用需要查询的字段，这将会减少addon字段的个数，在我另外一个文章还讲述了（select *）的其他的缺点参考：<a href="https://www.jianshu.com/p/ce063e2024ad">https://www.jianshu.com/p/ce063e2024ad</a></li>
</ul>
<h1 id="一、从一个问题出发"><a href="#一、从一个问题出发" class="headerlink" title="一、从一个问题出发"></a>一、从一个问题出发</h1><p>这是最近一个朋友遇到的案例，大概意思就是说我的表在Innodb中只有30G左右，为什么使用如下语句进行排序操作后临时文件居然达到了200多G，当然语句很变态，我们可以先不问为什么会有这样的语句，我们只需要研究原理即可，在本文的第13节会进行原因解释和问题重现。<br>临时文件如下：</p>
<p>下面是这些案例信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">show create table  t\G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: t</span><br><span class="line">Create Table: CREATE TABLE `t` (</span><br><span class="line">  `ID` bigint(20) NOT NULL COMMENT &#x27;ID&#x27;,</span><br><span class="line">  `UNLOAD_TASK_NO` varchar(50) NOT NULL ,</span><br><span class="line">  `FORKLIFT_TICKETS_COUNT` bigint(20) DEFAULT NULL COMMENT &#x27;叉车票数&#x27;,</span><br><span class="line">  `MANAGE_STATUS` varchar(20) DEFAULT NULL COMMENT &#x27;管理状态&#x27;,</span><br><span class="line">  `TRAY_BINDING_TASK_NO` varchar(50) NOT NULL ,</span><br><span class="line">  `STATISTIC_STATUS` varchar(50) NOT NULL ,</span><br><span class="line">  `CREATE_NO` varchar(50) DEFAULT NULL ,</span><br><span class="line">  `UPDATE_NO` varchar(50) DEFAULT NULL ,</span><br><span class="line">  `CREATE_NAME` varchar(200) DEFAULT NULL COMMENT &#x27;创建人名称&#x27;,</span><br><span class="line">  `UPDATE_NAME` varchar(200) DEFAULT NULL COMMENT &#x27;更新人名称&#x27;,</span><br><span class="line">  `CREATE_ORG_CODE` varchar(200) DEFAULT NULL COMMENT &#x27;创建组织编号&#x27;,</span><br><span class="line">  `UPDATE_ORG_CODE` varchar(200) DEFAULT NULL COMMENT &#x27;更新组织编号&#x27;,</span><br><span class="line">  `CREATE_ORG_NAME` varchar(1000) DEFAULT NULL COMMENT &#x27;创建组织名称&#x27;,</span><br><span class="line">  `UPDATE_ORG_NAME` varchar(1000) DEFAULT NULL COMMENT &#x27;更新组织名称&#x27;,</span><br><span class="line">  `CREATE_TIME` datetime DEFAULT NULL COMMENT &#x27;创建时间&#x27;,</span><br><span class="line">  `UPDATE_TIME` datetime DEFAULT NULL COMMENT &#x27;更新时间&#x27;,</span><br><span class="line">  `DATA_STATUS` varchar(50) DEFAULT NULL COMMENT &#x27;数据状态&#x27;,</span><br><span class="line">  `OPERATION_DEVICE` varchar(200) DEFAULT NULL COMMENT &#x27;操作设备&#x27;,</span><br><span class="line">  `OPERATION_DEVICE_CODE` varchar(200) DEFAULT NULL COMMENT &#x27;操作设备编码&#x27;,</span><br><span class="line">  `OPERATION_CODE` varchar(50) DEFAULT NULL COMMENT &#x27;操作码&#x27;,</span><br><span class="line">  `OPERATION_ASSIST_CODE` varchar(50) DEFAULT NULL COMMENT &#x27;辅助操作码&#x27;,</span><br><span class="line">  `CONTROL_STATUS` varchar(50) DEFAULT NULL COMMENT &#x27;控制状态&#x27;,</span><br><span class="line">  `OPERATOR_NO` varchar(50) DEFAULT NULL COMMENT &#x27;操作人工号&#x27;,</span><br><span class="line">  `OPERATOR_NAME` varchar(200) DEFAULT NULL COMMENT &#x27;操作人名称&#x27;,</span><br><span class="line">  `OPERATION_ORG_CODE` varchar(50) DEFAULT NULL COMMENT &#x27;操作部门编号&#x27;,</span><br><span class="line">  `OPERATION_ORG_NAME` varchar(200) DEFAULT NULL COMMENT &#x27;操作部门名称&#x27;,</span><br><span class="line">  `OPERATION_TIME` datetime DEFAULT NULL COMMENT &#x27;操作时间&#x27;,</span><br><span class="line">  `OPERATOR_DEPT_NO` varchar(50) NOT NULL COMMENT &#x27;操作人所属部门编号&#x27;,</span><br><span class="line">  `OPERATOR_DEPT_NAME` varchar(200) NOT NULL COMMENT &#x27;操作人所属部门名称&#x27;,</span><br><span class="line">  `FORKLIFT_DRIVER_NAME` varchar(200) DEFAULT NULL ,</span><br><span class="line">  `FORKLIFT_DRIVER_NO` varchar(50) DEFAULT NULL ,</span><br><span class="line">  `FORKLIFT_DRIVER_DEPT_NAME` varchar(200) DEFAULT NULL ,</span><br><span class="line">  `FORKLIFT_DRIVER_DEPT_NO` varchar(50) DEFAULT NULL ,</span><br><span class="line">  `FORKLIFT_SCAN_TIME` datetime DEFAULT NULL ,</span><br><span class="line">  `OUT_FIELD_CODE` varchar(200) DEFAULT NULL,</span><br><span class="line">  PRIMARY KEY (`ID`),</span><br><span class="line">  KEY `IDX_TRAY_BINDING_TASK_NO` (`TRAY_BINDING_TASK_NO`),</span><br><span class="line">  KEY `IDX_OPERATION_ORG_CODE` (`OPERATION_ORG_CODE`),</span><br><span class="line">  KEY `IDX_OPERATION_TIME` (`OPERATION_TIME`)</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 ROW_FORMAT=COMPRESSED KEY_BLOCK_SIZE=8</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">desc </span><br><span class="line">SELECT </span><br><span class="line">    ID,</span><br><span class="line">    UNLOAD_TASK_NO,</span><br><span class="line">    FORKLIFT_TICKETS_COUNT,</span><br><span class="line">    MANAGE_STATUS,</span><br><span class="line">    TRAY_BINDING_TASK_NO,</span><br><span class="line">    STATISTIC_STATUS,</span><br><span class="line">    CREATE_NO,</span><br><span class="line">    UPDATE_NO,</span><br><span class="line">    CREATE_NAME,</span><br><span class="line">    UPDATE_NAME,</span><br><span class="line">    CREATE_ORG_CODE,</span><br><span class="line">    UPDATE_ORG_CODE,</span><br><span class="line">    CREATE_ORG_NAME,</span><br><span class="line">    UPDATE_ORG_NAME,</span><br><span class="line">    CREATE_TIME,</span><br><span class="line">    UPDATE_TIME,</span><br><span class="line">    DATA_STATUS,</span><br><span class="line">    OPERATION_DEVICE,</span><br><span class="line">    OPERATION_DEVICE_CODE,</span><br><span class="line">    OPERATION_CODE,</span><br><span class="line">    OPERATION_ASSIST_CODE,</span><br><span class="line">    CONTROL_STATUS,</span><br><span class="line">    OPERATOR_NO,</span><br><span class="line">    OPERATOR_NAME,</span><br><span class="line">    OPERATION_ORG_CODE,</span><br><span class="line">    OPERATION_ORG_NAME,</span><br><span class="line">    OPERATION_TIME,</span><br><span class="line">    OPERATOR_DEPT_NO,</span><br><span class="line">    OPERATOR_DEPT_NAME,</span><br><span class="line">    FORKLIFT_DRIVER_NAME,</span><br><span class="line">    FORKLIFT_DRIVER_NO,</span><br><span class="line">    FORKLIFT_DRIVER_DEPT_NAME,</span><br><span class="line">    FORKLIFT_DRIVER_DEPT_NO,</span><br><span class="line">    FORKLIFT_SCAN_TIME,</span><br><span class="line">    OUT_FIELD_CODE</span><br><span class="line">FROM</span><br><span class="line">    t</span><br><span class="line">GROUP BY id , UNLOAD_TASK_NO , FORKLIFT_TICKETS_COUNT , </span><br><span class="line">MANAGE_STATUS , TRAY_BINDING_TASK_NO , STATISTIC_STATUS , </span><br><span class="line">CREATE_NO , UPDATE_NO , CREATE_NAME , UPDATE_NAME , </span><br><span class="line">CREATE_ORG_CODE , UPDATE_ORG_CODE , CREATE_ORG_NAME , </span><br><span class="line">UPDATE_ORG_NAME , CREATE_TIME , UPDATE_TIME , DATA_STATUS , </span><br><span class="line">OPERATION_DEVICE , OPERATION_DEVICE_CODE , OPERATION_CODE , </span><br><span class="line">OPERATION_ASSIST_CODE , CONTROL_STATUS , OPERATOR_NO ,</span><br><span class="line">OPERATOR_NAME , OPERATION_ORG_CODE , OPERATION_ORG_NAME , </span><br><span class="line">OPERATION_TIME , OPERATOR_DEPT_NO , OPERATOR_DEPT_NAME , </span><br><span class="line">FORKLIFT_DRIVER_NAME , FORKLIFT_DRIVER_NO , </span><br><span class="line">FORKLIFT_DRIVER_DEPT_NAME , FORKLIFT_DRIVER_DEPT_NO ,</span><br><span class="line">FORKLIFT_SCAN_TIME , OUT_FIELD_CODE;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">+----+-------------+-------------------------+------------+------+---------------+------+---------+------+---------+----------+----------------+</span><br><span class="line">| id | select_type | table                   | partitions | type | possible_keys | key  | key_len | ref  | rows    | filtered | Extra          |</span><br><span class="line">+----+-------------+-------------------------+------------+------+---------------+------+---------+------+---------+----------+----------------+</span><br><span class="line">|  1 | SIMPLE      | t | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 5381145 |   100.00 | Using filesort |</span><br><span class="line">+----+-------------+-------------------------+------------+------+---------------+------+---------+------+---------+----------+----------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure>
<p>也许你会怀疑这个语句有什么用，我们先不考虑功能，我们只考虑为什么它会生成200G的临时文件这个问题。<br>接下来我将分阶段进行排序的流程解析，注意了整个排序的流程均处于状态‘Creating sort index’下面，我们以filesort函数接口为开始进行分析。</p>
<h1 id="二、测试案例"><a href="#二、测试案例" class="headerlink" title="二、测试案例"></a>二、测试案例</h1><p>为了更好的说明后面的流程我们使用2个除了字段长度不同，其他完全一样的表来说明，但是需要注意这两个表数据量很少，不会出现外部排序，如果涉及外部排序的时候我们需要假设它们数据量很大。其次这里根据original filesort algorithm和modified filesort algorithm进行划分，但是这两种方法还没讲述，不用太多理会。</p>
<ul>
<li>original filesort algorithm（回表排序）</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; show create table tests1 \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: tests1</span><br><span class="line">Create Table: CREATE TABLE `tests1` (</span><br><span class="line">  `a1` varchar(300) DEFAULT NULL,</span><br><span class="line">  `a2` varchar(300) DEFAULT NULL,</span><br><span class="line">  `a3` varchar(300) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from tests1;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| a    | a    | a    |</span><br><span class="line">| a    | b    | b    |</span><br><span class="line">| a    | c    | c    |</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">| c    | g    | g    |</span><br><span class="line">| c    | h    | h    |</span><br><span class="line">+------+------+------+</span><br><span class="line">8 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc select * from tests1 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">|  1 | SIMPLE      | tests1 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    8 |    12.50 | Using where; Using filesort |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure>

<ul>
<li>modified filesort algorithm（不回表排序）<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; desc select * from tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">|  1 | SIMPLE      | tests2 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    8 |    12.50 | Using where; Using filesort |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; show create table tests2 \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: tests2</span><br><span class="line">Create Table: CREATE TABLE `tests2` (</span><br><span class="line">  `a1` varchar(20) DEFAULT NULL,</span><br><span class="line">  `a2` varchar(20) DEFAULT NULL,</span><br><span class="line">  `a3` varchar(20) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br><span class="line">1 row in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from tests2;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| a    | a    | a    |</span><br><span class="line">| a    | b    | b    |</span><br><span class="line">| a    | c    | c    |</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">| c    | g    | g    |</span><br><span class="line">| c    | h    | h    |</span><br><span class="line">+------+------+------+</span><br><span class="line">8 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc select * from tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">|  1 | SIMPLE      | tests2 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    8 |    12.50 | Using where; Using filesort |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">1 row in set, 1 warning (0.01 sec)</span><br></pre></td></tr></table></figure></li>
</ul>
<p>整个流程我们从filesort 函数接口开始讨论。下面第3到第10节为排序的主要流程。</p>
<h1 id="三、阶段1-确认排序字段及顺序"><a href="#三、阶段1-确认排序字段及顺序" class="headerlink" title="三、阶段1 确认排序字段及顺序"></a>三、阶段1 确认排序字段及顺序</h1><p>这里主要将排序顺序存入到Filesort 类的 sortorder中，比如我们例子中的order by a2,a3就是a2和a3列，主要接口为Filesort::make_sortorder，我们按照源码描述为sort字段（源码中为sort_length），显然我们在排序的时候除了sort字段以外，还应该包含额外的字段，到底包含哪些字段就与方法 original filesort algorithm（回表排序） 和 modified filesort algorithm（不回表排序）有关了，下面进行讨论。</p>
<h1 id="四、阶段2-计算sort字段的长度"><a href="#四、阶段2-计算sort字段的长度" class="headerlink" title="四、阶段2 计算sort字段的长度"></a>四、阶段2 计算sort字段的长度</h1><p>这里主要调用使用sortlength函数，这一步将会带入max_sort_length参数的设置进行判断，默认情况下max_sort_length 为1024字节。<br>这一步大概步骤为：</p>
<ol>
<li><p>循环每一个sort字段</p>
</li>
<li><p>计算每一个sort字段的长度：公式为 ≈ 定义长度 * 2</p>
</li>
</ol>
<p>比如这里例子中我定义了a1 varchar(300)，那么它的计算长度 ≈ 300 * 2（600），为什么是*2呢，这应该是和Unicode编码有关，这一步可以参考函数my_strnxfrmlen_utf8。同时需要注意这里是约等于，因为源码中还是其他的考虑，比如字符是否为空，但是占用不多不考虑了。<br>3. 带入max_sort_length参数进行计算</p>
<p>好了有了上面一个sort字段的长度，那么这里就和max_sort_length进行比较，如果这个这个sort字段大于max_sort_length的值，那么以max_sort_length设置为准，这步代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set_if_smaller(sortorder-&gt;length, thd-&gt;variables.max_sort_length);</span><br></pre></td></tr></table></figure>
<p>因此，如果sort字段的某个字段的超过了max_sort_length设置，那么排序可能不那么精确了。<br>到了这里每个sort字段的长度以及sort字段的总长度已经计算出来，比如前面给的两个不同列子中：</p>
<ul>
<li>（a2 varchar(300) a3 varchar(300) order by a2,a3）：每个sort字段约为300*2字节，两个字段的总长度约为1200字节。</li>
<li>（a2 varchar(20) a3 varchar(20) order by a2,a3）：每个sort字段约为20*2字节，两个字段的总长度约为80字节。<br>并且值得注意的是，这里是按照定义大小，如varchar(300) ，以300个字符来计算长度的，而不是我们通常看到的Innodb中实际占用的字符数量。这是排序使用空间大于Innodb实际数据文件大小的一个原因。</li>
</ul>
<p>下面我们以（a2 varchar(300) a3 varchar(300) order by a2,a3）为例实际看看debug的结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(gdb) p sortorder-&gt;field-&gt;field_name</span><br><span class="line">$4 = 0x7ffe7800fadf &quot;a3&quot;</span><br><span class="line">(gdb) p sortorder-&gt;length</span><br><span class="line">$5 = 600</span><br><span class="line">(gdb) p  total_length</span><br><span class="line">$6 = 1202（这里a2,a3 可以为NULL各自加了1个字节）</span><br><span class="line">(gdb) </span><br></pre></td></tr></table></figure>
<p>可以看出没有问题。<br>4. 循环结束，计算出sort字段的总长度。</p>
<p>后面我们会看到sort字段不能使用压缩（pack）技术。</p>
<h1 id="五、阶段3-计算额外字段的空间"><a href="#五、阶段3-计算额外字段的空间" class="headerlink" title="五、阶段3 计算额外字段的空间"></a>五、阶段3 计算额外字段的空间</h1><p>对于排序而言，我们很清楚除了sort字段以外，通常我们需要的是实际的数据，那么无外乎两种方式如下：</p>
<ul>
<li>original filesort algorithm：只存储rowid或者主键做为额外的字段，然后进行回表抽取数据。我们按照源码的描述，将这种关联回表的字段叫做ref字段（源码中变量叫做ref_length）。</li>
<li>modified filesort algorithm：将处于read_set（需要读取的字段）全部放到额外字段中，这样不需要回表读取数据了。我们按照源码的描述，将这些额外存储的字段叫做addon字段（源码中变量叫做addon_length）。<br>这里一步就是要来判断到底使用那种算法，其主要标准就是参数max_length_for_sort_data，其默认大小为1024字节，但是后面会看到这里的计算为（sort字段长度+addon字段的总和）是否超过了max_length_for_sort_data。其次如果使用了modified filesort algorithm算法，那么将会对addon字段的每个字段做一个pack（打包），主要目的在于压缩那些为空的字节，节省空间。<br>这一步的主要入口函数为Filesort::get_addon_fields下面是步骤解析。</li>
</ul>
<ol>
<li><p>循环本表全部字段</p>
</li>
<li><p>根据read_set过滤出不需要存储的字段</p>
</li>
</ol>
<p>这里如果不需要访问到的字段自然不会包含在其中，下面这段源码过滤代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (!bitmap_is_set(read_set, field-&gt;field_index)) //是否在read set中</span><br><span class="line">      continue;</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>获取字段的长度</li>
</ol>
<p>这里就是实际的长度了比如我们的a1 varchar(300)，且字符集为UTF8，那么其长度≈ 300*3 （900）。<br>4. 获取可以pack（打包）字段的长度</p>
<p>和上面不同，对于int这些固定长度类型的字段，只有可变长度的类型的字段才需要进行打包技术。<br>5. 循环结束，获取addon字段的总长度，获取可以pack（打包）字段的总长度</p>
<p>循环结束后可以获取addon字段的总长度，但是需要注意addon字段和sort字段可能包含重复的字段，比如例2中sort字段为a2、a3，addon字段为a1、a2、a3。<br>如果满足如下条件：<br>addon字段的总长度+sort字段的总长度 &gt; max_length_for_sort_data<br>那么将使用original filesort algorithm（回表排序）的方式，否则使用modified filesort algorithm的方式进行。下面是这一句代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">  if (total_length + sortlength &gt; max_length_for_sort_data) //如果长度大于了max_length_for_sort_data 则退出了</span><br><span class="line">  &#123;</span><br><span class="line">    DBUG_ASSERT(addon_fields == NULL);</span><br><span class="line">    return NULL;</span><br><span class="line">//返回NULL值 不打包了 使用 original filesort algorithm（回表排序）</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>我们在回到第2节例子中的第1个案例，因为我们对a1,a2,a3都是需要访问的，且他们的大小均为varchar(300) UTF8，那么addon字段长度大约为300 * 3 * 3&#x3D;2700字节 ，其次我们前面计算了sort字段大约为1202字节，因此 2700+1202 是远远大于max_length_for_sort_data的默认设置1024字节的，因此会使用original filesort algorithm方式进行排序。</p>
<p>如果是第2节例子中的第2个案例呢，显然要小很多了（每个字段varchar（20）），大约就是20 * 3 * 3（addon字段）+82（sort字段） 它是小于1024字节的，因此会使用modified filesort algorithm的排序方式，并且这些addon字段基本都可以使用打包（pack）技术，来节省空间。但是需要注意的是无论如何（sort字段）是不能进行打包（pack）的，而固定长度类型不需要打包（pack）压缩空间。</p>
<h1 id="六、阶段4-确认每行的长度"><a href="#六、阶段4-确认每行的长度" class="headerlink" title="六、阶段4 确认每行的长度"></a>六、阶段4 确认每行的长度</h1><p>有了上面的就计算后每一行的长度（如果可以打包是打包前的长度），下面就是这个计算过程。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (using_addon_fields()) </span><br><span class="line">//如果使用了 打包技术  检测 addon_fields 数组是否存在  使用modified filesort algorithm算法 不回表排序</span><br><span class="line">  &#123;</span><br><span class="line">    res_length= addon_length; //总的长度  3个 varchar(300) uft8 为 3*300*3</span><br><span class="line">  &#125;</span><br><span class="line">  else //使用original filesort algorithm算法</span><br><span class="line">  &#123;</span><br><span class="line">    res_length= ref_length;   //rowid(主键长度) </span><br><span class="line">    /* </span><br><span class="line">      The reference to the record is considered </span><br><span class="line">      as an additional sorted field</span><br><span class="line">    */</span><br><span class="line">    sort_length+= ref_length;  //实际上就是rowid(主键) +排序字段长度  回表排序</span><br><span class="line">  &#125;</span><br><span class="line">  /*</span><br><span class="line">    Add hash at the end of sort key to order cut values correctly.</span><br><span class="line">    Needed for GROUPing, rather than for ORDERing.</span><br><span class="line">  */</span><br><span class="line">  if (use_hash)</span><br><span class="line">    sort_length+= sizeof(ulonglong);</span><br><span class="line"></span><br><span class="line">  rec_length= sort_length + addon_length; </span><br><span class="line">//modified filesort algorithm sort_length 为排序键长度 addon_lenth 为访问字段长度，original filesort algorithm rowid(主键) +排序字段长度 ，因为addon_length为0</span><br></pre></td></tr></table></figure>
<p>好了我们稍微总结一下：</p>
<ul>
<li>original filesort algorithm：每行长度为sort字段的总长度+ref字段长度（主键或者rowid）。</li>
<li>modified filesort algorithm：每行的长度为sort字段的总长度+addon字段的长度（需要访问的字段总长度）。<br>当然到底使用那种算法参考上一节。但是要注意了对于varchar这种可变长度是以定义的大小为准了，比如UTF8 varchar（300）就是300*3&#x3D; 900 而不是实际存储的大小，而固定长度没有变化。</li>
</ul>
<p>好了，还是回头看看第2节的两个例子，分别计算它们的行长度：</p>
<ul>
<li>例子1：根据我们的计算，它将使用original filesort algorithm排序方式，最终的计算行长度应该为（sort字段长度+rowid长度）及 ≈ 1202+6 字节，下面是debug的结果：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(gdb) p rec_length</span><br><span class="line">$1 = 1208</span><br></pre></td></tr></table></figure></li>
<li>例子2：根据我们的计算，它将使用modified filesort algorithm排序方式，最终计算行长度应该为（sort字段长度+addon字段长度）及 ≈ 82 + 20 * 3 * 3 （结果为262），注意这里是约等于没有计算非空等因素和可变长度因素，下面是debug的结果：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(gdb) p rec_length</span><br><span class="line">$2 = 266</span><br></pre></td></tr></table></figure>
可以看出误差不大。</li>
</ul>
<h1 id="七、阶段5-确认最大内存分配"><a href="#七、阶段5-确认最大内存分配" class="headerlink" title="七、阶段5 确认最大内存分配"></a>七、阶段5 确认最大内存分配</h1><p>这里的分配内存就是参数sort_buffer_size大小有关了。但是是不是每次都会分配至少sort_buffer_size大小的内存的呢？其实不是，MySQL会判断是否表很小的情况，也就是做一个简单的运算，目的在于节省内存的开销，这里我们将来描述。</p>
<ol>
<li>大概计算出Innodb层主键叶子结点的行数</li>
</ol>
<p>这一步主要通过（聚集索引叶子结点的空间大小&#x2F;聚集索引每行大小 * 2）计算出一个行的上限，调入函数ha_innobase::estimate_rows_upper_bound，源码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> num_rows= table-&gt;file-&gt;estimate_rows_upper_bound(); </span><br><span class="line">//上限来自于Innodb 叶子聚集索引叶子结点/聚集索引长度 *2</span><br></pre></td></tr></table></figure>
<p>然后将结果存储起来，如果表很小那么这个值会非常小。<br>2.根据前面计算的每行长度计算出sort buffer可以容下的最大行数</p>
<p>这一步将计算sort buffer可以容纳的最大行数如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ha_rows keys= memory_available / (param.rec_length + sizeof(char*));</span><br><span class="line">//可以排序的 行数 sort buffer 中最大 可以排序的行数</span><br></pre></td></tr></table></figure>
<p>3.对比两者的最小值，作为分配内存的标准</p>
<p>然后对比两个值以小值为准，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">param.max_keys_per_buffer= (uint) min(num_rows &gt; 0 ? num_rows : 1, keys);</span><br><span class="line">//存储行数上限 和 可以排序 行数的 小值</span><br></pre></td></tr></table></figure>
<p>4.根据结果分配内存</p>
<p>分配如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">table_sort.alloc_sort_buffer(param.max_keys_per_buffer, param.rec_length);</span><br></pre></td></tr></table></figure>
<p>也就是根据总的计算出的行长度和计算出的行数进行分配。</p>
<h1 id="八、阶段6-读取数据，进行内存排序"><a href="#八、阶段6-读取数据，进行内存排序" class="headerlink" title="八、阶段6 读取数据，进行内存排序"></a>八、阶段6 读取数据，进行内存排序</h1><p>到这里准备工作已经完成了，接下就是以行为单位读取数据了，然后对过滤掉where条件的剩下的数据进行排序。如果需要排序的数据很多，那么等排序内存写满后会进行内存排序，然后将排序的内容写入到排序临时文件中，等待下一步做外部的归并排序。作为归并排序而言，每一个归并的文件片段必须是排序好的，否则归并排序是不能完成的，因此写满排序内存后需要做内存排序。如果写不满呢，那么做一次内存排序就好了。下面我们来看看这个过程，整个过程集中在find_all_keys函数中。</p>
<ol>
<li>读取需要的数据</li>
</ol>
<p>实际上在这一步之前还会做read_set的更改，因为对于original filesort algorithm（回表排序）的算法来讲不会读取全部需要的字段，为了简单起见不做描述了。</p>
<p>这一步就是读取一行数据了，这里会进入Innodb层读取数据，具体流程不做解释了，下面是这一行代码：<br>error&#x3D; file-&gt;ha_rnd_next(sort_form-&gt;record[0]); &#x2F;&#x2F;读取一行数据<br>2. 将Rows_examined 加1</p>
<p>这里这个指标对应的就是慢查中的Rows_examined了，这个指标在有排序的情况下会出现重复计算的情况，但是这里还是正确的，重复的部分后面再说。<br>3. 过滤掉where条件</p>
<p>这里将会过滤掉where条件中不满足条件的行，代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (!error &amp;&amp; !qep_tab-&gt;skip_record(thd, &amp;skip_record) &amp;&amp; !skip_record) </span><br><span class="line">//这里做where过滤条件 的比较 </span><br></pre></td></tr></table></figure>
<ol start="4">
<li>将行数据写入到sort buffer中</li>
</ol>
<p>这一步将会把数据写入到sort buffer中，需要注意这里不涉及排序操作，只是存储数据到内存中。其中分为了2部分：</p>
<ul>
<li>写入sort字段。如果是original filesort algorithm那么rowid（主键）也包含在其中了。</li>
<li>写入addon字段，这是modified filesort algorithm才会有的，在写入之前还会调用Field::pack对可以打包（pack）的字段进行压缩操作。对于varchar字段的打包函数就是Field_varstring::pack，简单的说存储的是实际的大小，而非定义的大小。<br>整个过程位于find_all_keys-&gt;Sort_param::make_sortkey 函数中。这一步还涉及到了我们非常关心的一个问题，到底排序的数据如何存储的问题，需要仔细阅读。</li>
</ul>
<p>下面我们就debug一下第2节中两个例子的不同存储方式。既然要去看内存中的数据，我们只要看它最终拷贝的内存数据是什么就好了，那么真相将会大白，我们只需要将断点放到find_all_keys函数上，做完一行数据的Sort_param::make_sortkey操作后看内存就行了，如下：</p>
<ul>
<li>例子1（字段都是varchar（300））：它将使用original filesort algorithm（回表排序）的方式，最终应该存储的是sort字段（a2，a3）+rowid。</li>
</ul>
<p>排序的结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from test.tests1 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">+------+------+------+</span><br><span class="line">3 rows in set (9.06 sec)</span><br></pre></td></tr></table></figure>

<p>我们以第二行为查看目标<br>由于篇幅的关系，我展示其中的一部分，因为这里大约有1200多个字节，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(gdb) x/1300bx start_of_rec</span><br><span class="line">0x7ffe7ca79998: 0x01    0x00    0x45    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799a0: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799a8: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799b0: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799b8: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799c0: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7ca799c8: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>这后面还有大量的0X20 0X00<br>我们看到了大量的0X20 0X00，这正是占位符号，实际有用的数据也就只有0x45 0x00这两个字节了，而0x45正是我们的大写字母E，也就是数据中的e，这和比较字符集有关。这里的0X20 0X00占用了大量的空间，我们最初计算sort 字段大约为1200字节，实际上只有少量的几个字节有用。<br>这里对于sort字段而言，比实际存储的数据大得多。</p>
<ul>
<li>例子2（字段都是varchar（20））：它将使用modified filesort algorithm，最终应该存储的是sort字段（a2，a3）+addon字段（需要的字段，这里就是a1，a2，a3）<br>排序的结果如下：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from test.tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">+------+------+------+</span><br></pre></td></tr></table></figure>
我们以第一行为查看目标<br>这里数据不大，通过压缩后只有91个字节了，我们整体查看如下：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(gdb) p rec_sz</span><br><span class="line">$6 = 91</span><br><span class="line">(gdb) x/91x start_of_rec </span><br><span class="line">0x7ffe7c991bc0: 0x01    0x00    0x44    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7c991bc8: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7c991bd0: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7c991bd8: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7c991be0: 0x20    0x00    0x20    0x00    0x20    0x00    0x20    0x00</span><br><span class="line">0x7ffe7c991be8: 0x20    0x01    0x00    0x44    0x00    0x20    0x00    0x20</span><br><span class="line">0x7ffe7c991bf0: 0x00    0x20    0x00    0x20    0x00    0x20    0x00    0x20</span><br><span class="line">0x7ffe7c991bf8: 0x00    0x20    0x00    0x20    0x00    0x20    0x00    0x20</span><br><span class="line">0x7ffe7c991c00: 0x00    0x20    0x00    0x20    0x00    0x20    0x00    0x20</span><br><span class="line">0x7ffe7c991c08: 0x00    0x20    0x00    0x20    0x00    0x20    0x00    0x20</span><br><span class="line">0x7ffe7c991c10: 0x00    0x20    0x07    0x00    0x00    0x01    0x62    0x01</span><br><span class="line">0x7ffe7c991c18: 0x64    0x01    0x64</span><br></pre></td></tr></table></figure>
这就是整行记录了，我们发现对于sort字段而言没有压缩，依旧是0x20 0x00占位，而对于addon字段（需要的字段，这里就是a1，a2，a3）而言，这里小了很多，因为做了打包（pack）即：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">0x01 0x62：数据b</span><br><span class="line"></span><br><span class="line">0x01 0x64：数据d</span><br><span class="line"></span><br><span class="line">0x01 0x64：数据d</span><br></pre></td></tr></table></figure>
而0x01应该就是长度了。<br>不管怎么说，对于sort字段而言依旧比实际存储的数据大很多。</li>
</ul>
<ol start="5">
<li>如果sort buffer存满，对sort buffer中的数据进行排序，然后写入到临时文件</li>
</ol>
<p>如果需要排序的数据量很大的话，那么sort buffer肯定是不能容下的，因此如果写满后就进行一次内存排序操作，然后将排序好的数据写入到外部排序文件中去，这叫做一个chunk。外部文件的位置由tmpdir参数指定，名字以MY开头，注意外部排序通常需要2个临时文件，这里是第1个用于存储内存排序结果的临时文件，以chunk的方式写入。如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">if (fs_info-&gt;isfull()) //如果sort buffer满了  并且sort buffer已经排序完成</span><br><span class="line">        &#123;</span><br><span class="line">          if (write_keys(param, fs_info, idx, chunk_file, tempfile)) //写入到物理文件 完成内存排序   如果内存不会满这里不会做 会在create_sort_index 中排序完成</span><br><span class="line">          &#123;</span><br><span class="line">            num_records= HA_POS_ERROR;</span><br><span class="line">            goto cleanup;</span><br><span class="line">          &#125;</span><br><span class="line">          idx= 0;</span><br><span class="line">          indexpos++;</span><br><span class="line">        &#125;    </span><br></pre></td></tr></table></figure>
<p>最终会调入write_keys函数进行排序和写入外部排序文件，这里核心就是先排序，然后循环每条排序文件写入到外部排序文件。下面我来验证一下写入临时文件的长度，我将第2节中的例子2数据扩大了N倍后，让其使用外部文件排序，下面是验证结果，断点write_keys即可：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">1161        if (my_b_write(tempfile, record, rec_length))</span><br><span class="line">(gdb) p rec_length</span><br><span class="line">$8 = 91</span><br></pre></td></tr></table></figure>
<p>可以每行的长度还是91字节（打包压缩后），和前面看到的长度一致，说明这些数据会完完整整的写入到外部排序文件，这显然会比我们想象的大得多。<br>好了到这里数据已经找出来了，如果超过sort buffer的大小，外部排序需要的结果已经存储在临时文件1了，并且它是分片（chunk）存储到临时文件的，它以MY开头。</p>
<h1 id="九、阶段7-排序方式总结输出"><a href="#九、阶段7-排序方式总结输出" class="headerlink" title="九、阶段7 排序方式总结输出"></a>九、阶段7 排序方式总结输出</h1><p>这里对上面的排序过程做了一个阶段性的总结，代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Opt_trace_object(trace, &quot;filesort_summary&quot;)</span><br><span class="line">    .add(&quot;rows&quot;, num_rows)</span><br><span class="line">    .add(&quot;examined_rows&quot;, param.examined_rows)</span><br><span class="line">    .add(&quot;number_of_tmp_files&quot;, num_chunks)</span><br><span class="line">    .add(&quot;sort_buffer_size&quot;, table_sort.sort_buffer_size())</span><br><span class="line">    .add_alnum(&quot;sort_mode&quot;,</span><br><span class="line">               param.using_packed_addons() ?</span><br><span class="line">               &quot;&lt;sort_key, packed_additional_fields&gt;&quot; :</span><br><span class="line">               param.using_addon_fields() ?</span><br><span class="line">               &quot;&lt;sort_key, additional_fields&gt;&quot; : &quot;&lt;sort_key, rowid&gt;&quot;); </span><br></pre></td></tr></table></figure>
<p>我们解析一下：</p>
<ul>
<li>rows：排序的行数，也就是应用where过滤条件后剩下的行数。</li>
<li>examined_rows：Innodb层扫描的行数，注意这不是慢查询中的Rows_examined，这里是准确的结果，没有重复计数。</li>
<li>number_of_tmp_files：外部排序时，用于保存结果的临时文件的chunk数量，每次sort buffer满排序后写入到一个chunk，但是所有chunk共同存在于一个临时文件中。</li>
<li>sort_buffer_size：内部排序使用的内存大小，并不一定是sort_buffer_size参数指定的大小。</li>
<li>sort_mode：这里解释如下</li>
</ul>
<ol>
<li>sort_key, packed_additional_fields：使用了modified filesort algorithm（不回表排序） ，并且有打包（pack）的字段，通常为可变字段比如varchar。</li>
<li>sort_key, additional_fields：使用了modified filesort algorithm（不回表排序），但是没有需要打包（pack）的字段，比如都是固定长度字段。</li>
<li>sort_key, rowid：使用了original filesort algorithm（回表排序）。</li>
</ol>
<h1 id="十、阶段8-进行最终排序"><a href="#十、阶段8-进行最终排序" class="headerlink" title="十、阶段8 进行最终排序"></a>十、阶段8 进行最终排序</h1><p>这里涉及2个部分如下：</p>
<ul>
<li>如果sort buffer不满，则这里开始进行排序，调入函数save_index。</li>
<li>如果sort buffer满了，则进行归并排序，调入函数merge_many_buff-&gt;merge_buffers，最后调入merge_index完成归并排序。<br>对于归并排序来讲，这里可能会生成另外2个临时文件用于存储最终排序的结果，它们依然以MY开头，且依然是存储在tmpdir参数指定的位置。因此在外部排序中将可能会生成3个临时文件，总结如下：</li>
<li>临时文件1：用于存储内存排序的结果，以chunk为单位，一个chunk的大小就是sort buffer的大小。</li>
<li>临时文件2：以前面的临时文件1为基础，做归并排序。</li>
<li>临时文件3：将最后的归并排序结果存储，去掉sort字段，只保留addon字段（需要访问的字段）或者ref字段（ROWID或者主键），因此它一般会比前面2个临时文件小。<br>但是它们不会同时存在，要么 临时文件1和临时文件2存在，要么 临时文件2和临时文件3存在。<br>这个很容易验证，将断点放到merge_buffers和merge_index上就可以验证了，如下：<br>临时文件1和临时文件2同时存在：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@gp1 test]# lsof|grep tmp/MY</span><br><span class="line">mysqld     8769     mysql   70u      REG              252,3   79167488    2249135 /mysqldata/mysql3340/tmp/MYt1QIvr (deleted)</span><br><span class="line">mysqld     8769     mysql   71u      REG              252,3   58327040    2249242 /mysqldata/mysql3340/tmp/MY4CrO4m (deleted)</span><br></pre></td></tr></table></figure>
临时文件2和临时文件3共同存在：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@gp1 test]# lsof|grep tmp/MY</span><br><span class="line">mysqld     8769     mysql   70u      REG              252,3     360448    2249135 /mysqldata/mysql3340/tmp/MYg109Wp (deleted)</span><br><span class="line">mysqld     8769     mysql   71u      REG              252,3   79167488    2249242 /mysqldata/mysql3340/tmp/MY4CrO4m (deleted)</span><br></pre></td></tr></table></figure>
但是由于能力有限对于归并排序的具体过程我并没有仔细学习了，这里给一个大概的接口。注意这里每次调用merge_buffers将会增加Sort_merge_passes 1次，应该是归并的次数，这个值增量的大小可以侧面反映出外部排序使用临时文件的大小。</li>
</ul>
<h1 id="十一、排序的其他问题"><a href="#十一、排序的其他问题" class="headerlink" title="十一、排序的其他问题"></a>十一、排序的其他问题</h1><p>这里将描述2个额外的排序问题。<br>1、original filesort algorithm（回表排序）的回表</p>
<p>最后对于original filesort algorithm（回表排序）排序方式而言，可能还需要做一个回表获取数据的操作，这一步可能会用到参数read_rnd_buffer_size定义的内存大小。<br>比如我们第2节中第1个例子将会使用到original filesort algorithm（回表排序），但是对于回表操作有如下标准：</p>
<ul>
<li>如果没有使用到外部排序临时文件则说明排序量不大，则使用普通的回表方式，调入函数rr_from_pointers，也就是单行回表方式。</li>
<li>如果使用到了使用到外部排序临时文件则说明排序量较大，需要使用到批量回表方式，这个时候大概的步骤就是读取rowid（主键）排序，然后批量回表，这将会在read_rnd_buffer_size指定的内存中完成，调入函数rr_from_cache。这也是一种优化方式，因为回表一般是散列的，代价很大。<br>2、关于排序中Rows_examined的计算</li>
</ul>
<p>首先这个值我说的是慢查询的中的Rows_examined，在排序中会出现重复计数的可能，前面第8节已经说明了一下，这个值在第8节还是正确的，但是最后符合where条件的数据在返回的时候还会调用函数evaluate_join_record，结果Rows_examined会增加符合where条件的行数。还是以我们第2节的两个例子为例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; select * from test.tests1 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">+------+------+------+</span><br><span class="line">3 rows in set (5.11 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; select * from test.tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+------+------+------+</span><br><span class="line">| a1   | a2   | a3   |</span><br><span class="line">+------+------+------+</span><br><span class="line">| b    | d    | d    |</span><br><span class="line">| b    | e    | e    |</span><br><span class="line">| b    | f    | f    |</span><br><span class="line">+------+------+------+</span><br><span class="line">3 rows in set (5.28 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc select * from tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">|  1 | SIMPLE      | tests2 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    8 |    12.50 | Using where; Using filesort |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br><span class="line"></span><br><span class="line">8 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc select * from tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">| id | select_type | table  | partitions | type | possible_keys | key  | key_len | ref  | rows | filtered | Extra                       |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">|  1 | SIMPLE      | tests2 | NULL       | ALL  | NULL          | NULL | NULL    | NULL |    8 |    12.50 | Using where; Using filesort |</span><br><span class="line">+----+-------------+--------+------------+------+---------------+------+---------+------+------+----------+-----------------------------+</span><br><span class="line">1 row in set, 1 warning (0.01 sec)</span><br></pre></td></tr></table></figure>

<p>慢查询如下，不要纠结时间（因为我故意debug停止了一会），我们只关注Rows_examined，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Time: 2019-12-23T12:03:26.108529+08:00</span><br><span class="line"># User@Host: root[root] @ localhost []  Id:     4</span><br><span class="line"># Schema:   Last_errno: 0  Killed: 0</span><br><span class="line"># Query_time: 5.118098  Lock_time: 0.000716  Rows_sent: 3  Rows_examined: 11  Rows_affected: 0</span><br><span class="line"># Bytes_sent: 184</span><br><span class="line">SET timestamp=1577073806;</span><br><span class="line">select * from test.tests1 where a1=&#x27;b&#x27; order by a2,a3;</span><br><span class="line"># Time: 2019-12-23T12:03:36.138274+08:00</span><br><span class="line"># User@Host: root[root] @ localhost []  Id:     4</span><br><span class="line"># Schema:   Last_errno: 0  Killed: 0</span><br><span class="line"># Query_time: 5.285573  Lock_time: 0.000640  Rows_sent: 3  Rows_examined: 11  Rows_affected: 0</span><br><span class="line"># Bytes_sent: 184</span><br><span class="line">SET timestamp=1577073816;</span><br><span class="line">select * from test.tests2 where a1=&#x27;b&#x27; order by a2,a3;</span><br></pre></td></tr></table></figure>

<p>我们可以看到Rows_examined都是11，为什么是11呢？显然我们要扫描总的行数为8（这里是全表扫描，表总共8行数据），然后过滤后需要排序的结果为3条数据，这3条数据会重复计数一次。因此就是8+3&#x3D;11，也就是说有3条数据重复计数了。</p>
<h1 id="十二、通过OPTIMIZER-TRACE查看排序结果"><a href="#十二、通过OPTIMIZER-TRACE查看排序结果" class="headerlink" title="十二、通过OPTIMIZER_TRACE查看排序结果"></a>十二、通过OPTIMIZER_TRACE查看排序结果</h1><p>要使用OPTIMIZER_TRACE只需要“SET optimizer_trace&#x3D;”enabled&#x3D;on”;”，跑完语句后查看information_schema.OPTIMIZER_TRACE即可。</p>
<p>前面第9节我们解释了排序方式总结输出的含义，这里我们来看看具体的结果，我们还是以第2节的2个例子为例：</p>
<ul>
<li>例1：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;filesort_priority_queue_optimization&quot;: &#123;</span><br><span class="line">  &quot;usable&quot;: false,</span><br><span class="line">  &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;filesort_execution&quot;: [</span><br><span class="line">],</span><br><span class="line">&quot;filesort_summary&quot;: &#123;</span><br><span class="line">  &quot;rows&quot;: 3,</span><br><span class="line">  &quot;examined_rows&quot;: 8,</span><br><span class="line">  &quot;number_of_tmp_files&quot;: 0,</span><br><span class="line">  &quot;sort_buffer_size&quot;: 1285312,</span><br><span class="line">  &quot;sort_mode&quot;: &quot;&lt;sort_key, rowid&gt;&quot;</span><br></pre></td></tr></table></figure></li>
<li>例2：<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot;filesort_priority_queue_optimization&quot;: &#123;</span><br><span class="line">  &quot;usable&quot;: false,</span><br><span class="line">  &quot;cause&quot;: &quot;not applicable (no LIMIT)&quot;</span><br><span class="line">&#125;,</span><br><span class="line">&quot;filesort_execution&quot;: [</span><br><span class="line">],</span><br><span class="line">&quot;filesort_summary&quot;: &#123;</span><br><span class="line">  &quot;rows&quot;: 3,</span><br><span class="line">  &quot;examined_rows&quot;: 8,</span><br><span class="line">  &quot;number_of_tmp_files&quot;: 0,</span><br><span class="line">  &quot;sort_buffer_size&quot;: 322920,</span><br><span class="line">  &quot;sort_mode&quot;: &quot;&lt;sort_key, packed_additional_fields&gt;&quot;</span><br></pre></td></tr></table></figure>
现在我们清楚了，这些总结实际上是在执行阶段生成的，需要注意几点如下：</li>
<li>这里的examined_rows和慢查询中的Rows_examined不一样，因为这里不会有重复计数，是准确的。</li>
<li>这里还会说明是否使用了优先队列排序即“filesort_priority_queue_optimization”部分。</li>
<li>通过“sort_buffer_size”可以发现，这里并没有分配参数sort_buffer_size指定的大小，节约了内存，这在第7节说明了。<br>其他指标在第9节已经说明过了，不在描述。</li>
</ul>
<h1 id="十三、回到问题本身"><a href="#十三、回到问题本身" class="headerlink" title="十三、回到问题本身"></a>十三、回到问题本身</h1><p>好了，大概的流程我描述了一遍，这些流程都是主要流程，实际上的流程复杂很多。那么我们回到最开始的案例上来。他的max_sort_length和max_length_for_sort_data均为默认值1024。<br>案例中的group by实际就是一个排序操作，我们从执行计划可以看出来，那么先分析一下它的sort字段。很显然group by 后的都是sort字段，其中字段CREATE_ORG_NAME其定义为 varchar（1000），它的占用空间为（1000 * 2）及2000字节，但是超过了max_sort_length的大小，因此为1024字节，相同的还有UPDATE_ORG_NAME字段也是varchar（1000），也会做同样处理，其他字段不会超过max_sort_length的限制，并且在第5节说过sort 字段是不会进行压缩的。</p>
<p>我大概算了一下sort字段的全部大小约为 （3900 * 2) 字节，可以看到一行数据的sort字段基本达到了8K的容量，而addon字段的长度（未打包压缩前）会更大，显然超过max_length_for_sort_data的设置，因此对于这样的排序显然不可能使用modified filesort algorithm（不回表排序了），使用的是original filesort algorithm（回表排序），因此一行的记录就是（sort 字段+主键）了，主键大小可以忽略，最终一行记录的大小就是8K左右，这个值通常会远远大于Innodb压缩后存储varchar字段的大小，这也是为什么本例中虽然表只有30G左右但是临时文件达到了200G以上的原因了。<br>好了，我们来重现一下问题，我们使用第2节的例1，我们将其数据增多，原理上我们的例1会使用到original filesort algorithm（回表排序）的方式，因为这里sort字段（a2，a3）的总长度+addon字段（a1，a2，a3）的长度约为300 * 2 * 2+300 * 3 * 3 这显示大于了max_length_for_sort_data的长度， 因此这个排序一行的长度就是sort字段（a2，a3）+ref字段（ROWID），大约就是300 * 2 * 2+6&#x3D;1206字节了。 下面是这个表的总数据和Innodb文件大小（我这里叫做bgtest5表）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mysql&gt; show create table bgtest5 \G</span><br><span class="line">*************************** 1. row ***************************</span><br><span class="line">       Table: bgtest5</span><br><span class="line">Create Table: CREATE TABLE `bgtest5` (</span><br><span class="line">  `a1` varchar(300) DEFAULT NULL,</span><br><span class="line">  `a2` varchar(300) DEFAULT NULL,</span><br><span class="line">  `a3` varchar(300) DEFAULT NULL</span><br><span class="line">) ENGINE=InnoDB DEFAULT CHARSET=utf8</span><br><span class="line">1 row in set (0.01 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; SELECT COUNT(*) FROM bgtest5;</span><br><span class="line">+----------+</span><br><span class="line">| COUNT(*) |</span><br><span class="line">+----------+</span><br><span class="line">|    65536 |</span><br><span class="line">+----------+</span><br><span class="line">1 row in set (5.91 sec)</span><br><span class="line"></span><br><span class="line">mysql&gt; desc select * from bgtest5  order by a2,a3;</span><br><span class="line">+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+----------------+</span><br><span class="line">| id | select_type | table   | partitions | type | possible_keys | key  | key_len | ref  | rows  | filtered | Extra          |</span><br><span class="line">+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+----------------+</span><br><span class="line">|  1 | SIMPLE      | bgtest5 | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 66034 |   100.00 | Using filesort |</span><br><span class="line">+----+-------------+---------+------------+------+---------------+------+---------+------+-------+----------+----------------+</span><br><span class="line">1 row in set, 1 warning (0.00 sec)</span><br></pre></td></tr></table></figure>

<p>注意这里是全表排序了，没有where过滤条件了，下面是这个表ibd文件的大小：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@gp1 test]# du -hs bgtest5.ibd</span><br><span class="line">11M     bgtest5.ibd</span><br><span class="line">[root@gp1 test]# </span><br></pre></td></tr></table></figure>
<p>下面我们就需要将gdb的断点打在merge_many_buff，我们的目的就是观察临时文件1的大小，这个文件前面说过了是存储内存排序结果的，如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@gp1 test]# lsof|grep tmp/MY</span><br><span class="line">mysqld     8769     mysql   69u      REG              252,3   79101952    2249135 /mysqldata/mysql3340/tmp/MYzfek5x (deleted)</span><br></pre></td></tr></table></figure>
<p>可以看到这个文件的大小为79101952字节，即80M左右，这和我们计算的总量1206（每行大小） * 65535（行数） 约为 80M 结果一致。这远远超过了ibd文件的大小11M，并且要知道，随后还会生成一个大小差不多的文件来存储归并排序的结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@gp1 test]# lsof|grep tmp/MY</span><br><span class="line">mysqld     8769     mysql   69u      REG              252,3   79167488    2249135 /mysqldata/mysql3340/tmp/MYzfek5x (deleted)</span><br><span class="line">mysqld     8769     mysql   70u      REG              252,3   58327040    2249242 /mysqldata/mysql3340/tmp/MY8UOLKa (deleted)</span><br></pre></td></tr></table></figure>
<p>因此得到证明，排序的临时文件远远大于ibd文件的现象是可能出现的。</p>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>挪威3日游(1)</title>
    <url>/2020/norway/</url>
    <content><![CDATA[<h1 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h1><p>因为团队中有位同事是挪威人， 我们经常听他讲一些挪威的事情， 还是对挪威蛮好奇的。 这次挪威转一圈， 发现挪威还是真的挺漂亮的， 冬天可以滑雪， 夏天可以看各种风景， 尤其是峡湾风景， 挪威号称是峡湾之国， 到处可以看到河流， 河流常常环山而下， 又常常在峡谷深处。 另外， 挪威还是看到各种艺术作品， 尤其是油画。 </p>
<h1 id="行程"><a href="#行程" class="headerlink" title="行程"></a>行程</h1><p>第一天，在奥斯陆转1天， 第二天参加挪威缩影旅行， 第三天卑尔根随便逛， 第4天飞瑞典。其中奥斯陆有很多不错展馆，没有逛完，略有遗憾。 </p>
<h2 id="攻略"><a href="#攻略" class="headerlink" title="攻略"></a>攻略</h2><ol>
<li>到了奥斯陆后， 可以做火车到central station， 然后到tourist information 处， 买张奥斯陆卡或者奥斯陆交通卡都可以， 顺便也可以要一份 《奥斯陆旅游指南》</li>
<li>挪威缩影， 直接可以在淘宝或蚂蜂窝购买， 价格都差不多， 购买了后， 是电子票， 可以打印出来或者保存在手机中， 一路会有人来检查。 到了奥斯陆central station 后， 在大屏幕上找到千万卑尔根的火车的站台（通常是早上8点25）</li>
<li>卑尔根， 卑尔根号称是卑尔根最漂亮的城市， 却是值得随便逛逛。</li>
</ol>
<p>奥斯陆，我们还有非常多的景点，我们没有玩到，这个城市，建议可以再多呆上2天，体会体会。</p>
<span id="more"></span>
<h1 id="奥斯陆"><a href="#奥斯陆" class="headerlink" title="奥斯陆"></a>奥斯陆</h1><p>《奥斯陆旅游指南》上有很多旅游推荐项目， 如果在奥斯陆呆超过1天或2天的话， 推荐可以看看这个介绍，上面找一些不错的推荐项目。</p>
<p>因为我们check in 酒店再出来， 已经3点了，其实完的东西已经不多了。</p>
<p>不过，好在还是转了几个地方，<br>强烈推荐维格兰雕塑公园， 维格兰雕塑公园非常漂亮， 即使没有维格兰的雕塑，整个公园景色也是十分漂亮，很多挪威人在这里跑步，闲逛，而维格兰的雕塑更是让这个公园升华到不是一座普通的公园，拥有着自己独特含义和独特思考的公园。<br>这里引述一段介绍<br>维格兰雕塑公园，又名弗罗格纳公园，是一座以雕像为主题的公园，园内展出了挪威雕像家古斯塔夫·维格兰的212座雕像作品。公园内的雕像集中突出人类“生与死”的主题，从婴儿出世开始，经过童年、少年、青年、壮年、老年，直到死亡，反映人生的全过程，发人深思。在众多雕塑中最著名的当属“愤怒的男孩”(Sinnataggen)和大石柱(The Monolith)。巨型石柱十分显眼，足有14米高，石上共雕刻了121个人物。至于“愤怒的男孩”，位于前往巨型石柱的小桥上的左侧，不留意很容易错过。</p>
<p>先来一个全景<br><img data-src="/img/norway/park1.jpeg" ></p>
<p>挑选几张有意思的</p>
<iframe height=498 width=510 src="http://player.youku.com/embed/XNDUzNDMwNjcyNA" frameborder=0 allowfullscreen></iframe>


<img data-src="/img/norway/park7.jpeg" >
<img data-src="/img/norway/park8.jpeg" >
<img data-src="/img/norway/park10.jpeg" >
<img data-src="/img/norway/park11.jpeg" >
<img data-src="/img/norway/park13.jpeg" >
<img data-src="/img/norway/park14.jpeg" >

<p> 夕阳下的维格兰公园，红色的夕阳照在雕塑上，像敷了一层红色的薄纱。<br><img data-src="/img/norway/park3.jpeg" ><br><img data-src="/img/norway/park9.jpeg" ></p>
<p>逛完公园， 做电车随便乱逛， 先去了viking 博物馆，但时间太晚，人家已经闭馆了，于是再坐电车回到市区， 先到了奥斯陆大学<br><img data-src="/img/norway/park5.jpeg" ></p>
<p>因为挪威皇宫就在附近，于是我们也顺便去了一下挪威皇宫， 挪威皇宫是欧洲最简陋的，也是最平易近人的皇宫<br><img data-src="/img/norway/park6.jpeg" ></p>
<p>在奥斯陆码头一家米其林餐厅，享用了一顿西餐， 在这里第一次吃生的生蚝，以前在国内不敢吃， 加上一些酱汁，味道非常鲜。</p>
<img data-src="/img/norway/park2.jpeg" >

<p>吃完饭， 吃的太饱了， 于是在码头上闲逛， 远处就能清晰看到阿克斯胡斯城堡， 于是决定围绕它走了一圈， 因为天色太晚， 不能买票进去， 走一圈也算完成一件心愿吧。<br><img data-src="/img/norway/park4.jpeg" ><br><img data-src="/img/norway/park12.jpeg" ></p>
<p>转完城堡，好累啊， 已经迈不开腿，赶紧回酒店睡觉，还好酒店也不是很远， 又坚持了10分钟回到酒店。 </p>
]]></content>
      <categories>
        <category>travel</category>
      </categories>
      <tags>
        <tag>travel</tag>
      </tags>
  </entry>
  <entry>
    <title>挪威3日游(2)</title>
    <url>/2020/norway2/</url>
    <content><![CDATA[<h2 id="挪威缩影（Norway-nutshell）"><a href="#挪威缩影（Norway-nutshell）" class="headerlink" title="挪威缩影（Norway nutshell）"></a>挪威缩影（Norway nutshell）</h2><p>挪威缩影，是挪威旅游局将挪威沿途的风景安排成一个行程，让游客做做火车，坐坐轮船，体验挪威的漂亮风景。这一路， 夏天山清水秀，冬天白雪皑皑， 景色确实很赞。</p>
<span id="more"></span>
<h3 id="第一程-奥斯陆到米达尔"><a href="#第一程-奥斯陆到米达尔" class="headerlink" title="第一程 奥斯陆到米达尔"></a>第一程 奥斯陆到米达尔</h3><p>这一路开始还是山清水秀，走着走着就变成白雪皑皑， 沿途看到无数河流环山而绕，开始河流还山清水秀，后面就冰封一层。到最后就是茫茫一片， 天地洁白， 偶尔看到几个滑雪的人， 都有时候担心滑雪会不会迷失方向， 中间还看到有人滑伞， 在雪山上滑伞，从来没有体验过， 看起来很刺激。</p>
<img data-src="/img/norway/nutshell.jpeg" >
<iframe height=498 width=510 src="http://player.youku.com/embed/XNDUzNDMwMzMzMg" frameborder=0 allowfullscreen></iframe>
<img data-src="/img/norway/nutshell1.jpeg" >

<h3 id="第二程-米达尔到flam"><a href="#第二程-米达尔到flam" class="headerlink" title="第二程 米达尔到flam"></a>第二程 米达尔到flam</h3><p>这一段是高山火车， 这一段景色更加迷人， 这一段如果在夏天， 中间还会有一些小的表演看看，不过因为临近过年，冰天雪地，表演人员就没有为大家show了。<br>高山火车行驶一段后，来到一个观景台， 大家下车拍照观景， 观景台正对着一个小瀑布<br><img data-src="/img/norway/nutshell2.jpeg" ><br><img data-src="/img/norway/nutshell3.jpeg" ><br>离开观景台， 时而左边风景优美，时而右边如画<br><img data-src="/img/norway/nutshell4.jpeg" ><br><img data-src="/img/norway/nutshell6.jpeg" ><br>快到了flam， 就差不多开始看到村庄了<br><img data-src="/img/norway/nutshell5.jpeg" ><br><img data-src="/img/norway/nutshell7.jpeg" ></p>
<h3 id="第三程，-flam-游峡湾"><a href="#第三程，-flam-游峡湾" class="headerlink" title="第三程， flam 游峡湾"></a>第三程， flam 游峡湾</h3><p>这一段差不多就是缩影的高潮部分， 这里大家坐船在峡湾中穿行2个小时。 </p>
<img data-src="/img/norway/ship.jpeg" >
<img data-src="/img/norway/ship1.jpeg" >
<img data-src="/img/norway/ship2.jpeg" >
<iframe height=498 width=510 src="http://player.youku.com/embed/XNDUzNDMwNjI2MA" frameborder=0 allowfullscreen></iframe>
### 第四程/第五程， 大巴和火车
因为第四程和第五程，天色以黑， 也看不到什么东西， 在车上已经有点昏昏欲睡。 不过这一段路程，如果是在夏天，就可以看到火车沿着海岸线行走，看沿途的大海。

]]></content>
      <categories>
        <category>travel</category>
      </categories>
      <tags>
        <tag>travel</tag>
      </tags>
  </entry>
  <entry>
    <title>挪威3日游(3)</title>
    <url>/2020/norway3/</url>
    <content><![CDATA[<h1 id="卑尔根"><a href="#卑尔根" class="headerlink" title="卑尔根"></a>卑尔根</h1><p>卑尔根，号称是挪威最漂亮的城市，也是世界文化遗产， 这里有非常多漂亮的建筑和展览馆。</p>
<p>这里插一段介绍<br>卑尔根（Bergen），是挪威霍达兰郡的首府，也是挪威第二大城市，同时还是挪威西海岸最大最美的港都，曾在2000年被联合国评选为“欧洲文化之都”，这里气候温和多雨，是一座“雨城”。<br>卑尔根是挪威第二大城市及霍达兰郡首府，也是挪威西部最大的城市，坐落在挪威西海岸陡峭的峡湾线上，倚着港湾和七座山头，市区频临碧湾（Byfjord），直通大西洋，是座风光明媚的港湾之城。由于受墨西哥暖流影响而生的暖风，使卑尔根成为多雨的地区。<br>2000年，卑尔根被评选为9个欧洲文化城市之一。它的魅力展示在剧院，舞蹈，音乐，艺术，食品和展览会中。卑尔根的主要建筑物游览区在港口附近，北部则留存着许多中世纪汉撒同盟时代的古老建筑，南部则是现代化的购物街。</p>
<p>非常漂亮的建筑<br><img data-src="/img/norway/b1.jpeg" ><br><img data-src="/img/norway/b2.jpeg" ><br><img data-src="/img/norway/b3.jpeg" ></p>
<span id="more"></span>
<p>我们乘缆车爬到山顶，一览整个卑尔根城市</p>
<img data-src="/img/norway/b4.jpeg" >
<img data-src="/img/norway/b5.jpeg" >
<img data-src="/img/norway/b6.jpeg" >

<p>这里我们碰到挪威的吉祥物， 山妖， 山妖面相丑陋，不过看起来挺可爱的</p>
<img data-src="/img/norway/b7.jpeg" >

<p>下山后，来到码头随便乱逛了一把<br>这里是卑尔根标志性的建筑， 5色木屋， 它是德国统治期间汉萨联盟搭建的房屋， 以前是汉萨商人的店铺或仓库<br><img data-src="/img/norway/b8.jpeg" ></p>
<p>汉萨联盟遗址， 以前是汉萨商人的仓库，现在是各种商店， 因为是周末，店铺休息，看不到店铺里卖的是什么<br><img data-src="/img/norway/b9.jpeg" ><br><img data-src="/img/norway/b10.jpeg" ><br><img data-src="/img/norway/b11.jpeg" ></p>
<p>离开码头，我们吃过午饭， 准备去卑尔根博物馆， 这里收藏有大量的艺术品，对于爱好艺术的人来说，是一次饕餮大餐， 逛一天都逛不完。<br><img data-src="/img/norway/b12.jpeg" ></p>
<p>各种艺术品和家具等<br><img data-src="/img/norway/b13.jpeg" ><br><img data-src="/img/norway/b14.jpeg" ><br>各种各样的油画， 有人物肖像， 有风景，有抽象派等等，仔细逛，一天都逛不完<br><img data-src="/img/norway/b15.jpeg" ><br><img data-src="/img/norway/b16.jpeg" ><br><img data-src="/img/norway/b17.jpeg" ></p>
<p>离开博物馆， 走在街上， 随便拍一拍，都有非常不错的收获<br><img data-src="/img/norway/b18.jpeg" ><br><img data-src="/img/norway/b19.jpeg" ><br><img data-src="/img/norway/b20.jpeg" ></p>
<p>最后在一家中餐馆作为今天的收官之战，“china palace”， 还不错，值得推荐</p>
<img data-src="/img/norway/b21.jpeg" >
]]></content>
      <categories>
        <category>travel</category>
      </categories>
      <tags>
        <tag>travel</tag>
      </tags>
  </entry>
  <entry>
    <title>OceanBase离线安装</title>
    <url>/2021/ob_offline_install/</url>
    <content><![CDATA[<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>将8月份写的离线安装文档, share 出来. 后续可能会发一系列的使用文档. </p>
<p>本文将以线上业务运行OceanBase为目标, 部署分布式版本, 如果想简单测试和试用OceanBase, 请参考<a href="https://open.oceanbase.com/quickStart">https://open.oceanbase.com/quickStart</a><br>​</p>
<h1 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h1><p>​<img data-src="/img/ob/install1.jpg" ></p>
<span id="more"></span>

<h1 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h1><p>安装前, 均使用root 进行操作, 安装过程中, 可以使用对应的普通用户</p>
<h2 id="名词解释"><a href="#名词解释" class="headerlink" title="名词解释"></a>名词解释</h2><ul>
<li>OBD: OceanBase Deployer,   OceanBase 部署工具</li>
<li>主控机: 运行OBD 安装包机器</li>
<li>OBServer : 每台安装 OceanBase 的物理机上面运行的 OceanBase 数据库进程&#x2F;服务，称为 OBServer  	</li>
<li>OBProxy : OceanBase Proxy, 是 OceanBase 高性能反向代理服务器，具有防连接闪断、 屏蔽后端异常(宕机、升级、网络抖动)、MySQL 协议兼容、强校 验、支持热升级和多集群等功能<br>​</li>
</ul>
<h2 id="部署模式"><a href="#部署模式" class="headerlink" title="部署模式"></a>部署模式</h2><p>在本例采用经典的三幅本部署模式, 使用4台机器:</p>
<ul>
<li>1台机器 部署 OBProxy  – 推荐客户端应用和OBProxy 部署一起, 减少第一次网络时延.</li>
<li>1-1-1 部署3副本OceanBase 集群, 每个zone 表示一个副本, 在本例中, 一个zone 只包含一台机器. 3个zone 可以生产环境中常常部署两地三中心模式, 三个机房三个副本, 每个机房一个副本, 其中两个机房距离较近.</li>
</ul>
<p>​</p>
<h2 id="软硬件要求"><a href="#软硬件要求" class="headerlink" title="软硬件要求"></a>软硬件要求</h2><table>
<thead>
<tr>
<th>项目</th>
<th>描述</th>
</tr>
</thead>
<tbody><tr>
<td>系统</td>
<td>Red Hat Enterprise Linux Server 7.x 版本（内核 Linux 3.10.0 版本及以上） </br>CentOS Linux 7.x 版本（内核 Linux 3.10.0 版本及以上）</br> Anolis OS 8.x 版本（内核 Linux 3.10.0 版本及以上）</td>
</tr>
<tr>
<td>CPU</td>
<td>企业级用户最低要求16核, 推荐32核及以上 </br>个人测试最低要求2核, 推荐8核及以上</td>
</tr>
<tr>
<td>内存</td>
<td>企业级应用最低要求64G,  推荐256G 及以上 </br>个人测试最低要求8G, 推荐64G 及以上</td>
</tr>
<tr>
<td>磁盘类型</td>
<td>推荐SSD</td>
</tr>
<tr>
<td>磁盘空间</td>
<td>内存大小的4倍及以上</td>
</tr>
<tr>
<td>文件系统</td>
<td>ext4或xfs, 当数据量超过16TB时, 使用xfs</td>
</tr>
<tr>
<td>网卡</td>
<td>千兆互联及以上</td>
</tr>
</tbody></table>
<h2 id="设置无密码SSH-登录"><a href="#设置无密码SSH-登录" class="headerlink" title="设置无密码SSH 登录"></a>设置无密码SSH 登录</h2><p>在安装前, 需要对每台机器的环境进行设置, 这些设置都需在超级管理员下操作, 建议打通 主控机器 到OBServer 和OBProxy 机器的信任登陆(即无密码登录), 如何设置无密码SSH 登录, 详情参考 <a href="https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/optional-set-password-free-ssh-logon">https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/optional-set-password-free-ssh-logon</a><br>​</p>
<p>推荐2个脚本, 方便在集群中批量执行命令和拷贝文件<br>批量拷贝文件,  可以将host list 换成自己实际机器列表</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#/usr/bin/bash</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hosts=(</span><br><span class="line">    &quot;ob001&quot;</span><br><span class="line">    &quot;ob002&quot;</span><br><span class="line">    &quot;ob003&quot;</span><br><span class="line">    &quot;obdriver&quot;</span><br><span class="line">    )</span><br><span class="line">    for host in &quot;$&#123;hosts[@]&#125;&quot;</span><br><span class="line">    do</span><br><span class="line"></span><br><span class="line">        echo &quot;begin to scp &quot; $@ &quot; on &quot; $host</span><br><span class="line">        scp -r $1 $host:$2</span><br><span class="line">    done</span><br></pre></td></tr></table></figure>
<p>批量执行命令, 可以将host list  换成自己实际的机器列表</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/usr/bin/bash</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">hosts=(</span><br><span class="line">    &quot;ob001&quot;</span><br><span class="line">    &quot;ob002&quot;</span><br><span class="line">    &quot;ob003&quot;</span><br><span class="line">    &quot;obdriver&quot;</span><br><span class="line">    )</span><br><span class="line">    for host in &quot;$&#123;hosts[@]&#125;&quot;</span><br><span class="line">    do</span><br><span class="line">        echo &quot;begin to run &quot; $@ &quot; on &quot; $host</span><br><span class="line">        ssh $host $@</span><br><span class="line">    done</span><br></pre></td></tr></table></figure>


<h2 id="创建使用用户"><a href="#创建使用用户" class="headerlink" title="创建使用用户"></a>创建使用用户</h2><p>对于个人测试用户, 可以直接使用root 账号, 对于企业用户, 推荐创新普通用户, 避免对系统照成安全冲击.  在本例中, 使用admin 作为示范, 企业用户可以根据自己需要, 使用自己常用的账户<br>​</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">useradd -U admin -d /home/admin -s /bin/bash</span><br><span class="line">mkdir -p /home/admin</span><br><span class="line">sudo chown -R admin:admin /home/admin</span><br></pre></td></tr></table></figure>


<p>设置密码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">passwd admin</span><br></pre></td></tr></table></figure>
<p>​</p>
<p>设置sudo 权限<br>vi &#x2F;etc&#x2F;sudoers      #添加oceanbase一行内容</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">## Same thing without a password</span><br><span class="line"># %wheel        ALL=(ALL)       NOPASSWD: ALL</span><br><span class="line">admin       ALL=(ALL)       NOPASSWD: ALL</span><br></pre></td></tr></table></figure>


<h2 id="磁盘规划"><a href="#磁盘规划" class="headerlink" title="磁盘规划"></a>磁盘规划</h2><p>OceanBase 数据库服务器依赖3个目录,   当个人测试使用时, 可以将所有数据放到1块盘下, 但在企业级用户中, 必须分别挂载3块磁盘: 数据盘, 事务日志盘, OBServer 安装盘. 当机器上没有3块盘时或者使用RAID 磁盘阵列时,  需要对磁盘或者磁盘阵列的逻辑卷进行分区, 分3块分区, 分区大小参考下面说明:</p>
<ul>
<li><p>数据盘</p>
<ul>
<li>配置参数为data_dir.  要根据业务需要，做好数据盘的规划. 数据盘承载了基线数据，物理上只有一个基线数据文件 block_file，在安装目录 store&#x2F;sstable 下。通过 OBServer 进程启动时一 次性创建，大小根据启动参数 datafile_disk_percentage 采用磁盘预分 配策略，默认值为 95%，创建后无法调整大小。OceanBase 的扩容缩 容采用加减机器的策略，目前不支持单机的磁盘级扩容和缩容。</li>
</ul>
</li>
<li><p>事务日志盘</p>
<ul>
<li>配置参数为redo_dir.  推荐大小为OBServer 内存3到4倍或以上. 事务日志盘包含多个固定大小的小文件，位于安装目录 store&#x2F;{clog,ilog,slog}，按需自动创建和清除，磁盘写到 80%会触发自 清除逻辑，但前提是这部分日志数据对应的内存数据已经通过合并融 合到了基线数据中，才能被删除。同等数据量， 事务日志的大小约为内存数据大小的三倍。所以事务日志盘所需空间 上限与两次合并操作间的业务数据总量成正比，经验公式是:事务日 志文件大小 &#x3D; 增量数据内存上限的 3 到 4 倍。</li>
</ul>
</li>
<li><p>OBServer 安装盘</p>
<ul>
<li><p>配置参数home_path. 推荐200G 或以上(保存7天或以上的日志量). OceanBase 的 rpm 包安装目录在&#x2F;home&#x2F;admin&#x2F;oceanbase 下，其中 基线数据文件和事务日志文件会通过软连接指向上述的两个独立磁 盘，还有另外一个不断增长的文件是 OB 运行日志，在安装目录 log 下。OB 进程本身无法自删除运行日志，需要定时任务或运维脚本完 成删除逻辑。 </p>
<p>磁盘划分后, 可以通过df -h 命令检查, 结果如下:</p>
</li>
</ul>
</li>
</ul>
<p>​<img data-src="/img/ob/install2.png" ><br>在本示例中: &#x2F;data 为数据磁盘, 大小1TB, &#x2F;redo 存放 redo 日志,  &#x2F;home&#x2F;admin&#x2F;oceanbase 存放oceanbase binary 和运行日志<br>​</p>
<p>检查目录权限</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ls –al #执行该命令</span><br><span class="line">drwxr-xr-x 2 admin admin 4096 2 月 9 18:43 </span><br><span class="line">drwxr-xr-x 2 admin admin 4096 2 月 9 18:43 log1</span><br><span class="line"></span><br><span class="line">若 admin 用户无权限，则以 root 用户执行如下命令 </span><br><span class="line">chown -R admin:admin /data</span><br><span class="line">chown -R admin:admin /redo</span><br><span class="line">chown -R admin:admin /home/admin</span><br></pre></td></tr></table></figure>
<p>​</p>
<h2 id="预检查"><a href="#预检查" class="headerlink" title="预检查"></a>预检查</h2><p>企业级用户建议运行OBServer 所有机器硬件配置和软件配置(操作系统, 操作系统内核, glibc, python 等软件包) 一致, OBProxy 机器和OBServer 机器软件配置一致(操作系统, 操作系统内核, glibc, python等软件包). </p>
<h3 id="检查操作系统"><a href="#检查操作系统" class="headerlink" title="检查操作系统"></a>检查操作系统</h3><p>当前支持的操作系统为:<br>​</p>
<p>Red Hat Enterprise Linux Server 7.x 版本（内核 Linux 3.10.0 版本及以上）<br>CentOS Linux 7.x 版本（内核 Linux 3.10.0 版本及以上）<br>​</p>
<ol>
<li>以root 用户登录服务器</li>
<li>查看os 版本</li>
</ol>
<p>		 				</p>
<p>RedHat7 系统显示如下 </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@redhat-04 /root]#cat /etc/redhat-release</span><br><span class="line">Red Hat Enterprise Linux Server release 7.2 (Maipo)</span><br></pre></td></tr></table></figure>
<p>CentOS7 系统显示如下: </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@centos-01 /root]#cat /etc/redhat-release </span><br><span class="line">CentOS Linux release 7.2.1511 (Core)</span><br></pre></td></tr></table></figure>
<p>在anolis 系统上:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@anolis ~]# cat /etc/os-release</span><br><span class="line">NAME=&quot;Anolis OS&quot;</span><br><span class="line">VERSION=&quot;8.2&quot;</span><br><span class="line">ID=&quot;anolis&quot;</span><br><span class="line">ID_LIKE=&quot;rhel fedora centos&quot;</span><br><span class="line">VERSION_ID=&quot;8.2&quot;</span><br><span class="line">PLATFORM_ID=&quot;platform:an8&quot;</span><br><span class="line">PRETTY_NAME=&quot;Anolis OS 8.2&quot;</span><br><span class="line">ANSI_COLOR=&quot;0;31&quot;</span><br><span class="line">HOME_URL=&quot;https://openanolis.org/&quot;</span><br></pre></td></tr></table></figure>
<p>​</p>
<p>其他系统, 如Debian9 系统显示如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@ob001:~# cat /etc/os-release</span><br><span class="line">PRETTY_NAME=&quot;Debian GNU/Linux 9 (stretch)&quot;</span><br><span class="line">NAME=&quot;Debian GNU/Linux&quot;</span><br><span class="line">VERSION_ID=&quot;9&quot;</span><br><span class="line">VERSION=&quot;9 (stretch)&quot;</span><br><span class="line">VERSION_CODENAME=stretch</span><br><span class="line">ID=debian</span><br><span class="line">HOME_URL=&quot;https://www.debian.org/&quot;</span><br><span class="line">SUPPORT_URL=&quot;https://www.debian.org/support&quot;</span><br><span class="line">BUG_REPORT_URL=&quot;https://bugs.debian.org/&quot;</span><br></pre></td></tr></table></figure>
<p>在unbutu 系统上:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">NAME=&quot;Ubuntu&quot;</span><br><span class="line">VERSION=&quot;20.04.2 LTS (Focal Fossa)&quot;</span><br><span class="line">ID=ubuntu</span><br><span class="line">ID_LIKE=debian</span><br><span class="line">PRETTY_NAME=&quot;Ubuntu 20.04.2 LTS&quot;</span><br><span class="line">VERSION_ID=&quot;20.04&quot;</span><br><span class="line">HOME_URL=&quot;https://www.ubuntu.com/&quot;</span><br><span class="line">SUPPORT_URL=&quot;https://help.ubuntu.com/&quot;</span><br><span class="line">BUG_REPORT_URL=&quot;https://bugs.launchpad.net/ubuntu/&quot;</span><br><span class="line">PRIVACY_POLICY_URL=&quot;https://www.ubuntu.com/legal/terms-and-policies/privacy-policy&quot;</span><br><span class="line">VERSION_CODENAME=focal</span><br><span class="line">UBUNTU_CODENAME=focal</span><br></pre></td></tr></table></figure>


<p>对于一些系统, 如Ubuntu&#x2F;Debian, 需要安装yum:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install build-essential </span><br><span class="line">sudo apt-get install yum -y</span><br><span class="line">sudo apt install yum-utils -y</span><br><span class="line">sudo ln -s /bin/bash /bin/sh</span><br><span class="line">apt-get install alien -y</span><br><span class="line">apt-get install rpm</span><br></pre></td></tr></table></figure>




<pre><code> 3. 查看内核版本, 要求操作系统3.10.0 及以上
</code></pre>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@centos-01 /root]#uname -r </span><br><span class="line">3.10.0-327.el7.x86_64</span><br></pre></td></tr></table></figure>

<h3 id="检查内存"><a href="#检查内存" class="headerlink" title="检查内存"></a>检查内存</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">free -g</span><br></pre></td></tr></table></figure>
<p>企业级应用最低要求64G,  推荐256G 及以上<br>如果free -g<br>​<img data-src="/img/ob/install3.png" ><br>显示的free列的内存小于配置文件中的memory_limit配置, 需要清理缓存或者修改配置memory_limit, 将memory_limit修改小于free 列的值. 清理缓存操作如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># echo 3 &gt; /proc/sys/vm/drop_caches</span><br></pre></td></tr></table></figure>
<p>​</p>
<h2 id="检查磁盘"><a href="#检查磁盘" class="headerlink" title="检查磁盘"></a>检查磁盘</h2><p>​</p>
<p>确保配置文件中, <code>data_dir, redo_dir, home_path</code>,  对应的磁盘已经完成挂载,   data_dir和redo_dir 对应目录为空, data_dir 对应目录的磁盘已经使用率必须低于4%.<br>​<img data-src="/img/ob/install4.png" ></p>
<h2 id="检查网卡名称"><a href="#检查网卡名称" class="headerlink" title="检查网卡名称"></a>检查网卡名称</h2><p>​<img data-src="/img/ob/install5.png" ><br>配置文件中, 有一个配置项”devname” 需要指定网卡. 在启动 OBServer 服务时，需要通过“-i”参数指定网卡，服务器有 可能有多个网卡以及多个 IP，OBServer 之间通信依赖指定的网卡和 IP。可以通过 ifconfig 命令查看网卡名称 (需要先安装 net-tools 依赖 包)，确保存在有效的网卡即可。<br>在本例中:<br>​<img data-src="/img/ob/install6.png" ></p>
<h2 id="配置limits-conf"><a href="#配置limits-conf" class="headerlink" title="配置limits.conf"></a>配置limits.conf</h2><p>ulimit 用于限制 shell 启动进程所占用的资源。个人测试使用,可以不用设置, 但企业用户必须设置.<br>有两种方法可以修 改资源限制，一种是通过启动时 session 级别指定，另外一种是修改 &#x2F;etc&#x2F;security&#x2F;limits.conf 配置文件，全局生效。<br>OBServer 进程涉及的几个限制包括线程最大栈空间大小(stack)， 最大文件句柄数(open files)，core 文件大小(core file size)。<br>如下在启动 OBServer 进程时，session 级别设置最大栈空间大小 为 unlimited，最大文件句柄数为 655350，core 文件大小为 unlimited </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$vi /etc/security/limits.conf 添加</span><br><span class="line">root soft nofile 655350</span><br><span class="line">root hard nofile 655350</span><br><span class="line">* soft nofile 655350</span><br><span class="line">* hard nofile 655350</span><br><span class="line">* soft stack 20480</span><br><span class="line">* hard stack 20480</span><br><span class="line">* soft nproc 655360</span><br><span class="line">* hard nproc 655360</span><br><span class="line">* soft core unlimited</span><br><span class="line">* hard core unlimited</span><br></pre></td></tr></table></figure>
<pre><code> 退出当前session, 重新登录
</code></pre>
<p>​</p>
<p>检查配置是否生效</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ulimit -a</span><br><span class="line"># 执行该命令，资源限制详情如下 (blocks, -c) 0</span><br><span class="line">core file size</span><br><span class="line">data seg size scheduling priority file size</span><br><span class="line">pending signals max locked memory</span><br><span class="line">(kbytes, -d) unlimited (-e) 0</span><br><span class="line">(blocks, -f) unlimited (-i) 772861</span><br><span class="line">(kbytes, -l) 64</span><br><span class="line">max memory size</span><br><span class="line">open files</span><br><span class="line">pipe size</span><br><span class="line">POSIX message queues real-time priority</span><br><span class="line">stack size</span><br><span class="line">cpu time</span><br><span class="line">max user processes virtual memory file locks</span><br><span class="line">(kbytes, -m) unlimited (-n) 1024</span><br><span class="line">(512 bytes, -p) 8</span><br><span class="line">(bytes, -q) 819200</span><br><span class="line">(-r) 0 (kbytes, -s) 8192</span><br><span class="line">(seconds, -t) unlimited (-u) 655360</span><br><span class="line">(kbytes, -v) unlimited (-x) unlimited</span><br></pre></td></tr></table></figure>
<p>​</p>
<h2 id="配置“sysctl-conf”文件"><a href="#配置“sysctl-conf”文件" class="headerlink" title="配置“sysctl.conf”文件"></a>配置“sysctl.conf”文件</h2><p>为保证 OceanBase 正常运行，请在安装 OceanBase 前修改所有物理机的“&#x2F;etc&#x2F;sysctl.conf”配置(用以提高 Linux 的系统性能)。</p>
<p>有一些参数, 操作系统已经提前设置了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># for oceanbase</span><br><span class="line">## 修改内核异步 I/O 限制</span><br><span class="line">fs.aio-max-nr=1048576</span><br><span class="line"></span><br><span class="line">## 网络优化</span><br><span class="line">net.core.somaxconn = 2048</span><br><span class="line">net.core.netdev_max_backlog = 10000 </span><br><span class="line">net.core.rmem_default = 16777216 </span><br><span class="line">net.core.wmem_default = 16777216 </span><br><span class="line">net.core.rmem_max = 16777216 </span><br><span class="line">net.core.wmem_max = 16777216</span><br><span class="line"></span><br><span class="line">net.ipv4.ip_local_port_range = 3500 65535 </span><br><span class="line">net.ipv4.ip_forward = 0 </span><br><span class="line">net.ipv4.conf.default.rp_filter = 1 </span><br><span class="line">net.ipv4.conf.default.accept_source_route = 0 </span><br><span class="line">net.ipv4.tcp_syncookies = 0 </span><br><span class="line">net.ipv4.tcp_rmem = 4096 87380 16777216 </span><br><span class="line">net.ipv4.tcp_wmem = 4096 65536 16777216 </span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384 </span><br><span class="line">net.ipv4.tcp_fin_timeout = 15 </span><br><span class="line">net.ipv4.tcp_max_syn_backlog = 16384 </span><br><span class="line">net.ipv4.tcp_tw_reuse = 1 </span><br><span class="line">net.ipv4.tcp_tw_recycle = 1 </span><br><span class="line">net.ipv4.tcp_slow_start_after_idle=0</span><br><span class="line"></span><br><span class="line">vm.swappiness = 0</span><br><span class="line">vm.min_free_kbytes = 2097152</span><br><span class="line"></span><br><span class="line"># 此处为oceanbase 的data 目录</span><br><span class="line">kernel.core_pattern = /data/core-%e-%p-%t </span><br></pre></td></tr></table></figure>
<p>其中, “kernel.core_pattern &#x3D; &#x2F;data&#x2F;core-%e-%p-%t ”,  &#x2F;data 为 oceanbase的data 目录,  另外如果是个人测试, 也可以只设置 “fs.aio-max-nr&#x3D;1048576”<br>​</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 配置生效</span><br><span class="line">sysctl -p</span><br></pre></td></tr></table></figure>
<p>​</p>
<h2 id="关闭防火墙和-SELinux"><a href="#关闭防火墙和-SELinux" class="headerlink" title="关闭防火墙和 SELinux"></a>关闭防火墙和 SELinux</h2><p>个人测试可以不用设置, 但企业用户建议进行设置</p>
<h3 id="firewalld关闭"><a href="#firewalld关闭" class="headerlink" title="firewalld关闭"></a>firewalld关闭</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#依次执行这 3 条命令 </span><br><span class="line">systemctl disable firewalld </span><br><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl status firewalld</span><br></pre></td></tr></table></figure>

<h3 id="selinux关闭"><a href="#selinux关闭" class="headerlink" title="selinux关闭"></a>selinux关闭</h3><p>vi &#x2F;etc&#x2F;selinux&#x2F;linux</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">SELINUX=disabled</span><br></pre></td></tr></table></figure>
<p>执行该命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">#查看配置已生效</span><br><span class="line">cat /etc/selinux/config</span><br></pre></td></tr></table></figure>


<h2 id="设置时钟同步"><a href="#设置时钟同步" class="headerlink" title="设置时钟同步"></a>设置时钟同步</h2><p>当下面任一状况时, 可以跳过设置时钟同步:</p>
<ol>
<li>若 NTP 时钟已经处于同步状态</li>
<li>部署为单机版</li>
<li>个人测试</li>
</ol>
<p>​</p>
<p>OceanBase 集群中各服务器的时间需保持一致，否则会导致 OceanBase 集群无法启动，运行时也会出现故障。对于企业用户来说, 时钟同步是<strong>非常非常重要</strong>, 物理机与时钟服务器的误差在 50ms 以下可认为时钟是同步状态 , 最大容忍误差不能超过200ms. 当超过200ms, 会出现无主状况, 恢复时钟同步后, 重启observer, 可以恢复状态. </p>
<h3 id="检查时钟同步"><a href="#检查时钟同步" class="headerlink" title="检查时钟同步"></a>检查时钟同步</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo clockdiff  $IP</span><br></pre></td></tr></table></figure>

<h3 id="配置时钟同步"><a href="#配置时钟同步" class="headerlink" title="配置时钟同步"></a>配置时钟同步</h3><p><a href="https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/optional-configuring-clock-sources">https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/optional-configuring-clock-sources</a><br>​</p>
<h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><h2 id="安装包组件"><a href="#安装包组件" class="headerlink" title="安装包组件"></a>安装包组件</h2><p>从<a href="https://open.oceanbase.com/softwareCenter/community">https://open.oceanbase.com/softwareCenter/community</a> 上下载所有的安装包, 本文展示的安装包的版本,可能已经过期, 麻烦从开源OceanBase官网下载最新版本的安装包.<br>​<img data-src="/img/ob/install7.png" ><br>如您的机器可以访问公网，并能够添加三方 YUM 软件源，您可以运行以下命令，使用 OceanBase 的官方软件源安装 OBD：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum install -y yum-utils</span><br><span class="line">sudo yum-config-manager --add-repo https://mirrors.aliyun.com/oceanbase/OceanBase.repo</span><br><span class="line">sudo yum install -y ob-deploy</span><br></pre></td></tr></table></figure>
<p>​</p>
<p>将所有的软件包, scp至 主控机器上</p>
<p>​</p>
<h2 id="安装OBD"><a href="#安装OBD" class="headerlink" title="安装OBD"></a>安装OBD</h2><p>当前使用root 用户, 当前操作只在主控机器上进行操作</p>
<h3 id="在线安装"><a href="#在线安装" class="headerlink" title="在线安装"></a>在线安装</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install -y ob-deploy</span><br></pre></td></tr></table></figure>

<h3 id="本地安装"><a href="#本地安装" class="headerlink" title="本地安装"></a>本地安装</h3><p>centos或redhat</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install ob-deploy-1.1.0-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>
<p>Ubuntu&#x2F;Debian</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alien -i ob-deploy-1.1.0-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>


<h2 id="安装OBLibs"><a href="#安装OBLibs" class="headerlink" title="安装OBLibs"></a>安装OBLibs</h2><p>当前使用root 用户, 需要在每台机器上执行,  </p>
<h3 id="在线安装-1"><a href="#在线安装-1" class="headerlink" title="在线安装"></a>在线安装</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install -y oceanbase-ce-libs</span><br></pre></td></tr></table></figure>

<h3 id="本地安装-1"><a href="#本地安装-1" class="headerlink" title="本地安装"></a>本地安装</h3><p>先将oceanbase-ce-libs-3.1.0-3.el7.x86_64.rpm 拷贝到每台机器下<br>​</p>
<p>centos或redhat或anolis</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install oceanbase-ce-libs-3.1.0-3.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>
<p>Ubuntu&#x2F;Debian</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alien -i oceanbase-ce-libs-3.1.0-3.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>


<h2 id="安装OBServer-OBProxy"><a href="#安装OBServer-OBProxy" class="headerlink" title="安装OBServer &amp; OBProxy"></a>安装OBServer &amp; OBProxy</h2><p>切换到admin 用户下<br>​</p>
<h3 id="将OceanBase数据库的离线软件包加入本地镜像"><a href="#将OceanBase数据库的离线软件包加入本地镜像" class="headerlink" title="将OceanBase数据库的离线软件包加入本地镜像"></a>将OceanBase数据库的离线软件包加入本地镜像</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">admin@obdriver:/data/rpm$ obd mirror clone *.rpm</span><br><span class="line">name: libobclient</span><br><span class="line">version: 2.0.0</span><br><span class="line">release:2.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: f73cae67e2ff5be0682ac2803aba33a7ed26430e</span><br><span class="line">add libobclient-2.0.0-2.el7.x86_64.rpm to local mirror</span><br><span class="line">name: obclient</span><br><span class="line">version: 2.0.0</span><br><span class="line">release:2.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: 1d2c3ee31f40b9d2fbf97f653f549d896b7e7060</span><br><span class="line">add obclient-2.0.0-2.el7.x86_64.rpm to local mirror</span><br><span class="line">name: ob-deploy</span><br><span class="line">version: 1.1.0</span><br><span class="line">release:1.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: c01dbbebc7f44b700833ce6846df09f20033675c</span><br><span class="line">add ob-deploy-1.1.0-1.el7.x86_64.rpm to local mirror</span><br><span class="line">name: obproxy</span><br><span class="line">version: 3.1.0</span><br><span class="line">release:1.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: 0b17cf0459a3b53c5a2febb6572894d183154c64</span><br><span class="line">add obproxy-3.1.0-1.el7.x86_64.rpm to local mirror</span><br><span class="line">name: oceanbase-ce</span><br><span class="line">version: 3.1.0</span><br><span class="line">release:3.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: b73bcd531bdf3f087391991b290ff2cbcdaa0dc9</span><br><span class="line">add oceanbase-ce-3.1.0-3.el7.x86_64.rpm to local mirror</span><br><span class="line">name: oceanbase-ce-libs</span><br><span class="line">version: 3.1.0</span><br><span class="line">release:3.el7</span><br><span class="line">arch: x86_64</span><br><span class="line">md5: 528144ec7ff0194a8b326491a396b8f5c87b1eaa</span><br><span class="line">add oceanbase-ce-libs-3.1.0-3.el7.x86_64.rpm to local mirror</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">admin@obdriver:~$ obd mirror list local</span><br><span class="line">+-------------------------------------------------------------------------------------------+</span><br><span class="line">|                                     local Package List                                    |</span><br><span class="line">+-------------------+---------+---------+--------+------------------------------------------+</span><br><span class="line">| name              | version | release | arch   | md5                                      |</span><br><span class="line">+-------------------+---------+---------+--------+------------------------------------------+</span><br><span class="line">| libobclient       | 2.0.0   | 2.el7   | x86_64 | f73cae67e2ff5be0682ac2803aba33a7ed26430e |</span><br><span class="line">| obclient          | 2.0.0   | 2.el7   | x86_64 | 1d2c3ee31f40b9d2fbf97f653f549d896b7e7060 |</span><br><span class="line">| ob-deploy         | 1.1.0   | 1.el7   | x86_64 | c01dbbebc7f44b700833ce6846df09f20033675c |</span><br><span class="line">| obproxy           | 3.1.0   | 1.el7   | x86_64 | 0b17cf0459a3b53c5a2febb6572894d183154c64 |</span><br><span class="line">| oceanbase-ce      | 3.1.0   | 3.el7   | x86_64 | b73bcd531bdf3f087391991b290ff2cbcdaa0dc9 |</span><br><span class="line">| oceanbase-ce-libs | 3.1.0   | 3.el7   | x86_64 | 528144ec7ff0194a8b326491a396b8f5c87b1eaa |</span><br><span class="line">+-------------------+---------+---------+--------+------------------------------------------+</span><br></pre></td></tr></table></figure>


<h3 id="下载配置文件"><a href="#下载配置文件" class="headerlink" title="下载配置文件"></a>下载配置文件</h3><p>到<a href="https://github.com/oceanbase/obdeploy/tree/master/example/autodeploy">https://github.com/oceanbase/obdeploy/tree/master/example/autodeploy</a> 上将所有配置文件下载下来<br>当前有几个配置文件:<br>​</p>
<ul>
<li><a href="https://github.com/oceanbase/obdeploy/blob/master/example/autodeploy/distributed-example.yaml">distributed-example.yaml</a>    :  分布式example</li>
<li><a href="https://github.com/oceanbase/obdeploy/blob/master/example/autodeploy/distributed-with-obproxy-example.yaml">distributed-with-obproxy-example.yaml</a>  : 分布式带obproxy的example</li>
<li><a href="https://github.com/oceanbase/obdeploy/blob/master/example/autodeploy/single-example.yaml">single-example.yaml</a>  : 单机example</li>
<li><a href="https://github.com/oceanbase/obdeploy/blob/master/example/autodeploy/single-with-obproxy-example.yaml">single-with-obproxy-example.yaml</a>  : 单机example</li>
</ul>
<p>​</p>
<p>在本例中, 我们使用分布式example, 我们将分布式配置文件 scp到 主控机器上. </p>
<h3 id="修改配置文件"><a href="#修改配置文件" class="headerlink" title="修改配置文件"></a>修改配置文件</h3><p>本例中, 以distributed-with-obproxy-example.yaml为例</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## Only need to configure when remote login is required</span><br><span class="line"># user:</span><br><span class="line">#   username: your username</span><br><span class="line">#   password: your password if need</span><br><span class="line">#   key_file: your ssh-key file path if need</span><br><span class="line">#   port: your ssh port, default 22</span><br><span class="line">#   timeout: ssh connection timeout (second), default 30</span><br><span class="line">oceanbase-ce:</span><br><span class="line">  servers:</span><br><span class="line">    - name: z1</span><br><span class="line">      # Please don&#x27;t use hostname, only IP can be supported</span><br><span class="line">      ip: 192.168.1.2</span><br><span class="line">    - name: z2</span><br><span class="line">      ip: 192.168.1.3</span><br><span class="line">    - name: z3</span><br><span class="line">      ip: 192.168.1.4</span><br><span class="line">  global:</span><br><span class="line">    # The working directory for OceanBase Database. OceanBase Database is started under this directory. This is a required field.</span><br><span class="line">    home_path: /root/observer</span><br><span class="line">    # The directory for data storage. The default value is $home_path/store.</span><br><span class="line">    # data_dir: /data</span><br><span class="line">    # The directory for clog, ilog, and slog. The default value is the same as the data_dir value.</span><br><span class="line">    # redo_dir: /redo</span><br><span class="line">    # External port for OceanBase Database. The default value is 2881.</span><br><span class="line">    # mysql_port: 2881</span><br><span class="line">    # Internal port for OceanBase Database. The default value is 2882.</span><br><span class="line">    # rpc_port: 2882</span><br><span class="line">    # Defines the zone for an observer. The default value is zone1.</span><br><span class="line">    # zone: zone1</span><br><span class="line">    # The maximum running memory for an observer. When ignored, autodeploy calculates this value based on the current server available resource.</span><br><span class="line">    # memory_limit: 58G</span><br><span class="line">    # The percentage of the maximum available memory to the total memory. This value takes effect only when memory_limit is 0. The default value is 80.</span><br><span class="line">    # memory_limit_percentage: 80 </span><br><span class="line">    # The reserved system memory. system_memory is reserved for general tenants. The default value is 30G. Autodeploy calculates this value based on the current server available resource.</span><br><span class="line">    # system_memory: 22G</span><br><span class="line">    # The size of a data file. When ignored, autodeploy calculates this value based on the current server available resource.</span><br><span class="line">    # datafile_size: 200G</span><br><span class="line">    # The percentage of the data_dir space to the total disk space. This value takes effect only when datafile_size is 0. The default value is 90.</span><br><span class="line">    # datafile_disk_percentage: 90</span><br><span class="line">    # System log level. The default value is INFO.</span><br><span class="line">    # syslog_level: INFO</span><br><span class="line">    # Print system logs whose levels are higher than WARNING to a separate log file. The default value is true. The default value for autodeploy mode is false.</span><br><span class="line">    # enable_syslog_wf: false</span><br><span class="line">    # Enable auto system log recycling or not. The default value is false. The default value for autodeploy mode is on.</span><br><span class="line">    # enable_syslog_recycle: true</span><br><span class="line">    # The maximum number of reserved log files before enabling auto recycling. When set to 0, no logs are deleted. The default value for autodeploy mode is 4.</span><br><span class="line">    # max_syslog_file_count: 4</span><br><span class="line">    # Cluster name for OceanBase Database. The default value is obcluster. When you deploy OceanBase Database and obproxy, this value must be the same as the cluster_name for obproxy.</span><br><span class="line">    # appname: obcluster</span><br><span class="line">    # Password for root. The default value is empty.</span><br><span class="line">    # root_password:</span><br><span class="line">    # Password for proxyro. proxyro_password must be the same as observer_sys_password. The default value is empty.</span><br><span class="line">    # proxyro_password:</span><br><span class="line">  z1:</span><br><span class="line">    zone: zone1</span><br><span class="line">  z2:</span><br><span class="line">    zone: zone2</span><br><span class="line">  z3:</span><br><span class="line">    zone: zone3</span><br><span class="line">obproxy:</span><br><span class="line">  servers:</span><br><span class="line">    - 192.168.1.5</span><br><span class="line">  global:</span><br><span class="line">    # The working directory for obproxy. Obproxy is started under this directory. This is a required field.</span><br><span class="line">    home_path: /root/obproxy</span><br><span class="line">    # External port. The default value is 2883.</span><br><span class="line">    # listen_port: 2883</span><br><span class="line">    # The Prometheus port. The default value is 2884.</span><br><span class="line">    # prometheus_listen_port: 2884</span><br><span class="line">    # rs_list is the root server list for observers. The default root server is the first server in the zone.</span><br><span class="line">    # The format for rs_list is observer_ip:observer_mysql_port;observer_ip:observer_mysql_port.</span><br><span class="line">    # Ignore this value in autodeploy mode.</span><br><span class="line">    # rs_list: 127.0.0.1:2881</span><br><span class="line">    # Cluster name for the proxy OceanBase Database. The default value is obcluster. This value must be set to the same with the appname for OceanBase Database.</span><br><span class="line">    # cluster_name: obcluster</span><br><span class="line">    # Password for obproxy system tenant. The default value is empty.</span><br><span class="line">    # obproxy_sys_password:</span><br><span class="line">    # Password for proxyro. proxyro_password must be the same with proxyro_password. The default value is empty.</span><br><span class="line">    # observer_sys_password:</span><br></pre></td></tr></table></figure>


<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## Only need to configure when remote login is required</span><br><span class="line"># user:</span><br><span class="line">#   username: your username</span><br><span class="line">#   password: your password if need</span><br><span class="line">#   key_file: your ssh-key file path if need</span><br><span class="line">#   port: your ssh port, default 22</span><br><span class="line">#   timeout: ssh connection timeout (second), default 30</span><br></pre></td></tr></table></figure>
<p>修改用户名和密码<br>​</p>
<p>通常这几个变量需要人肉设置一下, 每台机器的ip,  home_path, data_dir, redo_dir,  在本例中, 分别修改为&#x2F;home&#x2F;admin&#x2F;oceanbase&#x2F;ob, &#x2F;data&#x2F;ob, &#x2F;redo&#x2F;ob,  分别为之前挂载的磁盘. </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">oceanbase-ce:</span><br><span class="line">  servers:</span><br><span class="line">    - name: z1</span><br><span class="line">      # Please don&#x27;t use hostname, only IP can be supported</span><br><span class="line">      ip: 172.30.62.200</span><br><span class="line">    - name: z2</span><br><span class="line">      ip: 172.30.62.201</span><br><span class="line">    - name: z3</span><br><span class="line">      ip: 172.30.62.202</span><br><span class="line">  global:</span><br><span class="line">    # The working directory for OceanBase Database. OceanBase Database is started under this directory. This is a required field.</span><br><span class="line">    home_path: /home/admin/oceanbase/ob</span><br><span class="line">    # The directory for data storage. The default value is $home_path/store.</span><br><span class="line">    data_dir: /data/ob</span><br><span class="line">    # The directory for clog, ilog, and slog. The default value is the same as the data_dir value.</span><br><span class="line">    redo_dir: /redo/ob</span><br></pre></td></tr></table></figure>


<p>配置proxy,  修改ip 和home_path</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">obproxy:</span><br><span class="line">  servers:</span><br><span class="line">    - 172.30.62.203</span><br><span class="line">  global:</span><br><span class="line">    # The working directory for obproxy. Obproxy is started under this directory. This is a required field.</span><br><span class="line">    home_path: /home/admin/oceanbase</span><br></pre></td></tr></table></figure>


<p>另外推荐一个网站<a href="https://www.bejson.com/validators/yaml_editor/">https://www.bejson.com/validators/yaml_editor&#x2F;</a>, 可以对配置文件进行yaml 检测, 很多时候, 配置文件 多一个空格, 少一个空格, 极难发现,<br>​</p>
<p>​</p>
<h3 id="开始安装"><a href="#开始安装" class="headerlink" title="开始安装"></a>开始安装</h3><p>对于离线安装, 需要执行一步操作, 当连不上服务器, 需要把远程的repo 配置给删掉, 避免浪费时间消耗在连接远程的repo 之上. </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rm -fr ~/.obd/mirror/remote/*.repo</span><br></pre></td></tr></table></figure>
<p>开始安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">admin@obdriver:~$ obd cluster autodeploy obtest -c distributed-with-obproxy-example.yaml </span><br></pre></td></tr></table></figure>






<p>检查安装是否成功</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">admin@obdriver:~$ obd cluster list</span><br><span class="line">+------------------------------------------------------------+</span><br><span class="line">|                        Cluster List                        |</span><br><span class="line">+--------+---------------------------------+-----------------+</span><br><span class="line">| Name   | Configuration Path              | Status (Cached) |</span><br><span class="line">+--------+---------------------------------+-----------------+</span><br><span class="line">| obtest | /home/admin/.obd/cluster/obtest | running         |</span><br><span class="line">+--------+---------------------------------+-----------------+</span><br></pre></td></tr></table></figure>


<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">admin@obdriver:~$ obd cluster display obtest</span><br><span class="line">Get local repositories and plugins ok</span><br><span class="line">Open ssh connection ok</span><br><span class="line">Cluster status check ok</span><br><span class="line">Connect to observer ok</span><br><span class="line">Wait for observer init ok</span><br><span class="line">+-------------------------------------------------+</span><br><span class="line">|                     observer                    |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line">| ip            | version | port | zone  | status |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line">| 172.30.62.200 | 3.1.0   | 2881 | zone1 | active |</span><br><span class="line">| 172.30.62.201 | 3.1.0   | 2881 | zone2 | active |</span><br><span class="line">| 172.30.62.202 | 3.1.0   | 2881 | zone3 | active |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line"></span><br><span class="line">Connect to obproxy ok</span><br><span class="line">+-------------------------------------------------+</span><br><span class="line">|                     obproxy                     |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br><span class="line">| ip            | port | prometheus_port | status |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br><span class="line">| 172.30.62.203 | 2883 | 2884            | active |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br></pre></td></tr></table></figure>

<h2 id="修改配置"><a href="#修改配置" class="headerlink" title="修改配置"></a>修改配置</h2><p>OceanBase 数据库有数百个配置项，有些配置是耦合的，在您熟悉 OceanBase 数据库之前，不建议您修改示例配件文件中的配置。此处示例用来说明如何修改配置，并使之生效。<br>​</p>
<p>所有的参数介绍请参考</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">https://github.com/oceanbase/obdeploy/blob/master/plugins/oceanbase/3.1.0/parameter.yaml</span><br></pre></td></tr></table></figure>


<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用 edit-config 命令进入编辑模式，修改集群配置</span><br><span class="line">obd cluster edit-config lo</span><br><span class="line"># 修改 sys_bkgd_migration_retry_num 为 5</span><br><span class="line"># 注意 sys_bkgd_migration_retry_num 值最小为 3</span><br><span class="line"># 保存并退出后，OBD 会告知您如何使得此次改动生效</span><br><span class="line"># 此配置项仅需要 reload 即可生效</span><br><span class="line">obd cluster reload lo</span><br></pre></td></tr></table></figure>

<h1 id="验证​"><a href="#验证​" class="headerlink" title="验证​"></a>验证​</h1><h2 id="安装obclient"><a href="#安装obclient" class="headerlink" title="安装obclient"></a>安装obclient</h2><p>通常在主控机器上安装obclient,  需要切换到root 账号</p>
<h3 id="在线安装-2"><a href="#在线安装-2" class="headerlink" title="在线安装"></a>在线安装</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install -y libobclient</span><br><span class="line">yum install -y obclient</span><br></pre></td></tr></table></figure>

<h3 id="本地安装-2"><a href="#本地安装-2" class="headerlink" title="本地安装"></a>本地安装</h3><p>​</p>
<p>centos或redhat或anolis</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install libobclient-2.0.0-2.el7.x86_64.rpm</span><br><span class="line">yum install obclient-2.0.0-2.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>
<p>Ubuntu&#x2F;Debian</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alien -i libobclient-2.0.0-2.el7.x86_64.rpm</span><br><span class="line">alien -i obclient-2.0.0-2.el7.x86_64.rpm</span><br></pre></td></tr></table></figure>
<p>在debian 下需要把路径设置到系统环境变量中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PATH=/app/mariadb/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>​</p>
<p>在ubuntu下需要把路径设置到系统环境变量中</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PATH=/u01/obclient/bin:$PATH</span><br></pre></td></tr></table></figure>
<p>​</p>
<p>​</p>
<h2 id="安装mysql-开发包"><a href="#安装mysql-开发包" class="headerlink" title="安装mysql 开发包"></a>安装mysql 开发包</h2><p>如果需要运行sysbench, 或者tpch 等程序, 需要安装mysql 开发包</p>
<p>​</p>
<p>centos或redhat或anolis</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install mariadb</span><br><span class="line">yum install mariadb-libs</span><br><span class="line">yum install mariadb-devel</span><br></pre></td></tr></table></figure>
<p>Ubuntu</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apt-get install mariadb-server</span><br></pre></td></tr></table></figure>
<p>Debian</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">apt-get install mysql-server mysql-client libmariadbd18 libmariadbd-dev</span><br></pre></td></tr></table></figure>



<h2 id="检查租户"><a href="#检查租户" class="headerlink" title="检查租户"></a>检查租户</h2><p>使用oceanbase, 需要创建租户, 用户真正应用必须运行在租户下<br>创建租户有2种方式:<br>可以使用obd 来创建租户, 使用obd 创建租户时, 会把所有的资源</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">obd cluster tenant create $&#123;cluster_name&#125; -n $&#123;tenant_name&#125;</span><br></pre></td></tr></table></figure>
<p>​</p>
<p>创建租户, 请参考<br><a href="https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/create-a-user-tenant">https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.0/create-a-user-tenant</a><br>​</p>
<p>在本例中:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">admin@obdriver:~$ mysql -h$&#123;obproxy_ip&#125; -P$&#123;obproxy_port&#125; -uroot</span><br><span class="line">Welcome to the MariaDB monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 2</span><br><span class="line">Server version: 5.6.25 OceanBase 3.1.0 (r3-b20901e8c84d3ea774beeaca963c67d7802e4b4e) (Built Aug 10 2021 07:51:04)</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2018, Oracle, MariaDB Corporation Ab and others.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">MySQL [(none)]&gt; use oceanbase;</span><br><span class="line">Reading table information for completion of table and column names</span><br><span class="line">You can turn off this feature to get a quicker startup with -A</span><br><span class="line"></span><br><span class="line">Database changed</span><br><span class="line">MySQL [oceanbase]&gt; select * from gv$tenant;</span><br><span class="line">+-----------+-------------+-------------------+-------------------+----------------+---------------+-----------+---------------------------------------------+</span><br><span class="line">| tenant_id | tenant_name | zone_list         | primary_zone      | collation_type | info          | read_only | locality                                    |</span><br><span class="line">+-----------+-------------+-------------------+-------------------+----------------+---------------+-----------+---------------------------------------------+</span><br><span class="line">|         1 | sys         | zone1;zone2;zone3 | zone1;zone2,zone3 |              0 | system tenant |         0 | FULL&#123;1&#125;@zone1, FULL&#123;1&#125;@zone2, FULL&#123;1&#125;@zone3 |</span><br><span class="line">|      1001 | mytest      | zone1;zone2;zone3 | RANDOM            |              0 |               |         0 | FULL&#123;1&#125;@zone1, FULL&#123;1&#125;@zone2, FULL&#123;1&#125;@zone3 |</span><br><span class="line">+-----------+-------------+-------------------+-------------------+----------------+---------------+-----------+---------------------------------------------+</span><br><span class="line">2 rows in set (0.00 sec)</span><br><span class="line"></span><br><span class="line">MySQL [(none)]&gt;</span><br></pre></td></tr></table></figure>
<p>​</p>
<h1 id="企业用户最佳实践"><a href="#企业用户最佳实践" class="headerlink" title="企业用户最佳实践"></a>企业用户最佳实践</h1><h2 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h2><p>ob  运行日志, 事务日志, 数据文件 必须独立开, 如果没有3块盘支持, 则可以一块盘分3块分区<br>​</p>
<h2 id="时钟依赖"><a href="#时钟依赖" class="headerlink" title="时钟依赖"></a>时钟依赖</h2><p>OceanBase 集群中各服务器的时间需保持一致，否则会导致 OceanBase 集群无法启动，运行时也会出现故障。对于企业用户来说, 时钟同步是<strong>非常非常重要</strong>, 物理机与时钟服务器的误差在 50ms 以下可认为时钟是同步状态 , 最大容忍误差不能超过200ms. 当超过200ms, 会出现无主状况, 恢复时钟同步后, 重启observer, 可以恢复状态.<br>​</p>
<h2 id="网络时延"><a href="#网络时延" class="headerlink" title="网络时延"></a>网络时延</h2><p>server间的网络时延不能超过200ms，否则同步会严重滞后, 并且可能影响选举<br>网卡设置<br>建议配置2块万兆网卡，bond模式取名bond0，mode1或mode4均可以，推荐使用mode4，如果是mode4，交换机需要配置802.3ad。网卡名建议使用eth0，eth1。建议使用network服务，不要使用NetworkManager。</p>
<h2 id="参数设置"><a href="#参数设置" class="headerlink" title="参数设置"></a>参数设置</h2><ul>
<li><p>当系统写入tps 过高时, 超过系统支撑能力时, 为防止系统停止响应</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alter system set writing_throttling_trigger_percentage=75 tenant=all(或者具体tenantname);</span><br></pre></td></tr></table></figure>

</li>
<li><p>除非业务应用有配置重连尝试，否则建议关闭轮转合并, 切主也不能保证不杀事务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER SYSTEM SET enable_merge_by_turn = &#x27;False&#x27;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>内存设置</p>
<ul>
<li>租户的cpu和内存规格比建议不低于1:4,否则容易oom； </li>
<li>普通租户最小内存规格暂定5G以上；</li>
<li>租户内存太小时建议调大ob_sql_work_area_percentage，默认值5%，租户内存小于10G建议配20%左右；</li>
<li>partition 个数限制, 单机建议不要超过10万个分区, 另外partition 数量会受内存限制,  每个副本预留内存为168KB，因此10000个副本至少需要预留1.68G内存，或者说1G的租户最多能建6k左右个partition，需要根据partition数的规划设置租户内存；另外单机. </li>
<li>物理内存使用限制，默认为80，memstore内存可用百分比，建议服务器内存256G以上配置调整为90，256G以下保持默认50<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER SYSTEM SET memstore_limit_percentage = &#x27;90&#x27;;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ul>
<p>​</p>
<ul>
<li><p>slow query阈值调整 trace_log_slow_query_watermark 默认100ms，可以根据业务特点调整。如果阈值设置的太小，打印大量trace日志会影响性能.MySQL  默认值是1s. 大查询时间为10s</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">ALTER SYSTEM SET trace_log_slow_query_watermark = &#x27;1s&#x27;;</span><br><span class="line">ALTER SYSTEM SET large_query_threshold = &#x27;10s&#x27;;</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
<li><p>cpu 并发度调整</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- CPU并发度参数，建议配置为4，arm系统为2</span><br><span class="line">ALTER SYSTEM SET cpu_quota_concurrency = &#x27;4&#x27;;</span><br><span class="line"></span><br><span class="line">-- 资源软负载开关，控制资源均衡水位，默认为50%，即CPU内存使用超过50%就进行unit均衡，线上建议调整为100，达到手工控制unit分布的效果</span><br><span class="line">ALTER SYSTEM SET resource_soft_limit = &#x27;100&#x27;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>转储合并相关</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- 配置转储50次</span><br><span class="line">ALTER SYSTEM SET minor_freeze_times = 50;</span><br><span class="line"></span><br><span class="line">-- 转储触发水位百分比，建议256G以上配置调整为70，256G以下调整为60</span><br><span class="line">ALTER SYSTEM SET freeze_trigger_percentage = &#x27;60&#x27;;</span><br><span class="line"></span><br><span class="line">-- 数据拷贝并发为100</span><br><span class="line">ALTER SYSTEM SET data_copy_concurrency = 100;</span><br><span class="line">-- 服务器上数据传出并发为10</span><br><span class="line">ALTER SYSTEM SET server_data_copy_out_concurrency = 10;</span><br><span class="line">-- 服务器上数据传入并发为10</span><br><span class="line">ALTER SYSTEM SET server_data_copy_in_concurrency = 10;</span><br><span class="line"></span><br><span class="line">-- 转储预热时间，默认30s，设置了会延后转储释放的时间，改成0s</span><br><span class="line">ALTER SYSTEM SET minor_warm_up_duration_time = &#x27;0s&#x27;;</span><br><span class="line">-- 配置chunk内存大小(建议保持默认值0，ob自行分配)</span><br><span class="line">ALTER SYSTEM SET memory_chunk_cache_size = 0;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-- 最大包括版本数量，影响磁盘可用空间，默认为2，将多保留一个版本的数据在数据盘中，需调整为1</span><br><span class="line">ALTER SYSTEM SET max_kept_major_version_number = &#x27;1&#x27;;</span><br><span class="line">ALTER SYSTEM SET max_stale_time_for_weak_consistency = &#x27;2h&#x27;;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
<li><p>事务相关</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER SYSTEM SET clog_sync_time_warn_threshold = &#x27;1s&#x27;;</span><br><span class="line">ALTER SYSTEM SET trx_try_wait_lock_timeout = &#x27;0ms&#x27;;（默认就是 0ms，无需修改）</span><br><span class="line"></span><br><span class="line">-- 建议关闭一阶段提交，该参数值默认是false</span><br><span class="line">ALTER SYSTEM SET enable_one_phase_commit=&#x27;False&#x27;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>分区迁移速度控制, 若是集群负载很低，可以通过加大并发任务数加快 partition迁移速度, 调大迁移并发数</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alter system set data_copy_concurrency=40;</span><br><span class="line">alter system set server_data_copy_out_concurrency=20;</span><br><span class="line">alter system set server_data_copy_in_concurrency=20;</span><br></pre></td></tr></table></figure>
</li>
<li><p>压缩相关</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- （默认就是 zstd_1.0，无需修改）, 不过系统支持多种压缩算法</span><br><span class="line">ALTER SYSTEM SET default_compress_func = &#x27;zstd_1.0&#x27;;</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
<li><p>cache 刷新相关</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER SYSTEM SET autoinc_cache_refresh_interval = &#x27;43200s&#x27;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>prepare statement, server端ps受_ob_enable_prepared_statement开关控制，除了objdbc和oci的用户可以按照文档提供的说明使用server端ps，其他情况不建议用了；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- Prepared Statement参数，不用java建联的配置建议设为0</span><br><span class="line">ALTER SYSTEM SET _ob_enable_prepared_statement = 0;</span><br></pre></td></tr></table></figure>
</li>
<li><p>系统相关</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER SYSTEM SET server_permanent_offline_time = &#x27;7200s&#x27;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">-- （公有云建议5M，外部环境建议5M，否则建议默认值30M）</span><br><span class="line">ALTER SYSTEM SET syslog_io_bandwidth_limit = &#x27;5M&#x27;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>集群升级策略, 在进行版本升级，机器临时上下线，可以先进行一次转储，可以减少启动observer时候恢复时间</p>
</li>
<li><p>批量导入大量数据最佳策略, 如果集群是多租户的，如果某个租户要大批量导入数据，为避免影响其他租户, 导完数据后可以恢复以上两个参数: </p>
<ul>
<li>1.调整 cpu_quota_concurrency &#x3D;1 ，防止租户间cpu抢占</li>
<li>开启多轮转储减少合并触发，这样可以提高导入速度</li>
</ul>
</li>
</ul>
<p>​</p>
<ul>
<li>租户primary_zone配置, <ul>
<li><p>primar_zone配置到具体某个zone中, 适用场景：业务使用单表、zone_name1与应用在同机房、zone_name2和zone_name3作为从副本平时无业务流量，具体zone顺序需按机房优先级、按应用和ob的机房配置。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER TENANT SET PRIMARY_ZONE = &#x27;zone_name1;zone_name2,zone_name3&#x27;;</span><br></pre></td></tr></table></figure>
</li>
<li><p>打散primary_zone到所有全功能zone中, 使用场景：业务使用分区表、集群中所有副本都在同一机房或不同zone机房间网络延迟在1ms内，需要所有副</p>
</li>
</ul>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ALTER TENANT SET PRIMARY_ZONE = &#x27;zone_name1,zone_name2,zone_name3&#x27;;</span><br></pre></td></tr></table></figure>




<h3 id="租户设置"><a href="#租户设置" class="headerlink" title="租户设置"></a>租户设置</h3><ul>
<li><p>并发度设置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- 最大并发度，默认32，有大查询业务的建议调整为128</span><br><span class="line">SET GLOBAL ob_max_parallel_degree = 128;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line">parallel_max_servers 推荐设置为测试租户分配的 resource unit cpu 数的 10 倍</span><br><span class="line">如测试租户使用的 unit 配置为：create resource unit $unit_name max_cpu 26</span><br><span class="line">那么该值设置为 260</span><br><span class="line">parallel_server_target 推荐设置为 parallel_max_servers * 机器数*0.8</span><br><span class="line">那么该值为 260*3*0.8=624</span><br><span class="line">*/</span><br><span class="line">set global parallel_max_servers=260;</span><br><span class="line">set global parallel_servers_target=624;</span><br></pre></td></tr></table></figure>
</li>
<li><p>回收站设置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-- 回收站参数，ddl执行频率过大的场景一定要关闭，避免ddl执行过多引起租户性能异常</span><br><span class="line">SET GLOBAL recyclebin = 0;</span><br><span class="line"></span><br><span class="line">-- truncate回滚参数，truncate执行频率过大的场景一定要关闭</span><br><span class="line">SET GLOBAL ob_enable_truncate_flashback = 0;</span><br></pre></td></tr></table></figure>

</li>
<li><p>客户端命令长度,  OB客户端可发的命令长度受限于租户系统变量_max_allowed_packet_的限制（缺省4M),可以酌情调大；</p>
</li>
</ul>
<h3 id="obproxy配置"><a href="#obproxy配置" class="headerlink" title="obproxy配置"></a>obproxy配置</h3><ul>
<li>obproxy探活<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">alter proxyconfig set sock_option_flag_out = 2;  --  2代表keepalive</span><br><span class="line">alter proxyconfig set server_tcp_keepidle = 5;  --  启动keepalive探活前的idle时间，5秒。</span><br><span class="line">alter proxyconfig set server_tcp_keepintvl = 5;  -- 两个keepalive探活包之间的时间间隔，5秒</span><br><span class="line">alter proxyconfig set server_tcp_keepcnt = 2;  --  最多发送多少个keepalive包，2个。最长5+5*2=15秒发现dead_socket。</span><br><span class="line">alter proxyconfig set server_tcp_user_timeout = 5;  --  等待TCP层ACK确认消息的超时时长，5秒。</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>OceanBase</category>
      </categories>
      <tags>
        <tag>OceanBase</tag>
      </tags>
  </entry>
  <entry>
    <title>OceanBase监控对接Prometheus/Grafana</title>
    <url>/2021/obagent/</url>
    <content><![CDATA[<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>本文讲介绍如何让OceanBase监控对接Prometheus和Grafana. </p>
<p>​<img data-src="/img/ob/obagent1.jpg" ><br>​<span id="more"></span></p>
<h1 id="安装流程"><a href="#安装流程" class="headerlink" title="安装流程"></a>安装流程</h1><p>大致过程, 分为3大步骤:</p>
<ol>
<li>安装oceanbase和obagent</li>
<li>安装prometheus和grafana</li>
<li>配置prometheus和grafana</li>
</ol>
<h2 id="安装OceanBase和Obagent"><a href="#安装OceanBase和Obagent" class="headerlink" title="安装OceanBase和Obagent"></a>安装OceanBase和Obagent</h2><p>如何安装OceanBase 可以参考上一篇文章<a href="http://ilongda.com/2021/ob_offline_install/">《OceanBase离线安装》</a>, 本节重点介绍如何安装obagent, 可以参考文档<a href="https://open.oceanbase.com/docs/community/oceanbase-database/V3.1.1/use-obd-to-deploy-obagent">使用 OBD 部署 OBAgent</a></p>
<p>OBAgent 是一个监控采集框架。OBAgent 支持推、拉两种数据采集模式，可以满足不同的应用场景。OBAgent 默认支持的插件包括主机数据采集、OceanBase 数据库指标的采集、监控数据标签处理和 Prometheus 协议的 HTTP 服务。要使 OBAgent 支持其他数据源的采集，或者自定义数据的处理流程，您只需要开发对应的插件即可。</p>
<p>obagent 的配置, 在原来的配置基础上, 增加了obagent的配置, 详情可以参考<a href="https://github.com/oceanbase/obdeploy/blob/master/example/autodeploy/distributed-with-obproxy-and-obagent-example.yaml">distributed-with-obproxy-and-obagent-example</a>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">obagent:</span><br><span class="line">  depends:</span><br><span class="line">    - oceanbase-ce</span><br><span class="line">  # The list of servers to be monitored. This list is consistent with the servers in oceanbase-ce. </span><br><span class="line">  servers:</span><br><span class="line">    - name: server1</span><br><span class="line">      # Please don&#x27;t use hostname, only IP is supported.</span><br><span class="line">      ip: 172.19.33.2</span><br><span class="line">    - name: server2</span><br><span class="line">      ip: 172.19.33.3</span><br><span class="line">    - name: server3</span><br><span class="line">      ip: 172.19.33.4</span><br><span class="line">  # Set dependent components for the component.</span><br><span class="line">  # When the associated configurations are not done, OBD will automatically get the these configurations from the dependent components.</span><br><span class="line">  depends:</span><br><span class="line">    - oceanbase-ce</span><br><span class="line">  global:</span><br><span class="line">    # The working directory for obagent. obagent is started under this directory. This is a required field.</span><br><span class="line">    home_path: /root/observer</span><br><span class="line">    skip_proxy_sys_private_check: true</span><br></pre></td></tr></table></figure>

<p>特别说明:</p>
<ol>
<li>depends里面的 “oceanbase-ce” 的名字必须和配置文件集群的名字一致. </li>
<li>servers里面的配置必须与在配置文件中”oceanbase-ce”一节中servers 配置一摸一样</li>
<li>记住home_path, 后续需要用到这个路径.</li>
</ol>
<p>安装完成后, 可以执行“obd cluster display ” 看到obagent 已经启动了</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">obd cluster display obtest</span><br><span class="line">Get local repositories and plugins ok</span><br><span class="line">Open ssh connection ok</span><br><span class="line">Cluster status check ok</span><br><span class="line">Connect to observer ok</span><br><span class="line">Wait for observer init ok</span><br><span class="line">+-------------------------------------------------+</span><br><span class="line">|                     observer                    |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line">| ip            | version | port | zone  | status |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line">| 172.30.62.210 | 3.1.1   | 2881 | zone1 | active |</span><br><span class="line">| 172.30.62.211 | 3.1.1   | 2881 | zone2 | active |</span><br><span class="line">| 172.30.62.212 | 3.1.1   | 2881 | zone3 | active |</span><br><span class="line">+---------------+---------+------+-------+--------+</span><br><span class="line"></span><br><span class="line">Connect to obproxy ok</span><br><span class="line">+-------------------------------------------------+</span><br><span class="line">|                     obproxy                     |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br><span class="line">| ip            | port | prometheus_port | status |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br><span class="line">| 172.30.62.213 | 2883 | 2884            | active |</span><br><span class="line">+---------------+------+-----------------+--------+</span><br><span class="line">+---------------------------------------------------+</span><br><span class="line">|                      obagent                      |</span><br><span class="line">+---------------+-------------+------------+--------+</span><br><span class="line">| ip            | server_port | pprof_port | status |</span><br><span class="line">+---------------+-------------+------------+--------+</span><br><span class="line">| 172.30.62.210 | 8088        | 8089       | active |</span><br><span class="line">| 172.30.62.211 | 8088        | 8089       | active |</span><br><span class="line">| 172.30.62.212 | 8088        | 8089       | active |</span><br><span class="line">+---------------+-------------+------------+--------+</span><br></pre></td></tr></table></figure>


<h2 id="安装prometheus和grafana"><a href="#安装prometheus和grafana" class="headerlink" title="安装prometheus和grafana"></a>安装prometheus和grafana</h2><p>选择一台机器上安装prometheus 和grafana, 这台机器尽量不是observer 中的一台, 本例中, prometheus 和grafana 部署在obproxy机器上. </p>
<ol>
<li>从<a href="https://prometheus.io/download/">https://prometheus.io/download/</a> 上把prometheus 和alertmanager 下载下来, 本章将不介绍 alertmanager 怎么使用. </li>
<li>从<a href="https://grafana.com/grafana/download?pg=get&plcmt=selfmanaged-box1-cta1">https://grafana.com/grafana/download?pg=get&amp;plcmt=selfmanaged-box1-cta1</a> 上下载grapha</li>
<li>讲prometheus 和grafana 压缩包拷贝到obproxy 的机器上, </li>
<li>解压prometheus 和grafana<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># tar -xzf prometheus-2.31.0.linux-amd64.tar.gz</span><br><span class="line"># tar -xzf grafana-enterprise-8.2.3.linux-amd64.tar.gz</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="配置prometheus和grafana"><a href="#配置prometheus和grafana" class="headerlink" title="配置prometheus和grafana"></a>配置prometheus和grafana</h2><h3 id="配置prometheus"><a href="#配置prometheus" class="headerlink" title="配置prometheus"></a>配置prometheus</h3><ol>
<li>讲obagent上的prometheus 的配置文件给拷贝到prometheus 的安装目录中<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># cd prometheus-2.31.0.linux-amd64</span><br><span class="line"># mv prometheus.yml prometheus.yml.old</span><br><span class="line"># scp -r observer001:/root/observer/conf/prometheus_config/* . </span><br></pre></td></tr></table></figure>
备注说明: </li>
<li>observer001 为安装obagent的一台机器</li>
<li>&#x2F;root&#x2F;observer 为之前在配置文件中, 配置obagent中配置的home_path路径</li>
<li>从observer001 上会copy 过来几个文件, prometheus.yaml 和rules, rules 是存储拉取规则, prometheus 是配置prometheus的文件.</li>
</ol>
<p>启动prometheus</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nohup ./prometheus --config.file=./prometheus.yaml &gt;&gt; run.log 2&gt;&amp;1 &amp;</span><br></pre></td></tr></table></figure>

<p>检查run.log 可以查看运行日志. 正常情况下, </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># curl http://localhost:9090/metrics</span><br></pre></td></tr></table></figure>
<p>可以获得大量的数据. </p>
<h3 id="配置grafana"><a href="#配置grafana" class="headerlink" title="配置grafana"></a>配置grafana</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># cd grafana-8.2.3/</span><br><span class="line"># nohup bin/grafana-server &gt; run.log 2&gt;&amp;1 &amp;</span><br><span class="line"># ps -ef|grep grafana</span><br></pre></td></tr></table></figure>
<p>可以坚持run.log 或ps -ef|grep grafana 均可以查看到grafana 正常工作. </p>
<p>打开grafana 的页面,  第一次登录, 输入admin&#x2F;admin, 然后设置管理员密码, 然后增加data source<br>​<img data-src="/img/ob/obagent2.jpg" ><br>进入增加data source后, 选择prometheus, 然后进入配置prometheus 后, 关键设置url<br>​<img data-src="/img/ob/obagent3.jpg" ></p>
<p>import 配置项<br>​<img data-src="/img/ob/obagent4.jpg" ></p>
<p>ob 已经提前准备好了 15215和15216 , 一个是监控oceanbase, 一个是监控host的.<br>当加载好模版后, 在dashboard 就可以看到2个预设好的dashboard, </p>
<p>​<img data-src="/img/ob/obagent1.jpg" ></p>
<p>恭喜你, 已经完成配置oceanbase对接prometheus 和grafana</p>
]]></content>
      <categories>
        <category>OceanBase</category>
      </categories>
      <tags>
        <tag>OceanBase</tag>
      </tags>
  </entry>
  <entry>
    <title>paper推荐</title>
    <url>/2020/paper/</url>
    <content><![CDATA[<p>因为楼主有个不好的习惯， 论文看完后， 过了一段时间就忘了讲什么，另外英语并不是很好，英文论文常常理解抓不住重点，因为习惯做一个笔记， 方便以后进行会议， 也方便理解论文。<br>后期会不定时进行更新。有一些论文是之前留下的笔记，做了一些梳理。 </p>
<p>有一些论文，还没有读完， 读完的，会有link</p>
<h1 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h1><h2 id="System"><a href="#System" class="headerlink" title="System"></a>System</h2><ul>
<li><a href="/knowledge/paper/libr.html">《FusionInsight LibrA Huawei’s Enterprise Cloud Data Analytics Platform》</a></li>
<li><a href="/knowledge/paper/redshift.html">《Amazon Redshift and the Case for Simpler Data Warehouses》</a></li>
<li><a href="/knowledge/paper/snowflake.html">《The Snowflake Elastic Data Warehouse》</a></li>
<li><a href="/knowledge/paper/f1.html">《F1 Query: Declarative Querying at Scale》</a></li>
</ul>
<h2 id="Optimizer"><a href="#Optimizer" class="headerlink" title="Optimizer"></a>Optimizer</h2><ul>
<li>《Access Path Selection in a Relational Database Management System》 </li>
<li><a href="/knowledge/paper/The_Volcano_Optimizer_Generator.html">《The Volcano Optimizer Generator: Extensibility and Efficient Search》</a></li>
<li><a href="/knowledge/paper/Volcano.html">《Volcano-An Extensible and Parallel Query Evaluation System》</a></li>
<li><a href="/knowledge/paper/cascade.html">《The Cascades Framework for Query Optimization》</a></li>
<li><a href="/knowledge/paper/ms-sql-server-pdw.html">《Query Optimization in Microsoft SQL Server PDW》</a></li>
<li>《Inside The SQL Server Query Optimizer》</li>
<li>《Incorporating Partitioning and Parallel Plans into the SCOPE Optimizer》</li>
<li>《Orca: A Modular Query Optimizer Architecture for Big Data》</li>
<li>《How Good Are Query Optimizers, Really?》</li>
<li>《An overview of query optimization in relational systems.》</li>
<li>《Query optimization through the looking glass, and what we found running the Join Order Benchmark.》</li>
<li>《Adaptive statistics in Oracle 12c.》</li>
<li>《Exploiting Statistics on Query Expressions for Optimization》</li>
</ul>
<h1 id="BigData"><a href="#BigData" class="headerlink" title="BigData"></a>BigData</h1><ul>
<li><a href="/knowledge/paper/dataflow.html">《The Dataflow Model: A Practical Approach to Balancing Correctness, Latency, and Cost in Massive-Scale, Unbounded, Out-of-Order Data Processing》</a></li>
<li><a href="/knowledge/paper/heron.html">《Hero stream process stream》 </a></li>
<li><a href="/knowledge/paper/millwheel.html">《MillWheel: Fault-Tolerant Stream Processing at Internet Scale》</a></li>
<li><a href="/knowledge/paper/screamscope.html">《StreamScope: Continuous Reliable Distributed Processing of Big Data Streams》</a></li>
</ul>
]]></content>
      <categories>
        <category>Database</category>
        <category>BigData</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Database</tag>
      </tags>
  </entry>
  <entry>
    <title>performance schema 源码走读</title>
    <url>/2020/performance_schema/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>转载：<a href="/knowledge/mysql/source_code_reading/storage/performance_schema">performance_schema</a></p>
<p>performance schema 是一个存储引擎, 可以提供对mysql 所有指标的监控， 是一套非常详细而复杂的监控系统， 不同的指标，使用了不同的接口， 另外有几个特点：</p>
<ol>
<li>它是运行时态， 因此是全内存存储， 重启后会丢失之前的数据</li>
<li>为了减少对运行时态的影响， 绝大部分资源都是提前申请好， 在performance_schema 初始化的时候，已经申请好了。涉及到2块内存， 一个是class 配置信息， 一个pfs state </li>
<li>不能增加sql 种类和语法</li>
</ol>
<p>本文主要分 3块：</p>
<ol>
<li>初始化</li>
<li>基本数据结构</li>
<li>使用过程</li>
</ol>
<h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2><p>分为几个步骤</p>
<ol>
<li>准备pfs 内部系统的内存监控的类</li>
<li>准备好pfs 配置的内存, pfs 配置主要用于设置pfs_xx_class</li>
<li>初始化pfs – 初始化的核心操作， 最主要的核心操作是准备好PFS需要的资源，尤其是内存申请， class， pfs 监控项的container， 以mutex 为例： 申请param-&gt;m_mutex_class_sizing 个PFS_mutex_class， 存储到PFS_mutex_class的mutex_class_array中， 另外会申请监控項的container 如global_mutex_container</li>
<li>设置好所有的service, </li>
<li>把所有的pfs 的key 注册到pfs 中， 方便后续使用</li>
</ol>
<span id="more"></span>

<h3 id="pre-initialize-performance-schema"><a href="#pre-initialize-performance-schema" class="headerlink" title="pre_initialize_performance_schema"></a>pre_initialize_performance_schema</h3><p>第一步， 初始化PFS_builtin_memory_class的一些类， 和一些全局状态跟踪</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void pre_initialize_performance_schema() &#123;</span><br><span class="line">  pfs_initialized = false;</span><br><span class="line"></span><br><span class="line">  init_all_builtin_memory_class();</span><br><span class="line">  // 初始化类似 builtin_memory_mutex/builtin_memory_rwlock/builtin_memory_mdl 等等</span><br><span class="line">  // 这些变量可以跟踪每种指标对应的内存消耗</span><br><span class="line">  // builtin_memory_mutex 类型为 PFS_builtin_memory_class</span><br><span class="line"></span><br><span class="line">  PFS_table_stat::g_reset_template.reset();</span><br><span class="line">  // 对PFS_table_stat 类的静态变量g_reset_template 进行重设</span><br><span class="line">  // PFS_table_stat 主要成员是</span><br><span class="line">  //    PFS_table_io_stat m_index_stat[MAX_INDEXES + 1], 跟进这个index 的fetch/insert/update/delete</span><br><span class="line">  //    PFS_table_lock_stat m_lock_stat; table 有9种锁, 每种锁的状态</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  global_idle_stat.reset();  // idle 的状态跟踪 </span><br><span class="line">  global_table_io_stat.reset();  // table io 的状态跟踪, </span><br><span class="line">  global_table_lock_stat.reset();  // table 锁的状态跟踪</span><br><span class="line">  g_histogram_pico_timers.init();   // PFS_histogram_timers 的状态跟踪</span><br><span class="line">  global_statements_histogram.reset(); //PFS_histogram </span><br><span class="line"></span><br><span class="line">  /*</span><br><span class="line">    There is no automatic cleanup. Please either use:</span><br><span class="line">    - my_thread_end()</span><br><span class="line">    - or PSI_server-&gt;delete_current_thread()</span><br><span class="line">    in the instrumented code, to explicitly cleanup the instrumentation.</span><br><span class="line">  */</span><br><span class="line">  THR_PFS = nullptr;           // PFS_thread</span><br><span class="line">  for (int i = 0; i &lt; THR_PFS_NUM_KEYS; ++i) &#123;</span><br><span class="line">    THR_PFS_contexts[i] = nullptr;  //PFS_table_context</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="init-pfs-instrument-array"><a href="#init-pfs-instrument-array" class="headerlink" title="init_pfs_instrument_array"></a>init_pfs_instrument_array</h3><p>   申请内存存放， PFS_instr_config, 每個pfs 的监控项的开关放在这里， 后面每个pfs 监控项在register class时， 会从这个配置项中获取是否打开， 是否要进行timer</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/**</span><br><span class="line">  Initialize the dynamic array used to hold PFS_INSTRUMENT configuration</span><br><span class="line">  options.</span><br><span class="line">*/****</span><br><span class="line">void init_pfs_instrument_array() &#123;</span><br><span class="line">  pfs_instr_config_array = new Pfs_instr_config_array(PSI_NOT_INSTRUMENTED);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">typedef Prealloced_array&lt;PFS_instr_config *, 10&gt; Pfs_instr_config_array;</span><br></pre></td></tr></table></figure>

<h3 id="initialize-performance-schema"><a href="#initialize-performance-schema" class="headerlink" title="initialize_performance_schema"></a>initialize_performance_schema</h3><p>初始化 performance_schema storage</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pfs_rc = initialize_performance_schema(</span><br><span class="line">          &amp;pfs_param, &amp;psi_thread_hook, &amp;psi_mutex_hook, &amp;psi_rwlock_hook,</span><br><span class="line">          &amp;psi_cond_hook, &amp;psi_file_hook, &amp;psi_socket_hook, &amp;psi_table_hook,</span><br><span class="line">          &amp;psi_mdl_hook, &amp;psi_idle_hook, &amp;psi_stage_hook, &amp;psi_statement_hook,</span><br><span class="line">          &amp;psi_transaction_hook, &amp;psi_memory_hook, &amp;psi_error_hook,</span><br><span class="line">          &amp;psi_parallel_query_hook, &amp;psi_parallel_operator_hook,</span><br><span class="line">          &amp;psi_data_lock_hook, &amp;psi_system_hook);</span><br><span class="line">      if ((pfs_rc != 0) &amp;&amp; pfs_param.m_enabled) &#123;</span><br><span class="line">        pfs_param.m_enabled = false;</span><br><span class="line">        LogErr(WARNING_LEVEL, ER_PERFSCHEMA_INIT_FAILED);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">initialize_performance_schema （） &#123;</span><br><span class="line">  pfs_automated_sizing(param);  //把PFS_sizing_data large_data 设置到param 中， 主要是类似p-&gt;m_events_waits_history_long_sizing</span><br><span class="line">  pfs_minimal_setting(param);  如果设置了performance_schema_minimal 为true， 则很多设置全部关掉</span><br><span class="line">  init_timers();  //初始化timer 一些偏硬件/操作系统底层函数， 方便获取一些时间</span><br><span class="line">  init_event_name_sizing(param); //设置 mutex_class_start/rwlock_class_start， </span><br><span class="line">  //在register psi（register_mutex_class）时， 得到PSI_mutex_info-&gt;m_event_name_index=mutex_class_start + index</span><br><span class="line"></span><br><span class="line">  register_global_classes(); // 注冊global 的class in pre_initialize_performance_schema</span><br><span class="line"></span><br><span class="line">  minimal_global_classes(param); // 当注册performance_schema_minimal 为true， 修改global class的一些enable和m_timed</span><br><span class="line"></span><br><span class="line">  //</span><br><span class="line">  init_sync_class  </span><br><span class="line">  // 以mutex 为例： 申请param-&gt;m_mutex_class_sizing 个PFS_mutex_class， </span><br><span class="line">  //存储到mutex_class_array 后， 后面register 会进行设置， 在init 会查找， 申请的内存变化会更新到builtin_memory_mutex_class</span><br><span class="line">  init_thread_class</span><br><span class="line">  init_table_share  // 初始化global_table_share_container， 但没有真正申请内存  </span><br><span class="line">  //typedef PFS_buffer_scalable_container&lt;PFS_table_share, 4 * 1024, 4 * 1024&gt; PFS_table_share_container;</span><br><span class="line">  init_table_share_lock_stat</span><br><span class="line">  // 很多数据结构使用无锁hash 来存储</span><br><span class="line"></span><br><span class="line">  // 设置一大堆consumer的flag</span><br><span class="line">  flag_events_stages_current =</span><br><span class="line">        param-&gt;m_consumer_events_stages_current_enabled;</span><br><span class="line"></span><br><span class="line">  init_pfs_plugin_table</span><br><span class="line">  // PFS_dynamic_table_shares::init_mutex</span><br><span class="line">  //</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="设置PFS-service"><a href="#设置PFS-service" class="headerlink" title="设置PFS service"></a>设置PFS service</h3><p>设置各种service, 类似这样</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">。。。</span><br><span class="line">if (psi_memory_hook != NULL) &#123;</span><br><span class="line">  service = psi_memory_hook-&gt;get_interface(PSI_CURRENT_MEMORY_VERSION);</span><br><span class="line">  if (service != NULL) &#123;</span><br><span class="line">    set_psi_memory_service(service);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">。。。</span><br></pre></td></tr></table></figure>

<p>这个地方就是把这个地方设置一下<br>typedef struct PSI_mutex_service_v1 PSI_mutex_service_t;<br>PSI_mutex_service_t     psi_mutex_service  &#x3D;   pfs_mutex_service_v1   &#x2F;   psi_mutex_noop<br>psi_mutex_service 定义在psi_noop.cc 文件中， pfs_mutex_service_v1 定义在storage&#x2F;perfschema&#x2F;pfs.cc中</p>
<p>如果是pfs 插件编译， 就会使用这个， 但目前是直接编译进内核， 因此不需要插件化加载<br>mysql_service_psi_mutex_v1_t               mysql_service_psi_mutex_v1  &#x3D; imp_performance_schema_psi_mutex_v1<br>mysql_service_psi_mutex_v1_t imp_performance_schema_psi_mutex_v1 定义在storage&#x2F;perfschema&#x2F;pfs.cc中</p>
<h3 id="初始化所有的key"><a href="#初始化所有的key" class="headerlink" title="初始化所有的key"></a>初始化所有的key</h3><p>初始化所有的key, 提前把一部分 register mutext&#x2F;memory psi 等结构 注册进去</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/*</span><br><span class="line">    Now that we have parsed the command line arguments, and have initialized</span><br><span class="line">    the performance schema itself, the next step is to register all the</span><br><span class="line">    server instruments.</span><br><span class="line">  */</span><br><span class="line">static void init_server_psi_keys(void) &#123;.</span><br><span class="line"></span><br><span class="line">  ...</span><br><span class="line">  count = static_cast&lt;int&gt;(array_elements(all_server_mutexes));</span><br><span class="line">  mysql_mutex_register(category, all_server_mutexes, count);</span><br><span class="line"></span><br><span class="line">  count = static_cast&lt;int&gt;(array_elements(all_server_rwlocks));</span><br><span class="line">  mysql_rwlock_register(category, all_server_rwlocks, count);</span><br><span class="line">  ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h2><p>公共数据结构, 后续会使用到, 先列在这里<br><a href="https://dev.mysql.com/doc/dev/mysql-server/8.0.20/structPFS__instr.html">https://dev.mysql.com/doc/dev/mysql-server/8.0.20/structPFS__instr.html</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct PFS_instr &#123;</span><br><span class="line">  /** Internal lock. */</span><br><span class="line">  pfs_lock m_lock;</span><br><span class="line">  /** Enabled flag. */</span><br><span class="line">  bool m_enabled;</span><br><span class="line">  /** Timed flag. */</span><br><span class="line">  bool m_timed;</span><br><span class="line">  /** Container page. */</span><br><span class="line">  PFS_opaque_container_page *m_page; // 参考PFS_partitioned_buffer_scalable_container</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">//存儲在結構pfs_instr_config_array 中</span><br><span class="line">struct PFS_instr_config &#123;  </span><br><span class="line">  /* Instrument name. */</span><br><span class="line">  char *m_name;</span><br><span class="line">  /* Name length. */</span><br><span class="line">  uint m_name_length;</span><br><span class="line">  /** Enabled flag. */</span><br><span class="line">  bool m_enabled;</span><br><span class="line">  /** Timed flag. */</span><br><span class="line">  bool m_timed;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>有這麼多種類</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">enum PFS_class_type &#123;</span><br><span class="line">  PFS_CLASS_NONE = 0,</span><br><span class="line">  PFS_CLASS_MUTEX = 1,</span><br><span class="line">  PFS_CLASS_RWLOCK = 2,</span><br><span class="line">  PFS_CLASS_COND = 3,</span><br><span class="line">  PFS_CLASS_FILE = 4,</span><br><span class="line">  PFS_CLASS_TABLE = 5,</span><br><span class="line">  PFS_CLASS_STAGE = 6,</span><br><span class="line">  PFS_CLASS_STATEMENT = 7,</span><br><span class="line">  PFS_CLASS_TRANSACTION = 8,</span><br><span class="line">  PFS_CLASS_SOCKET = 9,</span><br><span class="line">  PFS_CLASS_TABLE_IO = 10,</span><br><span class="line">  PFS_CLASS_TABLE_LOCK = 11,</span><br><span class="line">  PFS_CLASS_IDLE = 12,</span><br><span class="line">  PFS_CLASS_MEMORY = 13,</span><br><span class="line">  PFS_CLASS_METADATA = 14,</span><br><span class="line">  PFS_CLASS_ERROR = 15,</span><br><span class="line">  PFS_CLASS_THREAD = 16,</span><br><span class="line">  /* Reserve 17-29 for official mysql */</span><br><span class="line">  PFS_CLASS_PARALLEL_QUERY = 30,</span><br><span class="line"></span><br><span class="line">  PFS_CLASS_LAST = PFS_CLASS_PARALLEL_QUERY,</span><br><span class="line">  PFS_CLASS_MAX = PFS_CLASS_LAST + 1</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">// 做一些状态统计的</span><br><span class="line">struct PFS_single_stat &#123;</span><br><span class="line">  /** Count of values. */</span><br><span class="line">  ulonglong m_count;</span><br><span class="line">  /** Sum of values. */</span><br><span class="line">  ulonglong m_sum;</span><br><span class="line">  /** Minimum value. */</span><br><span class="line">  ulonglong m_min;</span><br><span class="line">  /** Maximum value. */</span><br><span class="line">  ulonglong m_max;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/** Instrumentation metadata for a mutex. */</span><br><span class="line">struct PFS_ALIGNED PFS_mutex_class : public PFS_instr_class &#123;</span><br><span class="line">  /** Mutex usage statistics. */</span><br><span class="line">  PFS_mutex_stat m_mutex_stat;</span><br><span class="line">  /** Singleton instance. */</span><br><span class="line">  PFS_mutex *m_singleton;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">/** Information for all instrumentation. */</span><br><span class="line">struct PFS_instr_class &#123;</span><br><span class="line">  /** Class type */</span><br><span class="line">  PFS_class_type m_type;</span><br><span class="line">  /** True if this instrument is enabled. */</span><br><span class="line">  bool m_enabled;</span><br><span class="line">  /** True if this instrument is timed. */</span><br><span class="line">  bool m_timed;</span><br><span class="line">  /** Instrument flags. */</span><br><span class="line">  uint m_flags;</span><br><span class="line">  /** Volatility index. */</span><br><span class="line">  int m_volatility;</span><br><span class="line">  /**</span><br><span class="line">    Instrument name index.</span><br><span class="line">    Self index in:</span><br><span class="line">    - EVENTS_WAITS_SUMMARY_*_BY_EVENT_NAME for waits</span><br><span class="line">    - EVENTS_STAGES_SUMMARY_*_BY_EVENT_NAME for stages</span><br><span class="line">    - EVENTS_STATEMENTS_SUMMARY_*_BY_EVENT_NAME for statements</span><br><span class="line">    - EVENTS_TRANSACTIONS_SUMMARY_*_BY_EVENT_NAME for transactions</span><br><span class="line">  */</span><br><span class="line">  uint m_event_name_index;</span><br><span class="line">  /** Instrument name. */</span><br><span class="line">  char m_name[PFS_MAX_INFO_NAME_LENGTH];</span><br><span class="line">  /** Length in bytes of @c m_name. */</span><br><span class="line">  uint m_name_length;</span><br><span class="line">  /** Documentation. */</span><br><span class="line">  char *m_documentation;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="使用"><a href="#使用" class="headerlink" title="使用"></a>使用</h2><p>以mutex 为例，<br>在配置文件中，打开performance_schema， 对部分的配置进行单独设置</p>
<p>对于performance schema 关闭的情况下, psi_mutex_service 对应的就是psi_mutex_noop<br>对于打开performance schema情况下, 对应的是 pfs_mutex_service_v1<br>每个配置项是 performance_schema_instrument &#x3D; ‘ wait&#x2F;synch&#x2F;mutex  &#x3D;  ON  ‘ 是一行， 可以多项，表示enable 多个pfs 监控项, 如果不是精确匹配的话， 就建议增加正则匹配% 来代表所有</p>
<p>m_consumer_global_instrumentation_enabled  可以控制如锁之类（mutex&#x2F;lock&#x2F;rwlock&#x2F;cond）， 文件（file）， table 之类， 控制范围比较广， 默认为true<br>performance_schema_consumer_thread_instrumentation， thread 相关的都由他控制， 默认为true， </p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">performance_schema = ON</span><br><span class="line">m_consumer_global_instrumentation_enabled = 1  </span><br><span class="line">// 对于一些配置，可以单独进行设置</span><br><span class="line">performance_schema_max_mutex_classes=1024</span><br><span class="line">performance_schema_instrument = &#x27; wait/synch/mutex/%  =  ON  &#x27;</span><br><span class="line">performance_schema_instrument = &#x27; wait/io/file/%  =  ON  &#x27;</span><br></pre></td></tr></table></figure>

<h3 id="使用接口"><a href="#使用接口" class="headerlink" title="使用接口"></a>使用接口</h3><p>对mutex 的使用完全和使用pthread mutex 行为基本一致， 可以参考components&#x2F;pfs_example&#x2F;pfs_example.cc</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"></span><br><span class="line">mysql_mutex_register  --&gt; psi_mutex_service-&gt;register_mutex  --&gt; pfs_register_mutex_v1</span><br><span class="line">mysql_mutex_init   --&gt; psi_mutex_service-&gt;init_mutex   /my_mutex_init</span><br><span class="line">mysql_mutex_destroy</span><br><span class="line">mysql_mutex_lock</span><br><span class="line">mysql_mutex_trylock</span><br><span class="line">mysql_mutex_unlock</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static PSI_mutex_key key_mutex_x = 0;</span><br><span class="line">static PSI_mutex_key key_mutex_y = 0;</span><br><span class="line"></span><br><span class="line">static PSI_mutex_info all_example_mutex[] = &#123;</span><br><span class="line">    &#123;&amp;key_mutex_x, &quot;X&quot;, PSI_FLAG_SINGLETON, PSI_VOLATILITY_PERMANENT,</span><br><span class="line">     &quot;Example doc, permanent mutex, singleton.&quot;&#125;,</span><br><span class="line">    &#123;&amp;key_mutex_y, &quot;Y&quot;, 0, PSI_VOLATILITY_QUERY,</span><br><span class="line">     &quot;Example doc, very volatile mutexes.&quot;&#125;&#125;;</span><br><span class="line"></span><br><span class="line">static mysql_mutex_t my_mutex_x;</span><br><span class="line">static mysql_mutex_t my_mutex_y;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">mysql_mutex_register(&quot;pfs_example&quot;, all_example_mutex, 2);</span><br><span class="line"></span><br><span class="line">mysql_mutex_init(key_mutex_x, &amp;my_mutex_x, NULL);</span><br><span class="line">mysql_mutex_init(key_mutex_y, &amp;my_mutex_y, NULL);</span><br><span class="line"></span><br><span class="line">mysql_mutex_lock(&amp;my_mutex_x);</span><br><span class="line">mysql_mutex_trylock(&amp;my_mutex_y);</span><br><span class="line"></span><br><span class="line">mysql_mutex_unlock(&amp;my_mutex_y);</span><br><span class="line">mysql_mutex_unlock(&amp;my_mutex_x);</span><br><span class="line"></span><br><span class="line">mysql_mutex_destroy(&amp;my_mutex_x);</span><br><span class="line">mysql_mutex_destroy(&amp;my_mutex_y);</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>lock 的时候， 就是mysql_mutex_lock(&amp;m_thd-&gt;LOCK_thd_data);</p>
<h3 id="关键的数据结构"><a href="#关键的数据结构" class="headerlink" title="关键的数据结构"></a>关键的数据结构</h3><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">struct mysql_mutex_t &#123;</span><br><span class="line">  /** The real mutex. */</span><br><span class="line">  my_mutex_t m_mutex;</span><br><span class="line">  /**</span><br><span class="line">    The instrumentation hook.</span><br><span class="line">    Note that this hook is not conditionally defined,</span><br><span class="line">    for binary compatibility of the @c mysql_mutex_t interface.</span><br><span class="line">  */</span><br><span class="line">  struct PSI_mutex *m_psi&#123;nullptr&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">struct my_mutex_t &#123;</span><br><span class="line">  union u &#123;</span><br><span class="line">    native_mutex_t m_native;          ////////pthread_mutex_t</span><br><span class="line">    safe_mutex_t *m_safe_ptr;</span><br><span class="line">  &#125; m_u;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">/** Instrumented mutex implementation. @see PSI_mutex. */</span><br><span class="line">struct PFS_ALIGNED PFS_mutex : public PFS_instr &#123;</span><br><span class="line">  /** Mutex identity, typically a @c pthread_mutex_t. */</span><br><span class="line">  const void *m_identity;</span><br><span class="line">  /** Mutex class. */</span><br><span class="line">  PFS_mutex_class *m_class;</span><br><span class="line">  /** Instrument statistics. */</span><br><span class="line">  PFS_mutex_stat m_mutex_stat;</span><br><span class="line">  /** Current owner. */</span><br><span class="line">  PFS_thread *m_owner;</span><br><span class="line">  /**</span><br><span class="line">    Time stamp of the last lock.</span><br><span class="line">    This statistic is not exposed in user visible tables yet.</span><br><span class="line">  */</span><br><span class="line">  ulonglong m_last_locked;</span><br><span class="line">&#125;;</span><br><span class="line">struct PSI_mutex_info_v1 &#123;</span><br><span class="line">  /**</span><br><span class="line">    Pointer to the key assigned to the registered mutex.</span><br><span class="line">  */</span><br><span class="line">  PSI_mutex_key *m_key;</span><br><span class="line">  /**</span><br><span class="line">    The name of the mutex to register.</span><br><span class="line">  */</span><br><span class="line">  const char *m_name;</span><br><span class="line">  /**</span><br><span class="line">    The flags of the mutex to register.</span><br><span class="line">    @sa PSI_FLAG_SINGLETON</span><br><span class="line">  */</span><br><span class="line">  unsigned int m_flags;</span><br><span class="line">  /** Volatility index. */</span><br><span class="line">  int m_volatility;</span><br><span class="line">  /** Documentation. */</span><br><span class="line">  const char *m_documentation;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">struct PFS_ALIGNED PFS_mutex_class : public PFS_instr_class &#123;</span><br><span class="line">  /** Mutex usage statistics. */</span><br><span class="line">  PFS_mutex_stat m_mutex_stat;</span><br><span class="line">  /** Singleton instance. */</span><br><span class="line">  PFS_mutex *m_singleton;</span><br><span class="line">&#125;;</span><br><span class="line">struct PFS_mutex_stat &#123;</span><br><span class="line">  /** Wait statistics. */</span><br><span class="line">  PFS_single_stat m_wait_stat;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="使用流程"><a href="#使用流程" class="headerlink" title="使用流程"></a>使用流程</h3><ol>
<li>注册<br>使用上,需要先register psi, 类似这样</li>
</ol>
<p>先创建PSI_mutex_key&#x2F;PSI_mutex_info， 然后进行注册</p>
<p>参考之前的使用方式</p>
<p>注册函数解析</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pfs_register_mutex_v1 &#123;</span><br><span class="line">  // 生成formatted_name  &lt;--   mutex_instrument_prefix.str + / + category + / + PSI_mutex_info_v1.m_name</span><br><span class="line">  key = register_mutex_class(formatted_name, (uint)full_length, info);   </span><br><span class="line">  *(PSI_mutex_info_v1-&gt;m_key) = key</span><br><span class="line"></span><br><span class="line">  //register_mutex_class 功能</span><br><span class="line">  // 从mutex_class_array 中找到一个空的 PFS_mutex_class, 这个index 后面存储到*(PSI_mutex_info_v1-&gt;m_key) </span><br><span class="line">  // init_instr_class， 初始化这个PFS_mutex_class， </span><br><span class="line">  // configure_instr_class  ， 从pfs_instr_config_array 中找有没有和PFS_mutex_class-&gt;m_name 正则匹配的， 则设置PFS_mutex_class</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="2">
<li>init 操作</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static inline int inline_mysql_mutex_init(</span><br><span class="line">    PSI_mutex_key key MY_ATTRIBUTE((unused)), mysql_mutex_t *that,</span><br><span class="line">    const native_mutexattr_t *attr, const char *src_file MY_ATTRIBUTE((unused)),</span><br><span class="line">    uint src_line MY_ATTRIBUTE((unused))) &#123;</span><br><span class="line">  that-&gt;m_psi = PSI_MUTEX_CALL(init_mutex)(key, &amp;that-&gt;m_mutex);   </span><br><span class="line">  // 这个地方调用 psi_mutex_service-&gt;init_mutex(key, &amp;that-&gt;m_mutex); --&gt; pfs_init_mutex_v1</span><br><span class="line">     </span><br><span class="line"></span><br><span class="line">  return my_mutex_init(&amp;that-&gt;m_mutex, attr);  // 这个就是原始pthread 的init</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">//從mutex_class_array 拿到對應key的PFS_mutex_class</span><br><span class="line">// pfs = create_mutex(klass, identity);   从global_mutex_container 中拿到PFS_mutex, 然后初始化PFS_mutex</span><br><span class="line">PSI_mutex *pfs_init_mutex_v1(PSI_mutex_key key, const void *identity) &#123;</span><br><span class="line">  PFS_mutex_class *klass;</span><br><span class="line">  PFS_mutex *pfs;</span><br><span class="line">  klass = find_mutex_class(key);</span><br><span class="line">  if (unlikely(klass == NULL)) &#123;</span><br><span class="line">    return NULL;</span><br><span class="line">  &#125;</span><br><span class="line">  pfs = create_mutex(klass, identity);</span><br><span class="line">  return reinterpret_cast&lt;PSI_mutex *&gt;(pfs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>lock&#x2F;unlock 的过程<br>当开始锁的时候， 如果enable 了time 跟踪， 会记录下申请锁 到获得锁 的时间戳， 在获得锁的时候， 会把等待时间累加进去， 并记录获得锁的时间， 如果enable 了thread， 会把时间累加到event_name_array[index]上，如果enable FLAG_EVENT, 会有一个PFS_events_waits event , 然后插入 insert_events_waits_history.<br>unlock 的时候，就直接把指针给指向空, 这个地方没有跟踪 lock的时间。 <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">static inline int inline_mysql_mutex_lock(</span><br><span class="line">    mysql_mutex_t *that, const char *src_file MY_ATTRIBUTE((unused)),</span><br><span class="line">    uint src_line MY_ATTRIBUTE((unused))) &#123;</span><br><span class="line">  int result;</span><br><span class="line"></span><br><span class="line">  if (that-&gt;m_psi != NULL) &#123;</span><br><span class="line">    /* Instrumentation start */</span><br><span class="line">    PSI_mutex_locker *locker;</span><br><span class="line">    PSI_mutex_locker_state state;</span><br><span class="line">    locker = PSI_MUTEX_CALL(start_mutex_wait)(</span><br><span class="line">        &amp;state, that-&gt;m_psi, PSI_MUTEX_LOCK, src_file, src_line);  --&gt; pfs_start_mutex_wait_v1</span><br><span class="line"></span><br><span class="line">    /* Instrumented code */</span><br><span class="line">    result = my_mutex_lock(&amp;that-&gt;m_mutex);</span><br><span class="line"></span><br><span class="line">    /* Instrumentation end */</span><br><span class="line">    if (locker != NULL) &#123;</span><br><span class="line">      PSI_MUTEX_CALL(end_mutex_wait)(locker, result);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    return result;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  /* Non instrumented code */</span><br><span class="line">  result = my_mutex_lock(&amp;that-&gt;m_mutex);</span><br><span class="line"></span><br><span class="line">  return result;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">PSI_mutex_locker *pfs_start_mutex_wait_v1(PSI_mutex_locker_state *state,</span><br><span class="line">                                          PSI_mutex *mutex,</span><br><span class="line">                                          PSI_mutex_operation op,</span><br><span class="line">                                          const char *src_file, uint src_line) &#123;</span><br><span class="line">  PFS_mutex *pfs_mutex = reinterpret_cast&lt;PFS_mutex *&gt;(mutex);</span><br><span class="line">  DBUG_ASSERT((int)op &gt;= 0);</span><br><span class="line">  DBUG_ASSERT((uint)op &lt; array_elements(mutex_operation_map));</span><br><span class="line">  DBUG_ASSERT(state != NULL);</span><br><span class="line"></span><br><span class="line">  DBUG_ASSERT(pfs_mutex != NULL);</span><br><span class="line">  DBUG_ASSERT(pfs_mutex-&gt;m_class != NULL);</span><br><span class="line"></span><br><span class="line">  if (!pfs_mutex-&gt;m_enabled) &#123;</span><br><span class="line">    return NULL;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  uint flags;</span><br><span class="line">  ulonglong timer_start = 0;</span><br><span class="line"></span><br><span class="line">  if (flag_thread_instrumentation) &#123;</span><br><span class="line">    PFS_thread *pfs_thread = my_thread_get_THR_PFS();</span><br><span class="line">    if (unlikely(pfs_thread == NULL)) &#123;</span><br><span class="line">      return NULL;</span><br><span class="line">    &#125;</span><br><span class="line">    if (!pfs_thread-&gt;m_enabled) &#123;</span><br><span class="line">      return NULL;</span><br><span class="line">    &#125;</span><br><span class="line">    state-&gt;m_thread = reinterpret_cast&lt;PSI_thread *&gt;(pfs_thread);</span><br><span class="line">    flags = STATE_FLAG_THREAD;</span><br><span class="line"></span><br><span class="line">    if (pfs_mutex-&gt;m_timed) &#123;</span><br><span class="line">      timer_start = get_wait_timer();</span><br><span class="line">      state-&gt;m_timer_start = timer_start;</span><br><span class="line">      flags |= STATE_FLAG_TIMED;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (flag_events_waits_current) &#123;</span><br><span class="line">      if (unlikely(pfs_thread-&gt;m_events_waits_current &gt;=</span><br><span class="line">                   &amp;pfs_thread-&gt;m_events_waits_stack[WAIT_STACK_SIZE])) &#123;</span><br><span class="line">        locker_lost++;</span><br><span class="line">        return NULL;</span><br><span class="line">      &#125;</span><br><span class="line">      PFS_events_waits *wait = pfs_thread-&gt;m_events_waits_current;</span><br><span class="line">      state-&gt;m_wait = wait;</span><br><span class="line">      flags |= STATE_FLAG_EVENT;</span><br><span class="line"></span><br><span class="line">      PFS_events_waits *parent_event = wait - 1;</span><br><span class="line">      wait-&gt;m_event_type = EVENT_TYPE_WAIT;</span><br><span class="line">      wait-&gt;m_nesting_event_id = parent_event-&gt;m_event_id;</span><br><span class="line">      wait-&gt;m_nesting_event_type = parent_event-&gt;m_event_type;</span><br><span class="line"></span><br><span class="line">      wait-&gt;m_thread_internal_id = pfs_thread-&gt;m_thread_internal_id;</span><br><span class="line">      wait-&gt;m_class = pfs_mutex-&gt;m_class;</span><br><span class="line">      wait-&gt;m_timer_start = timer_start;</span><br><span class="line">      wait-&gt;m_timer_end = 0;</span><br><span class="line">      wait-&gt;m_object_instance_addr = pfs_mutex-&gt;m_identity;</span><br><span class="line">      wait-&gt;m_event_id = pfs_thread-&gt;m_event_id++;</span><br><span class="line">      wait-&gt;m_end_event_id = 0;</span><br><span class="line">      wait-&gt;m_operation = mutex_operation_map[(int)op];</span><br><span class="line">      wait-&gt;m_source_file = src_file;</span><br><span class="line">      wait-&gt;m_source_line = src_line;</span><br><span class="line">      wait-&gt;m_wait_class = WAIT_CLASS_MUTEX;</span><br><span class="line"></span><br><span class="line">      pfs_thread-&gt;m_events_waits_current++;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    if (pfs_mutex-&gt;m_timed) &#123;</span><br><span class="line">      timer_start = get_wait_timer();</span><br><span class="line">      state-&gt;m_timer_start = timer_start;</span><br><span class="line">      flags = STATE_FLAG_TIMED;</span><br><span class="line">      state-&gt;m_thread = NULL;</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      /*</span><br><span class="line">        Complete shortcut.</span><br><span class="line">      */</span><br><span class="line">      /* Aggregate to EVENTS_WAITS_SUMMARY_BY_INSTANCE (counted) */</span><br><span class="line">      pfs_mutex-&gt;m_mutex_stat.m_wait_stat.aggregate_counted();</span><br><span class="line">      return NULL;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  state-&gt;m_flags = flags;</span><br><span class="line">  state-&gt;m_mutex = mutex;</span><br><span class="line">  return reinterpret_cast&lt;PSI_mutex_locker *&gt;(state);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void pfs_end_mutex_wait_v1(PSI_mutex_locker *locker, int rc) &#123;</span><br><span class="line">  PSI_mutex_locker_state *state =</span><br><span class="line">      reinterpret_cast&lt;PSI_mutex_locker_state *&gt;(locker);</span><br><span class="line">  DBUG_ASSERT(state != NULL);</span><br><span class="line"></span><br><span class="line">  ulonglong timer_end = 0;</span><br><span class="line">  ulonglong wait_time = 0;</span><br><span class="line"></span><br><span class="line">  PFS_mutex *mutex = reinterpret_cast&lt;PFS_mutex *&gt;(state-&gt;m_mutex);</span><br><span class="line">  DBUG_ASSERT(mutex != NULL);</span><br><span class="line">  PFS_thread *thread = reinterpret_cast&lt;PFS_thread *&gt;(state-&gt;m_thread);</span><br><span class="line"></span><br><span class="line">  uint flags = state-&gt;m_flags;</span><br><span class="line"></span><br><span class="line">  if (flags &amp; STATE_FLAG_TIMED) &#123;</span><br><span class="line">    timer_end = get_wait_timer();</span><br><span class="line">    wait_time = timer_end - state-&gt;m_timer_start;</span><br><span class="line">    /* Aggregate to EVENTS_WAITS_SUMMARY_BY_INSTANCE (timed) */</span><br><span class="line">    mutex-&gt;m_mutex_stat.m_wait_stat.aggregate_value(wait_time);</span><br><span class="line">  &#125; else &#123;</span><br><span class="line">    /* Aggregate to EVENTS_WAITS_SUMMARY_BY_INSTANCE (counted) */</span><br><span class="line">    mutex-&gt;m_mutex_stat.m_wait_stat.aggregate_counted();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  if (likely(rc == 0)) &#123;</span><br><span class="line">    mutex-&gt;m_owner = thread;</span><br><span class="line">    mutex-&gt;m_last_locked = timer_end;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  if (flags &amp; STATE_FLAG_THREAD) &#123;</span><br><span class="line">    PFS_single_stat *event_name_array;</span><br><span class="line">    event_name_array = thread-&gt;write_instr_class_waits_stats();</span><br><span class="line">    uint index = mutex-&gt;m_class-&gt;m_event_name_index;</span><br><span class="line"></span><br><span class="line">    DBUG_ASSERT(index &lt;= wait_class_max);</span><br><span class="line">    DBUG_ASSERT(sanitize_thread(thread) != NULL);</span><br><span class="line"></span><br><span class="line">    if (flags &amp; STATE_FLAG_TIMED) &#123;</span><br><span class="line">      /* Aggregate to EVENTS_WAITS_SUMMARY_BY_THREAD_BY_EVENT_NAME (timed) */</span><br><span class="line">      event_name_array[index].aggregate_value(wait_time);</span><br><span class="line">    &#125; else &#123;</span><br><span class="line">      /* Aggregate to EVENTS_WAITS_SUMMARY_BY_THREAD_BY_EVENT_NAME (counted) */</span><br><span class="line">      event_name_array[index].aggregate_counted();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    if (flags &amp; STATE_FLAG_EVENT) &#123;</span><br><span class="line">      PFS_events_waits *wait =</span><br><span class="line">          reinterpret_cast&lt;PFS_events_waits *&gt;(state-&gt;m_wait);</span><br><span class="line">      DBUG_ASSERT(wait != NULL);</span><br><span class="line"></span><br><span class="line">      wait-&gt;m_timer_end = timer_end;</span><br><span class="line">      wait-&gt;m_end_event_id = thread-&gt;m_event_id;</span><br><span class="line">      if (thread-&gt;m_flag_events_waits_history) &#123;</span><br><span class="line">        insert_events_waits_history(thread, wait);</span><br><span class="line">      &#125;</span><br><span class="line">      if (thread-&gt;m_flag_events_waits_history_long) &#123;</span><br><span class="line">        insert_events_waits_history_long(wait);</span><br><span class="line">      &#125;</span><br><span class="line">      thread-&gt;m_events_waits_current--;</span><br><span class="line"></span><br><span class="line">      DBUG_ASSERT(wait == thread-&gt;m_events_waits_current);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">// unlock 逻辑比较简单， 把对于的psi 对象指针指向空</span><br><span class="line">void pfs_unlock_mutex_v1(PSI_mutex *mutex) &#123;</span><br><span class="line">  PFS_mutex *pfs_mutex = reinterpret_cast&lt;PFS_mutex *&gt;(mutex);</span><br><span class="line"></span><br><span class="line">  DBUG_ASSERT(pfs_mutex != NULL);</span><br><span class="line"></span><br><span class="line">  /*</span><br><span class="line">    Note that this code is still protected by the instrumented mutex,</span><br><span class="line">    and therefore is thread safe. See inline_mysql_mutex_unlock().</span><br><span class="line">  */</span><br><span class="line"></span><br><span class="line">  /* Always update the instrumented state */</span><br><span class="line">  pfs_mutex-&gt;m_owner = NULL;</span><br><span class="line">  pfs_mutex-&gt;m_last_locked = 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="查询performance"><a href="#查询performance" class="headerlink" title="查询performance"></a>查询performance</h3><pre><code>&gt; show tables from performance_schema;
&gt; show tables like &#39;events_statement%&#39;;
&gt; show tables like &#39;events_wait%&#39;;
&gt; select * from events_statements_history;
</code></pre>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>《乔布斯传》读后感</title>
    <url>/2018/qiaobusi/</url>
    <content><![CDATA[<div align="center" style="width: 480px; height: auto;  text-align: center;" >
                <img data-src="/img/qiaobusi.png" >
</div>


<p>乔布斯传，很早以前就看到人手一册， 但看到外界对乔布斯的点评就如同媒体点评马老师一样， 众彩纷纭， 最近因为机缘巧合， 被人要求阅读一下乔布斯传， 就把乔布斯传，拿过来读了一番， 读完之后，有很多不同的感悟，挑2个和大家探讨一下。<br> 第一个印象就是 唯有偏执才能成功，做什么事情都有自己的想法和见地， 甚至对很多事情到了偏执的程度， 年少的乔布斯就放荡不羁，想到了什么就会坚信不疑，   对精神世界的探索， 对素食主义的偏好， 对极简主义的信奉，所幸这些偏执大部分都是善意的， 但在中国， 有句古语叫， 兼听则明， 偏听则暗， 个人观点， 天才往往是超凡脱俗， 天才往往总是坚持自己内心深处的追求， 总是引领世界， 将世界引向自己的方向， 如果非天才级的人物， 最终还是会走向“三个臭皮匠抵得上一个诸葛亮”，依赖群体智慧， 群体的智慧往往是最稳定，大部分时候都是正确的。<br>营销大师，这个世界上， 有2种事情是最难的， 第一就是从别人的口袋里把钱掏过来， 第二个，就是把自己的思想灌输到别人的大脑中。 乔布斯是一位世界级的营销大师。 乔布斯，最开始也不是总是灌输自己的idea到别人的脑中， 但从印度之行回来后， 就开始开挂的人生， 总是在不停的说服其他人按照自己想法，当还是一家小公司时，在做每次展览的时候，就深谙如何抓住眼球 而且他总是和很多营销大师进行交流， 因此他的营销技巧在不断的完善， 另外，他对营销的追求， 远远是高于其他人一个量级， 因此，当苹果的广告出来时，总是给人耳目一新。 营销已经不仅仅对苹果的产品产生深远影响， 同样带来了一个 “乔布斯磁场”， 当乔布斯出现时，大家最后总是在不知不觉中和乔布斯的观点一致。</p>
<p>最后，一千个读者就会有一千个哈姆雷特， 相信大家每次阅读乔布斯，都会有不同的感悟 。</p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>杂谈</tag>
      </tags>
  </entry>
  <entry>
    <title>查询过程</title>
    <url>/2020/query_flow/</url>
    <content><![CDATA[<h1 id="Query-流程"><a href="#Query-流程" class="headerlink" title="Query 流程"></a>Query 流程</h1><p>转载：<a href="/knowledge/mysql/source_code_reading/server/query/query_flow.html">query_flow</a><br><img data-src="/assets/query_flow.png" alt="query_flow"><br><img data-src="/assets/query_flow2.png" alt="query_flow2"><br>本文简单介绍， 详情参考<a href="/knowledge/mysql/source_code_reading/server/query/index.html">query</a></p>
<span id="more"></span>

<h1 id="query-入口"><a href="#query-入口" class="headerlink" title="query 入口"></a>query 入口</h1><p>do_command函数在sql&#x2F;sql_parse.cc定义,代码如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bool do_command(THD *thd) &#123;</span><br><span class="line">  NET *net= &amp;thd-&gt;net;</span><br><span class="line">  packet_length = my_net_read(net);</span><br><span class="line">  packet = (char*) net-&gt;read_pos;</span><br><span class="line">  command = (enum enum_server_command) (uchar) packet[0]; // 解析客户端传过来的命令类型</span><br><span class="line">  dispatch_command(command, thd, packet+1, (uint) (packet_length-1));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h1 id="dispatch"><a href="#dispatch" class="headerlink" title="dispatch"></a>dispatch</h1><p>再看dispatch_command函数在sql&#x2F;sql_parse.cc定义,精简代码如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bool dispatch_command(enum enum_server_command command, THD thd, char packet, uint packet_length) &#123;</span><br><span class="line">  NET *net = &amp;thd-&gt;net;</span><br><span class="line">  thd-&gt;command = command;</span><br><span class="line">  switch (command) &#123; //判断命令类型</span><br><span class="line">    case COM_INIT_DB: ...;</span><br><span class="line">    case COM_TABLE_DUMP: ...;</span><br><span class="line">    case COM_CHANGE_USER: ...;</span><br><span class="line">    ...</span><br><span class="line">    case COM_QUERY: //如果是Query</span><br><span class="line">    alloc_query(thd, packet, packet_length); //从网络数据包中读取Query, 并扩容内存存入thd-&gt;set_query, shrink thd-&gt;packet/thd-&gt;convert_buffer, </span><br><span class="line">    mysql_parse(thd, thd-&gt;query, thd-&gt;query_length, &amp;end_of_stmt); //送去解析</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="parser"><a href="#parser" class="headerlink" title="parser"></a>parser</h1><p>mysql_parse函数负责解析SQL(sql&#x2F;sql_parse.cc), 详情可以参考<a href="/knowledge/mysql/source_code_reading/server/query/parser.html">mysql_parser</a> 精简代码如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">void mysql_parse(THD *thd,</span><br><span class="line">    const</span><br><span class="line">    char *inBuf,</span><br><span class="line">    uint</span><br><span class="line">    length, const</span><br><span class="line">    char ** found_semicolon) &#123;</span><br><span class="line">       </span><br><span class="line">    lex_start(thd); //初始化线程解析描述符</span><br><span class="line">      </span><br><span class="line">    if (query_cache_send_result_to_client(thd, (char*) inBuf,length) &lt;= 0) &#123; </span><br><span class="line">         // 看query cache中有否命中，有就直接返回结果，否则进行查找</span><br><span class="line">            Parser_state parser_state(thd, inBuf, length);   </span><br><span class="line">            parse_sql(thd, &amp; parser_state, NULL); // 解析SQL语句</span><br><span class="line">            mysql_execute_command(thd); // 执行</span><br><span class="line">       </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    mysql_rewrite_query(thd);</span><br><span class="line"></span><br><span class="line">    error = mysql_execute_command(thd, true);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="query-处理"><a href="#query-处理" class="headerlink" title="query 处理"></a>query 处理</h1><p>终于开始执行mysql_execute_command接近3k行, 优化阶段和执行阶段揉在一起， 可以参考<a href="/knowledge/mysql/source_code_reading/server/query/execute.html">execute</a>非常精简代码如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">int mysql_execute_command(THD *thd) &#123;</span><br><span class="line">  LEX  *lex= thd-&gt;lex;  // 解析过后的SQL语句的语法结构</span><br><span class="line">  TABLE_LIST *all_tables = lex-&gt;query_tables;   // 该语句要访问的表的列表</span><br><span class="line">  switch (lex-&gt;sql_command) &#123;</span><br><span class="line">      ...</span><br><span class="line">      case SQLCOM_INSERT:</span><br><span class="line">      insert_precheck(thd, all_tables);</span><br><span class="line">      mysql_insert(thd, all_tables, lex-&gt;field_list, lex-&gt;many_values, lex-&gt;update_list, lex-&gt;value_list, lex-&gt;duplicates, lex-&gt;ignore);</span><br><span class="line">      break; ...</span><br><span class="line">      case SQLCOM_SELECT:</span><br><span class="line">      select_precheck(thd,lex, all_tables, first_table));    // 检查用户对数据表的访问权限</span><br><span class="line">      execute_sqlcom_select(thd, all_tables);     // 执行select语句</span><br><span class="line">      break;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">bool select_precheck(THD *thd, LEX *lex, TABLE_LIST *tables,</span><br><span class="line">                     TABLE_LIST *first_table)</span><br><span class="line">&#123;</span><br><span class="line">  if (tables)</span><br><span class="line">  &#123;</span><br><span class="line">    res= check_table_access(thd,</span><br><span class="line">                            privileges_requested,</span><br><span class="line">                            tables, FALSE, UINT_MAX, FALSE) ||</span><br><span class="line">         (first_table &amp;&amp; first_table-&gt;schema_table_reformed &amp;&amp;</span><br><span class="line">          check_show_access(thd, first_table));</span><br><span class="line">  &#125;</span><br><span class="line">  else</span><br><span class="line">    res= check_access(thd, privileges_requested, any_db, NULL, NULL, 0, 0);</span><br><span class="line">    </span><br><span class="line">  return res;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Redshift 产品分析 《Amazon Redshift and the Case for Simpler Data Warehouses》</title>
    <url>/2020/redshift/</url>
    <content><![CDATA[<h1 id="Redshift-随谈"><a href="#Redshift-随谈" class="headerlink" title="Redshift 随谈"></a>Redshift 随谈</h1><p>无意中看到《Amazon Redshift and the Case for Simpler Data Warehouses》这篇论文的读书笔记(应该是2018年写的)， 于是将论文笔记梳理一下，分享给大家。<br>这是2015年sigmod的一篇论文，这篇论文介绍了redshift 很多产品化的细节， 技术性探讨并不多(有一点aws 软文的感觉)，强烈建议云数据库类的产品经理好好阅读一下， 里面很多理念和产品化的做法aws 2015年就实现了，这在当时是非常超前的，而且有些东西至今国内很多云厂商都还没有实现。 </p>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>先来看一下2017年 Redshift 战绩： 2017财年， 整个aws 数据库部门营收是36 billion $,  而不同于其他数据库云厂商的是， Redshift 占比达到惊人的25%， 也就是9 billion $, 这个数字远远超过国内所有olap 数据库的总和， 简直就是一个天文数字。 </p>
<p>整片论文，换个角度去看，我们带这问题 《How Redshift is success?》去看论文，会带来很多意想不到的思路：</p>
<ul>
<li>Redshift 目标客户是谁？</li>
<li>这个市场前景是多少？</li>
<li>目标客户的需求是什么？</li>
<li>怎么赢得客户</li>
<li>架构和技术分析</li>
</ul>
<span id="more"></span>
<h1 id="Redshift-基本介绍"><a href="#Redshift-基本介绍" class="headerlink" title="Redshift 基本介绍"></a>Redshift 基本介绍</h1><p>Redshift 是2013年推出来， 2014&#x2F;2015年数据库部门增长率最高的olap数据库(Aurora 出来后，号称Aurora 是增长最快的)。<br><img data-src="/img/redshift.png" ><br>技术是基于ParAccel 系统演化而来， 这里一个小插曲，ParAccel 大概是硅谷一群做数据库的人，基于postgres 7.x 做出来一款mpp 数据库，这款数据库吸收了之前开源界很多数据库的设计，比如列存借鉴了c-store&#x2F;monetdb&#x2F;x100, 压缩技术类似vertica，  2008年左右，这帮数据库的人自己出来创业， aws 2009 年找到他们，购买了他们的源码授权， 结果2年后，ParAccel自己倒闭了，而aws的Redshift 越活越好（估计aws 没有少挖 ParAccel的人， ParAccel 肯定最后抗不住）。</p>
<p>今天看Redshift, 有一点点类似postgres-xl的架构，技术上，采用列存，并且支持列存压缩， 计算存储一体化， 支持本地join， code gen， 并且非常容易即可进行scale out。 </p>
<p>数据同时存在s3 和db本地盘中， 每个数据同步写到第一个slice和至少另外一个node的slice中。当磁盘或节点出现故障时， 队列用于限制受影响的slice数， redshift 尝试平衡，重新replication的资源影响和当disk或node增长时，带来相应的失败。 数据异步同步到s3. primary和secondary &#x2F;s3 上数据皆可以读取， s3 上的备份还可以放到其他region。<br>执行器， query plan会被编译成机器码， 多了一些overhead</p>
<p> 和aws 很多service 紧密合作， 利用ec2 作为instance， s3 做备份， simple workflow（swf） 管控action， cloudwatch 作为用户实例的metrics， simple notification service（sns）作审计日志， key management service&#x2F;cloudhsm 作为key management ，  vpc 做security, 还利用了很多内部能力来做部署， 短期credential， 日志收集， metering。 可以利用s3 的高可用和便利的api， 允许我们自动备份， 持续，自动解决用户的需求， s3 还可解决本地存储的页错误， 实现流式恢复能力， 元数据和catalog 恢复后，即可sql 查询。</p>
<p> 有一个manager 帮助部署引擎， 收集events和metrics， 生成实例事件， 归档&#x2F;rotating 日志， 监控节点&#x2F;db&#x2F;日志错误， 还有少量功能执行受限操作， 管控平台是额外集群， 负责集群间的监控和报警， 初始的运维task， 终端用户的请求， 比如节点替换， 集群伸缩容， 备份， 恢复，部署，打patch。</p>
<h1 id="目标客户是谁？"><a href="#目标客户是谁？" class="headerlink" title="目标客户是谁？"></a>目标客户是谁？</h1><p>大部分的db vendor 目标都是大客户， 但Redshift 目标是olap的所有客户， 当DLA 和snowflake 在市场上获得成功后， redshift 立马推出与之对标的产品， 其目的就是解决所有olap需求。<br>在论文里，其实很清楚的写着他们的宗旨</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">宗旨： 如何更便捷的让用户消费redshift, 让用户非常方便，并且极高的性价比获得分析能力, $1000 /TB/Year</span><br></pre></td></tr></table></figure>
<h1 id="市场前景"><a href="#市场前景" class="headerlink" title="市场前景"></a>市场前景</h1><p>论文对这的论断是： 分析市场占关系数据库(1&#x2F;3, $14B  VS  $45B), GARTNER预估 每年8 ～ 11% 的增长， 过去10年， 分析的数据量是每年30～ 40% 增长， 过去的12个月，增速已经达到50 ～ 60%。<br>这个论断和国内的市场结果完全不一样， 国内olap市场大概只有1&#x2F;10 的水准， 这个结果可能第一和国内olap数据库水平比较差； 第二，大家上云的需求量有区别，国内oltp比较重要，会对云厂商依赖重一些，而olap 系统挂了也没有关系，因此上云需求也就少了</p>
<h1 id="客户需求是什么？"><a href="#客户需求是什么？" class="headerlink" title="客户需求是什么？"></a>客户需求是什么？</h1><h2 id="使用数据仓库的企业"><a href="#使用数据仓库的企业" class="headerlink" title="使用数据仓库的企业"></a>使用数据仓库的企业</h2><p> 传统的企业数据仓库， 收集各种数据源的数据， 通过bi 访问， 他们需要无缝从现有bi或etl 工具迁移过来， redshift 解放他们运维这些系统的压力并让用很轻松的scale-out&#x2F;scale-in， 当迁移系统时， 他们更偏爱现有的db系统，而不care 系统是哪家厂商。 当硬件升级或license 到期，或到了规模上限或同厂商提供第二套系统但第二套系统和早期sql 不兼容时，他们会来尝试redshift， 针对这些客户， redshift 不断强化线性增长， 无限扩容， postgres 兼容， 并不断完善工具系统。</p>
<ul>
<li>释放DBA – 释放运维压力，附加工具不断完善</li>
<li>让系统轻松scale-out&#x2F;scale-in， 按需扩容</li>
<li>良好的兼容性 – <ul>
<li>无缝兼容现有的BI&#x2F;ETL 工具</li>
<li>提供现有系统血缘相近的db</li>
<li>保持协议兼容，现有系统可以继续使用</li>
</ul>
</li>
</ul>
<h2 id="大数据客户"><a href="#大数据客户" class="headerlink" title="大数据客户"></a>大数据客户</h2><p>去年有一篇文章《大数据已死》介绍了大数据的3驾马车 cloudera&#x2F;hontorworks&#x2F;mapr 3家公司奄奄一息， 直到去年才暴露出大数据的问题。 其实早在redshift 一出来， redshift 就准备干死大数据这一套的开源系统。</p>
<p>论文这样描述：<br>半结构化的大数据分析， 常常对日志或事务数据集成分析， 一些客户从hive 迁移过来， 获得更好的成本和性能， 他们边用sql或bi工具来使用系统，简便是他们最care的特性之一， 他们没有dba团队， 数据存在大量无效数据， 并且他们需要更简便。 redshift 支持透明数仓， 在数据湖上或自动半结构化数据。</p>
<p>大部分的数据是dark 数据， 收集了但不分析， 没有什么用， 因此常常把数据存储到hadoop 或nosql（带冷热分离能力）只是解决了一部分的需求。成本， 大部分的商业数据库价格昂贵， 因此很难评估大数据清晰的价值</p>
<p>总结下来就是：</p>
<ol>
<li>超强的性价比： 大数据常常是无效数据多， 因此需要极低的价格， </li>
<li>释放运维压力，使用大数据的企业没有dba，因此需要解决运维压力</li>
<li>兼容现有的bi&#x2F;sql 即可</li>
</ol>
<h2 id="加速在线业务的客户"><a href="#加速在线业务的客户" class="headerlink" title="加速在线业务的客户"></a>加速在线业务的客户</h2><p>这种客户的特点是业务驱动， 消费大量原始数据， 跑大型sql 产生在线业务需要的结果， 比如广告技术，数据转化&#x2F;数据消费， 客户用sql直接或申明式展示内容并在hadoop 生态也是一样， sql 越来越替代mr的使用。</p>
<h2 id="samll-data-客户"><a href="#samll-data-客户" class="headerlink" title="samll data 客户"></a>samll data 客户</h2><p>有一些用户并没有使用过传统数仓，他们直接运行分析任务在他们的事务系统中， redshift 帮助他们搭建数仓， 并获得性能提升， oltp系统offline并保留历史， 这些用户会有一个短的滞后， 自动数据变更和schema 自动创建和维护很重要。</p>
<p>价值点：</p>
<ol>
<li>冷热分离， 将冷数据offline到redshift， 实际上对oltp系统有一定的加速</li>
<li>更强的分析能力，并且不影响在线业务</li>
<li>让用户快速搭建olap系统，并降低用户迁移成本， 自动数据变更， schema变更</li>
</ol>
<h1 id="怎样将用户吸引进来"><a href="#怎样将用户吸引进来" class="headerlink" title="怎样将用户吸引进来"></a>怎样将用户吸引进来</h1><p>Redshift 将如何将用户吸引进来，做的十分极致， 用了大量的手段：</p>
<ol>
<li>简化购买流程</li>
</ol>
<p>减少用户实验成本， 提供60天免费使用， 压缩ssd 到160g， 随后， 每个节点打包价$0.25&#x2F;hour&#x2F;node, 含软件和硬件维护费用</p>
<ol>
<li><p>创建集群快， 即使是PB 级的cluster， 创建不超过15分钟。<br>1.1 “time to first report”, 从一开始浏览网页， 评估redshift 服务， 发送第一个query， 获得第一个结果， 用零售的习惯去理解用户的行为， 对产品决策很有帮助。<br>1.1.1 保持postgres odbc&#x2F;jdbc 完全的兼容， 客户现有的系统无需修改即可使用<br>1.1.2 价格体系是和容量相关<br>1.1.3 减少前端步骤 如创建和配置， 能减少流失率<br>1.2 打包交付， 提供给用户的信息只包含节点的数量和类型， 基本网络类型， 管理账号信息， 未来这些信息也尽可能少。<br>1.2.1 早期创建集群耗时15minute， 后来通过预配置只需3分钟搞定<br>1.2.2 减少错误成本， 用户可以自由实验， 让用户db 很方便收回和exchange， 头2个月免费使用160g 压缩ssd， 并且基于小时的计费方式，减少用户的负担<br>1.2.3 用户可以任意伸缩容或部署一个新的集群，做并行迁移， 让老的集群只读</p>
</li>
<li><p>数据快速加载</p>
</li>
</ol>
<p>10 minute load 5B rows, 9.75 hours load 150 B rows, backup 30min, restore 用了4.8 hour， join 2 万亿 和60亿 只花了14 minute<br>数据加载是一个特殊的query 过程， 使用修改过的postgressql copy 命令， 可以直接从s3， dynamoDB, emr, SSH 上获取数据， 多个slice 可以同时并行拉取数据， copy还可以直接支持json和压缩， 加密数据。</p>
<h1 id="怎样将用户留下来"><a href="#怎样将用户留下来" class="headerlink" title="怎样将用户留下来"></a>怎样将用户留下来</h1><ul>
<li>性价比</li>
<li>简单易用，释放运维压力</li>
<li>稳定性第一</li>
<li>后台推荐系统</li>
</ul>
<h2 id="性价比"><a href="#性价比" class="headerlink" title="性价比"></a>性价比</h2><p>redshift 目前基本超过现在能看到的开源olap 数据库或大数据系统， 并且提供极低的价格， $1000 &#x2F;TB&#x2F;Year， 这个价格下，很少有系统能提供如此高的性价比。</p>
<h2 id="释放运维压力"><a href="#释放运维压力" class="headerlink" title="释放运维压力"></a>释放运维压力</h2><ul>
<li><p>减少运维管理<br>复杂性， 云上数据库需要解决数据库的复杂性， 比如部署， 运维， 备份， 调优. 减少管理， 减少迁移， 备份， 自动备份， 恢复， 部署，打patch， 错误探测和恢复， 高级功能如加密，伸缩容， 灾难恢复也只要点几下。</p>
<ol>
<li>不需要dba， 不需要db 日常管理， 如安装，打patch， 监控， 修复备份和恢复。</li>
<li>db的运维应该是申明式的</li>
<li>集群备份会均分到每个节点， 集群备份会自动执行和过期。</li>
<li>当需要备份到其他region， 用户只用点击click box 和选择region， 它会备份到本地或远程region， 恢复也是流式， 几分钟就能在其他region 进行恢复。</li>
<li>加密是很直接</li>
<li>未来， 用户不用初始的table 管理操作， 让他们接近备份操作， db能自我决定， 当load 过载或访问性能下降。</li>
<li>减少扩容担心， 价格仅和数据量相关， 管控操作也是并行的</li>
<li>部署和打patch是自动， 用户无感知， 一个星期一个feature， 快速迭代来寻找用户最关心的feature</li>
</ol>
</li>
<li><p>减少性能调优<br>自动tuning， 默认设置是足够的， 高级用户可以做一些调优的操作， 比如自动挑选压缩类型， 通过多维-curve 来避免indexing 和projecting</p>
<ol>
<li>很少工具来进行性能调优， 我们来承担这份工作， 用户只需关注db类型和节点数， 个别表的sort 方式和分布模型。</li>
<li>用户有时想设置一些参数， 比如列压缩类型， redshift 减少这种设置， 或者让这些设置更精准， db 提供足够信息如查询pattern， 数据分布，压缩成本</li>
<li>减少设置， sort column和key平衡分布， 我们的一个技术是减少后续优化操作</li>
<li>系统可以grow 或收缩 随load 变化， 减轻数据和查询的连接</li>
</ol>
</li>
</ul>
<p> 一个功能就是， 在周5释放集群，在周日晚上恢复。</p>
<h2 id="稳定性第一"><a href="#稳定性第一" class="headerlink" title="稳定性第一"></a>稳定性第一</h2><p>对用户非常尊重， 每个节点增加1分钟的开销都需要很多天的调研， 一个缺陷的bug fix， 即使是1000多天才回让集群重启一下都要调研一下， 持续提高可靠性，可用性，自驱。<br>列了一些教训</p>
<ol>
<li>2013年开始，几千套集群， 更偏重迭代而不是重构， 失败是很常见的， 当出现故障时， 降级比丢失可用性更关键， aws 有5千万的code， 经常会出现少量的regression， 当某个service 失去服务时， 让自己弹性很有必要。 我们每个data center 有预配置节点， 可以持续部署或替换节点，当ec2部署中断， 可以增加本地备份，防止s3 或网络故障。</li>
<li>不间断服务， 用户期望小的patch而不是大的， 打patch 是繁重过程， 因此自动打patch， 限制在用户允许的30分钟窗口内每周， patch 可回滚， 当出现错误或延迟时，可以自动回滚。 任何时刻用户只在一个patch verison， 这样可以很便捷的确认issue， 每两周推动新的engine， 以前是4周， 现在降低失败的概率</li>
</ol>
<h2 id="客户推荐系统"><a href="#客户推荐系统" class="headerlink" title="客户推荐系统"></a>客户推荐系统</h2><p>用pareto 分析调度任务， severity level 2 的报警才让engineer 参与， 否则研发会被日常维护给淹没， 系统自动收集日志，分析前10 的错误。 pareto 可以帮助了解用户需求， 每年会直接1v1 对话客户。</p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>OLAP</tag>
      </tags>
  </entry>
  <entry>
    <title>罗瓦涅米之旅</title>
    <url>/2020/rovaniemi/</url>
    <content><![CDATA[<h1 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h1><p>原本计划去新西兰玩一圈， 攻略和行程都差不多计划好， 正准备双11 开始腐败时， 忽然老婆说飞猪上有亏本卖的芬兰极光之旅， 从来没有去看过极光， 也从来没有去那么冷的地方玩，一直很想玩高山滑雪， 虽然对芬兰那边的极冷环境有一点点害怕，但看了飞猪的极光之旅，感觉整个行程，还是充满很多惊喜和欢乐。另外，还有一点特别打动我的是， 飞猪可以将行程延几天， 但实际上， 在双11 那天， 让飞猪去问， 能不能延5天，答复过年期间机票很紧张， 无法延续， 再次咨询能否延3天， 依旧答复不可以。 最后一怒之下，决定彻底放飞自己， 在整个芬兰之后的行程里， 自己安排了6天， 飞挪威，丹麦， 瑞典。 </p>
<p> 芬兰这个6天 机票 + 酒店的性价比非常高，完全不需要导游， 所有的游玩项目都是标准件， 想玩什么就直接上飞猪或<a href="http://www.nordictravels.eu/">www.nordictravels.eu</a>(当地一个很大旅游公司， 更推荐直接在这个上面进行预定)直接预定。完全不需要导游， 如果想要延期玩几天的划， 直接申请延长5天， 多余的5天，可以去挪威，瑞典玩一下。 注意，有可能在双11 这天， 因为订单比较多， 反而不能延长， 建议牺牲掉双11的红包， 提前一个月进行预定。 </p>
<p>整个北欧冬天白天时间非常短，早上9点天才灰蒙蒙的亮，在罗瓦涅米下午3点天就彻底黑了， 在赫尔辛基下午4点天就黑了， 其他如挪威丹麦稍微好一点，能坚持到5点，天才黑。不过，傍晚和朝霞是非常漂亮，尤其是阳光照在厚厚积雪的屋顶，漂亮极了。 </p>
<p>先上几张图片镇楼<br><img data-src="/img/rovaniemi/aurora.jpeg" ><br><img data-src="/img/rovaniemi/aurora1.JPG" ></p>
<p>另外有那种雪地摩托，也值得推荐， 另外关于哈士奇雪橇和驯鹿雪橇， 有短途的500m和1千米， 也有远一点的10km，费用不一样， 需要注意一点。</p>
<span id="more"></span>
<h1 id="攻略"><a href="#攻略" class="headerlink" title="攻略"></a>攻略</h1><p>罗瓦涅米，我们是过年前一周去的， 是1月20 ～ 23， 还不是一年最冷的时候，零下1度到10度（导游一直说我们去的这一年是最暖和的一年），非常适合游玩， 等我们离开的时候，温度不断下降， 离开后4天，温度达到零下25度。罗瓦涅米其实也是一个只适合在冬天游玩的地方。 这个地方很多有非常多的游玩项目，自己想玩什么就玩什么。 </p>
<p>建议1. 游玩项目，建议直接上<a href="http://www.nordictravels.eu/">www.nordictravels.eu</a> 这家官网上直接预定， 这家公司，非常大， 所有游玩项目都是官方价格， 童叟无欺， 而且很多游玩比如极光之类的游玩，他们都很专业。 </p>
<p>我们在罗瓦涅米， 玩了， 破冰船， 极光摄影团， 极光巴士， 罗瓦涅米一日游， 森林滑雪。 整个体验下来。好玩程度， 从高到底</p>
<ol>
<li>极光摄影团</li>
<li>森林滑雪</li>
<li>破冰船</li>
<li>罗瓦涅米一日游</li>
</ol>
<p>晚上看了， 有人推荐冰钓也不错， 不过冰钓主要是看风景，可能带小孩不是特别方便。 另外有那种雪地摩托，也值得推荐， 另外关于哈士奇雪橇和驯鹿雪橇， 有短途的500m和1千米， 也有远一点的10km，费用不一样， 需要注意一点。</p>
<h2 id="极光之旅"><a href="#极光之旅" class="headerlink" title="极光之旅"></a>极光之旅</h2><p>来罗瓦涅米，最好玩也是印象最深刻的是极光之旅， 来罗瓦涅米如果没有看到极光，那相当于白来一趟。 如果碰上极光很好的夜晚， 而你又特别喜欢摄影的话， 可以在那里好好享受几个小时的摄影时光。通常旅行社会开车把大家带到一个很偏远的地方， 这个地方光污染比较少， 经常是在一个冰湖上。在那里视野非常开阔， 能见度也非常的高。 我在这里碰到了我有史以来最明亮的夜晚。 </p>
<img data-src="/img/rovaniemi/beauty.JPG" >
放一张美女镇楼
<img data-src="/img/rovaniemi/love.JPG" >
在极光下， 向爱人示爱或求婚， 是不是非常浪漫呢？
<img data-src="/img/rovaniemi/me.jpeg" >
<img data-src="/img/rovaniemi/me2.JPG" >
应广大群众要求，放2张楼主照片
看一次极光，一位大人差不多要900一次，如果提前预定了，但当晚没有极光或者云比较多，也看不到，白白浪费钱， 因此，建议不要提前进行预定， 等到了罗瓦涅米， 在下午5点时，根据情况再决定是否要预定还是不预定。 
1. 下2个app， "Aurora Map" 和 “Aurora Now” 2个app，
2. 下了app 后，在app上看当地的kp （是叫电磁强度还是太阳风暴强度不记得了），里面会对当晚或后面几天kp进行预测，  如果当晚kp 不高（小于3），就建议不要预定了。 大于等于3 就可以考虑了
3. 如果5点左右还在下雨或云层比较厉害， 在app再看看cloud 预测，如果cloud 很厉害，也不用看
4. 如果kp和cloud 都满足条件， 赶紧上www.nordictravels.eu 这家网站， 下订单， 可以直接打电话给他们，他们提供中文电话服务。 
5. 下单推荐下极光摄影团项目， 旅行社他们一个大巴40/50人，会配上2个摄影师，专门帮助大家拍照， 而且他们拍照经验相对而已还是非常丰富， 比大部分摄影菜鸟还是要强很多。 另外第二次报名时， 直接半价。 

<p>这里吐槽一下我们接机的导游zero， 我们第二天晚上， 下着小雨， 但却不停忽悠我们说， 今晚的kp是这几天最高，建议我们购买她的极光巴士， 结果差不多2千块全部打水飘， 就为了赚一些中介费，纯粹是坑人。 </p>
<h2 id="滑雪"><a href="#滑雪" class="headerlink" title="滑雪"></a>滑雪</h2><p>滑雪其实也是罗瓦涅米最好玩的项目， 但不知为啥，国人似乎玩的比较少， 罗瓦涅米有很多滑雪场， 这些滑雪场都是免费的， 只要你有装备， 你想怎么划就怎么划。 菜鸟就去菜鸟的滑雪场， 高手就去高手的滑雪场， 茄子萝卜各有所爱。 推荐的玩法， 如果在飞猪上下单， 记得提前几天下单， 另外一点， 滑雪是全英文的， 没有中文讲解， 因此要稍微懂一些英文， 即使在飞猪上选择中文， 教练还是英文教练，选择中文还要贵200. 也可以上<a href="http://www.nordictravels.eu上下单./">www.nordictravels.eu上下单。</a> </p>
<p>滑雪的教练，会先问，滑雪水平如何， 如果是菜鸟， 会带到菜鸟的场地， 然后先教大家简单的滑雪动作， 比如刹车， 防止摔伤， 怎么爬坡，怎么滑行等， 动作非常简单，没有玩的，基本上练1个小时后差不多就会基本动作了。另外芬兰的滑雪装备比国内的要非常优秀， 很轻， 和每个人的身高体重很适配， 比国内的滑雪板使用起来更舒适和顺手。 教练带我们练了一个小时后， 带我们到一个菜鸟滑道上，带我们玩了一圈， 然后我们自己就在这个菜鸟滑道上玩了2个小时， 坦白讲，大人和小孩都玩的很开心。 </p>
<img data-src="/img/rovaniemi/ski.jpeg" >
推荐玩法：
1. 第一天在飞猪或nodict官网下单， 让他们的教练先教我们一下基本的动作， 另外， 也会带我们去滑雪场和租赁中心租设备。
2. 如果后面想自己去滑雪， 就可以自己几个人组个团，租一辆车，带上中午吃的一些东西， 自己去昨天的滑雪场和租赁中心进行租赁。 

<h2 id="破冰船"><a href="#破冰船" class="headerlink" title="破冰船"></a>破冰船</h2><p>破冰船， 就是搭乘一艘破冰船，航线在冰封的海面上。 破冰船每天都开一次， 行走的路线非常固定，行走路线的冰层每天都被破， 因此没有路线上的冰没有那么后， 路线边上的冰大概看了一下30公分左右。</p>
<img data-src="/img/rovaniemi/icebreak.jpeg" >
然后船航行差不多一个小时后， 到了一个稍微开阔的水域， 船停在这里，让大家穿着虾服， 可以下水游泳， 游完泳， 大家上船换羽绒服，然后到冰封的海面上玩， 堆堆雪人拍拍照, 冰封的海面，一望无际， 小朋友可以在这里打打雪仗，堆堆雪人，大人可以多拍拍照片。 

<img data-src="/img/rovaniemi/swim.jpeg" >
另外， 玩破冰船的，中午会在瑞典一个小镇上 吃午餐，这个小镇的风景非常漂亮，无论是冬天还是夏天，景色都是非常迷人， 可以驻足拍照一段时间。

<img data-src="/img/rovaniemi/icetown.jpeg" >
 整体而已， 破冰船，玩一次就够了，下次估计就不会再想玩了。 
一点小建议就是， 破冰船如果想玩，可以提前在双11 预定， 会有一点小红包。 

<h2 id="圣诞老人村一日游"><a href="#圣诞老人村一日游" class="headerlink" title="圣诞老人村一日游"></a>圣诞老人村一日游</h2><p>一日游， 基本行程就是带大家去看一下日出，然后到圣诞老人村， 见见圣诞老人， 坐一下哈士奇雪橇（只有1千米）， 坐一些驯鹿雪橇（大概1千米还是2千米）， 最后去一下北极博物馆， 其中北极博物馆，导游的讲解比较详细，还是给行程增色不少。 </p>
<img data-src="/img/rovaniemi/husky.jpeg" >
<img data-src="/img/rovaniemi/reindeer.jpeg" >

<p>圣诞老人村，其实挺漂亮的，无论是白天阳光下的木屋，还是晚上的冰雕餐馆，很适合在这里玩上一天，  玩的项目也多，小朋友可以拿着滑雪板在这里坐滑雪板滑雪。很适合在这里玩上一天， </p>
<img data-src="/img/rovaniemi/house.jpeg" >
如果住圣诞老人村的话， 其实这个活动，不需要报这个项目， 因为， 基本上见圣诞老人， 哈士奇雪橇，驯鹿雪橇都是在圣诞老人村， 自己都可以自费玩， 而且费用上自己玩可能更便宜一点， 另外一点时间上会比较自由， 不过，还是推荐雪地摩托， 我看很多老外都有选择雪地摩托，还是对这个有点期待。 

<p>北极圈的日出还是很漂亮的，不过不一定要跟团， 自己平时也能看得到， </p>
<p>如果想要自由行的话， 圣诞老人村差不多非常适合度假和休息， 不过房间非常紧俏， 如果预定，差不多提前2个月就需要开始预定。 而且价格也不便宜</p>
]]></content>
      <categories>
        <category>travel</category>
      </categories>
      <tags>
        <tag>travel</tag>
      </tags>
  </entry>
  <entry>
    <title>scala 概述</title>
    <url>/2016/scala-general/</url>
    <content><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>scala 就是 将函数式编程和面向对象编程进行融合， 并加入静态类型语言的一种编程语言<br>是一种运行在jvm上的，可以无缝和java 结合的编程语言</p>
<span id="more"></span>

<h2 id="函数式编程"><a href="#函数式编程" class="headerlink" title="函数式编程"></a>函数式编程</h2><ul>
<li>函数就是对象， 函数就是头等值， 函数和字符串，整数处在同一个地位， 可以被当作函数参数或函数返回值保存到变量中， 也可以在函数中定义函数，就像定义整数一样，也可以定义匿名函数，并把函数插到代码任意地方</li>
<li>不可变数据结构是函数式编程的基石</li>
<li>方法不应该有任何副作用， 即可重入</li>
</ul>
<h2 id="静态类型："><a href="#静态类型：" class="headerlink" title="静态类型："></a>静态类型：</h2><ul>
<li>确定变量和表达式的类型， 所有类型都是明确制定，并非动态变化， 但却很好的解决了程序的过度冗长</li>
<li>通过类型推断避免冗余性</li>
<li>通过模式匹配获得灵活性</li>
<li>好处：<ul>
<li>类型检查</li>
<li>安全重构，</li>
</ul>
</li>
</ul>
<ul>
<li>用户可以自定义类或库<ul>
<li>评论：任何语言不是都可以这么做么， 没有什么特别的</li>
</ul>
</li>
<li>actor并发编程模型<ul>
<li>评论： 其实就是基于消息的异步编程， 新瓶换旧酒， 异步编程框架都是基于消息的actor模型， 唯一一点， scala的actor编程框架使用会更加简单， 封装性更好。<br><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1eUnZMVXXXXbkXXXXXXXXXXXX" alt="enter image description here"></li>
</ul>
</li>
</ul>
<h2 id="scala-思想来源"><a href="#scala-思想来源" class="headerlink" title="scala 思想来源"></a>scala 思想来源</h2><ul>
<li>采用java &amp; c# 大部分， 表达式，句子，代码块 多数和java一样， 还采用了java的很多元素， 基本类型，类库和执行模式</li>
<li>统一对象模型来自smalltalk</li>
<li>actor库来着erlang</li>
<li>函数式编程方式来自和sml&#x2F;ocaml&#x2F;f# 为代表的ml家族语言</li>
<li>方法调用和字段选择的统一访问原则来自eiffel</li>
</ul>
]]></content>
      <categories>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title>scala 入门</title>
    <url>/2016/scala-start/</url>
    <content><![CDATA[<h1 id="scala-入门初探"><a href="#scala-入门初探" class="headerlink" title="scala 入门初探"></a>scala 入门初探</h1><p>本章介绍scala 入门基本知识</p>
<span id="more"></span>

<h2 id="scala-解释器"><a href="#scala-解释器" class="headerlink" title="scala 解释器"></a>scala 解释器</h2><p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1v6nOMVXXXXatXFXXXXXXXXXX" alt="scala shell"></p>
<pre><code>- 变量
- 冒号和类型
- 等号
- 结果
</code></pre>
<p>当对多个文件调用scala时， 需要首先对他们进行编译<br><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1qxvDMVXXXXa1XVXXXXXXXXXX" alt="build"></p>
<p>但scalar 比较慢， 推荐使用fsc， fsc 会启动一个后台程序，扫描jar文件， 调用fsc时，仅把源码提交给后台进行编译<br><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1bofNMVXXXXa1XFXXXXXXXXXX" alt="fsc build"></p>
<h2 id="变量定义"><a href="#变量定义" class="headerlink" title="变量定义"></a>变量定义</h2><ul>
<li>val， 类似java的final变量</li>
<li>var， 非final变量</li>
</ul>
<h2 id="函数定义："><a href="#函数定义：" class="headerlink" title="函数定义："></a>函数定义：</h2><p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1gcPLMVXXXXbDXFXXXXXXXXXX" alt="function_def"><br><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1Md6BMVXXXXbUXVXXXXXXXXXX" alt="image"><br>如果函数结果可以推导出来，可以不用写函数结果的类型<br>如果函数体只有一行，可以不用写花括号<br>Unit 表示void 类型</p>
<h2 id="scala脚本："><a href="#scala脚本：" class="headerlink" title="scala脚本："></a>scala脚本：</h2><p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1LZPvMVXXXXXYaXXXXXXXXXXX" alt="image"></p>
<h2 id="循环语句"><a href="#循环语句" class="headerlink" title="循环语句"></a>循环语句</h2><p>while<br>foreach</p>
<p>args.foreach(arg &#x3D;&gt; println(arg))<br>等价<br>args.foreach((arg: String) &#x3D;&gt; println(arg))</p>
<p>如果函数语句只有一行，并且直邮一个参数，可以缩写参数<br>args.foreach(println)</p>
<p>for 语法</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1XJbyMVXXXXc3XVXXXXXXXXXX" alt="image"></p>
<h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1vSYAMVXXXXXUXVXXXXXXXXXX" alt="image"></p>
<p>其中 for(i &lt;- 0 to 2)<br>有一个原则：<br>方法若只有一个参数并且方法返回值有接收者，调用时，可以省略点和括号<br>因此等价于 for (i &lt;- 0.to(2))</p>
<p>其中greetStrings 指定了数组变量，因此不能修改为其他变量，但内部是可以重新赋值的</p>
<p>greetString(0) 等价于 greetString.apply(i)<br>任何对于对象值参数应用都（直接用传递一个活多个值参数时）被转化为对apply方法的调用</p>
<p>当对带有括号，并包括1到若干参数赋值时， 编译器自动调用对象的update函数，对括号里面的参数和等号右边的对象执行调用<br>greetStrings(0) &#x3D; “hello”<br>转化为<br>greetStrings.update(0, “hello”)</p>
<p>还可以更加简洁</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB16PfwMVXXXXc2XVXXXXXXXXXX" alt="1"></p>
<p>等价于</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1OvzHMVXXXXXbXVXXXXXXXXXX" alt="1"></p>
<h2 id="list"><a href="#list" class="headerlink" title="list"></a>list</h2><p>scala.List 不同于java 的java.util.List, 一旦创建就不可改变， 内部的元素也是不可变的。</p>
<p>:::  实现叠加功能</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1D8zpMVXXXXXGaFXXXXXXXXXX" alt="1"></p>
<p>:: 发音 cons,  把新元素添加到列表的最前端， 并且它是右操作符</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB13UPMMVXXXXcfXpXXXXXXXXXX" alt="2"></p>
<p>下面可以得到和上面一样的结果， Nil 是空列表的简写</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1EMrzMVXXXXcKXVXXXXXXXXXX" alt="1"></p>
<p>列表没有append操作<br>原因是，随列表增长， append耗时也会增长， 而:: 操作耗时是固定的。<br>如果想做append操作</p>
<ul>
<li>调用::,  然后调用reverse</li>
<li>使用ListBuffer</li>
</ul>
<p>list 函数列表, List 索引基于0</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1ldTvMVXXXXXOXVXXXXXXXXXX" alt="1"></p>
<h2 id="Tuple"><a href="#Tuple" class="headerlink" title="Tuple"></a>Tuple</h2><p>Tuple 也是不可变对象， 但和List不同， 它可以含有不同类型的元素</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1o1bwMVXXXXataXXXXXXXXXXX" alt="1"></p>
<p>tuple的索引是基于1:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">99</span><br><span class="line">Luftballons</span><br></pre></td></tr></table></figure>


<p>为什么是基于1， 因为对于静态类型元组其他语言 Haskell&#x2F;ML 1是传统。<br>不能使用pair(0), 因为pair(0)就是 pair.apply(0), 但apply不能满足一个函数返回不同的类型， 因此不能这样操作</p>
<p>＃ set<br>set分为可变set和不可变set</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1TUnvMVXXXXbfaXXXXXXXXXXX" alt="1"></p>
<p>scala的trait 类似java的interface<br>实现了java的接口，在scala里面称为mix in trait</p>
<p>默认是不可变set<br>例如：</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1ApTQMVXXXXXlXFXXXXXXXXXX" alt="1"></p>
<p>当执行+&#x3D; 操作时， 实际上是创建一个新的set</p>
<p>如果需要可变set， 得必须指定是可变set</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1aBHrMVXXXXamapXXXXXXXXXX" alt="1"></p>
<h2 id="map"><a href="#map" class="headerlink" title="map"></a>map</h2><p>map也分可变map和不可变map， 不可变map是默认的</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1I.rpMVXXXXanapXXXXXXXXXX" alt="1"></p>
<p>scala的任何对象都可以调用-&gt;函数， 返回包含键值对的二元组</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1lL6xMVXXXXX.aXXXXXXXXXXX" alt="2"></p>
<h2 id="副作用"><a href="#副作用" class="headerlink" title="副作用"></a>副作用</h2><p>scala里面有一种行为，常常称为副作用， 就是不返回值的行为称为副作用。暗指一个该函数重复执行不能得到一个明确的结果。<br>有一种仅为了副作用而执行的方式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def add(b: Byte): Unit = sum += b</span><br></pre></td></tr></table></figure>
<p>可以改写为</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">def add(b: Byte) &#123;sum += b&#125;</span><br></pre></td></tr></table></figure>

<p>去掉类型和＝， 并用花括号来包括</p>
<p>另外因为任何类型都可以转化为Unit, 因此，当一个函数结果是某个类型比如string时， 但函数返回类型指定了Unit, 则丢弃结果</p>
<p><img data-src="http://img3.tbcdn.cn/5476e8b07b923/TB1bDPKMVXXXXaiXFXXXXXXXXXX" alt="1"></p>
<p>因此这种情况很容易导致用户发生错误， 比如用户其实是想要返回值，但漏写了&#x3D;， 于是导致函数无结果返回</p>
<h2 id="分号"><a href="#分号" class="headerlink" title="分号;"></a>分号;</h2><p>当一行只有一个语句时，可以不用分号， 当有多个语句时，得用分号</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">val s = &quot;hello&quot;; println(s)</span><br></pre></td></tr></table></figure>

<p>但注意 scala 是把操作符放到尾部</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x +</span><br><span class="line">y +</span><br><span class="line">z</span><br></pre></td></tr></table></figure>

<p>等价于(x+y+z) 但如果是</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">x</span><br><span class="line">+y</span><br><span class="line">+z</span><br></pre></td></tr></table></figure>
<p>则变成了3个独立语句</p>
]]></content>
      <categories>
        <category>Scala</category>
      </categories>
      <tags>
        <tag>Scala</tag>
      </tags>
  </entry>
  <entry>
    <title>The ScreamScope Model： Microsoft ScreamScope 编程模型</title>
    <url>/2016/screamscope/</url>
    <content><![CDATA[<h1 id="插曲"><a href="#插曲" class="headerlink" title="插曲"></a>插曲</h1><p><a href="https://www.usenix.org/system/files/conference/nsdi16/nsdi16-paper-lin-wei.pdf">screamscope</a> 论文读了好几个月了，把之前分享，今天发出来。</p>
<hr>
<h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h1><p><B><U>论文主要是提出一种设计理念 rVertex&#x2F;rStream, 这个设计理念其实还非常先进。尤其是在低延迟和容错性上思考很多</B></U></p>
<p>这个设计理念换了一种角度来思考常见的分布式计算框架（常见思路，主要是考虑DAG 和节点）， 将计算拆解为计算单元（rVertex）和管道(rStream)2种抽象， 尤其是管道（rStream）将上下游的关系进行解藕， 对failure 问题上还是解的很漂亮。</p>
<h2 id="核心一些观点："><a href="#核心一些观点：" class="headerlink" title="核心一些观点："></a>核心一些观点：</h2><ul>
<li>这套系统起源于批处理系统SCOPE, 是对SCOPE 系统一个扩展，并且将原来一些批处理的任务已经迁移到StreamScope 上。已经部署到2万台机器上，每天处理百亿／数十TB 的数据。另外因为它起源于SCOPE, 它应该用sql 解决应用问题上， 会比其他流式框架要更成熟（这个是个人猜测）；</li>
<li>用户接口上面， 为用户提供申明式语言（类似sql）和udf,</li>
<li>用户提交一段类sql，将它编译成logic plan(含一些udf和各种算子)，然后用优化器，选择一个最优路径，然后，转化为physical plan，部署到每台机器上， 最后用job manager 来跟踪所有的状态。 很多组件都是用scope的组件完成或稍加改造。 （现代系统大致思路都是这个逻辑）   </li>
<li>接口抽象上，接口还是适配性非常强； 节点rVertex 提供3个核心接口Load&#x2F;Execute&#x2F;GetSnapshot， 这个模型可以适配到绝大部分计算场景。rStream 接口 Write(seq, e)／Register(seq)／GarbageCollect(seq)</li>
<li>在容错性上， 首先通过rStream 来将上下游节点进行解藕， 下游的失败不一定需要影响到上游， 然后提供3种策略来，让用户选择。（读者可以看后面的详细介绍）</li>
<li>在exactly-once 要求上， 依赖3大部分： 1. 容错机制； 2. sequence number（每条消息配置单调递增的） 3. 确定性， 明确每个节点在状态相同时，接受相同输入时（无论是多实例同时计算或者同一个实例重启后计算），必须产生相同结果</li>
<li>性能上， 1. 通过sequence number来减少ack 数据流；2. rStream 的3层设计 （volatile／Reliable&#x2F;GC）在保障稳定性同时，可以获得一些好的性能。3. 一次读取，可以获取一个小collection</li>
</ul>
 <span id="more"></span>

<h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>StreamScope 是 SCOPE  批处理系统的流式扩展的设计与实现。StreamScope 深度考虑SCOPE中的架构， compiler， 优化器和任务管理器, 对这些组件进行调整或redesign 以适应流式计算。通过对批处理和流计算的整合在实践中提供显著好处。</p>
<p>在StreamScope 中， 用户程序类似sql。 这个程序倍编译成一个流式 DAG 如图4 所示</p>
<p><img data-src="http://img3.tbcdn.cn/L1/461/1/c4eeb3b681401ab943322dc9481b941b2df1b770" alt="screenshot"></p>
<p>为了产生这种DAG, StreamScope 的compiler 执行如下步骤：</p>
<ul>
<li>程序首先被转化为logical plan(DAG), logical plan 中含有StreamScope runtime operators， 如临时join， window aggregates和用户自定义函数。</li>
<li>StreamScope optimizer 评估各种执行计划， 选择一个评估最低成本的执行计划， 基于可获得的资源， 数据参数如数据流入速度和内部成本模型</li>
<li>创建最终的physical plan(DAG), 映射一个logical 节点到适当的physical 节点上，并发执行。 为每个节点生成code， 并部署到集群上。 这些细节类似SCOPE .</li>
</ul>
<p>整个执行由streaming job manager 进行精心安排：</p>
<ul>
<li>调度节点到并建立DAG 中的channel到不同的机器上</li>
<li>监控进程并跟踪snapshots</li>
<li>当发现错误时提供容错，并初始化恢复动作。</li>
</ul>
<p>不像批处理的job manager， 批处理的job manager在不同的时间上调度节点， 流计算job manager在任务的起始阶段就开始调度DAG中所有的节点 。 为了提供容错性和应付动态变更， rVertex 和rStream 用来实现DAG 中的节点和channel， 同job manager协同工作。</p>
<h1 id="编程模型"><a href="#编程模型" class="headerlink" title="编程模型"></a>编程模型</h1><p>本章将介绍一个high－level的编程模型概述， 重点描述重要概念，包括数据模型和查询语言。</p>
<p>连续事件流（continuous event StreamScope）。 在StreamScope中， 数据以事件流的形式来表达， 每一个描述一个潜在的无限事件集合， 每一个事件流有一个定义好的schema。 除此之外， 每一个事件有一个事件间隔[Vs, Ve), 描述事件有效的起始时间和终止事件。</p>
<p>像其他的流计算引擎， StreamScope 支持current time increments(CTI) event, 它可以来保证截止到CTI的Vs的event已经发送完毕； 也就意味着，在CTI event 后再没有消息的timestamp小于Vs。 依赖CTI event的算子决定了当前处理事件从而保证流程继续并丢掉失效的状态信息。</p>
<p>Declarative query language. (申明式查询语言)， StreamScope 提供一个陈述式查询语言， 这样用户可以编程他们的应用而不用担心分布式环境的一些细节，比如scalability或容错性。 尤其是， StreamScope 扩展了SCOPE 查询语言 来支撑一个full  temporal relational algebra（完整所有关系型代数），通过用户自定义函数， aggregator 和算子来进行扩展。</p>
<p>StreamScope支持一套复杂的关系型算子包括 projection， filter， grouping和join 适配到所有语法。 举例来说， 一个inner join 适用于存在重叠时间窗口的事件。 window是另外一个重要概念。 一个window明确定义时间窗口和在这个窗口内的事件子集， 这样在这个子集上可以做aggregate。 StreamScope支持几种时间窗口，比如hopping／tumbling／snapshot 窗口。 例如， hopping window是按照固定大小H进行jump的窗口（大小为S）, 一个新的S大小的窗口会被创建每H 单位时间内。</p>
<p>Example.<br><img data-src="http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/aloha/aloha/6c58947d56e453105d3828b39a830e08/image.png" alt="image"></p>
<p>Figure 1 展示一个实例程序， 他执行连续分析行为在Process上并Alert 事件流。 一个StreamScope程序包含一系列在事件流上申明式查询操作。 Process 事件记录了每一个process并且关联用户，而Alert event记录了每一个alert的信息， 包括谁产生这个alert。 这个程序首先join 2个数据流并关联用户信息到alert，然后用一个hopping window计算每个用户 alert的数量每5秒钟 。</p>
<h1 id="StreamScope-抽象"><a href="#StreamScope-抽象" class="headerlink" title="StreamScope 抽象"></a>StreamScope 抽象</h1><p>StreamScope的程序执行可以用一个DAG 来表述， 每一个vertex 在输入数据流上进行本地计算并产生输出数据流。 每一个数据流描述为一个无限顺序的事件， 每个事件包含一个连续增加的sequence number（序列号）。</p>
<p><img data-src="http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/aloha/aloha/12ac8360628ba278f64cab4ab7f334b4/image.png" alt="image"></p>
<p>图2展示了图1的的DAG, 每一个stage的计算会被分区到多个节点上进行并行执行。StreamScope 根据数据量和计算复杂度来决定每个stage的并发程度。</p>
<p>一个节点可以维护一个本地状态。 它的执行从它最初的状态开始并逐步执行。 在每一步， 节点从它的输入源上中消费下一个事件， 更新状态，并可能产生新的事件到它的输出流。 这个节点的执行可以通过一系列的snapshot来跟踪， 每一个snapshot都是一个三元组，包含当前输入流的sequence numbers， 输出流的sequence numbers和它的当前状态。</p>
<p><img data-src="http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/aloha/aloha/6ca6b875f6804d884878a3d2163a3c0f/image.png" alt="image"></p>
<p>图3 展示了节点的处理过程， 从snapshot s0 到 s1 （处理了a1）， 然后到s2（处理了b1）. StreamScope 引入2个抽象 rStream 和rVertex 来实现流和节点。</p>
<h1 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h1><h2 id="rStream-概念"><a href="#rStream-概念" class="headerlink" title="rStream 概念"></a>rStream 概念</h2><p>不同于节点直接通过网络进行通信， StreamScope引入一个rStream抽象来解藕上下游的节点 通过一些属性来达到错误恢复。</p>
<p>rStream 包含一系列event，这些event包含连续并单调递增的sequence number， 支持多个writer和reader。 一个writer 调用Write(seq, e) 吧sequence number seq加到event中去。  rStream支持多个writer主要是为了允许同一个vertex的2个实例， 它会非常有用，当处理失败和重复执行中的stragglers。</p>
<p>一个reader可以调用Register(seq) 来显示他的感兴趣的event的起始sequence number seq，并开始通过ReadNext来读取数据，ReadNext 会返回下一个batch的带有sequence numbers的事件并调整读取偏移量。在实现中， event可以被push到一个注册的reader中，而不是被pull。 每一个reader可以异步处理events而不用和同个stream的气体readers或writers同步。一个reader同样可以rewind 一个stream通过重新register sequence number。 rStream 同样支持GarbageCollect(seq)来显示所有的小于seq的event不再需要并可以被丢弃。rStream 保留下面属性</p>
<ul>
<li>唯一性(Uniqueness), 每个sequence number是一个唯一值。 当第一个seq的写成功后， 任何后续的关联到seq的写操作都会被扔弃。</li>
<li>有效性（Validity）假设一个ReadNext 返回一个带seq的event， 那必然有一个成功的Write(seq, e)</li>
<li>可靠性(Reliability), 假设一个write(seq, e)成功了， 任何ReadNext 读取到seq 位置时，都会返回(seq, e)</li>
</ul>
<p>唯一性保证了每一个sequence number的一致性， 有效性保证每个sequence number的event value的正确性， 可靠性保证写到流的所有event 都是available。 rStream 可以通过一个带有后台存储的可靠的pub&#x2F;sub 系统来实现， 但StreamScope采用一个更高效的实现，避免时延变长因为在关键路径上把数据序序列化到存储上， 后面会介绍这个实现。</p>
<h2 id="实现rStream"><a href="#实现rStream" class="headerlink" title="实现rStream"></a>实现rStream</h2><p>rStream  抽象提供稳定的管道， 允许receiver 可以从任何指定位置进行read。 一个简单直接的实现是持久化和稳定的写数据到底层的Cosmos  分布式文件系统。 这些在关键路径上的同步写会带入显著的延迟。 StreamScope因此使用一个混合schema，将一些关键路径上的写操作移出单提供稳定可靠的channel的效果： event首先在内存中进行缓存起来，可以直接传输给消费方的节点。 内存中的buffer 会异步刷新到 Cosmos 来容错。 当错误发生时， 内存中的buffer会丢失，但当需要时，可以被重新计算。</p>
<p>为了在失败时，可以重新计算丢失的event， stream 跟踪每条消息的计算，类似TimeStream的依赖跟踪或D-Stream的血统跟踪， job manager跟踪节点的snapshots， 它可以用后来来通知如何重现event到输出流中。 一个节点自己决定什么时候获取snapshot， 保存并汇报给job manager。 举例来说，如图5，<br><img data-src="http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/aloha/aloha/7338ad5d3520095a76b9865e62798d11/image.png" alt="image"></p>
<p>节点v4 发送2个更新到job manager， 第一个更新汇报<code>snapshot s1=&#123;&lt;2, 7&gt;, &lt;12&gt;, t1&#125;</code>, 它表示这个节点这个秒时， 消费到2的event对第一个数据流，消费到7对第二个数据流， 并且在状态t1，产生event 12. 第二个update s2&#x3D;<code>&#123;&lt;5, 10&gt;, &lt;20&gt;, t2&#125;</code>, 它接受到5的event 在第一个数据流， 在第二个数据流到10， 当前状态为t2. 这种跟踪机制完全对用户透明。 如果输出流中的event 16需要被重新计算， job manager可以找到最大的output sequence number 小于16的snapshot， 这个例子中是s1. 这样他会启动一个新的节点， 加载snapshot s1, 然后持续计算直到产生event 16。这个新实例的执行需要第一个数据流的event 3到5， 第二个数据流的8到10， 这样有可能会触发上游节点重新计算，当这些event也是无法获取时。 当原始输入数据假设为可靠序列化时，这个过程最终会结束（指下游不断触发上游做重新计算，直到需要的原始数据已经持久化好，就不用再触发上游做重新计算）。总的来说， 这种设计移动flush 到可靠持久化存储的过程到关键路径外， 同时，减少需要重新计算的event的数量。 因为rStream 是无限的， 在一个真实的实现中， 垃圾收集是有必要删除失效的event和相关的tracking 信息（用来在错误发生时，重新生成event之用）</p>
<p><img data-src="http://aligitlab.oss-cn-hangzhou-zmf.aliyuncs.com/uploads/aloha/aloha/1736a2ece8c7db918c1556f23e23aa42/image.png" alt="image"></p>
<p>图6 展示了rStream 的实现方式。 在本例中， 只有一个writer W 和3个reader R1, R2, R3. 数据流不断增长从左到右。 stream的头（标记为GC）包含失效的event和可以被垃圾回收的event， 紧接着时一系列已经被可靠持久化的event， stream的尾部（最新的event） 是volatile， 当失败发生时，这些数据会丢失。 checkpoint可以定期创建（比如c1,c2, c3, c4, c5）, 当volatile 部分的stream 丢失时， it 可以从c4 snapshot开始做重新计算。 在可靠持久化部分的event可以提供给R1 R2而无序重新计算。 在可靠存储中还有部分数据直接重播。 没有更近一步的重叠重新计算需要重新恢复。</p>
<h2 id="垃圾回收"><a href="#垃圾回收" class="headerlink" title="垃圾回收"></a>垃圾回收</h2><p>StreamScope 持久化snapshot， StreamScope 和其他跟踪信息（用于恢复错误）， 并且需要确定什么时候开始进行垃圾回收。 StreamScope 为节点／StreamScope维护一个low－water－marks。 对于一个stream， 这个low-water-mark指向需要的最小event的sequence number。</p>
<p>对于每个节点， snapshot 根据它的输入流和输出流的sequence number来做完全排序。 举例来说， 假设一个节点有2个输入，1个输出， snapshot s 为<code>(&lt;7, 12&gt;, &lt;5&gt;)</code> 将会比比<code>(&lt;7, 20&gt;, &lt;8&gt;)</code>要小， 并且不存在<code>(&lt;6, 16&gt;, &lt;4&gt; )</code>这样的snapshot。</p>
<p>考虑一个节点v ， I 作为它的输入数据流， O 做为它的输出流。 节点v 维护一个low-water-marker sequence number lm0 为每个输出流， 初始化为0. 节点v实现GC(o, m)来实现垃圾回收， 显示所有小于m的sequence number的event将不再被下游vertex需要（下游vertex 消费输出流o）。 简单假设，每一个数据流只被一个下游节点消费， 但一般来说， 一个流经常被多个下游节点一起消费。</p>
<ul>
<li>假如 m &lt;&#x3D; lm0, 返回； ／／ 不需要进一步gc</li>
<li>设置lm0到m。 假设s是最新的checkpoint的snapshot， s必须满足条件， 在s中输出流o的sequence number并不高于lm0. 丢掉所有小于s的snapshot</li>
<li>对于每个输入的stream， 让vi 是上游节点，它产生输入流i 并且让si是对应s中输入流i的sequence number si， 调用vi GarbageCollect(si), 丢掉所有小于si的event在输入流i中， 递归调用vi GC(i, si)intuitive</li>
</ul>
<p>直觉来说， GC(o, m) 算出哪些信息将不再被下游节点需要， sequence number小于m。 当最重输出event被持久化或消费，或档任何输出的event被持久化。 图7 显示一个low-water-marks的例子。 尽管递归确定算法， 可以通过相反的拓扑遍历顺序来实现。</p>
<h2 id="rVertex-概念"><a href="#rVertex-概念" class="headerlink" title="rVertex 概念"></a>rVertex 概念</h2><p>rVertex 支持如下的操作<br>Load(s) 节点从snapshot s 开始一个实例。<br>Execute()  从当前snapshot 开始执行一步<br>GetSnapshot() 返回当前snapshot</p>
<p>一个节点可以以Load(s0) 开始， s0是起始状态并且所有的流以起始的position。 节点然后可以执行一系列的Execute(), Execute  会读取输入数据， 更新状态，产生新数据。任何时候， 节点可以调用GetSnapshot() 获取当前snapshot并保存它。 当节点失败时， 可以用Load(s)来restart。</p>
<p>确定性(Determinism). 对于一个确定输入流的节点来说， 运行 Execute() 在相同的snapshot上会产生相同的状态（snapshot）和相同的输出结果。</p>
<p>确定性保证了当从失败中进行重放event时，数据的准确性。 它也暗示了执行从不同输入stream获取的event的顺序是确定的； 第4章会介绍StreamScope是怎么做到顺序性而又不引入不必要的delay。 确定性极大保证正确性，并让应用更容易开发和调试。</p>
<h2 id="实现rVertex"><a href="#实现rVertex" class="headerlink" title="实现rVertex"></a>实现rVertex</h2><p>实现rVertex的关键是保障如section 3所述的确定性， 它要求function determinism和input determinism。 在StreamScope中， 所有的算子和用户自定义函数必须确定性的。 我们假设一个任务的输入stream是确定性的， event的顺序和值都是确定性的。 唯一的不确定性是穿过不同管道的event的顺序性。因为StreamScope使用CTI event做为标记， 我们插入一个特殊的MERGE 算子在一个接收多个输入的节点的起始位置， 这样可以生成一个确定性的顺序，为后序的操作。通过等待对应的CTI event 来露出并排序event，并按照确定性顺序来emit 它们。 因为， 节点的处理逻辑用相同方式等待CTI event,   这种方式并没有引入额外的dely。<br>StreamScope 对每个stream的event 以连续单调递增的方式进行打标sequence number。 一个节点可以用sequence number来从所有的流中定位最后的消费／产生 event。 在每个步骤， 一个节点消费输入流的一个event，比如调用Execute(),  它可能改变内部状态，产生新的event 到输出流中， 因此达到一个新的snapshot。 GetSnapshot() 返回当前snapshot， 他可以在一个步骤后暂停执行或者在不中断执行的情况，对一些copy－on－write的数据做一些拷贝动作，来保证一致性。Load(s)  启动一个节点并load s 作为当前snapshot在继续执行前。 为了可以从一个snapshot上可以进行断点恢复， 一个节点会定期做checkpoint。</p>
<h2 id="错误恢复"><a href="#错误恢复" class="headerlink" title="错误恢复"></a>错误恢复</h2><p>rStream 抽象解藕了上下游节点，从而允许单个节点从错误中恢复。当一个节点失败时， 可以简单重启节点通过Load(s) 从最近的保存的snapshot 开始执行。 rVertex 抽象表示恢复后的执行同没有错误发生时的执行结果是相同的。rStream抽象保证重启的节点可以reread 输入数据。 第4章介绍 如何实现rVertex和rStream. 不同的错误恢复策略来达到不同的tradeoff</p>
<h3 id="错误恢复策略"><a href="#错误恢复策略" class="headerlink" title="错误恢复策略"></a>错误恢复策略</h3><p>StreamScope 必须能够从错误中进行恢复。 rVertex 和rStream 抽象结果下游的节点， 从而很容易查找并恢复错误。 除此之外， 他们还抽象潜在的实现机制， 允许他们共享公共的机制来容错。</p>
<p>已经实现了集中错误恢复策略， 可以根据一些因子来做判断和选择， 普通情况开销(需要资源消耗)， 普通情况费用（指延迟）， 恢复成本（恢复资源）和恢复时间。</p>
<p>目前有3种策略， 对于rStream 和rVertex, 每个节点可以从错误中独立恢复出来。 因此，这些策略可以用在这些节点上甚至相同job上不同的节点使用不同的策略。</p>
<h3 id="基于checkpoint的恢复。"><a href="#基于checkpoint的恢复。" class="headerlink" title="基于checkpoint的恢复。"></a>基于checkpoint的恢复。</h3><p>节点会定期做checkpoint，把snapshot保存到持久化存储上。 当一个节点失败时， 他会加载最近的checkpoint 并继续执行。 checkpoint 的直接实现会引入正常执行的额外开销， 并且在维护一个大的state时并不是很理想。 高级的checkpoint技术会需要特定的数据结构，他们会引入复杂性和额外开销。</p>
<h3 id="基于重播机制的恢复。"><a href="#基于重播机制的恢复。" class="headerlink" title="基于重播机制的恢复。"></a>基于重播机制的恢复。</h3><p>常见的流计算是无状态或者因为使用window 算子儿拥有一个短期的内存。也就是说， 当前的内部状态依赖最新window的一些event。 这这鞋情况下， 节点可以抛开显示的checkoint，而采用重新加载那个window的event从而从一个起始状态开始rebuild 状态。 然而这是一种特殊情况， 很常见很有用。 利用这种属性， stream能够简单跟踪输入／输出流的sequence number而不用存储节点的本地状态。 这种策略有可能需要重新加载一个大的window， 但它避免checkpoint的一些开销。<br>这种策略有一个潜在暗示在垃圾回收机制。 不是从一个snapshot中加载一个状态， 一个节点必须recover从它输入的早起的event， 这些event必须可以获得。</p>
<h3 id="replication机制的recovery。"><a href="#replication机制的recovery。" class="headerlink" title="replication机制的recovery。"></a>replication机制的recovery。</h3><p>另外一种策略是对于相同的节点同时有多个instance。 他们连接到相同的输入流和输出流。 rStream 允许多个reader和writer， 自动根据sequence number进行去重。<br>rVertex的确定性属性让replication 方式可行， 因为这些instance 行为是一致性的。 通过replication， 一个节点可以有instance 轮流进行checkpoint而不会影响latency，因为其他的instance正以正常速度进行允许。 当一个instance fail， 它可以获得另外一个instance的当前snapshot，从而直接加速recovery。 这些好处都是来自于同时运行多个instance。</p>
<h1 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h1><h2 id="StreamScope-在现有的分布式流计算引擎上选择另外一种方式。"><a href="#StreamScope-在现有的分布式流计算引擎上选择另外一种方式。" class="headerlink" title="StreamScope 在现有的分布式流计算引擎上选择另外一种方式。"></a>StreamScope 在现有的分布式流计算引擎上选择另外一种方式。</h2><p>minibatch 的带RDD 的流处理。 不是支持连续的流模型， D-Streams 模型一个流计算为一系列minibatch的计算在一些小的时间间隔，并且利用immutable RDD 来做错误恢复。 将流计算拆解为一系列minibatch的方式会比较笨重， 因为一些流算子，比如windowing， join， aggregation， 维护状态到处理event 会高效一些。 拆分这些操作到独立的minibatch计算要求重建计算状态从前一个batch在处理当前batch event之前。 比如图1 的inner join。 这个join的算子需要track 所有的event， 这些event 有可能生成匹配结果从当前或将来batch 以高效的数据结构并且可以仅当接收到CTI event 时retie他们， 这种join状态是潜在复杂的join类型， 并且需要在每个batch或连续的mini－batch中进行重构。 更近一步， D-Streams 不考虑低延迟和容错性， 一个minibatch决定节点计算的粒度， 然而一个imuutable RDD, 主要为了错误恢复， 根据每个minibatch来创建。 这种低延迟要求小的small batch size甚至已经没有必要在那个粒度开启错误恢复。</p>
<h2 id="非确定性。"><a href="#非确定性。" class="headerlink" title="非确定性。"></a>非确定性。</h2><p>rVertex 要求确定性来保证正确性和容易debug。 非确定性容易引起不一致性当一个节点失败重新计算时。 非确定性有可能引起重新执行结果偏离起始的执行并导致一种情况， 下游节点使用2种不一致的输出event。 StreamScope 可以扩展去支持不一致性，但以一定代价。<br>一种方式来避免因为非确定导致的不一致性 是保证节点输出的任何event 不再需要重新计算。 这可以通过在让下游可见event之前，对它做checkpoint并持久化到存储中去。 这就是millwheel的本质。 这个设计会引入显著额外开销，因为在关键路径上的高昂checkpoint。 一种可选的方式是log 非确定性的决定当执行replay是。 log方式的开销会小于checkpoint方式， 但这种方式要求所有的非确定的来源必须被标记，适度log并重放。 StreamScope 并不支持这种实现方式。</p>
<h2 id="乱序event。"><a href="#乱序event。" class="headerlink" title="乱序event。"></a>乱序event。</h2><p>event可以不按它吗应用时间的顺序来到达， 比如event来自多个消息。 比如storm或millwheel 分配一个唯一的但非顺序性的id给每个event。 下游节点发送带这些id的acks给上游节点来跟踪状态和处理失败。 StreamScope 解藕 event的logical order 于物理发送或消费顺序。 它借用了流数据库中的CTI  理念 来达到乱序event处理在语言和算子层面。 在系统层面， StreamScope 分配唯一病情顺序性的sequence number给event， 从而轻松可以跟踪处理进程和错误恢复， 从而避免显著的acks而引起性能开销。</p>
<h1 id="生产经验"><a href="#生产经验" class="headerlink" title="生产经验"></a>生产经验</h1><ul>
<li>从batch到流， StreamScope 是batch处理系统的扩展，并且大量使用现有的组件。并且大量的批处理应用迁移到StreamScope上， 并且提供迁移支持， 允许batch version来验证流部分的正确性。</li>
<li>伸缩性和健壮性波动。 rStream 有效的保证了错误恢复时和扩容时，新节点能更上节奏。</li>
<li>简化分布式流计算。 声明式语言让业务方很容易些流应用。StreamScope 提供off-line模式，  有限的数据持久化到存储后， 可以模拟线上数据流， 并且对一个节点进行单独debug</li>
<li>回溯， 比如发生数据订正时， 就需要对数据进行回溯，修正之前的数据。  StreamScope会保留所有的checkpoints 和输入channel 到一个全局repository， 它实现了一定的保留策略。</li>
<li>当系统维护时不间断执行。其实就是利用rVetex的确定性，当部分节点需要升级维护时，会启动一个备份，当备份节点ready后， 会把停机维护的节点给杀掉。</li>
</ul>
]]></content>
      <categories>
        <category>BigData</category>
        <category>流计算</category>
      </categories>
      <tags>
        <tag>BigData</tag>
        <tag>Stream Process</tag>
        <tag>ScreamScope</tag>
      </tags>
  </entry>
  <entry>
    <title>《OceanBase开发者手册》之二 如何设置IDE开发环境</title>
    <url>/2021/set_ide/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>《OceanBase开发者手册》 主要指导开发者如何参与到OceanBase 的研发, 铺平参与OceanBase 开发的准备工作遇到的问题, 当前章节大概这几篇文章, 未来可能会增加部分文章, 目前OceanBase 源码参考OceanBase 开源官网的<a href="https://open.oceanbase.com/articles/8600129">《开源数据库OceanBase源码解读》 系列</a> :</p>
<ol>
<li>如何编译OceanBase源码</li>
<li>如何设置IDE开发环境</li>
<li>如何成为OceanBase Contributor</li>
<li>如何修改OceanBase文档</li>
<li>如何debug OceanBase</li>
<li>如何运行测试</li>
<li>如何修bug<br>​</li>
</ol>
<p>本文将介绍如何在开发环境中， 设置编译器， 重点设置编译器的 code format 工具 – clang-fromat。 本文内容来自内部同事分享, 该设置可以分享给所有的c&#x2F;c++ 项目中.  </b></p>
<p>clang-format是clang（一个面向C系语言的轻量级编译器）中一个工具，主要负责代码的格式化和排版工作，可独立于clang工作，所以经常被单独用来用作代码规范格式化，很多第三方插件也都集成了clang-fromat。clang-format与各个IDE集成. clang-format 差不多已经快成为c&#x2F;c++ 上实时的代码格式化标准. </p>
<span id="more"></span>
<p>​</p>
<h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><h1 id="vscode"><a href="#vscode" class="headerlink" title="vscode"></a>vscode</h1><p>既然看到这步了，我就姑且认为你已经装好了vscode，如果没有的话，可以先移步vscode官网下载</p>
<h2 id="STEP-1"><a href="#STEP-1" class="headerlink" title="STEP 1"></a>STEP 1</h2><p>首先确保你的开发环境下的vscode安装了C&#x2F;C++扩展;<br><img data-src="images/developer/vscode1.png"><br>这里要注意vscode远程和本地vscode插件不共用</p>
<h2 id="STEP-2"><a href="#STEP-2" class="headerlink" title="STEP 2"></a>STEP 2</h2><p>在setting中对Clang_format_style进行设置, 确认C&#x2F;C++扩展的配置Clang_format_style 设置成file （此处默认是file，如果不放心可以检查一下）;<br><img data-src="images/developer/vscode2.png"></p>
<h2 id="STEP-3"><a href="#STEP-3" class="headerlink" title="STEP 3"></a>STEP 3</h2><p>将准备好的<a href="https://raw.githubusercontent.com/oceanbase/oceanbase/master/.clang-format">.clang-format</a>文件拷贝到工程目录下（部分项目工程目录下已存在）</p>
<h2 id="STEP-FINAL"><a href="#STEP-FINAL" class="headerlink" title="STEP FINAL"></a>STEP FINAL</h2><p>恭喜你已经完成vscode 中clang format 设置， 如果前面都完成了的话，那么在vscode中格式化代码时就会自动根据.clang-format配置格式化文件</p>
<h1 id="eclipse"><a href="#eclipse" class="headerlink" title="eclipse"></a>eclipse</h1><h2 id="STEP-1-1"><a href="#STEP-1-1" class="headerlink" title="STEP 1:"></a>STEP 1:</h2><p>首先需要在你的开发环境下载clang-format   （此处后面推广的时候提供wget包下载或者其他更通用的方式）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$brew install clang-format</span><br></pre></td></tr></table></figure>
<p>或者可以下载整个LLVM然后在目录下找到clang-format, 记录下clang-format的路径. </b><br>Linux&#x2F;Mac环境下最好拷贝至&#x2F;usr&#x2F;bin目录下，方便直接命令执行.</p>
<p>当执行$OBDEV_ROOT&#x2F;build.sh –init 后， 会自动下载clang-format, 你可以在这里看到它</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find ./ -name clang-format</span><br><span class="line">./deps/3rd/usr/local/oceanbase/devtools/bin/clang-format</span><br></pre></td></tr></table></figure>

<h2 id="STEP-2-1"><a href="#STEP-2-1" class="headerlink" title="STEP 2:"></a>STEP 2:</h2><p>eclipse中安装插件CppStyle</p>
<img data-src="images/developer/eclipse1.png">

<h2 id="STEP-3-1"><a href="#STEP-3-1" class="headerlink" title="STEP 3:"></a>STEP 3:</h2><p>配置 CppStyle中clang-format的路径：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">（如果你CppStyle插件安装成功并重启的话，就会有这项配置）</span><br><span class="line">Preferences -&gt; C/C++ -&gt; CppStyle </span><br></pre></td></tr></table></figure>
<p>将之前下载的clang-format路径配置到Clang-format path中去</p>
<h2 id="STEP-4"><a href="#STEP-4" class="headerlink" title="STEP 4:"></a>STEP 4:</h2><p>配置 Code Formatter 为CppStyle：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Preferences -&gt; C/C++ -&gt; Code Style -&gt; Formatter</span><br></pre></td></tr></table></figure>
<p>将里面Code Formatter的配置选中下拉框选项 CppStyle(clang-format) （如果前面流程正确走完，此处应有此选项）</p>
<h2 id="STEP-5"><a href="#STEP-5" class="headerlink" title="STEP 5:"></a>STEP 5:</h2><p>将准备好的<a href="https://raw.githubusercontent.com/oceanbase/oceanbase/master/.clang-format">.clang-format</a>文件拷贝到工程目录下（部分项目工程目录下已存在）</p>
<h2 id="STEP-FINAL-1"><a href="#STEP-FINAL-1" class="headerlink" title="STEP FINAL:"></a>STEP FINAL:</h2><p>此时就完成了所有准备工作，在eclipse编写代码的时候，格式化代码的时候，就会自动引用.clang-format的配置重新编排代码</p>
<h1 id="CLion"><a href="#CLion" class="headerlink" title="CLion"></a>CLion</h1><p>啊，写攻略终于写到一个轻松的了，JetBrains YYDS！<br>CLion天然集成了clang-format，所以只需要确认几项配置即可</p>
<h2 id="STEP-1-2"><a href="#STEP-1-2" class="headerlink" title="STEP 1:"></a>STEP 1:</h2><p>随便打开某个.h&#x2F;.c&#x2F;.cpp文件，在右下角点击’4 spaces’ 然后选择Enable ClangFormat</p>
<img data-src="images/developer/clion.png">

<p>如果此处没有’4 spaces’，而是直接就是ClangFormat，那么就是CLion自动识别到存在.clang-format文件，帮忙配置好了</p>
<h2 id="STEP-2-2"><a href="#STEP-2-2" class="headerlink" title="STEP 2:"></a>STEP 2:</h2><p>确认’Enable ClangFormat’配置是否打开（这个CLion也是默认开启的）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Preferences -&gt; Editor -&gt; Code Style</span><br></pre></td></tr></table></figure>
<img data-src="images/developer/clion1.png">

<h2 id="STEP-3-2"><a href="#STEP-3-2" class="headerlink" title="STEP 3:"></a>STEP 3:</h2><p>将准备好的<a href="https://raw.githubusercontent.com/oceanbase/oceanbase/master/.clang-format">.clang-format</a>文件拷贝到工程目录下（部分项目工程目录下已存在）</p>
<h2 id="STEP-FINAL-2"><a href="#STEP-FINAL-2" class="headerlink" title="STEP FINAL:"></a>STEP FINAL:</h2><p>CLion就可以直接使用clang-format进行格式化了，当执行Reformat Code时就会自动编排代码</p>
<h1 id="VIM"><a href="#VIM" class="headerlink" title="VIM"></a>VIM</h1><h2 id="STEP-1-3"><a href="#STEP-1-3" class="headerlink" title="STEP 1:"></a>STEP 1:</h2><p>首先需要<a href="https://github.com/llvm/llvm-project/blob/llvmorg-12.0.1/clang/tools/clang-format/clang-format.py">clang-format.py</a>文件我们可以直接去github上面把对应文件拷贝下来;</p>
<h2 id="STEP-2-3"><a href="#STEP-2-3" class="headerlink" title="STEP 2:"></a>STEP 2:</h2><p>然后配置当前用户的.vimrc文件（如果没有的话，在当前用户的根目录下创建.vimrc文件即可）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">map &lt;C-K&gt; :pyf &lt;path-to-this-file&gt;/clang-format.py&lt;cr&gt;</span><br><span class="line">imap &lt;C-K&gt; &lt;c-o&gt;:pyf &lt;path-to-this-file&gt;/clang-format.py&lt;cr&gt;</span><br><span class="line"></span><br><span class="line">function! Formatonsave()</span><br><span class="line">  let l:formatdiff = 1</span><br><span class="line">  pyf &lt;path-to-this-file&gt;/clang-format.py</span><br><span class="line">endfunction</span><br><span class="line">autocmd BufWritePre *.h,*.cc,*.cpp call Formatonsave()</span><br></pre></td></tr></table></figure>
<p>代码块中的 ‘<path-to-this-file>‘ 替换成之前拷贝下来的clang-format.py的路径，然后保存并重启终端</p>
<p>PS：前面两行是增加主动触发clang-format功能</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">normal模式下，ctrl+k将格式化一行代码</span><br><span class="line">visual模式下，ctrl+k将格式化选中代码</span><br><span class="line">insert模式下，ctrl+k将格式化一行代码</span><br></pre></td></tr></table></figure>

<p>最后一段的function则是当使用vim保存当前.h&#x2F;.cc&#x2F;.cpp文件时，会自动将文件所有内容格式化</p>
<h2 id="STEP-3-3"><a href="#STEP-3-3" class="headerlink" title="STEP 3:"></a>STEP 3:</h2><p>将准备好的<a href="https://raw.githubusercontent.com/oceanbase/oceanbase/master/.clang-format">.clang-format</a>文件拷贝到工程目录下（部分项目工程目录下已存在）</p>
<h2 id="STEP-FINAL："><a href="#STEP-FINAL：" class="headerlink" title="STEP FINAL："></a>STEP FINAL：</h2><p>完成前面的工作，vim就成功集成了clang-format，只不过需要注意的是，使用的时候先需要cd到工程路径下，并确保工程路径下已有.clang-format文件，然后在该路径下，使用vim去修改文件即可（在使用vim时就不要切换当前目录啦）</p>
<h1 id="EMACS"><a href="#EMACS" class="headerlink" title="EMACS"></a>EMACS</h1><p>EMACS貌似很强大的一个编辑器（都不确定是否应该称之为编辑器），但是对新人来说学习成本略高，折腾了一个晚上才勉强搞定😅<br>如果看这一块的话，我就默认大家已经了解了emacs的一些基本操作，展开讲可以单开一个系列的语雀了，所以我这里只放出和clang-format集成相关的操作了，其他的不做过多讲解<br>STEP 1:<br>首先需要在你的开发环境下载clang-format   （此处后面推广的时候提供wget包下载或者其他更通用的方式）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">brew install clang-format</span><br></pre></td></tr></table></figure>
<p>或者可以下载整个LLVM然后在目录下找到clang-format<br>Linux环境下需要拷贝至&#x2F;usr&#x2F;bin目录下<br>MAC环境也需要配置到对应PATH路径中</p>
<p>当执行$OBDEV_ROOT&#x2F;build.sh –init 后， 会自动下载clang-format, 你可以在这里看到它</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">find ./ -name clang-format</span><br><span class="line">./deps/3rd/usr/local/oceanbase/devtools/bin/clang-format</span><br></pre></td></tr></table></figure>


<h2 id="STEP-2-4"><a href="#STEP-2-4" class="headerlink" title="STEP 2:"></a>STEP 2:</h2><p>然后需要使用package-install安装clang-format包，如果没有的话，可以修改package sources，这里展示一下我使用的sources配置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(&quot;melpa&quot; . &quot;http://mirrors.tuna.tsinghua.edu.cn/elpa/melpa/&quot;)</span><br><span class="line">(&quot;org-cn&quot; . &quot;http://mirrors.tuna.tsinghua.edu.cn/elpa/org/&quot;)</span><br><span class="line">(&quot;gnu&quot; . &quot;http://mirrors.tuna.tsinghua.edu.cn/elpa/gnu/&quot;)</span><br></pre></td></tr></table></figure>

<h2 id="STEP-3-4"><a href="#STEP-3-4" class="headerlink" title="STEP 3:"></a>STEP 3:</h2><p>安装完成后，找到安装的插件位置，我的是mac系统，安装位置在用户根目录下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.emacs.d/elpa/clang-format-20191106.950</span><br></pre></td></tr></table></figure>
<p>找到该路径下的clang-format.el文件，讲该文件的路径配置到.emacs配置文件中去（配置路径自行根据实际情况调整）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(load &quot;/Users/xxx/.emacs.d/elpa/clang-format-20191106.950/clang-format.el&quot;)</span><br></pre></td></tr></table></figure>
<p>PS：如果是mac系统的话比较麻烦，mac系统使用GUI打开emacs时，shell里面配置的环境变量是不会自动带过来的，这个时候需要在.emacs中额外配置一些内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(defun set-exec-path-from-shell-PATH ()</span><br><span class="line">  &quot;Set up Emacs&#x27; `exec-path&#x27; and PATH environment variable to match</span><br><span class="line">that used by the user&#x27;s shell.</span><br><span class="line"></span><br><span class="line">This is particularly useful under Mac OS X and macOS, where GUI</span><br><span class="line">apps are not started from a shell.&quot;</span><br><span class="line">  (interactive)</span><br><span class="line">  (let ((path-from-shell (replace-regexp-in-string</span><br><span class="line">        &quot;[ \t\n]*$&quot; &quot;&quot; (shell-command-to-string</span><br><span class="line">            &quot;$SHELL --login -c &#x27;echo $PATH&#x27;&quot;</span><br><span class="line">                ))))</span><br><span class="line">    (setenv &quot;PATH&quot; path-from-shell)</span><br><span class="line">    (setq exec-path (split-string path-from-shell path-separator))))</span><br><span class="line"></span><br><span class="line">(set-exec-path-from-shell-PATH)</span><br></pre></td></tr></table></figure>

<h2 id="STEP-4-1"><a href="#STEP-4-1" class="headerlink" title="STEP 4:"></a>STEP 4:</h2><p>将准备好的<a href="https://raw.githubusercontent.com/oceanbase/oceanbase/master/.clang-format">.clang-format</a>文件拷贝到工程目录下（部分项目工程目录下已存在）</p>
<h2 id="STEP-FINAL-3"><a href="#STEP-FINAL-3" class="headerlink" title="STEP FINAL:"></a>STEP FINAL:</h2><p>现在就已经完成了clang-format的集成工作，在开发中，只需要在文件编辑界面执行M-x clang-format-buffer 即可。此时clang-format会自动向本级及父级目录找到.clang-format文件，并根据文件配置格式化代码</p>
]]></content>
      <categories>
        <category>OceanBase</category>
      </categories>
      <tags>
        <tag>OceanBase</tag>
      </tags>
  </entry>
  <entry>
    <title>Snowflake 架构讨论 《The Snowflake Elastic Data Warehouse》</title>
    <url>/2020/snowflake/</url>
    <content><![CDATA[<h1 id="snowflake-随谈"><a href="#snowflake-随谈" class="headerlink" title="snowflake 随谈"></a>snowflake 随谈</h1><h1 id="随想"><a href="#随想" class="headerlink" title="随想"></a>随想</h1><p>今天，如果从事大数据或者OLAP 领域的朋友，都 应该仔细阅读一下snowflake 的论文。 snowflake 是前年看的， 但一直想写一篇介绍的读后感，一直没有下笔， 放在心中， 成为一个疙瘩， 终于在新年新气象的号召下， 终于把当初的阅读笔记找出， 梳理一遍， 列一下snowflake 中，很多有意思的东西。<br />论文原地址 ：<a href="https://www-conf.slac.stanford.edu/xldb2016/talks/published/Tues_7_Marcin_Z_XLDB-2016-05-24-release.pdf">The Snowflake Elastic Data Warehouse</a></p>
<h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>snowflake 的架构呈现出来时， 还是很让人眼前一亮， 这一套架构， 吸收了传统数据库mpp 的架构的优点， 有吸收了云上DLA 架构（serverless）的优势， 整体是一套对云计算非常友好的olap 系统。 这一套系统比传统大数据（hadoop系列&#x2F;emar） 要轻量高效， 比传统的mpp数据库（on-premise的云数据库）又要性价比高， 更便宜更灵活。 </p>
<p>整套系统是完全部署在云上， 所有的计算节点和service 都是购买虚拟机， 而存储是使用aws 的s3或微软的类s3的对象存储。 整套架构是share disk 的架构， 并且设计了一套都有cache机制，让整个计算层是无状态的， 所有有状态的东西存储到kvstore中， 而前端节点采用微服务， 保障系统的可靠性又让系统的成本最低化。  </p>
<img data-src="/img/snowflake.png" >
<span id="more"></span>

<h1 id="计算"><a href="#计算" class="headerlink" title="计算"></a>计算</h1><p>计算层有个query process pool， virtual warehouse 就是一个用户独享的cluster， 这个virtual warehouse 由几个ec2 来组成。 这个cluster 的规格就由用户购买规格来决定的， 用户购买规格类似购买t-shirt 一样， 就只有xxs –&gt; xxl 等几个规格， 用户不需要涉及多少个cpu&#x2F;内存&#x2F;本地存储等等一系列概念， 非常简单直接， 而且每种规格是以分钟计费。</p>
<p>当扩容后， 下一分钟后的新sql或者队列中的sql 就可以运行在扩容后virtual warehouse。</p>
<p>当没有query时， 可以将virtual house 进行自动挂起（不过计算单位还是分钟）， 当query 来时， 自动resume。 （这样的功能，更加证明）<br /><br><br />启动一个session时， 并没有绑定一个virtual warehouse， 直到一个virtual warehouse 绑定到一个session后， 这个session的所有sql才能到virtual warehouse上执行。 一个session只能绑定一个virtual warehouse， 但一个virtual warehouse可以绑定多个session， 甚至绑定一个user， 这样这个user的所有session自动绑定到这个virtual warehouse。  <br /><br><br />不同版本的virtual warehouse 可以使用相同的ec2， 因此可以共享cache。 <br /><br><br />未来snowflake， 可以进行share ec2. <br /><br><br />根据上面提供几点功能， 我对背后架构的一个解读。 </p>
<ol>
<li>能提供这么强的弹性， 第一种方式是类似hadoop 这种大集群架构（先表示对论文提到的virtual warehouse 是有ec2 来组成保持一点怀疑，因为大集群方式通常是成本最低的）， 部署一个超大的hadoop， 来了一个sql， 就分配一批docker 来为这个sql 进行服务， docker 隔离了 cpu和内存。 </li>
<li>第二种方式， 是以虚拟机为调度单元， 有请求时，将用户设定大小的虚拟机集群划给用户， 当没有请求时， 这些虚拟机分配给其他的用户。</li>
</ol>
<p> </p>
<p>从论文的描述来讲， 更倾向于第二种架构， 第一，在云上要保证足够的安全性和隔离性 使用虚拟机会更安全， 但一般来讲，虚拟机是无法达到如此高的灵活性。 但snowflake 做一些投机取巧的事情， 第一， 他是以分钟为单位进行计费， 1分钟足够将一个虚拟机划给另外一个客户。 第二，在数据库领域很少出现一分钟内没有任何请求的case， 很多bi 工具或客户段， 他们都会定时发送请求过来， 激活链接。  </p>
<p>在基于virtual warehouse由ec2来组成后， snowflake 有一个非常powerful的调度系统， 并且随时在系统中保留了几个hot的ec2， 随时让这几个ec2 扩容到需要扩容的virtual warehouse中。 并向前再推导一步， ec2 的规格应该非常少， 不会超过3种， 这样就能很方便的将一个ec2 从一个virtual warehouse 迁移到另外一个virtual warehouse。 <br /><br><br />另外， snowflake的优化器和执行器 提供一个很强的扩展性， 比如在1000个节点可以运行， 在10个节点也能运行， 只是时间被拉长。 这样印证了系统。 </p>
<p>snowflake 就支持xxs –&gt; xxl 这些规格， 这样就将主流用户把握住， 避免浪费精力在那种超级大客户上， 这种超级大客户（规模超过xxl）很多时候， 他们需要的是服务， 而不是产品，甚至比拼的是销售。 而且技术上要为这些超级大客户备机器也是一件拉高成本的糟糕事情。 </p>
<h1 id="存储"><a href="#存储" class="headerlink" title="存储"></a>存储</h1><ol>
<li>目前的设计， 每个virtual warehouse的cache 是不能共享。</li>
<li>每个ec2 都有一个本地存储， 当读取数据时，都是从s3 中将数据捞到本地存储中， 当写入数据时， 如果本地磁盘满，会将结果临时存储到s3上， 保障写通畅。 </li>
<li>每个ec2 上的cache 采用lru 算法。 当扩容时， 采用一致性hash， 如果数据已被cache住，就直接读取， 如果因为扩容， 数据在一致性hash后，飘到其他机器上， 没有关系，重新捞取数据，然后利用lru的自动淘汰算法，将老的数据全部淘汰换成新的。 </li>
<li>存储格式上， 使用了列村， 并且对列村进行压缩和优化过， 对用户不可见。 </li>
<li>每张表被分成大小不变的file （这样降低s3 的成本）， 将每个列的元数据信息存储公共的元数据服务里面。 </li>
<li>支持半结构化数据， json， avro 格式数据</li>
<li>支持acid – 事物， 号称支持snapshot isolation。 </li>
<li>支持回收站， 跨region backup， 支持clone。 （以来share disk 和cache 的无状态设计）</li>
<li>对热点文件做了一个优化， 使用了file stealing技术， 当一个peer 发现他的peer 节点还有文件没有读取， 改变文件的ownership 在当前query下， 这样这个peer帮助忙节点完成一些计算工作。 （这也是为什么s3 中文件都是固定大小）</li>
<li>没有事物引擎， 也没有buffer pool</li>
</ol>
<p>分析：<br />这种share disk和cache 的设计，让整个virtual warehouse 处在一个无状态的状态下，因此，调度器可以随时将一些ec2 切走。 另外， 因为定位的是olap系统，不是oltp系统， 对 请求的失败或时延没有那么高的要求。 </p>
<p>当数据写入时， 可以通道直接打通到virtual warehouse， 但作者没有介绍，如何解决故障问题， 比如当数据写入到s3 前，写入节点的ec2 发生故障， 怎么保障数据一致性。 因为数据是share disk架构， 并且系统没有做类似paxos 的3节点日志， 系统应该是通过提供一个事物来支持这种failover， 当写入s3 成功后，才返回事物成功。 <br /> </p>
<h1 id="优化器-执行引擎"><a href="#优化器-执行引擎" class="headerlink" title="优化器&amp; 执行引擎"></a>优化器&amp; 执行引擎</h1><ol>
<li>号称没有使用index （一种怀疑是全列存架构）</li>
<li>推迟执行， 减少optimizer的错误</li>
<li>持续收集query state， performance counter， detect node fail</li>
<li>执行引擎支持vectorize – simd – 也说明他们底层实现是c&#x2F;c++ 语言</li>
<li>做了大量的下推操作， </li>
<li>没有采用pruning 技术， 在oltp中，随机访问很场景， 因此使用b+ 树非常多， 但在s3中，并且大量使用压缩的情况下， pruning 很多时候没有什么效果，需要采用其他的技术， </li>
<li>min-max based pruning， 做区间判断是否可以跳过文件。 （比如join时， 在build table时，收集信息， 然后在probe时，可以跳过一个不匹配的文件）</li>
<li>small materialized aggregate</li>
<li>zone map</li>
<li>data skipping</li>
</ol>
<br />

<h1 id="common-service"><a href="#common-service" class="headerlink" title="common service"></a>common service</h1><ol>
<li>所有的service 是无状态的， 随时可以升级，扩容</li>
<li>hard state 存储到kv store中， kv store 也是通过mapping layer来访问， 使用metadata version， schema evolution， 保障向前兼容。</li>
<li>采用微服务的这种架构， 让系统扩展性非常好，并且节省了成本。</li>
</ol>
<p> </p>
<h1 id="半结构化数据"><a href="#半结构化数据" class="headerlink" title="半结构化数据"></a>半结构化数据</h1><p>可以将数据从json， avro， xml， load 到variant<br />variant 自描述， 压缩binary 序列化， 可以快速kv 查询， 高些test， hash 笔记， schema 可以自我进化。 </p>
<p>udf 支持javascript， udf 支持variant， 以后支持存储过程。 </p>
<p>impala 和dremel 都使用完整的table schema ，从而支持半结构化的data， snowflake 用了一种新的自动类型探测和列式存储。 </p>
<p>当存半结构化数据是， 对table file 进行statics 分析， 自动类型探测， 决定哪种type ， 然后对某些列从原始文档中删除，然后用相同格式和压缩方式进行单独存储， 这些列通过物化视图来访问。 </p>
<p>分析：<br />这一段吹的神乎其神， 应该是解决了某几个场景，但个人觉得对半结构化支持， 应该牺牲了性能来做。 <br />像论文里面提到一种方法flatten， 旋转nested document到多行， 用sql lateral view来展示flatten的操作。 </p>
<h1 id="mvcc"><a href="#mvcc" class="headerlink" title="mvcc"></a>mvcc</h1><ol>
<li>一个历史文件默认保留90天</li>
<li>有一个time travel， 读取一个历史版本 （timestamp xxx before）</li>
<li>回收站</li>
<li>clone， 不做物理clone， 只是metadata clone，做snapshot非常方便。  两个table 可以独立修改。</li>
</ol>
<p>  </p>
]]></content>
      <categories>
        <category>Database</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>OLAP</tag>
      </tags>
  </entry>
  <entry>
    <title>斯德哥尔摩一日游</title>
    <url>/2020/stockholm/</url>
    <content><![CDATA[<h1 id="题外话"><a href="#题外话" class="headerlink" title="题外话"></a>题外话</h1><p>这次北欧之行， 有一点安排不合理就是增加了斯德哥尔摩， 中间从挪威离开，没有直接去丹麦，而是在斯德哥尔摩呆了一天，让整个行程非常紧张， 本身每次换城市，都是在白天的黄金时间换，到酒店checkin基本上差不多2点了，而北欧的白天又特别短， 不到5点就天黑了，玩的时间太匆忙了。</p>
<p>斯德哥尔摩参观了几个不错的景点， 另外斯德哥尔摩有许多非常有意思的景点， 还是推荐更长的假期来慢慢游玩。</p>
<h1 id="市政厅"><a href="#市政厅" class="headerlink" title="市政厅"></a>市政厅</h1><p>我们正好赶上4点钟市政厅的导游， 导游给我们讲解了市政厅的许多故事和展览。</p>
<p>加一段介绍<br>建于1911年，历时12年才完成，是瑞典建筑中最重要的作品。建筑两边临水，一座巍然矗立着的塔楼，与沿水面展开的裙房形成强烈的对比，加之装饰性很强的纵向长条窗，整个建筑犹如一艘航行中的大船，宏伟壮丽。<br>800万块红砖砌成的外墙，在高低错落、虚实相谐中保持着北欧传统古典建筑的诗情画意。市政厅的右侧是一座高106米，带有3个镀金皇冠的尖塔，代表瑞典、丹麦、挪威三国人民的合作无间。据说登上塔顶部，可一览整个城市的风貌。</p>
<p>先来看一看外观<br><img data-src="/img/stockholm/hall.jpg" ></p>
<span id="more"></span>
<p>整个市政厅最辉煌的是golden hall， golden hall 是用来办舞会而建，大厅金碧辉煌，用真的金子贴上玻璃而装饰，大厅里带有瑞典历史文化色彩和信仰。 </p>
<p>lake queen, 瑞典神话中的女神，象征和平和幸福<br><img data-src="/img/stockholm/hall1.jpeg" ></p>
<p>瑞典男神和女神<br><img data-src="/img/stockholm/hall2.jpeg" ><br><img data-src="/img/stockholm/hall3.jpeg" ></p>
<p>遗留的人头<br><img data-src="/img/stockholm/hall4.jpeg" ></p>
<p>princess hall, 墙上的壁画是公主历史五年亲手一笔一笔画出来，每画一副都必须一气呵成，非常麻烦， 中间一个小插曲， 公主花1年多，已经完成了一版，但几幅画中，有2幅不是很满意，公主决定推倒重来，于是又花了好几年才完成所有壁画（大概4幅）</p>
<img data-src="/img/stockholm/hall5.jpeg" >
<img data-src="/img/stockholm/hall6.jpeg" >
<img data-src="/img/stockholm/hall7.jpeg" >

<p>其他还有一些厅就不介绍，比如blue hall， council room等。</p>
<h1 id="街拍"><a href="#街拍" class="headerlink" title="街拍"></a>街拍</h1><p>去的时候，瑞典皇宫已经关门了，很遗憾<br><img data-src="/img/stockholm/s.jpeg" ></p>
<p>诺贝尔展览馆也关门了<br><img data-src="/img/stockholm/s4.jpeg" ></p>
<p>一个不错的教堂<br><img data-src="/img/stockholm/s1.jpeg" ><br><img data-src="/img/stockholm/s3.jpeg" ></p>
<p> 街拍<br><img data-src="/img/stockholm/s2.jpeg" ></p>
]]></content>
      <categories>
        <category>travel</category>
      </categories>
      <tags>
        <tag>travel</tag>
      </tags>
  </entry>
  <entry>
    <title>DB性能测试-常用3套件-手把手一步一步跑sysbench</title>
    <url>/2020/sysbench/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>把过去的写的一篇笔记分享一下， 数据库最常用的测试三套件， sysbench – oltp 测试， tpch – olap 测试， tpcc – 事务性能测试。<br>本文手把手 一步一步 run sysbench</p>
<p>整个过程， 分为</p>
<ul>
<li>介绍</li>
<li>准备工作</li>
<li>编译</li>
<li>测试</li>
<li>疑难杂症<span id="more"></span></li>
</ul>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>下面引用老外的一段话来介绍一下sysbench</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sysbench is a scriptable multi-threaded benchmark tool based on LuaJIT. It is most frequently used for database benchmarks, but can also be used to create arbitrarily complex workloads that do not involve a database server.</span><br><span class="line"></span><br><span class="line">sysbench comes with the following bundled benchmarks:</span><br><span class="line"></span><br><span class="line">    * oltp_*.lua: a collection of OLTP-like database benchmarks</span><br><span class="line">    * fileio: a filesystem-level benchmark</span><br><span class="line">    * cpu: a simple CPU benchmark</span><br><span class="line">    * memory: a memory access benchmark</span><br><span class="line">    * threads: a thread-based scheduler benchmark</span><br><span class="line">    * mutex: a POSIX mutex benchmark</span><br></pre></td></tr></table></figure>
<p>今天我们最主要使用的oltp 系列测试</p>
<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><p>安装相应的包</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum -y install gcc gcc-c++ autoconf automake make libtool bzr mysql-devel git mysql</span><br><span class="line">yum -y install make automake libtool pkgconfig libaio-devel</span><br><span class="line">yum -y install openssl-devel</span><br></pre></td></tr></table></figure>

<p>执行如下命令配置Sysbench client，使内核可以使用所有的CPU核处理数据包（默认设置为使用2个核），同时减少CPU核之间的上下文切换。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo sh -c &#x27;for x in /sys/class/net/eth0/queues/rx-*; do echo ffffffff&gt;$x/rps_cpus; done&#x27;</span><br><span class="line">sudo sh -c &quot;echo 32768 &gt; /proc/sys/net/core/rps_sock_flow_entries&quot;</span><br><span class="line">sudo sh -c &quot;echo 4096 &gt; /sys/class/net/eth0/queues/rx-0/rps_flow_cnt&quot;</span><br><span class="line">sudo sh -c &quot;echo 4096 &gt; /sys/class/net/eth0/queues/rx-1/rps_flow_cnt&quot;</span><br></pre></td></tr></table></figure>
<p>备注： 说明 ffffffff表示使用32个核。请根据实际配置修改，例如ECS为8核，则输入ff。</p>
<h1 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h1><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/akopytov/sysbench.git</span><br><span class="line">##从Git中下载sysbench</span><br><span class="line"></span><br><span class="line">cd sysbench</span><br><span class="line">##打开sysbench目录</span><br><span class="line"></span><br><span class="line">git checkout 1.0.18</span><br><span class="line">##切换到sysbench 1.0.18版本， 也可以不用切换到1.0.18 版本上，直接使用master</span><br><span class="line"></span><br><span class="line">./autogen.sh</span><br><span class="line">##运行autogen.sh</span><br><span class="line"></span><br><span class="line">./configure --prefix=/usr --mandir=/usr/share/man</span><br><span class="line"></span><br><span class="line">make</span><br><span class="line">##编译</span><br><span class="line"></span><br><span class="line">make install</span><br></pre></td></tr></table></figure>

<h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1><p>sysbench 的测试 通常类似这样,  分为3个阶段， 一个prepare， 一个run， 一个cleanup</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600  oltp_write_only prepare</span><br><span class="line">##准备数据</span><br><span class="line"></span><br><span class="line">sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600   --threads=XXX --percentile=95 --report-interval=1 oltp_write_only run</span><br><span class="line">##运行workload</span><br><span class="line"></span><br><span class="line">sysbench --db-driver=mysql --mysql-host=XXX --mysql-port=XXX --mysql-user=XXX --mysql-password=XXX --mysql-db=sbtest --table_size=25000 --tables=250 --events=0 --time=600   --threads=XXX --percentile=95  oltp_write_only cleanup</span><br><span class="line">##清理</span><br></pre></td></tr></table></figure>
<p>命令解释</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--mysql-host       IP</span><br><span class="line">--mysql-port       端口号</span><br><span class="line">--mysql-db         希望链接的数据库</span><br><span class="line">--mysql-user       用户名</span><br><span class="line">--mysql-password   密码</span><br><span class="line">--table_size       每张表初始化的数据数量</span><br><span class="line">--tables           初始化表的数量</span><br><span class="line">--threads          启动的线程</span><br><span class="line">--time             运行时间设为0表示不限制时间</span><br><span class="line">--report-interval  运行期间日志，单位为秒</span><br><span class="line">--events           最大请求数量，定义数量后可以不需要--time选项</span><br><span class="line">--rand-type        访问数据时使用的随机生成函数 可以选择&quot;special&quot;， &quot;uniform&quot;， &quot;gaussian&quot;， &quot;pareto&quot;， 默认special， 早期时uniform</span><br><span class="line">--skip_trx=on      在只读测试中可以选择打开或关闭事务， 默认是打开</span><br></pre></td></tr></table></figure>


<p>作者写了一个自动测试的脚本， 读者可以从<a href="https://github.com/longdafeng/test/tree/master/shell/sysbench">https://github.com/longdafeng/test/tree/master/shell/sysbench</a>  将脚本下载下来<br>记得将 脚本放到 sysbench 源码目录下src&#x2F;lua 下面</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd sysbench</span><br><span class="line">cd src/lua</span><br><span class="line">wget https://raw.githubusercontent.com/longdafeng/test/master/shell/sysbench/start-sysbench.sh </span><br><span class="line">wget https://raw.githubusercontent.com/longdafeng/test/master/shell/sysbench/start.sh</span><br><span class="line">nohup ./start.sh hostxxx portxxx userxxx passwordxxx dbxxx &gt; run.log 2&gt;&amp;1 &amp;</span><br><span class="line">tail -f run.log</span><br></pre></td></tr></table></figure>
<p>其中hostxxx, portxxx, userxxx, passwordxxx, dbxxx 修改为真实mysql的参数<br>这个脚本， 是设置不同大表大小， 设置不同随机参数， 设置不同的线程数， 设置是否打开或关闭事务， 依次运行oltp_read_only, oltp_write_only, oltp_read_write 3个集成测试，<br>在src&#x2F;lua 目录下， 还有很多单项测试, 比如insert, point_select, update_index, update_non_index, select_random_points, select_random_ranges 分别是针对不同的场景的测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@kudu lua]# ls *.lua</span><br><span class="line">bulk_insert.lua  oltp_common.lua  oltp_insert.lua        oltp_read_only.lua   oltp_update_index.lua      oltp_write_only.lua  select_random_points.lua</span><br><span class="line">empty-test.lua   oltp_delete.lua  oltp_point_select.lua  oltp_read_write.lua  oltp_update_non_index.lua  prime-test.lua       select_random_ranges.lua</span><br></pre></td></tr></table></figure>




<h1 id="疑难杂症"><a href="#疑难杂症" class="headerlink" title="疑难杂症"></a>疑难杂症</h1><h2 id="性能差"><a href="#性能差" class="headerlink" title="性能差"></a>性能差</h2><p>sysbench 是对cpu&#x2F;memory&#x2F;网络非常敏感的测试， 经常遇到 很多客户在测试的过程中，发现性能和预期的差距比较大， 深究后，发现， sysbench的肉机（客户端） 和目标测试数据不在同一个局域网或者一个vpc 内（云上客户）， 对于很多云数据库， 肉机和目标mysql 必须在同一个region， 并且是在同一个vpc， 并且在链接字符串的时候，必须使用私有的链接地址，不能使用公网的链接地址， 公网的链接地址会经过很多跳。</p>
<p>假设语句是：<br>sysbench oltp_read_write.lua –mysql-host&#x3D;127.0.0.1 –mysql-port&#x3D;3306 –mysql-db&#x3D;sbtest –mysql-user&#x3D;root –mysql-password&#x3D;123456 –table_size&#x3D;200000000 –tables&#x3D;1 –threads&#x3D;500 –events&#x3D;500000 –report-interval&#x3D;10 –time&#x3D;0</p>
<h2 id="no-such-built-in-test-file-or-module"><a href="#no-such-built-in-test-file-or-module" class="headerlink" title="no such built-in test, file or module"></a>no such built-in test, file or module</h2><p>如果执行的时候提示FATAL: Cannot find benchmark ‘oltp_read_write.lua’: no such built-in test, file or module</p>
<p>切换到sysbench的源码目录（sysbench.tar.gz解压路径）<br>find .&#x2F; -name oltp_read_write.lua<br>.&#x2F;src&#x2F;lua&#x2F;oltp_read_write.lua<br>接着切换到src&#x2F;lua 目录再执行语句</p>
<h2 id="“Can-not-connect-to-MySQL-server-Too-many-connections”"><a href="#“Can-not-connect-to-MySQL-server-Too-many-connections”" class="headerlink" title="“Can not connect to MySQL server. Too many connections”"></a>“Can not connect to MySQL server. Too many connections”</h2><p>#如果执行的时候命令行提示“Can not connect to MySQL server. Too many connections”-mysql 1040错误：<br>shell&gt;mysql -uroot -p****<br>mysql&gt;show variables like ‘max_connections’;(查看当前的最大连接数)<br>mysql&gt;set global max_connections&#x3D;1000;(设置最大连接数为1000，可以再次查看是否设置成功)<br>mysql&gt;show variables like ‘max_connections’;(查看当前的最大连接数)<br>mysql&gt;exit</p>
<h2 id="sysbench-无法运行"><a href="#sysbench-无法运行" class="headerlink" title="sysbench 无法运行"></a>sysbench 无法运行</h2> <figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ldd /usr/bin/sysbench</span><br></pre></td></tr></table></figure>
<p>正常情况下， sysbench 依赖的所有library 应该都可以resolve 掉， 如果有的时候，没有找到依赖的library， 最常见的是没有找到mysql的library<br>需要安装</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum -y install mysql-devel mysql</span><br></pre></td></tr></table></figure>
<p>然后再重新编译sysben的源码</p>
<p>如果问题依旧存在<br>可以尝试， 手动创建连接</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">去根目录找一下：</span><br><span class="line">find / -name &quot;*mysqlclient_r*&quot;</span><br><span class="line">/usr/lib64/mysql/libmysqlclient_r.so.18</span><br><span class="line">/usr/lib64/mysql/libmysqlclient_r.so.18.1.0</span><br><span class="line">库文件是有的，不过带个数字后缀，给库文件建立软链接：</span><br><span class="line">ln -s /usr/lib64/mysql/libmysqlclient_r.so.18 /usr/lib64/mysql/libmysqlclient_r.so</span><br></pre></td></tr></table></figure>

<p>如果问题还是不能解决， 最后的办法就是从github 上下载mysql的源码， 先对mysql 源码进行编译，安装，然后再重新编译sysbench</p>
<pre><code># --with-mysql-includes选项指定mysql的include文件夹，里面是一些.h的头文件，比如mysql.h，未安装mysql-community-devel-version是没有include文件夹的
# with-mysql-libs选项指定mysql的一些lib，里面是一些.a文件和.so文件，比如libmysqlclient.a，libmysqlclient.so
# 比如./configure --prefix=/usr   --with-mysql-includes=/usr/include/mysql --with-mysql-libs=/usr/lib64/mysql
</code></pre>
]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>Tesla 行驶中突然失去动力</title>
    <url>/2022/tesla-is-bullshit/</url>
    <content><![CDATA[<h1 id="随谈"><a href="#随谈" class="headerlink" title="随谈"></a>随谈</h1><p>从这次开车开车过程中, 车子突然失去动力后, 坦白讲, 我从一位Tesla 粉开始转黑. 过去4年一直推荐朋友买Tesla, 我现在只会建议, 大家还是买老牌的油车, 不要选择一个以互联网方式做事的车企. </p>
<p>Tesla 太激进了, 一直将用户当作小白鼠来实验, 从Tesla 系统的升级策略上来讲, 基本上一个月一次, 这么高的频率, 试问怎么可能会做大量充分的测试呢. 而且, 过去很多事实(1. 在中国偷工减料; 2. 私传数据; 3. 刹车门事件)已经证明, Tesla 只是对中国消费者身上如何获得利润, 而不是如何更好的服务. </p>
<img data-src="/assets/tesla-stop.jpg" >

<span id="more"></span>

<h1 id="经过"><a href="#经过" class="headerlink" title="经过"></a>经过</h1><p>即使Tesla 对我赔偿, 我根本也不care, 只是国内太多的Tesla粉, 觉得这个事情太傻了. 我先陈述一下事实,  事情经过是:</p>
<ol>
<li>2022年2月26日早上9点半，在路上正常行驶，拿手机过程中可能碰了一下换挡拨片，不知道切到了哪个档位，一下子屏幕出现报警，平时白色字显示的档位，全部变成红色，屏幕不停提示“前电机禁用” 过一会儿出现“路边安全停车”，此时车子完全失去动力.  (以前也出现过, 行驶中无意中触碰换挡拨片, 但都是只告警一后, 处理一下就恢复正常)</li>
<li>此时, 无论怎么切换档位，踩油门或者刹车都不行，就依靠车子惯性路边停车。 还好这个时候, 不是在高速上, 在一个流量不大的行驶道上, 否则不堪设想. </li>
<li>停车后，操作启动，换挡，加油，开门，关门 都无法启动车子，车子始终显示“前电机禁用” ，平时白色字显示的档位全部红色加粗显示。</li>
<li>强制重启特斯拉，花了很久（比平时关机时间长）才关机成功，重启也花了很久（也比平时重启的时间长，期间屏幕一直黑，估计后台自检程序检测不过），屏幕亮后，和重启前一样，屏幕显示“前电机禁用”，平时白色字显示的档位全部红色加粗显示，操作启动，换挡，加油，刹车，开门关门，各种操作无法启动车子。</li>
<li>最神奇的事情来了, 打电话给400特斯拉客服，告知安排拖车过来，人下车注意安全，下车后，过了15分钟左右，再上车发现一切恢复正常了，可以正常启动和操作，此时拖车公司电话过来，就取消了拖车. 事后, 和Tesla 维修人员沟通才了解, Tesla 自带一块手机卡, 非用户实名注册的手机卡, 可以直接将数据直接传输到Tesla 服务中心. </li>
<li>400特斯拉客服电话过来，我要求解释为什么行驶中突然失去动力？客服一堆官方各种推脱, 后来客户看实在是回答不下去了, 答应半小时给一个回复. </li>
<li>过了3小时，一直没有收到Tesla答复, 直到再次电话400特斯拉客服，客服才安排第二天送到4s店对电机进行检修。</li>
<li>再一次神奇的事情发生了,  Tesla 检修完, 给出一个官方的答复是 “数据量太大, 数据网关处理不过来, 发生故障”. 也就是这个时候, Tesla工作人员解释了这件事情, Tesla 会在后台收集数据, 然后上传到Tesla 数据中心, 数据量太大, 程序响应不过来, 现在, 已经讲固件重新格式化, 重新安装最新版本. <img data-src="/assets/tesla_fix.jpg" ></li>
</ol>
<h1 id="反思"><a href="#反思" class="headerlink" title="反思"></a>反思</h1><p>以前, 以为Tesla 在美国已经跑了很多年, 应该是非常成熟的技术, 而且用户量也非常大, 现在想想, Tesla 还是太激进了, 而且百度一下 “tesla 失去动力”, 搜出一大堆问题, 这种事情, 个人推测tesla 为了更快的迭代速度, 根本没有做足够多的测试, 就把产品放到用户身上进行测试.<br>另外一点也一直想不通, tesla的自动驾驶, 居然还要花钱去买, 这种完全把用户当小白鼠来进行测试的一个不成熟的产品, 还要用户花 2万 ~ 8万, 将性命交给一个自动驾驶level 仅仅为2级的系统, 就算免费给我使用, 我都不会使用, 而且还有各种宣传各种开车睡觉的视频, 这种草菅人命的营销, 纯属误导消费者的行为, 希望国家或有关单位能勒令禁止. </p>
]]></content>
      <categories>
        <category>杂谈</category>
      </categories>
      <tags>
        <tag>Tesla失去动力</tag>
        <tag>前电机禁用</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>/2024/test-no-front-mat/</url>
    <content><![CDATA[<p>test for long time</p>
<p>last</p>
<p>中文:<br>a:</p>
<ul>
<li>first</li>
<li>second</li>
<li>third</li>
</ul>
]]></content>
  </entry>
  <entry>
    <title>DB性能测试-常用3套件-手把手一步一步跑tpcc</title>
    <url>/2020/tpcc/</url>
    <content><![CDATA[<h1 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h1><p>把过去的写的一篇笔记分享一下， 数据库最常用的测试三套件， sysbench – oltp 测试， tpch – olap 测试， tpcc – 事务性能测试。<br>本文手把手 一步一步 run tpcc</p>
<p>整个过程， 分为</p>
<ul>
<li>介绍</li>
<li>准备工作</li>
<li>编译</li>
<li>测试</li>
<li>疑难杂症<span id="more"></span></li>
</ul>
<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p><a href="http://www.tpc.org/tpcc/">http://www.tpc.org/tpcc/</a><br>TPCC有不同的运行方式，用来测试数据库的压力工具，模拟一个电商的业务，主要的业务有新增订单，库存查询，发货，支付等模块的测试。 详情可以参考 <a href="https://github.com/domino-succ/tpcc-hbase/wiki/%E4%B8%AD%E6%96%87-TPC-C%E7%AE%80%E4%BB%8B">https://github.com/domino-succ/tpcc-hbase/wiki/中文-TPC-C简介</a></p>
<h2 id="模型简介"><a href="#模型简介" class="headerlink" title="模型简介"></a>模型简介</h2><p>在测试开始前，TPC-C Benchmark规定了数据库的初始状态，也就是数据库中数据生成的规则，其中ITEM表中固定包含10万种商品，仓库的数量可进行调整，假设WAREHOUSE表中有W条记录，那么：</p>
<ul>
<li>STOCK表中应有W×10万条记录(每个仓库对应10万种商品的库存数据)；</li>
<li>DISTRICT表中应有W×10条记录(每个仓库为10个地区提供服务)；</li>
<li>CUSTOMER表中应有W×10×3000条记录(每个地区有3000个客户)；</li>
<li>HISTORY表中应有W×10×3000条记录(每个客户一条交易历史)；</li>
<li>ORDER表中应有W×10×3000条记录(每个地区3000个订单)，并且最后生成的900个订单被添加到NEW-ORDER表中，每个订单随机生成5~15条ORDER-LINE记录。</li>
</ul>
<p>在测试过程中，每一个地区（DISTRICT）都有一个对应的终端（Terminal），模拟为用户提供服务。在每个终端的生命周期内，要循环往复地执行各类事务，每个事务的流程如图所示，当终端执行完一个事务的周期后，就进入下一个事务的周期，如下图所示。<br><img data-src="/img/tpcc.png" ></p>
<p>客户下单后，包含若干个订单明细（ORDER-LINE）的订单（ORDER）被生成，并被加入新订单（NEW-ORDER）列表。<br>客户对订单支付还会产生交易历史（HISTORY）。<br>每个订单(ORDER) 平均包含10条订单项(ORDER-LINE), 其中1% 需要从远程仓库中获取.<br>这些就是TPC-C模型中的9个数据表。其中，仓库的数量W可以根据系统的实际情况进行调整，以使系统性能测试结果达到最佳。</p>
<h2 id="Metrics"><a href="#Metrics" class="headerlink" title="Metrics"></a>Metrics</h2><p>TPCC用tpmC值（Transactions per Minute）来衡量系统最大有效吞吐量. 其中Transactions以NewOrder Transaction为准，即最终衡量单位为每分钟处理的订单数。</p>
<h2 id="事务类型"><a href="#事务类型" class="headerlink" title="事务类型"></a>事务类型</h2><p>该benchmark包含5类事务</p>
<ul>
<li>NewOrder: 新订单的生成从某一仓库随机选取5-15件商品, 创建新订单. 其中1%的事务需要回滚(即err).  一般来说新订单请求不可能超出全部事务请求的45% |</li>
<li>Payment : 订单付款更新客户账户余额, 反映其支付情况. 占比 43% </li>
<li>OrderStatus : 最近订单查询 随机显示一个用户显示其最有益条订单, 显示该订单内的每个商品状态. 占比4% </li>
<li>Delivery  : 配送, 模拟批处理交易更新该订单用户的余额, 把发货单从neworder中删除. 占比4% </li>
<li>StockLevel  : 库存缺货状态分析 , 占比4%</li>
</ul>
<h2 id="要求"><a href="#要求" class="headerlink" title="要求"></a>要求</h2><p>然后，终端模拟用户输入事务所需的参数，并等待一个输入时间（Keying Time）；等待结束后，事务执行正式开始，执行结束后记录事务的实际执行时间（txnRT），TPC-C对每类事务的执行时间都有一个最低要求，分别是：</p>
<ul>
<li>至少90%的NewOrder事务执行时间要低于5秒，</li>
<li>至少90%的Payment事务执行时间要低于5秒，</li>
<li>至少90%的OrderStatus事务执行时间要低于5秒，</li>
<li>至少90%的Payment事务执行时间要低于5秒，</li>
<li>至少90%的StockLevel事务执行时间要低于20秒；</li>
</ul>
<p>最后，终端模拟用户对结果的查看以及思考，等待一个思考时间（Thinking Time）；在思考时间结束后，进入下一个事务周期。 在整个测试过程结束后，用处理过的新订单事务总数量除以整个测试运行的分钟数并取整，就得到了tpmC的值。</p>
<h1 id="测试工具调研"><a href="#测试工具调研" class="headerlink" title="测试工具调研"></a>测试工具调研</h1><p>TPC-C测试常用的测试工具包括tpcc-mysql，benchmark-sql，Hammer DB，DBT2，sqlbench。这些工具对TPC-C标准的支持程度不尽相同。经过调研发现从DBT2改进来的开源的sqlbench工具是最接近标准要求的测试工具。因此我们首先对比不同工具对标准的支持情况，然后介绍使用sqlbench进行TPC-C测试的步骤。</p>
<h2 id="tpcc-mysql简介"><a href="#tpcc-mysql简介" class="headerlink" title="tpcc-mysql简介"></a>tpcc-mysql简介</h2><p><a href="https://github.com/Percona-Lab/tpcc-mysql">TPCC-MYSQL</a> 是percona基于TPC-C(下面简写成TPCC)衍生出来的产品，专用于MySQL基准测试。用来测试数据库的压力工具，模拟一个电商的业务，主要的业务有新增订单，库存查询，发货，支付等模块的测试。使用说明明文档（<a href="https://www.percona.com/blog/2013/07/01/tpcc-mysql-simple-usage-steps-and-how-to-build-graphs-with-gnuplot/%EF%BC%89%E3%80%82">https://www.percona.com/blog/2013/07/01/tpcc-mysql-simple-usage-steps-and-how-to-build-graphs-with-gnuplot/）。</a></p>
<h2 id="benchmark-sql简介"><a href="#benchmark-sql简介" class="headerlink" title="benchmark-sql简介"></a>benchmark-sql简介</h2><p><a href="https://sourceforge.net/projects/benchmarksql/">benchmark-sql</a>是java语言实现TPCC工具，使用JDBC接口，支持Oracle、PostgreSQL、firebird和MySQL。</p>
<h2 id="HammerDB简介"><a href="#HammerDB简介" class="headerlink" title="HammerDB简介"></a>HammerDB简介</h2><p><a href="http://www.hammerdb.com/document.html">HammerDB</a>是Tcl语言实现TPCC&#x2F;TPCH工具，使用存储过程和Tcl包，支持Oracle、SQL Server、DB2、MySQL、PostgreSQL、Redis、Trafodion。支持Windows图形界面以及Tcl脚本脚本，功能比较完善。</p>
<h2 id="DBT2简介"><a href="#DBT2简介" class="headerlink" title="DBT2简介"></a>DBT2简介</h2><p><a href="http://osdldbt.sourceforge.net/">Databases Test 2</a>是由Open Source Development Lab开发的用于测试数据库性能的测试工具，虽然没有完全实现TPCC但是基本上也是模拟了OLTP的应用场景的，测试结果包括每秒处理的事务数、CPU使用率、IO以及内存的使用情况</p>
<h2 id="sqlbench简介"><a href="#sqlbench简介" class="headerlink" title="sqlbench简介"></a>sqlbench简介</h2><p><a href="https://github.com/swida/sqlbench">sqlbench</a>源自DBT2，作者阿里巴巴 荣生(diancheng.wdc)。原来的DBT2把整个测试过程分成client和 driver 两个应用程序，每个terminal需要 2个线程。如果测试的warehouse较多需要占用机器大量资源。而sqlbench对这方面做了优化，合并了这两个应用程序，同时优 化了线程的使用，使用1个线程处理多个terminal，大大减少了机器资源的使用。使一台机器可以运行更多的warehouse。另外 DBT2外部依赖较多，如对R环境的依赖，sqlbench去掉了不必要的外部依赖，目前sqlbench只依赖测试数据库的客户端库。</p>
<h2 id="数据库支持"><a href="#数据库支持" class="headerlink" title="数据库支持"></a>数据库支持</h2><table>
<thead>
<tr>
<th>sqlbench</th>
<th>MySQL, PostgreSQL</th>
</tr>
</thead>
<tbody><tr>
<td>tpcc-mysql</td>
<td>MySQL</td>
</tr>
<tr>
<td>benchmark-sql</td>
<td>PostgreSQL, EnterpriseDB and Oracle, MySQL</td>
</tr>
<tr>
<td>HammerDB</td>
<td>Oracle Database, SQL Server, IBM Db2, MySQL, MariaDB, PostgreSQL and Redis</td>
</tr>
<tr>
<td>DBT2</td>
<td>MySQL, PostgreSQL</td>
</tr>
</tbody></table>
<h2 id="对sql执行方式的支持"><a href="#对sql执行方式的支持" class="headerlink" title="对sql执行方式的支持"></a>对sql执行方式的支持</h2><table>
<thead>
<tr>
<th>sqlbench</th>
<th>plain SQL，prepared statement，stored procedure</th>
</tr>
</thead>
<tbody><tr>
<td>tpcc-mysql</td>
<td>Prepared statement</td>
</tr>
<tr>
<td>benchmarksql</td>
<td>Prepared statement</td>
</tr>
<tr>
<td>HammerDB</td>
<td>Stored Procedure</td>
</tr>
<tr>
<td>DBT2</td>
<td>Plain SQL，prepared statement，stored procedure</td>
</tr>
</tbody></table>
<h2 id="对key-in-time和think-time的支持"><a href="#对key-in-time和think-time的支持" class="headerlink" title="对key-in time和think time的支持"></a>对key-in time和think time的支持</h2><p>TPC-C标准规定了每一中交易中的模拟用户输入和对输出结果的思考时间，这使得同一个terminal发起的SQL事务是非常低频率的操作。TPC-C标准通过这两个延迟时间限制了同一个terminal在给定的时间内能完成的交易数量，与此同时标准规定用一时间最多只有10个terminals访问同一个warehouse。经过计算1个warehouse能提供的最多TpmC为12.86。</p>
<table>
<thead>
<tr>
<th>sqlbench</th>
<th>YES</th>
</tr>
</thead>
<tbody><tr>
<td>tpcc-mysql</td>
<td>NO</td>
</tr>
<tr>
<td>benchmark-sql</td>
<td>NO</td>
</tr>
<tr>
<td>HammerDB</td>
<td>NO</td>
</tr>
<tr>
<td>DBT2</td>
<td>YES</td>
</tr>
</tbody></table>
<h2 id="对terminal和database-connection的解耦"><a href="#对terminal和database-connection的解耦" class="headerlink" title="对terminal和database connection的解耦"></a>对terminal和database connection的解耦</h2><p>TPC-C规定了terminal到事务处理引擎中间必须通过网络连接，但是这里所列出的所有工具都不支持这种架构。DBT2和sqlbench虽然不支持这种三层结构，但是支持terminal处理和DB连接用不同的线程分开，其他几个工具没有terminal的概念，直接通过db connection thread完成交易。</p>
<p><img data-src="https://intranetproxy.alipay.com/skylark/lark/0/2019/png/105349/1573401426816-e09d8730-610a-48a9-b18e-d8fff1fba88b.png#align=left&display=inline&height=383&name=image.png&originHeight=766&originWidth=1520&size=201206&status=done&style=none&width=760" alt="image.png"></p>
<table>
<thead>
<tr>
<th>sqlbench</th>
<th>Terminal和DB conneciton解耦，可以单独配置数量。Termial处理线程支持复用，缺省配置每个线程支持50个terminal。</th>
</tr>
</thead>
<tbody><tr>
<td>tpcc-mysql</td>
<td>没有terminal，只能配置db connection数量</td>
</tr>
<tr>
<td>benchmark-sql</td>
<td>没有terminal，只能配置db connection数量</td>
</tr>
<tr>
<td>HammerDB</td>
<td>没有terminal，只能配置db connection数量</td>
</tr>
<tr>
<td>DBT2</td>
<td>Terminal和DB conneciton解耦，可以单独配置数量</td>
</tr>
</tbody></table>
<h2 id="TPC-C标准中Home-Warehouse支持"><a href="#TPC-C标准中Home-Warehouse支持" class="headerlink" title="TPC-C标准中Home Warehouse支持"></a>TPC-C标准中Home Warehouse支持</h2><p>标准要求每一个terminal在整个测试运行周期内保持warehouse ID不变，即home warehouse不变。</p>
<table>
<thead>
<tr>
<th>sqlbench</th>
<th>支持terminal home warehouse</th>
</tr>
</thead>
<tbody><tr>
<td>tpcc-mysql</td>
<td>不支持，warehouse每个交易随机生成</td>
</tr>
<tr>
<td>benchmark-sql</td>
<td>不支持，warehouse每个交易随机生成</td>
</tr>
<tr>
<td>HammerDB</td>
<td>支持terminal home warehouse</td>
</tr>
<tr>
<td>DBT2</td>
<td>支持terminal home warehouse</td>
</tr>
</tbody></table>
<h2 id="Terminal上的可视信息交互"><a href="#Terminal上的可视信息交互" class="headerlink" title="Terminal上的可视信息交互"></a>Terminal上的可视信息交互</h2><p>标准定义了用户从terminal输入数据，然后交易结果的细节数据需要返回给terminal用户用于展示，这会带来额外的时延。所有工具都没有对terminal信息交互的支持。</p>
<h1 id="sqlbench"><a href="#sqlbench" class="headerlink" title="sqlbench"></a>sqlbench</h1><h2 id="prepare"><a href="#prepare" class="headerlink" title="prepare"></a>prepare</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install -y autoconf automake mysql mysql-devel postgresql-devel</span><br></pre></td></tr></table></figure>

<h2 id="compile"><a href="#compile" class="headerlink" title="compile"></a>compile</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/swida/sqlbench.git</span><br><span class="line">cd sqlbench</span><br><span class="line">aclocal</span><br><span class="line">autoconf</span><br><span class="line">autoheader</span><br><span class="line">automake --add-missing</span><br><span class="line">./configure --with-postgresql=yes --with-mysql=yes </span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>

<h2 id="load-数据"><a href="#load-数据" class="headerlink" title="load 数据"></a>load 数据</h2><p>从 <a href="https://github.com/longdafeng/test/tree/master/shell/tpcc/sqlbench">https://github.com/longdafeng/test/tree/master/shell/tpcc/sqlbench</a> 上把load.sh 脚本下载下来</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd sqlbench</span><br><span class="line">cd src/scripts</span><br><span class="line">wget https://raw.githubusercontent.com/longdafeng/test/master/shell/tpcc/sqlbench/load.sh</span><br><span class="line">nohup ./load.sh ipxxxx portxxx userxxx passwordxxx dbnamexxx warehousexxx &gt; load.log 2&gt;&amp;1 &amp;</span><br><span class="line">tail -f load.log </span><br></pre></td></tr></table></figure>
<ol>
<li>必须使用ip， 建议不要使用域名， 因为使用域名，经常建立不了到数据库的链接</li>
<li>脚本是放到${sqlbench_source_dir}&#x2F;src&#x2F;scripts 下</li>
</ol>
<ul>
<li>ipxxxx     数据库的ip</li>
<li>portxxx    数据库的端口号</li>
<li>userxxx    数据库的用户名</li>
<li>password   数据库的密码</li>
<li>dbnamexxx  数据库的库名字</li>
<li>warehousexxx warehouse 的个数 ， 比如100</li>
</ul>
<h2 id="运行测试"><a href="#运行测试" class="headerlink" title="运行测试"></a>运行测试</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd sqlbench</span><br><span class="line"># MySQL:</span><br><span class="line">nohup ./src/core/sqlbench -t mysql --dbname=tpcc --user=user --password=password --host=127.0.0.1 --port=3306 -w100 -c32 -l7200 -r1200 --sqlapi=storeproc &gt;run.log 2&gt;&amp;1 &amp;</span><br><span class="line">tail -f run.log</span><br></pre></td></tr></table></figure>

<p>这里:</p>
<p>• -t 指定PostgreSQL数据库 –dbname和–host为数据库的连接参数，其他没指定的使用默认参数<br>• -w 指定测试数据为100个warehouse<br>• -l 共运行测试时间为7200秒<br>• -r 其中ramp up的时间为1200秒<br>• -c 共使用32个数据库连接<br>sqlbench其他的常用参数包括：<br>• –no-thinktime 默认的TPC-C测试是有keying time和thinking time的，模拟真正的用户场景，可通过指定这个参数将相应 的时间设置成0，不控制时间间隔，产生最大压力<br>• –sqlapi 选择SQL执行的方式，可选：<br>• simple 为普通SQL方式<br>• extended 使用prepare&#x2F;bind&#x2F;execute方式，该方式先生成查询计划缓存起来，后面直接执行，效率更高<br>• storeproc 使用存储过程，这种方式与比extended相比还节省了与数据库服务器通信的开销<br>• -s与-e指定开始和结束的warehouse数，在更多warehouse时，可以使用这2个选项分配warehouse，分成多个sqlbench压测同 一个数据库<br>• –altered默认情况sqlbench下根据TPC-C标准生成terminal数（每个terminal代表一个user，每个warehouse 10个terminal， 也可以使用–tpw改变），这个参数直接指定了terminal个数，被这些warehouse平均分。<br>• –sleep指定每创建一个线程后sleep的时间，默认为1s<br>• -o 用来指定output目录，用来存储错误日志及测试结果文件<br>sqlbench的其他参数是用来定制TPC-C标准的各个部分的，包括keying time、thinking time的时间，各个事务所占比率，各个 表的数据量等，默认值都是遵从TPC-C标准的。</p>
<p>比如常用</p>
<ol>
<li><p>没有think time控制</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./src/core/sqlbench -t mysql --dbname=tpcc --user=user --password=password --host=$HOST --port=$PORT -w$WH -c$CONN -l7200 -r1200 --sqlapi=storeproc --no-thinktime --sleep=10</span><br></pre></td></tr></table></figure>
</li>
<li><p>有think time控制</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./src/core/sqlbench -t mysql --dbname=tpcc --user=user --password=password --host=$HOST --port=$PORT -w$WH -c$CONN -l7200 -r1200 --sqlapi=storeproc --sleep=10</span><br><span class="line"></span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="生成测试报告"><a href="#生成测试报告" class="headerlink" title="生成测试报告"></a>生成测试报告</h2><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">src/utils/post_process -l mix.log</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title>台湾环岛自由行攻略</title>
    <url>/2016/traveltaiwan/</url>
    <content><![CDATA[<p>很早之前， 朋友就推荐过台湾， 称台湾绝对值得游玩一趟的， 于是，很早就把台湾通行证给办了。 而且， 台湾说的是国语， 英文不好的朋友，大可不必担心语言沟通问题。 另外， 台湾并没有网上说的，很歧视或排斥大陆游客， 我玩的时候，发现普遍讲话非常有礼貌，开口打扰了，闭口谢谢。另外，运气特别好的是，丈母娘她们报名的跟团游， 导游特别好， 没有强制购物，也没有强制玩景点时快速结束， 全程耐心等待游客， 而且经常扛箱子。 （可能因为第一导游是刚入行， 第二，行程是淡季，非十一或春节等）</p>
<h1 id="总攻略"><a href="#总攻略" class="headerlink" title="总攻略"></a>总攻略</h1><p>去台湾玩，选择哪些地点，怎么玩。 这里说一些我个人的小技巧， </p>
<ul>
<li>第一种办法，上途牛／携程／去哪儿， 挑一个时间和自己差不多跟团游， 看他玩了哪些地方， 然后，记下来。</li>
<li>另外一个好办法，强烈推荐手机安装“梦想旅行”， 每到一个城市，它会告诉这个城市有哪些非常不错的景点， 你挑选几个，然后，他会给你安排一下行程。</li>
</ul>
<p><B>台北有几个地方，值得推荐一下</B></p>
<ul>
<li>垦丁， 漂亮的地方特别多， 也有很多小孩玩的地方，比如 海洋生物馆， 尤其是夜宿海底隧道， 至少要提前半年预定， 绝对赞。</li>
<li>花莲， 和垦丁类似</li>
<li>日月潭， 类似千岛湖</li>
<li>清境农场</li>
<li>中台禅寺， 信佛的人，一定要去</li>
<li>台北， 台北故宫博物馆，101， 夜市， 中正纪念堂。</li>
</ul>
<p>台北如果玩的时间非常长的话，超过2周， 可以推荐环岛游， 如果不足2周，建议半岛游， 如果半岛游的话， 就没有必要到在一个地方往返。<br>最早安排的行程是 台北（1天）–&gt; 清境（1天） –&gt; 日月潭（1天） –&gt; 高雄（1天） –&gt; 垦丁（3天） –&gt; 台北（2天）， 但最后觉得需要在台北买不少东西， 台北需要放到最后， 最后行程安排是 台北（1天） –&gt; 垦丁（3天） –&gt; 高雄（1天） –&gt; 日月潭（1天） –&gt; 清境（1天） –&gt; 台北（2天）。 这个时候才发现机票没有订好， 没有必要在订 杭州到 台北的往返， 完全可以 去程杭州 –&gt; 高雄，返程台北–&gt; 杭州， 这样就可以节省半天 从台北到高雄的时间，也节省了一张高铁票。</p>
<span id="more"></span>

<h1 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h1><h2 id="签证："><a href="#签证：" class="headerlink" title="签证："></a>签证：</h2><p>去台湾的签证，相比美国和泰国之类，要麻烦非常多。分为</p>
<ol>
<li>台湾通行证</li>
<li>台湾签注</li>
<li>入台证</li>
</ol>
<p>办理台湾通行证， 需要差不多要2周的时间， 签注基本当天就可以完成， 另外在上海和杭州的朋友，可以在周末办理。<br>不过，办完通行证后， 一定要记得查看签注类型， 是自由行的签注，还是跟团的签注。<br>在直辖市或省会旅游，发的都是自由行的签注， 但在二线城市，很多就是跟团签注， 如果是自由行的签注，可以跟团游也可以自由行，但跟团的签注，就只能跟团，不能自由行。(自由签证是“大陆居民前往台湾签证(G)”, 跟团签证是”大陆居民前往台湾签证（L）”)<br>楼主就是开始不知道签注类型，以为都是自由行的， 结果在办理入台证的时候，才傻眼了， 发现有3份签注是跟团的， 而这个时候，开始退机票，退租车， 退房。<br><img data-src="https://gsnapshot.alicdn.com/imgextra/imgextra/i1/224591973/TB2FA0XuXXXXXXsXpXXXXXXXXXX_!!224591973.jpg?time=1474032664000" alt="img"></p>
<p>办理入台证， 建议提前2个月先上淘宝，查看办理入台证需要的哪些条件， 一般会卡在资产证明和紧急联系人证明上面， 资产证明，一般需要一张存款表或收入证明或信用卡金卡证明， 如果通过存储证明的话， 那至少要提前1个月办理定期存款，存款3个月。 如果紧急联系人不是在一个户口本上， 则需要到公安局开具联系人关系证明。<br>最后在办理入台证， 最好提前3周左右开始办理， 这样可以在淘宝上选择最便宜的办理方式。</p>
<h2 id="住"><a href="#住" class="headerlink" title="住"></a>住</h2><p>基本都是在booking上定的， 现在来看的话， 在booking上定会略微有点贵， 建议可以多比较几家订票网站， 比如阿里去啊，携程，自在客，大鱼，airbnb。 在台湾住了快10天， 感觉台湾的酒店都非常不错，酒店之间的差距不像大陆酒店之间的差距那么大， 无论大酒店还是小民宿都很干净，服务人员服务态度也特别好，完全没有歧视网上所说的歧视大陆。所以建议大家选择酒店， 关注2点即可， 价格和地段， 如果是自驾游的话，再关注是否有停车位。</p>
<p>使用booking， 好的地方：</p>
<ol>
<li>酒店非常全， 基本上涵盖面最大</li>
<li>评价非常好， 挑好酒店后， 看看评价里面有没有硬伤</li>
</ol>
<p>使用booking，小心的地方：</p>
<ol>
<li>很多酒店，不接受退订， 因此一定要小心是否退订， 我记得订日月潭的酒店的时候， 订完第二天， 就进行了预付款扣除， 在入住的前15天退订，还是扣除费用， 最后被逼无奈，只能再住一天，把能取消的酒店给取消掉。 但很多酒店可以接受因为台风而退订， 所以，当碰上台风时， 可以打电话给酒店进行改签。</li>
<li>很多酒店在展示房间的时候， 是显示无税的价格， 但当真正入住的时候，往往要15％的税， 所以，记得检查booking 发来确认预订酒店的邮件， 确认预订的真正价格。</li>
</ol>
<h2 id="通信和上网"><a href="#通信和上网" class="headerlink" title="通信和上网"></a>通信和上网</h2><ol>
<li>建议在网上买一张能上网的电话卡和无线wifi，<br>为什么建议买一张电话卡，主要是方便打uber，租车，注册打的软件或者紧急通话， 淘宝上 100元的带10天不限流量和50元台币的电话卡都不错， 另外吐槽一下， 台湾的预付电话卡费用太贵了，6元一分钟， 而直接使用国内电话拨打也就1元1分钟， 所以，可以建议，就用台湾的电话卡接收电话，因为台湾的4g 信号很不错， 好几个工作电话，后面都让对方改用钉钉网络电话， 效果还挺好。</li>
<li>无线wifi里面的上网卡和电话卡，最好不是一家的， 因为，到一个地方，可能电话卡信号很好，但上网卡信号不好， 反之亦然。</li>
<li>台北机场有免费的wifi， 也可以直接在台北机场购买卡， 稍微看了一下，价格比淘宝价格贵一点点。</li>
</ol>
<h2 id="行"><a href="#行" class="headerlink" title="行"></a>行</h2><p>机票： 越早订越便宜， 现在机票基本上各大网站价格在一个水平线上，不会出现大幅优惠， 阿里去啊有时会搞一些促销，但这些促销产品往往日期都是上班时间，并不适合出行旅游。</p>
<p>台北高铁： 台北高铁也是越早订越便宜， 如果提前一个月订，可以订到7折的高铁票， 不过，如果订了高铁票，提前退票的话，会扣5%的手续费</p>
<p>台北铁路： 很多人推荐走台北铁路， 可以一路观光， 不过台北铁路需要台湾身份证才能预订， 不过，可以通过淘宝搞定（淘宝还真是万能的淘宝）</p>
<h3 id="自驾游"><a href="#自驾游" class="headerlink" title="自驾游"></a>自驾游</h3><p>最后一个行上， 个人强烈推荐 环岛自驾游， 如果经济压力比较大，可以选择在垦丁几天驾车，其他地方使用公共交通或租用机车（摩托车）。 自驾游， 人会轻松很多， 尤其在等车或晚上的时候，可以心不慌，另外如果自己开车，逛的地方会远远超过租用机车（摩托车）的范围。</p>
<p>如果选择公共交通的话， 需要做更多的攻略， 酒店住的地方需要在交通比较方便的地方， 在什么地方搭乘长途汽车或火车得提前弄清楚，不过长途汽车或火车其实还比较方便， 不过非常容易查到怎么行走，推荐一个网站 <a href="http://guide.youtx.com/%EF%BC%8C">http://guide.youtx.com/，</a> 输入当前地和目的地， 他会告诉你具体怎么到， 做什么车。</p>
<h4 id="租车"><a href="#租车" class="headerlink" title="租车"></a>租车</h4><ul>
<li>首先上淘宝办理 香港本地驾照， 因为台湾是国际idp 成员，但中国不是，台湾是不认中国驾照，而香港是国际idp成员，但香港idp 驾照需要香港本地身份证才能办理， 不过，随着香港人在台湾租车越来越多，台湾大部分组成公司都承认香港的本地驾照。 推荐<a href="https://shop108152449.taobao.com/?spm=2013.1.1000126.d21.o0lno6%EF%BC%8C">https://shop108152449.taobao.com/?spm=2013.1.1000126.d21.o0lno6，</a> 老板服务态度确实好（免费给他打个广告）。注意办理香港本地驾照需要2周时间，玩家最好预留好足够的时间。</li>
<li>台湾租车公司有很多租车软件，有avis／rentcars／大鱼， 进行比价一下，选择便宜的一款即可</li>
</ul>
<h4 id="租车小经验："><a href="#租车小经验：" class="headerlink" title="租车小经验："></a>租车小经验：</h4><ol>
<li>在rentcars 下单时， 会提示，要不要购买全包的保险，每天100元， 其实可以不用购买， 因为租车公司会购买一些保险</li>
<li>一些租车公司，可以提供免费的儿童安全座椅和导航装置， 比如这次选择的中租租车</li>
<li>特别小心， 租车上不允许吃东西或带宠物，否则需要罚款3000台币。之前，小孩在车上吃饼干，有一点饼干屑，租车公司要求交清洁费3000台币， 我argue， 车子出现故障耽误我们半天行程， 最后，取消的清洁费。 </li>
<li>记得自己准备车载usb 充电器，台湾租车是不提供usb 充电器（美国租车是提供车载usb 充电器）， 强烈推荐，自己准备车载收音机， 因为，台湾电台广告超多， 听的不爽</li>
<li>当车子出现问题时， 可以要求租车公司更换， 不过一般情况下， 如果车子没有发生问题，更换车子会收取一定的费用。</li>
<li>台湾租车公司服务态度普遍比较好， 记得在最后还车时， 需要收取500的高速过路费， 不过，因为车子剩余的油比较多，大概700元，直接冲抵掉了高速费用。 这里投诉一下美国的thrift公司，当时网上下单时，是满借满还， 结果到了租车的时候，变成空借空还， 骗我白送一箱油给他们。</li>
</ol>
<h4 id="导航软件"><a href="#导航软件" class="headerlink" title="导航软件"></a>导航软件</h4><p>试过高德， 百度，google， 最后发现 高德，百度无法使用， 只能选择google， google导航和高德导航相比，差的太远， 经常误报，走着走着，突然改变线路，让你调转方向，简直是让人吐血。  </p>
<h4 id="打的"><a href="#打的" class="headerlink" title="打的"></a>打的</h4><ol>
<li>台湾打的的费用非常贵， 起步70 台币， 然后随便走一下就200 台币了， 差不多uber 的1.4倍的价格</li>
<li>uber 台湾还可以用， 就是在定位的时候， 经常定不准，需要手动把自己的位置在google地图上调整好。</li>
<li>下了台北机场的时候， 找机场大巴的时候， 在机场大巴售票处碰到几位穿衬衫的大哥，咨询怎么坐车到酒店， 当时告诉我们，现在一个大巴到什么地方， 然后再打的到酒店， 然后说，你差不多需要500台币， 不如到前面做的士，800台币可以做到。后来，查询google，发现有直达的长途大巴， 再看这几个人，根本就是拉黑的的人，穿的像工作人员， 专拉大陆游客， 不过，真打的的话，确实也要800多台币。</li>
</ol>
<h2 id="购物："><a href="#购物：" class="headerlink" title="购物："></a>购物：</h2><p>这次很遗憾，没有怎么在台北购物，所以不能给玩家一些很好的建议。就在台北101 地下 买了一些化妆品，<br>因为大概是10.2号在台北，正好赶上101 周年纪念，很多化妆品（不过都是台湾的本土品牌）打折，确实比国内便宜很多<br>台北101 下面有苹果专卖店， 计算下来，ipad mini， 国内3688， 那边大概3500， 再加上退税，可以便宜大概300块。不过，iphone 小心 电信4g 不能用，得提前网上调查清楚。</p>
<p>台北是可以退税的， 只要满2000 台币，就可以让开退税单，然后到机场退税， 退税税率大概是4%。</p>
<h2 id="吃："><a href="#吃：" class="headerlink" title="吃："></a>吃：</h2><p>台湾的吃还是非常不错，值得赞的，估摸着是中华民族就是一个好吃的民族。</p>
<ol>
<li>夜市里有很多小吃， 可以值得去尝试一下， 不过夜市里面很多小吃偏甜，不喜欢甜的玩家，估计会有点遗憾。</li>
<li>台北101 下面有个鼎泰丰， 值得推荐一下</li>
<li>去吃了一次 台北， 信义坊， 还不错</li>
<li>在垦丁大街上， 一路小吃，想找个像样的餐馆，还真难找</li>
<li>在垦丁可以吃海鲜， 不过，海鲜的价格也不是非常便宜。</li>
<li>在日月潭 松鹤楼吃的很团餐， 尤其推荐菜总统鱼非常一般，还不如对面的另外一家 做的鱼</li>
</ol>
<h2 id="意外"><a href="#意外" class="headerlink" title="意外"></a>意外</h2><ol>
<li>在台湾，太容易出现台风了， 所以当碰上台风时， 估计会有一天甚至几天闷在酒店， 这个时候，只能在出行前，检查是否有台风，尽量争取绕过台风， 因为机票很多时候，提前一个月就订好了， 所以，时间基本不能修改， 不过，可以修改行程，尽量避免遇到台风中心。</li>
<li>如果出现受伤或意外， 其实，是购买了保险，可以报销的， 就是需要出诊单和正式发票</li>
</ol>
]]></content>
      <categories>
        <category>travel</category>
      </categories>
      <tags>
        <tag>travel</tag>
      </tags>
  </entry>
  <entry>
    <title>zookeeper 扩容</title>
    <url>/2016/zookeeper-enlarge/</url>
    <content><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>因为阿里经常进行机房断网演练， 如果一套zk 只能部署在一个机房时， 当发生断网时， 这套zk是无法为其他机房提供zk 服务， 因此需要将单机房zk 升级到多机房zk， 但因为zookeeper是强同步方式， 所有的请求会在内部进行同步， 如果机器之间延迟比较大时， zookeeper 问题会非常多， 因此，这套解决方案前提条件是同城多机房, 并且时延比较小。</p>
<p>这套解决方案也适合， zookeeper 升级扩容和zookeeper 机器替换</p>
<p>在多机房方案中， 常常是3机房， 这个时候，推荐221 的分布模式， 客户端多的机房多部署一台zookeeper</p>
<span id="more"></span>

<h1 id="解决的问题"><a href="#解决的问题" class="headerlink" title="解决的问题"></a>解决的问题</h1><p>目前zk 是3台机器， 现在需要再新增3台机器， 并把老的3台机器中一台给下线掉。</p>
<h1 id="步骤"><a href="#步骤" class="headerlink" title="步骤"></a>步骤</h1><ul>
<li>扩容新zookeeper</li>
<li>下线无用的zookeeper</li>
<li>更新所有zookeeper</li>
</ul>
<p>zk的变更其实需要非常小心， 如果发生错误，会导致整个zk停止服务， 会导致大片程序出错。<br>所以， 思路是，逐步增加机器， 尽量减少leader的变更</p>
<h2 id="扩容新zookeeper"><a href="#扩容新zookeeper" class="headerlink" title="扩容新zookeeper"></a>扩容新zookeeper</h2><p>扩容时， 新增一台机器的配置，仅仅比运行zk的配置多一台机器， 从而保证zk集群的leader不会发生任何变更</p>
<p>老的zookeeper 配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># The number of milliseconds of each tick</span><br><span class="line">tickTime=2000</span><br><span class="line"># The number of ticks that the initial</span><br><span class="line"># synchronization phase can take</span><br><span class="line">initLimit=10</span><br><span class="line"># The number of ticks that can pass between</span><br><span class="line"># sending a request and getting an acknowledgement</span><br><span class="line">syncLimit=5</span><br><span class="line"># the directory where the snapshot is stored.</span><br><span class="line">maxClientCnxns=300</span><br><span class="line">dataDir=/dev/shm/zk/data</span><br><span class="line">dataLogDir=/dev/shm/zk/logs</span><br><span class="line"></span><br><span class="line"># the port at which the clients will connect</span><br><span class="line">clientPort=2181</span><br><span class="line"># The number of snapshots to retain in dataDir</span><br><span class="line">autopurge.snapRetainCount=5</span><br><span class="line"># Purge task interval in hours</span><br><span class="line"># Set to &quot;0&quot; to disable auto purge feature</span><br><span class="line">autopurge.purgeInterval=1</span><br><span class="line"></span><br><span class="line">#minSessionTimeout=10000</span><br><span class="line">minSessionTimeout=100</span><br><span class="line">maxSessionTimeout=100000</span><br><span class="line"></span><br><span class="line">server.1=zkA.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.2=zkB.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.3=zkC.jstorm.alibaba.com:2888:3888</span><br></pre></td></tr></table></figure>

<h3 id="扩容D"><a href="#扩容D" class="headerlink" title="扩容D"></a>扩容D</h3><p>新增D 的配置</p>
<p>扩容后新的配置是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 其他配置 同老的配置 ##</span><br><span class="line">server.1=zkA.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.2=zkB.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.3=zkC.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.4=zkD.jstorm.alibaba.com:2888:3888</span><br></pre></td></tr></table></figure>

<p>有几点需要注意：</p>
<ul>
<li>&#x2F;dev&#x2F;shm&#x2F;zk&#x2F;data 目录下，记得创建id</li>
<li>本例中， zookeeper 的目录是放到共享内存中， 因此需要一个cronjob 每分钟 把新的增量数据文件同步到本地硬盘中，并把本地硬盘中的过时文件删除</li>
<li>下线机器的id 会被保留，不会覆盖， 避免出现数据紊乱</li>
<li>增加D 后，需要确保A&#x2F;B&#x2F;C&#x2F;D zk提供服务，并且集群只有一个leader， 如果没有，则需要重做；有很多的方法， 下面提供一种方法<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> ~  echo srvr | nc zkD.jstorm.alibaba.com 2181</span><br><span class="line">Zookeeper version: 3.4.5-1392090, built on 09/30/2012 17:52 GMT</span><br><span class="line">Latency min/avg/max: 0/0/13432</span><br><span class="line">Received: ***</span><br><span class="line">Sent: ***</span><br><span class="line">Connections: ***</span><br><span class="line">Outstanding: 0</span><br><span class="line">Zxid: 0x***</span><br><span class="line">Mode: follower</span><br><span class="line">Node count: ***</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="扩容E"><a href="#扩容E" class="headerlink" title="扩容E"></a>扩容E</h3><p>新增E 的配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 其他配置 同老的配置 ##</span><br><span class="line">server.1=zkA.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.2=zkB.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.3=zkC.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.4=zkD.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.5=zkE.jstorm.alibaba.com:2888:3888</span><br></pre></td></tr></table></figure>

<p>有几点需要注意：</p>
<ul>
<li>&#x2F;dev&#x2F;shm&#x2F;zk&#x2F;data 目录下，记得创建id</li>
<li>本例中， zookeeper 的目录是放到共享内存中， 因此需要一个cronjob 每分钟 把新的增量数据文件同步到本地硬盘中，并把本地硬盘中的过时文件删除</li>
<li>下线机器的id 会被保留，不会覆盖， 避免出现数据紊乱</li>
<li>增加E 后，需要确保A&#x2F;B&#x2F;C&#x2F;D&#x2F;E zk提供服务，集群只有一个leader</li>
</ul>
<h3 id="扩容F"><a href="#扩容F" class="headerlink" title="扩容F"></a>扩容F</h3><p>新增F 的配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 其他配置 同老的配置 ##</span><br><span class="line">server.1=zkA.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.2=zkB.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.3=zkC.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.4=zkD.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.5=zkE.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.6=zkF.jstorm.alibaba.com:2888:3888</span><br></pre></td></tr></table></figure>

<p>有几点需要注意：</p>
<ul>
<li>&#x2F;dev&#x2F;shm&#x2F;zk&#x2F;data 目录下，记得创建id</li>
<li>本例中， zookeeper 的目录是放到共享内存中， 因此需要一个cronjob 每分钟 把新的增量数据文件同步到本地硬盘中，并把本地硬盘中的过时文件删除</li>
<li>下线机器的id 会被保留，不会覆盖， 避免出现数据紊乱</li>
<li>增加E 后，需要确保每台zk提供服务</li>
</ul>
<h3 id="更新D-配置"><a href="#更新D-配置" class="headerlink" title="更新D 配置"></a>更新D 配置</h3><p>更新d 的配置后， 重启D 的zookeeper， 并检查所有zk 节点是否正常</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 其他配置 同老的配置 ##</span><br><span class="line">server.1=zkA.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.2=zkB.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.3=zkC.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.4=zkD.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.5=zkE.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.6=zkF.jstorm.alibaba.com:2888:3888</span><br></pre></td></tr></table></figure>



<h3 id="更新E-配置"><a href="#更新E-配置" class="headerlink" title="更新E 配置"></a>更新E 配置</h3><p>更新e 的配置后， 重启e 的zookeeper， 并检查所有zk 节点是否正常</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 其他配置 同老的配置 ##</span><br><span class="line">server.1=zkA.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.2=zkB.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.3=zkC.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.4=zkD.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.5=zkE.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.6=zkF.jstorm.alibaba.com:2888:3888</span><br></pre></td></tr></table></figure>


<h2 id="更新老zookeeper的配置"><a href="#更新老zookeeper的配置" class="headerlink" title="更新老zookeeper的配置"></a>更新老zookeeper的配置</h2><p>步骤：</p>
<ul>
<li>检查老zk， 谁是leader， 谁是follower</li>
<li>更新zookeeper 配置</li>
<li>重新启动zookeeper</li>
<li>检查重启的zookeeper是否能提供服务</li>
</ul>
<p>注意几点：</p>
<ul>
<li>还是必须一台一台的操作， 一台完成后，才能进行下一台</li>
<li>配置文件 含有6台机器， 而不是5台机器</li>
<li>变更过程中， 所有zk 的角色不发生任何变更。</li>
</ul>
<p>在本例中， 假设leader是c, 则我们先变更a, 成功后，再变更b</p>
<p>这次的配置文件是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 其他配置 同老的配置 ##</span><br><span class="line">server.1=zkA.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.2=zkB.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.3=zkC.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.4=zkD.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.5=zkE.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.6=zkF.jstorm.alibaba.com:2888:3888</span><br></pre></td></tr></table></figure>

<h2 id="下掉老zk的leader"><a href="#下掉老zk的leader" class="headerlink" title="下掉老zk的leader"></a>下掉老zk的leader</h2><ul>
<li>杀死老zk的leader</li>
<li>检查所有zk是否提供服务， 确保所有zk能够提供服务</li>
</ul>
<h2 id="更新所有机器的配置"><a href="#更新所有机器的配置" class="headerlink" title="更新所有机器的配置"></a>更新所有机器的配置</h2><p>这次的配置文件是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 其他配置 同老的配置 ##</span><br><span class="line">server.1=zkA.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.2=zkB.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.4=zkD.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.5=zkE.jstorm.alibaba.com:2888:3888</span><br><span class="line">server.6=zkF.jstorm.alibaba.com:2888:3888</span><br></pre></td></tr></table></figure>

<p>新的配置文件， 会剔除掉一台zk机器， 就是老的zk  leader</p>
<p>注意几点：</p>
<ul>
<li>还是必须一台一台的操作， 一台完成后，才能进行下一台</li>
<li>配置文件 含有5台机器，新的配置文件同样需要同步到下线的c机器上，以防止c后面被误启动</li>
<li>变更过程中， leader所在的机器必须是最后变更， 这样可以减少一次leader选举</li>
</ul>
]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
</search>
